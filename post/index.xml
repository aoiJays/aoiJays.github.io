<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on BiribiriBird</title>
        <link>https://example.com/post/</link>
        <description>Recent content in Posts on BiribiriBird</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>Example Person</copyright>
        <lastBuildDate>Fri, 16 Jan 2026 21:55:42 +0800</lastBuildDate><atom:link href="https://example.com/post/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>如何在VSC中的RemoteSSH使用需要科学的插件</title>
        <link>https://example.com/p/%E5%A6%82%E4%BD%95%E5%9C%A8vsc%E4%B8%AD%E7%9A%84remotessh%E4%BD%BF%E7%94%A8%E9%9C%80%E8%A6%81%E7%A7%91%E5%AD%A6%E7%9A%84%E6%8F%92%E4%BB%B6/</link>
        <pubDate>Fri, 16 Jan 2026 21:55:42 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A6%82%E4%BD%95%E5%9C%A8vsc%E4%B8%AD%E7%9A%84remotessh%E4%BD%BF%E7%94%A8%E9%9C%80%E8%A6%81%E7%A7%91%E5%AD%A6%E7%9A%84%E6%8F%92%E4%BB%B6/</guid>
        <description>&lt;h2 id=&#34;教程&#34;&gt;教程
&lt;/h2&gt;&lt;p&gt;原理&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;远程 VS Code
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   ↓（HTTP &lt;span class=&#34;nv&#34;&gt;Proxy&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; 127.0.0.1:PORT）
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;远程 SSH 的 127.0.0.1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   ↓（RemoteForward）
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;你本地的 127.0.0.1:PORT
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   ↓
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;你本地的代理（Clash / v2ray / shadowsocks）
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   ↓
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;OpenAI/...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;假设使用Clash，默认端口在7890&lt;/p&gt;
&lt;h3 id=&#34;ssh-config&#34;&gt;SSH Config
&lt;/h3&gt;&lt;p&gt;首先是VSC的ssh配置文件&lt;/p&gt;
&lt;p&gt;原本是：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Host xx.xx.xx.xx
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  HostName xx.xx.xx.xx
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  User niu
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;增加一行&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Host xx.xx.xx.xx
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  HostName xx.xx.xx.xx
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  User niu
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  RemoteForward 7890 127.0.0.1:7890
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;vsc设置&#34;&gt;VSC设置
&lt;/h3&gt;&lt;p&gt;打开 VS Code 设置&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Ctrl + ,&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;或 &lt;code&gt;Ctrl + Shift + P&lt;/code&gt; → &lt;code&gt;Preferences: Open Settings (UI)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;搜索 &lt;code&gt;proxy&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;找到设置：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Http: Proxy
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;填：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;http://127.0.0.1:7890
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A6%82%E4%BD%95%E5%9C%A8vsc%E4%B8%AD%E7%9A%84remotessh%E4%BD%BF%E7%94%A8%E9%9C%80%E8%A6%81%E7%A7%91%E5%AD%A6%E7%9A%84%E6%8F%92%E4%BB%B6/assets/image-20260116215806738.png&#34;
	width=&#34;761&#34;
	height=&#34;128&#34;
	srcset=&#34;https://example.com/p/%E5%A6%82%E4%BD%95%E5%9C%A8vsc%E4%B8%AD%E7%9A%84remotessh%E4%BD%BF%E7%94%A8%E9%9C%80%E8%A6%81%E7%A7%91%E5%AD%A6%E7%9A%84%E6%8F%92%E4%BB%B6/assets/image-20260116215806738_hu_fb4016bb4ac9d4db.png 480w, https://example.com/p/%E5%A6%82%E4%BD%95%E5%9C%A8vsc%E4%B8%AD%E7%9A%84remotessh%E4%BD%BF%E7%94%A8%E9%9C%80%E8%A6%81%E7%A7%91%E5%AD%A6%E7%9A%84%E6%8F%92%E4%BB%B6/assets/image-20260116215806738_hu_99701ff36ce8145f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;594&#34;
		data-flex-basis=&#34;1426px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;reload&#34;&gt;reload
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Ctrl&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Shift&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;P&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;→&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Developer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Reload&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Window&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;此时codex应该就能正常连接登录了&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Personalization Survey</title>
        <link>https://example.com/p/personalization-survey/</link>
        <pubDate>Sat, 13 Dec 2025 21:20:00 +0800</pubDate>
        
        <guid>https://example.com/p/personalization-survey/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;rap-retrieval-augmented-personalization-for-multimodal-large--language-models&#34;&gt;RAP Retrieval-Augmented Personalization for Multimodal Large  Language Models
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2410.13360&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RAP Retrieval-Augmented Personalization for Multimodal Large  Language Models&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;intro&#34;&gt;Intro
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;对每个concept进行微调是昂贵的&lt;/li&gt;
&lt;li&gt;MyVLM和Yo&amp;rsquo;LLaVA都需要进行额外的训练去添加新的concept从而实现个性化&lt;/li&gt;
&lt;li&gt;都需要一些样本的正例与负例进行学习&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/personalization-survey/assets/image-20251217212521296.png&#34;
	width=&#34;1485&#34;
	height=&#34;343&#34;
	srcset=&#34;https://example.com/p/personalization-survey/assets/image-20251217212521296_hu_507ae72255eda6a9.png 480w, https://example.com/p/personalization-survey/assets/image-20251217212521296_hu_eca083438ec3aa1c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;432&#34;
		data-flex-basis=&#34;1039px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RAP只需要一张图以及一些相关的信息&lt;/li&gt;
&lt;li&gt;支持用户&lt;strong&gt;实时修改&lt;/strong&gt;database，从而调整模型的个性化输出&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同时RAP构建了一个Pipeline，用于收集大量训练数据，帮助模型先学会理解如何使用用户个人concept的范式&lt;/p&gt;
&lt;p&gt;paper的贡献总结为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提出RAP-MLLM框架，支持用户在不需要训练的情况下让模型适应新的concept&lt;/li&gt;
&lt;li&gt;开发了一个训练数据收集pipeline，支持训练个性化assistant&lt;/li&gt;
&lt;li&gt;最终模型在image captioning and question answering等个性化任务中表现优异&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;method&#34;&gt;Method
&lt;/h3&gt;&lt;h4 id=&#34;rap-framework&#34;&gt;RAP Framework
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/personalization-survey/assets/image-20251218223432497.png&#34;
	width=&#34;1205&#34;
	height=&#34;562&#34;
	srcset=&#34;https://example.com/p/personalization-survey/assets/image-20251218223432497_hu_61d054f981efd32d.png 480w, https://example.com/p/personalization-survey/assets/image-20251218223432497_hu_18772be850246792.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;framework&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;214&#34;
		data-flex-basis=&#34;514px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;建立一个数据库，记录每个concept的一个头像、描述，使用视觉特征作为检索键
&lt;ul&gt;
&lt;li&gt;视觉特征通过一个现有的已经过训练的Encoder&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;检索
&lt;ul&gt;
&lt;li&gt;对于用户的图片输入
&lt;ul&gt;
&lt;li&gt;基于YOLO系列做detector，根据设定好的参数识别出ROI区域&lt;/li&gt;
&lt;li&gt;将ROI区域送入Encoder，得到视觉特征，进行检索&lt;/li&gt;
&lt;li&gt;计算欧拉距离最近的top-k组concept&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;对于用户文本输入
&lt;ul&gt;
&lt;li&gt;通过文本中的name，检索是否存在于database中，进行提取&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;生成：将多组（图片，描述）以及用户输入图片及描述送入MLM进行回答&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;personalization-dataset&#34;&gt;Personalization Dataset
&lt;/h4&gt;&lt;p&gt;如果只是这样，当时的模型也不一定总能生成准确的回复&lt;/p&gt;
&lt;p&gt;因此希望构建一个数据集，用于提升模型的生成能力&lt;/p&gt;
&lt;h5 id=&#34;视觉定位visual--grounding&#34;&gt;视觉定位Visual  grounding
&lt;/h5&gt;&lt;p&gt;基于RefCOCO（单物体目标检测数据集）、ILSVRC2015-VID（ 视频目标检测数据集）、TAO 以及 CustomConcept101、Object365 （多对象数据集）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入：裁剪出物体对应的标注图像，使用Gemini1.5生成描述&lt;/li&gt;
&lt;li&gt;训练输出：对应物体的边界框&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;指令遵循instruction-following&#34;&gt;指令遵循Instruction Following
&lt;/h5&gt;&lt;p&gt;该部分包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图像标题生成 (Image Captioning)：将目标概念的裁剪图、名称及描述注入模型输入，要求模型生成能反映这些特定概念的标题&lt;/li&gt;
&lt;li&gt;问答 (Question Answering) ：利用种子问题迭代生成多样化的对话，涵盖视觉相关问题和纯文本查询&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;trick&#34;&gt;trick
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;为了让模型对检索器返回的噪声更加鲁棒，在训练输入中加入噪声概念，但是要求模型的输出仍然不变，学会过滤信息&lt;/li&gt;
&lt;li&gt;对裁剪出的图片进行旋转、翻转、3D合成新视角……&lt;/li&gt;
&lt;li&gt;加入LLaVA模型原有的数据集LLaVA-Instruct-665k，防止灾难性遗忘&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;training-free-personalization-via-retrieval-and-reasoning&#34;&gt;Training-Free Personalization via Retrieval and Reasoning
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/html/2503.18623v1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Training-Free Personalization via Retrieval and Reasoning on Fingerprints&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;intro-1&#34;&gt;Intro
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;现有方法都需要进行训练&lt;/li&gt;
&lt;li&gt;但是VLMs实际上接触的语义概念是足够多的，内部知识丰富&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Paper同样构建了一个带有参考图像、描述的数据库&lt;/p&gt;
&lt;p&gt;使用VLM通过&lt;strong&gt;distinctive attributes&lt;/strong&gt;对描述进行enrich&lt;/p&gt;
&lt;h3 id=&#34;method-1&#34;&gt;Method
&lt;/h3&gt;&lt;h4 id=&#34;database&#34;&gt;Database
&lt;/h4&gt;&lt;p&gt;首先构建database&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;输入：&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;参考图像 ($I_i$)&lt;/strong&gt;：用户提供的包含特定个性化概念图片&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;概念名称 ($c_i$)&lt;/strong&gt;：用户为该概念起的名称&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;类别 ($g_i$)&lt;/strong&gt;：该概念所属的语义类别（如“毛绒玩具”或“猫”）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;中间处理：&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;利用 VLM 提取&lt;strong&gt;指纹属性 ($A_i$)&lt;/strong&gt;（即能将该物体与其同类区分开的关键特征，如“粉色领结”、“Nashville 吉他标志”）和&lt;strong&gt;判别性描述 ($d_i$)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;利用&lt;strong&gt;视觉编码器&lt;/strong&gt;和&lt;strong&gt;文本编码器&lt;/strong&gt;生成图像特征 ($f_i^V$) 和文本特征 ($f_i^T$)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;输出（存入数据库 $\mathcal{D}$）：&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;包含 ${I_i, c_i, g_i, d_i, A_i, f_i^V, f_i^T}$ 的完整条目&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;文本特征由$d_i$作为输入生成&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plain&#34; data-lang=&#34;plain&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Describe the &amp;lt; g_i &amp;gt; in the image identified by the
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;concept-identifier &amp;lt; c_i &amp;gt; and highlight what makes it
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;unique.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Your response MUST be in valid JSON format and must
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;follow EXACTLY the format below:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;general: a brief description of the object in one sentence.,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;category: category of the object,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;distinct features: [List of distinct features that makes the
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;object unique],
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;IMPORTANT:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;* List only the most distinguishing features that set this
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  object apart.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;* Avoid generic descriptions that apply to every object in
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  this category.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;* Do not include any extra text or commentary. Any devi-
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  ation from this format will be considered incorrect.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;假设传入一张毛绒玩具的图像，及其名字和物体类别，该阶段返回内容为：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;general&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;A brown and white Shiba-inu dog plush toy in a sleeping posture.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;category&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Stuffed animal&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;distinct features&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;Brown and white fur color&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;Closed eyes indicating a sleeping posture&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;Small pointed ears&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;Soft, plush texture&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;同时保存视觉特征和文本特征向量进入database&lt;/p&gt;
&lt;h4 id=&#34;multimodal-retrieval&#34;&gt;Multimodal Retrieval
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;输入：查询图像
&lt;ul&gt;
&lt;li&gt;将图像的视觉向量，分别与数据库中的视觉特征和文本特征进行相似度计算&lt;/li&gt;
&lt;li&gt;最终的相似度分数由两者均值得到&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;输出：top-k的候选concepts&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;结合两者，避免出现视觉误导&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;attribute-focused-cot-reasoning&#34;&gt;Attribute-focused CoT reasoning
&lt;/h4&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;You&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;are&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;helpful&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AI&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agent&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;specializing&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;image&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;analysis&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;object&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;recognition&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Your&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;task&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;analyze&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;compare&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;image&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;three&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;provided&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;descriptions&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Below&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;are&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ci1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;n&#34;&gt;Info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     &lt;span class=&#34;n&#34;&gt;general&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;generic&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;description&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;about&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ci1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     &lt;span class=&#34;n&#34;&gt;category&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;category&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ci1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     &lt;span class=&#34;n&#34;&gt;distinct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;distinct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;feature&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;distinct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;feature&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ci2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;n&#34;&gt;Info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     &lt;span class=&#34;n&#34;&gt;general&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;generic&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;description&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;about&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ci2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     &lt;span class=&#34;n&#34;&gt;category&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;category&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ci2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     &lt;span class=&#34;n&#34;&gt;distinct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;distinct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;feature&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;distinct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;feature&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ci3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;n&#34;&gt;Info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     &lt;span class=&#34;n&#34;&gt;general&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;generic&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;description&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;about&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ci3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     &lt;span class=&#34;n&#34;&gt;category&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;category&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ci3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     &lt;span class=&#34;n&#34;&gt;distinct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;distinct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;feature&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;distinct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;feature&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Your&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Task&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Compare&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;image&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;each&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;description&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;answer&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;following&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;question&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;Which&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;description&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;matches&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;subject&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;?&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;Answer&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;List&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;shared&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attributes&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;between&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;image&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;each&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;description&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;very&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;concisely&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;If&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;no&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attributes&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;match&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;certain&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;option&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;generate&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Provide&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;brief&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reasoning&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;your&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;final&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;answer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Respond&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;strictly&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;following&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;JSON&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;s2&#34;&gt;&amp;#34;A&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;[Matching attributes for option A]&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;s2&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;[Matching attributes for option B]&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;s2&#34;&gt;&amp;#34;C&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;[Matching attributes for option C]&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;s2&#34;&gt;&amp;#34;Reasoning&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;lt;Brief justification&amp;gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;s2&#34;&gt;&amp;#34;Answer&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;lt;one of A, B, C&amp;gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Any&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;deviation&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;this&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;format&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;will&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;be&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;considered&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;incorrect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Do&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;output&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;any&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;additional&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;输入：查询图像 + &lt;strong&gt;候选concepts的文本描述&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;任务：模型需要列出查询图像与每个候选概念之间&lt;strong&gt;共同拥有&lt;/strong&gt;的属性&lt;/li&gt;
&lt;li&gt;输出：预测最佳匹配概念以及共享属性列表&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这部分需要使用CoT&lt;/p&gt;
&lt;h4 id=&#34;cross-modal-attribute-verification&#34;&gt;Cross-modal Attribute Verification
&lt;/h4&gt;&lt;p&gt;这部分的主要目的是排查模型幻觉&lt;/p&gt;
&lt;p&gt;有些属性可能根本没有出现在图像中，造成了模型误判&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用文本编码器对&lt;strong&gt;每个&lt;/strong&gt;&lt;u&gt;共享的指纹属性&lt;/u&gt;进行编码&lt;/li&gt;
&lt;li&gt;依次计算与查询图像的相似度&lt;/li&gt;
&lt;li&gt;计算得到相似度均值最高的concept（代表共享属性和对应图像最匹配）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果该concept就是CoT推理得到的最优concept，那么就结束算法&lt;/p&gt;
&lt;p&gt;否则我们需要更加精确的CoT&lt;/p&gt;
&lt;h4 id=&#34;pairwise-reasoning&#34;&gt;Pairwise Reasoning
&lt;/h4&gt;&lt;p&gt;只提供了文本描述看来是不够的，我们需要结合所有信息进行昂贵的推理&lt;/p&gt;
&lt;p&gt;保证这步确实完成任务&lt;/p&gt;
&lt;p&gt;转化为多个二分类任务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入
&lt;ul&gt;
&lt;li&gt;查询图像&lt;/li&gt;
&lt;li&gt;一个候选concept的原始图像+文本描述&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;输出
&lt;ul&gt;
&lt;li&gt;VLM 输出层中 &amp;ldquo;Yes&amp;rdquo; 和 &amp;ldquo;No&amp;rdquo; Token 的置信度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;因此全过程先通过&lt;strong&gt;检索&lt;/strong&gt;缩小范围，再通过&lt;strong&gt;CoT&lt;/strong&gt;快速筛选，最后只在&lt;strong&gt;属性验证&lt;/strong&gt;失败时才调用最重的&lt;strong&gt;配对推理&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;repic-reinforced-post-training-for-personalizing-multi-modallanguagemodels&#34;&gt;RePIC: Reinforced Post-Training for Personalizing Multi ModalLanguageModels
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2506.18369&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;intro-2&#34;&gt;Intro
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;在多概念图像描述任务中，SFT模型的效果一般不行，依赖大量高质量数据&lt;/li&gt;
&lt;li&gt;同一对象的不同视觉图片可能差异较大，特别是姿势、位置、光照、背景变化&lt;/li&gt;
&lt;li&gt;整合信息时可能遗漏和不准确&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;method-2&#34;&gt;Method
&lt;/h3&gt;&lt;p&gt;通过强化学习GRPO进行训练&lt;/p&gt;
&lt;p&gt;数据集采用Subject200K以及合成数据（扩散模型生成）&lt;/p&gt;
&lt;p&gt;提供了大量同一物体在不同光照、姿态下的多样化视觉特征&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/personalization-survey/assets/image-20251221154116222.png&#34;
	width=&#34;1680&#34;
	height=&#34;425&#34;
	srcset=&#34;https://example.com/p/personalization-survey/assets/image-20251221154116222_hu_7399cdb17f748286.png 480w, https://example.com/p/personalization-survey/assets/image-20251221154116222_hu_539093feff2888ae.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;395&#34;
		data-flex-basis=&#34;948px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;oct---object-consistency-tuning&#34;&gt;OCT - Object Consistency Tuning
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;构造正负图像对
&lt;ul&gt;
&lt;li&gt;正例：图像对包含相同对象&lt;/li&gt;
&lt;li&gt;负例：图像对包含不同对象&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;模型回答：图像A是否包含图像B的同一个物体？
&lt;ul&gt;
&lt;li&gt;正例需要回答Yes&lt;/li&gt;
&lt;li&gt;负例需要回答No&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;vlt---visual-localization-tuning&#34;&gt;VLT - Visual Localization Tuning
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;模型根据指令，预测指定物体的边界框&lt;/li&gt;
&lt;li&gt;若IoU大于等于0.5，给出对应奖励&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;ict---identity-consistency-tuning&#34;&gt;ICT - Identity Consistency Tuning
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;要求模型生成一段描述，并且需要包含正确的个性化标签，如&lt;code&gt;&amp;lt;name&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;若场景中有m个，模型提到了n个，则获得&lt;code&gt;n/m&lt;/code&gt;的奖励&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;为了避免模型通过生成 &lt;code&gt;This is &amp;lt;name&amp;gt;&lt;/code&gt; 这种无意义的简短废话刷分&lt;/p&gt;
&lt;p&gt;要求模型至少输出100个token&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;preferthinker-reasoning-based-personalized-image-preference-assessment&#34;&gt;PreferThinker: Reasoning-based Personalized Image Preference Assessment
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2511.00609&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PreferThinker: Reasoning-based Personalized Image Preference Assessment&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;intro-3&#34;&gt;Intro
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;任务：仅给少量“喜欢/不喜欢”参考图，判断候选图哪个更合用户口味
&lt;ul&gt;
&lt;li&gt;个性化数据极其稀缺&lt;/li&gt;
&lt;li&gt;个人的喜好往往是多维度、复杂、难以描述的，无法用一个数值描述&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;method-3&#34;&gt;Method
&lt;/h3&gt;&lt;p&gt;个体偏好常涉及多维度视觉要素（如艺术风格、颜色、媒介、饱和度、细节等）&lt;/p&gt;
&lt;p&gt;远超“文本-图像对齐”或“美观度”等通用偏好所能刻画&lt;/p&gt;
&lt;p&gt;但是组成“&lt;strong&gt;复杂口味&lt;/strong&gt;”的基本组成要素，多多少少是能够列举出来的、通用的&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;要么喜欢“高饱和度”，要么喜欢“低饱和度”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;paper根据参考图像，构建用户画像&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;喜欢：……&lt;/li&gt;
&lt;li&gt;讨厌：……&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;按照画像进行评估与推理&lt;/p&gt;
&lt;h4 id=&#34;profile&#34;&gt;Profile
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;从Lexica中提取prompt中频率最高、且对生成结果影响最大的视觉元素（15个）&lt;/li&gt;
&lt;li&gt;找了 100 个受试者进行投票，让大家选出“最能代表个人偏好”的元素（缩小到5个）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;结果：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Art Style（艺术风格）： 比如 Anime, Realistic, Surrealism。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Color（颜色）： 比如 Pastel, Neon, Grayscale。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Art Medium（艺术媒介）： 比如 Oil Painting, Digital Art, Sketch。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Saturation（饱和度）： 比如 Vibrant, Muted。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Detail（细节度）： 比如 Intricate, Minimalist。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Profile将基于这五个维度进行描述，但问题的关键是如何用丰富的词汇描述准这五个维度&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;针对每一个维度，都收集了大量的细粒度描述词&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;对于颜色，不能只是红、蓝……&lt;/p&gt;
&lt;p&gt;应该包含“Blush Pink”（腮红粉）、“Electric Lime”（电光绿）等具体词汇&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/personalization-survey/assets/image-20251223191929206.png&#34;
	width=&#34;2361&#34;
	height=&#34;537&#34;
	srcset=&#34;https://example.com/p/personalization-survey/assets/image-20251223191929206_hu_94642b68d864d90a.png 480w, https://example.com/p/personalization-survey/assets/image-20251223191929206_hu_9ef4b02375216792.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;439&#34;
		data-flex-basis=&#34;1055px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;dataset&#34;&gt;Dataset
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;模拟8w个用户&lt;/li&gt;
&lt;li&gt;随机采样五个视觉偏好要素，为每个用户分配其&lt;strong&gt;视觉偏好画像&lt;/strong&gt;与&lt;strong&gt;非偏好画像&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;真实用户可能同时具有多种偏好：为部分用户分配了&lt;strong&gt;多个偏好画像&lt;/strong&gt;（2w）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;基于profile，结合从 Lexica/COCO 等数据集里选的初始 Prompt（19w条） ，扔给 Text-to-Image进行图像生成
&lt;ul&gt;
&lt;li&gt;生成一组 &lt;strong&gt;参考图 (Reference Images)&lt;/strong&gt;：代表用户的历史喜好&lt;/li&gt;
&lt;li&gt;生成两张 &lt;strong&gt;候选图 (Candidate Images)&lt;/strong&gt;：一张符合偏好，一张符合“厌恶偏好”&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/personalization-survey/assets/image-20251223194930780.png&#34;
	width=&#34;2199&#34;
	height=&#34;646&#34;
	srcset=&#34;https://example.com/p/personalization-survey/assets/image-20251223194930780_hu_4d5eef3832252e38.png 480w, https://example.com/p/personalization-survey/assets/image-20251223194930780_hu_1b626db433b8d0fc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;340&#34;
		data-flex-basis=&#34;816px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;使用Claude3.7做&lt;strong&gt;先预测后评价&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入（相当于直接给了答案）
&lt;ul&gt;
&lt;li&gt;参考图（喜欢的 &amp;amp; 不喜欢的）&lt;/li&gt;
&lt;li&gt;两张候选图&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;输出：（需要CoT）
&lt;ul&gt;
&lt;li&gt;预测：基于参考图，把用户的画像（Art Style: xxx, Color: xxx）写出来&lt;/li&gt;
&lt;li&gt;评估：对比两张候选图，在 5 个维度上分别进行解释和打分&lt;/li&gt;
&lt;li&gt;作答：给出A和B哪个更喜欢&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对数据进行清洗：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;偏好画像预测与真实标签明显不匹配的样本&lt;/li&gt;
&lt;li&gt;结论与推理过程矛盾的样本&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最后得到：60,000 名用户样本&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/personalization-survey/assets/image-20251223195620396.png&#34;
	width=&#34;2227&#34;
	height=&#34;478&#34;
	srcset=&#34;https://example.com/p/personalization-survey/assets/image-20251223195620396_hu_8a28a8d7a69aef5d.png 480w, https://example.com/p/personalization-survey/assets/image-20251223195620396_hu_42f38761ac763757.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;465&#34;
		data-flex-basis=&#34;1118px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;training&#34;&gt;Training……
&lt;/h4&gt;&lt;p&gt;pass&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Yo LLaVA Your Personalized Language and Vision Assistant</title>
        <link>https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/</link>
        <pubDate>Sat, 13 Dec 2025 21:20:00 +0800</pubDate>
        
        <guid>https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.alphaxiv.org/abs/2406.09400&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Yo&amp;rsquo;LLaVA: Your Personalized Language and Vision Assistant | alphaXiv&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro
&lt;/h2&gt;&lt;h3 id=&#34;personalization&#34;&gt;Personalization
&lt;/h3&gt;&lt;p&gt;用户有时候想问的不是&lt;code&gt;我该给一只狗买什么生日礼物&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;而是&lt;code&gt;我该给我的狗买什么生日礼物&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;模型能够&lt;strong&gt;识别、理解并谈论用户特定的概念或对象&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;但是模型一般来说学的都是通用的内容，并不知道用户自身的setting&lt;/p&gt;
&lt;h3 id=&#34;yollava&#34;&gt;Yo&amp;rsquo;LLaVA
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;给定少量（几张）特定对象的照片，模型学会将该对象嵌入为一组&lt;strong&gt;潜在 Token（Latent Tokens）&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;比单纯的文本提示更加到位&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;contribution&#34;&gt;Contribution
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;防止灾难性遗忘：Yo&amp;rsquo;LLaVA冻结了大部分的预训练参数，只针对一些特殊token&lt;/li&gt;
&lt;li&gt;捕捉细粒度视觉细节：引入了&lt;strong&gt;困难负样本挖掘（Hard Negative Mining）&lt;/strong&gt;，即使用视觉上相似但并非该对象的图片进行训练，迫使模型学习更具辨别力的特征&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;读入：五张个性化subject的图片&lt;/li&gt;
&lt;li&gt;构造对比学习：检索clip相似的若干图片和随机图片，进行recognition训练（带图）&lt;/li&gt;
&lt;li&gt;构造对话文本数据：使用LLaVA对图片进行描述，生成通用对话文本，进行纯文本训练&lt;/li&gt;
&lt;li&gt;输出：能够识别图片中的subject和直接描述subject的模型&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work
&lt;/h2&gt;&lt;h3 id=&#34;soft-prompt-tuning&#34;&gt;Soft Prompt Tuning
&lt;/h3&gt;&lt;p&gt;Soft Prompt Tuning 并不修改预训练模型的核心权重，而是通过在&lt;strong&gt;输入端&lt;/strong&gt;引入一组&lt;strong&gt;可学习的Tokens&lt;/strong&gt;来进行优化&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method
&lt;/h2&gt;&lt;p&gt;Yo&amp;rsquo;LLaVA的目标是只给若干张subjec的图片，能够做到&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过视觉识别subject
&lt;ul&gt;
&lt;li&gt;whether &lt;sks&gt; is in a photo or not&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;支持关于subject的VQA任务
&lt;ul&gt;
&lt;li&gt;ask about &lt;code&gt;&amp;lt;sks&amp;gt;&lt;/code&gt;’s location&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;缺乏图片输入的情况下，在纯文本环境中回答subject的视觉特征
&lt;ul&gt;
&lt;li&gt;ask questions about intrinsic attributes of &lt;code&gt;&amp;lt;sks&amp;gt;&lt;/code&gt; like its color, shape&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;personalizing-the-subject-as-a-learnable-prompt&#34;&gt;Personalizing the Subject as a Learnable Prompt
&lt;/h3&gt;&lt;p&gt;为了识别图片中是否存在特定的subject&lt;/p&gt;
&lt;p&gt;native的做法是：使用prompt详尽地描述subject的每一个细节，但要么很困难要么做不到&lt;/p&gt;
&lt;p&gt;需要引入Soft Prompt Tuning，对Prompt层进行学习&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;sks&amp;gt; is &amp;lt;token1&amp;gt;&amp;lt;token2&amp;gt;...&amp;lt;tokenk&amp;gt;. 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Can you recognize &amp;lt;sks&amp;gt; in this photo?
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;只需要增加几个新的token和对应输出权重&lt;/li&gt;
&lt;li&gt;不需要修改MLMs的预训练权重&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，对于参数的变化总结为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输出层增加的参数：最后输出的分类头参数矩阵由$C\times N$扩展到$C\times (N+1)$
&lt;ul&gt;
&lt;li&gt;$C$表示上一个hidden feature的维度&lt;/li&gt;
&lt;li&gt;$N$表示词表维度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;token1&amp;gt;&amp;lt;token2&amp;gt;. . . &amp;lt;tokenk&amp;gt;&lt;/code&gt;Prompt层中的可学习token，以及&lt;code&gt;&amp;lt;sks&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;定义可训练的参数:&lt;/p&gt;
$$
\theta = \left\{\text{&lt;sks&gt;, &lt;token1&gt;,...&lt;tokenk&gt;},W_{(:,N+1)}\right\}
$$&lt;p&gt;
构造大量对话文本$(I,X_q,X_a)$，分别表示图片、提问、标准回答，进行训练&lt;/p&gt;
&lt;p&gt;从而让模型学习到新的concept（注意冻结其他参数）&lt;/p&gt;
&lt;h3 id=&#34;enhancing-recognition-with-hard-negative-mining&#34;&gt;Enhancing Recognition with Hard Negative Mining
&lt;/h3&gt;&lt;p&gt;对于识别问题，比较简单的训练方式就是询问subject是否在图片中&lt;/p&gt;
&lt;p&gt;显然不能全是正例，不然会训崩&lt;/p&gt;
&lt;p&gt;paper从LAION中抽样了100张图片作为负例，混合训练&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251215230809533.png&#34;
	width=&#34;1208&#34;
	height=&#34;492&#34;
	srcset=&#34;https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251215230809533_hu_5319841205a1c781.png 480w, https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251215230809533_hu_1eadf14d5e4847f6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;245&#34;
		data-flex-basis=&#34;589px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;同时我们需要避免模型过度泛化&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;subject：yellow + dog&lt;/p&gt;
&lt;p&gt;model: any yellow animal&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;为了增强训练，paper采用了&lt;strong&gt;hard negative mining&lt;/strong&gt;的方法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;若subject是一只毛绒狗，则负例应该选择其他不是狗的毛绒动物&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251215231211500.png&#34;
	width=&#34;700&#34;
	height=&#34;828&#34;
	srcset=&#34;https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251215231211500_hu_2eef17c8d9139b2e.png 480w, https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251215231211500_hu_4df7f716972627da.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Hard Negative&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;84&#34;
		data-flex-basis=&#34;202px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;因此最后训练数据图片的组成为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;100张随机抽取&lt;/li&gt;
&lt;li&gt;100张通过CLIP计算相似度得到top-m张图（m=100）&lt;/li&gt;
&lt;li&gt;正样本（5张左右）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然后paper构造了30条左右的prompt，以不同方式询问与回答：&lt;code&gt;&amp;lt;sks&amp;gt;&lt;/code&gt;在图里吗？&lt;/p&gt;
&lt;h3 id=&#34;learning-to-engage-in-natural-conversations-about-the-subject&#34;&gt;Learning to Engage in Natural Conversations about the Subject
&lt;/h3&gt;&lt;p&gt;通过上述算法，模型掌握了识别的能力，但未必掌握了如何描述subject：&lt;code&gt;Describe &amp;lt;sks&amp;gt; in detail.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;因此需要进一步训练，使得模型能够在对话中熟悉掌握subject的本质特性&lt;/p&gt;
&lt;p&gt;paper定义了10份通用对话模板，分为&lt;strong&gt;人类&lt;/strong&gt;、&lt;strong&gt;物体&lt;/strong&gt;两种（方便套用任何需要进行个性化训练的subject）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;避免过于细节的问题，例如：subject的尾巴是什么颜色的？&lt;/p&gt;
&lt;p&gt;显然不是所有物体都有这个特征&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;对于每一张图像，使用LLaVA针对问题生成回答，完成数据集构建&lt;/p&gt;
&lt;p&gt;为了让模型真实地记住subject的特征，避免模型通过图像泄露得到答案&lt;/p&gt;
&lt;p&gt;这一阶段训练是&lt;strong&gt;纯文本&lt;/strong&gt;的，只使用问题-答案对进行训练&lt;/p&gt;
&lt;h2 id=&#34;experiment&#34;&gt;Experiment
&lt;/h2&gt;&lt;h3 id=&#34;train&#34;&gt;Train
&lt;/h3&gt;&lt;p&gt;对于单个subject，使用5张图像作为输入，软提示的视角token数量设定为16&lt;/p&gt;
&lt;p&gt;使用LLaVA-1.5-13B，进行单轮对话训练，GPU选择单卡A6000&lt;/p&gt;
&lt;h3 id=&#34;dataset&#34;&gt;Dataset
&lt;/h3&gt;&lt;p&gt;数据集的初始构建由40个subject构成：&lt;code&gt;Person (10), Pets (5), Landmarks (5), Objects (15), and Fiction Characters (5).&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;每个subject含有10-20张图片，切分为训练集和测试集&lt;/p&gt;
&lt;h3 id=&#34;baselines&#34;&gt;Baselines
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Naive LLaVA&lt;/li&gt;
&lt;li&gt;LLaVA + Prompt：通过提示词提供subject信息给LLaVA&lt;/li&gt;
&lt;li&gt;GPT-4V
&lt;ul&gt;
&lt;li&gt;+Prompt&lt;/li&gt;
&lt;li&gt;+Images（GPT-4V支持多轮图像对话，因此可以提供多个subject的图片，单张图片1k token）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;图片信息显著比文本提示更加丰富，因此GPT-4V+Images应当是性能的理论上界（提供了充足的描述）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;文本提示的获得方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;人工（约 16 token）&lt;/li&gt;
&lt;li&gt;模型生成&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了方便对比，准备了两组文本提示词：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;拼接人工+模型生成（约1.3k的token）&lt;/li&gt;
&lt;li&gt;模型再总结（约16 token）&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;results&#34;&gt;Results
&lt;/h3&gt;&lt;h4 id=&#34;recognition-ability&#34;&gt;Recognition Ability
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;40 个主体，每个主体有 5 到 10 张包含该对应主体的test图像&lt;/li&gt;
&lt;li&gt;对于每个主体，其所有的测试图像均作为&lt;strong&gt;正样本&lt;/strong&gt;，而来自其余 39 个类别的测试图像则作为&lt;strong&gt;负样本&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;总共有 333 个正向测试样本和 13,320 个负向测试样本&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实验提供图像+问题&lt;code&gt;Can you see if &amp;lt;sks&amp;gt; is in this photo? Answer with a single word or phrase.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217091440247.png&#34;
	width=&#34;2038&#34;
	height=&#34;974&#34;
	srcset=&#34;https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217091440247_hu_2bcbcc9cf4482e3d.png 480w, https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217091440247_hu_5bf7089a10cc7438.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;results&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;209&#34;
		data-flex-basis=&#34;502px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Weighted是正负样本准确率的均值&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;过长的描述会对性能产生负面影响（即使用 1.3k 个 token 仅达到 0.650），可能描述了多余内容&lt;/li&gt;
&lt;li&gt;给出的参考图像越多，性能越好&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217091828473.png&#34;
	width=&#34;765&#34;
	height=&#34;530&#34;
	srcset=&#34;https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217091828473_hu_7f4e43661a201c7f.png 480w, https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217091828473_hu_ed1a2e03807f7567.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;144&#34;
		data-flex-basis=&#34;346px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;question-answering&#34;&gt;Question Answering
&lt;/h4&gt;&lt;p&gt;准备了多道A或者B的选择题&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;171道视觉（基于图片提问）&lt;/li&gt;
&lt;li&gt;400纯文本&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;comparison-with-myvlm&#34;&gt;Comparison with MyVLM
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217092656075.png&#34;
	width=&#34;2051&#34;
	height=&#34;414&#34;
	srcset=&#34;https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217092656075_hu_faca1316d356e695.png 480w, https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217092656075_hu_eccb22db9d4a8924.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;495&#34;
		data-flex-basis=&#34;1188px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;ablation-studies&#34;&gt;Ablation Studies
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217093115393.png&#34;
	width=&#34;2146&#34;
	height=&#34;869&#34;
	srcset=&#34;https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217093115393_hu_f0cefe64659a01c9.png 480w, https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217093115393_hu_25314fe91eb4172e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20251217093115393&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;246&#34;
		data-flex-basis=&#34;592px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对Prompt的可学习token长度的消融：越长越好，为了均衡性能，选择16&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对subject传入的图像数的消融：越多越好，选择5&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据集构建消融&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;纯LLaVA：
&lt;ul&gt;
&lt;li&gt;识别能力随机&lt;/li&gt;
&lt;li&gt;描述能力完全不行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;构造识别数据：&lt;code&gt;&amp;lt;sks&amp;gt;&lt;/code&gt;是否在图中？
&lt;ul&gt;
&lt;li&gt;识别能力提升&lt;/li&gt;
&lt;li&gt;描述能力完全不行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;构造文本对话数据
&lt;ul&gt;
&lt;li&gt;识别能力略微提升&lt;/li&gt;
&lt;li&gt;描述能力具备&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;构造Hard Negative样本
&lt;ul&gt;
&lt;li&gt;识别能力显著提升&lt;/li&gt;
&lt;li&gt;描述能力具备&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217154719910.png&#34;
	width=&#34;1610&#34;
	height=&#34;344&#34;
	srcset=&#34;https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217154719910_hu_cc43ccd0a36ec226.png 480w, https://example.com/p/yo-llava-your-personalized-language-and-vision-assistant/assets/image-20251217154719910_hu_baaee4f1f0248f3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;数据集消融&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;468&#34;
		data-flex-basis=&#34;1123px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>LLaDA-Rec - Discrete Diffusion for Parallel Semantic ID Generation in Generative Recommendation</title>
        <link>https://example.com/p/llada-rec-discrete-diffusion-for-parallel-semantic-id-generation-in-generative-recommendation/</link>
        <pubDate>Fri, 21 Nov 2025 15:36:00 +0800</pubDate>
        
        <guid>https://example.com/p/llada-rec-discrete-diffusion-for-parallel-semantic-id-generation-in-generative-recommendation/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro
&lt;/h2&gt;&lt;p&gt;Generative recommendation基于AR LLM，面临两个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;unidirectional constraint：无法在建模item语义时，捕获全局依赖&lt;/li&gt;
&lt;li&gt;error accumulation：错误累积&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;补充一些前置知识：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RQ-VAE（Residual Quantized Variational Autoencoder）
&lt;ul&gt;
&lt;li&gt;需要把Item表示成一个离散的token序列（Semantic ID），使用类LLM的生成方式进行推荐&lt;/li&gt;
&lt;li&gt;RQ-VAE把Item的embedding压缩成离散token
&lt;ul&gt;
&lt;li&gt;RA-VAE是多层级的，每一层会拟合一点，最后输出一个token序列&lt;/li&gt;
&lt;li&gt;通过控制层数，控制token序列长度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;将生成式推荐运用到dLMs上也面临若干问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mismatch between Residual Quantization (RQ) and Discrete Diffusion
&lt;ul&gt;
&lt;li&gt;多层级的方案与dlms的并行不是很契合，且dlms序列中所有token同等重要&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Beam Search is Not Directly Applicable to Discrete Diffusion
&lt;ul&gt;
&lt;li&gt;Beam Search比较适合自回归的top k，但是固定从左到右&lt;/li&gt;
&lt;li&gt;dlms是双向的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Differences between Language Modeling and Recommendation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Contribution&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Parallel Tokenization&lt;/strong&gt;：设计了多头VQ-VAE，将物品切分为多个子向量，每个向量并行查找独立的codebook，最终生成ID&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Discrete Diffusion Training&lt;/strong&gt;：使用两种mask机制
&lt;ul&gt;
&lt;li&gt;User-History Mask&lt;/li&gt;
&lt;li&gt;Next-Item Mask&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Discrete Diffusion Inference&lt;/strong&gt;：适配了Beam Search&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminaries&#34;&gt;Preliminaries
&lt;/h2&gt;&lt;p&gt;推荐任务的问题定义：&lt;/p&gt;
$$
\mathcal{H} = \left [ i_1, i_2, ..., i_{n-1}\right] 
$$&lt;ul&gt;
&lt;li&gt;基于用户历史的物品信息，预测下一个可能的物品$i_n$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;生成式推荐将单个物品表示为&lt;strong&gt;定长&lt;/strong&gt;的若干个token&lt;/p&gt;
$$
\mathcal{S_H} = \left[c_{1,1},...,c_{1,M},...,c_{n-1,1},...,c_{n-1,M}\right]
$$&lt;p&gt;
我们需要找到一个最佳的模型$\theta$，使得：&lt;/p&gt;
$$
\theta^* = \arg \max_\theta  P_\theta(s_n\mid \mathcal{S_H})
$$&lt;p&gt;
这个转化为AR LLM的建模还是非常方便的&lt;/p&gt;
&lt;p&gt;对于dLM：&lt;/p&gt;
&lt;p&gt;$$
P_\theta(s_n\mid \mathcal{S_H}) = \prod_{t=1}^T\prod_{m=1}^M\begin{cases}
P_\theta(c_{n,m}\mid s_n^t,\mathcal{S_H}) &amp;amp; if \space [MASK]\
1 &amp;amp; otherwise&lt;/p&gt;
&lt;p&gt;\end{cases}
$$&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/llada-rec-discrete-diffusion-for-parallel-semantic-id-generation-in-generative-recommendation/assets/image-20251127231720077.png&#34;
	width=&#34;1360&#34;
	height=&#34;636&#34;
	srcset=&#34;https://example.com/p/llada-rec-discrete-diffusion-for-parallel-semantic-id-generation-in-generative-recommendation/assets/image-20251127231720077_hu_d91e9c45c767b211.png 480w, https://example.com/p/llada-rec-discrete-diffusion-for-parallel-semantic-id-generation-in-generative-recommendation/assets/image-20251127231720077_hu_ed7572c2e81d9356.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Method&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;213&#34;
		data-flex-basis=&#34;513px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;parallel-tokenization-via-multi-head-vq-vae&#34;&gt;Parallel Tokenization via Multi-Head VQ-VAE
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;希望多个 token 之间是“完全平等”的，不应该存在 RQ-VAE 那种“前面的 token 更重要&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Embedding通过Bert、Sentence-T5等得到$v_i$&lt;/li&gt;
&lt;li&gt;通过Encoder（MLP实现），得到潜在空间$z$&lt;/li&gt;
&lt;li&gt;将向量切成多个子向量，每个向量送入不同的Head&lt;/li&gt;
&lt;li&gt;每个子向量查codebook，并行得到token(code index)&lt;/li&gt;
&lt;li&gt;将code index对应的向量（code embeddings），进行拼接&lt;/li&gt;
&lt;li&gt;Decoder重建$\hat v_i$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;整个Tokenizer的损失由两部分组成：&lt;/p&gt;
$$
L_{Recon} = \left \| v_i-\hat v_i \right \|^2_2
$$&lt;p&gt;
（L2范数的平方）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Encoder：学习如何编码到合适的latent space&lt;/li&gt;
&lt;li&gt;Codebook：学习到如何覆盖latent space&lt;/li&gt;
&lt;li&gt;Decoder：重建&lt;/li&gt;
&lt;/ul&gt;
$$
L_{VQ} = \sum_{m=1}^M \left (  \left\| sg[z_{i,m}] - e_{c_i,m}\right\|_2^2 + \alpha \left\|z_{i,m}-sg[e_{c_{i,m}}]\right\|^2_2 \right)
$$&lt;ul&gt;
&lt;li&gt;对于第一项
&lt;ul&gt;
&lt;li&gt;sg代表阻止接受梯度，只有$e$会接受梯度&lt;/li&gt;
&lt;li&gt;这样只更新codebook，使得codebook更接近latent space向量$z$（请靠近encoder的输出）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;对于第二项
&lt;ul&gt;
&lt;li&gt;sg阻止codebook的梯度&lt;/li&gt;
&lt;li&gt;更新encoder，贴近codebook&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最终的损失：&lt;/p&gt;
$$
\mathcal{L_{\text{VQ-VAE}}} = \mathcal{L_\text{Recon}} + \mathcal{L_\text{VQ}}
$$&lt;h3 id=&#34;discrete-diffusion-training&#34;&gt;Discrete Diffusion Training
&lt;/h3&gt;&lt;h4 id=&#34;user-history-level-masking&#34;&gt;User-History Level Masking
&lt;/h4&gt;&lt;p&gt;参考LLaDA的预训练&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;让模型学会用户序列内部的关系&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;next-item-level-masking&#34;&gt;Next-Item Level Masking
&lt;/h4&gt;&lt;p&gt;参考LLaDA的SFT&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;理解同一 item 的 token 内部结构&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;但是LLaDA-Rec的训练没有分成两个阶段&lt;/p&gt;
&lt;p&gt;提出了一个联合损失函数：&lt;/p&gt;
$$
L_{total} = L_{Item-Mask} + \lambda_{His-Mask}L_{His-mask} + \lambda_{Reg}\left\|\theta\right\|^2
$$&lt;h3 id=&#34;discrete-diffusion-inference&#34;&gt;Discrete Diffusion Inference
&lt;/h3&gt;&lt;p&gt;直接使用模型不太行，没法做到生成前k个推荐项目&lt;/p&gt;
&lt;p&gt;所以如何把Beam-Search嵌入到dlms中&lt;/p&gt;
&lt;p&gt;一开始我们会有一个全部都是&lt;code&gt;[MASK]&lt;/code&gt;的序列，长度为$M$​：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[MASK] [MASK] [MASK] ... [MASK] [MASK] 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;dlm可以预测所有位置的生成token的置信度&lt;/p&gt;
&lt;p&gt;假设我们要迭代$T$次，因此$K = M/T$&lt;/p&gt;
&lt;p&gt;每次依照置信度选择前$K$个token位置，其他位置remask&lt;/p&gt;
&lt;p&gt;根据这些位置，以及超参数$B$，迭代出$B$条置信度最高的路径&lt;/p&gt;
&lt;p&gt;做beam search&lt;/p&gt;
&lt;p&gt;不断迭代&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Happy LLM · Part1 · Transformer</title>
        <link>https://example.com/p/happy-llm-part1-transformer/</link>
        <pubDate>Fri, 14 Nov 2025 20:15:32 +0800</pubDate>
        
        <guid>https://example.com/p/happy-llm-part1-transformer/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&#34;transformer&#34;&gt;Transformer
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;[参考资料](&lt;a class=&#34;link&#34; href=&#34;https://datawhalechina.github.io/happy-llm/#/./chapter2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://datawhalechina.github.io/happy-llm/#/./chapter2/&lt;/a&gt;第二章 Transformer架构)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;注意力机制&#34;&gt;注意力机制
&lt;/h2&gt;&lt;p&gt;对于一个token序列，注意力机制建立了三个键值：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;query：表示想找什么特征&lt;/li&gt;
&lt;li&gt;key：表示我有什么特征&lt;/li&gt;
&lt;li&gt;value：信息正文&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此为了衡量query和key的特征之间的相似度，我们可以引入&lt;strong&gt;点积&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所有的query向量和所有的key做点积&lt;/p&gt;
$$
QK^\top
$$&lt;p&gt;
得到&lt;strong&gt;注意力矩阵&lt;/strong&gt;，点积越大越相似&lt;/p&gt;
&lt;p&gt;同时为了防止数值爆炸（维数$d_k$越大，累加的数值会越多）&lt;/p&gt;
&lt;p&gt;做一下缩放：&lt;/p&gt;
$$
\frac{QK^\top}{\sqrt{d_k}}
$$&lt;p&gt;
然后通过softmax做一下归一化，确保所有权重之和为1，方便约束数值&lt;/p&gt;
&lt;p&gt;最后对应权重乘上对应的Value&lt;/p&gt;
&lt;p&gt;这样我们计算得到的是上下文文本内容的vector&lt;/p&gt;
$$
\text{attention}(Q,K,V) = \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right)V
$$&lt;h3 id=&#34;self-attention&#34;&gt;Self-Attention
&lt;/h3&gt;&lt;p&gt;注意力机制处理了两个序列（Q、K来自不同序列）之间互相的查询&lt;/p&gt;
&lt;p&gt;自注意力理所当然是查询自己&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;检查自己所说过的内容，确保逻辑一致&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于自注意力，每个Token都会有自己的Q、K、V&lt;/p&gt;
&lt;p&gt;自然三个矩阵的维度是匹配的（跟序列长度有关），&lt;code&gt;(batch_size, seq_len, d_model)&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;**Question：**如果你的输入序列有 4 个 token，那么计算 self-attention 的注意力矩阵 size 会是多少？&lt;/p&gt;
&lt;p&gt;**Answer：**每个token对应另外4个token的注意力分数，所以是(4,4)&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;mask-self-attention&#34;&gt;Mask Self-Attention
&lt;/h3&gt;&lt;p&gt;模型学习过程中，有时候会遮蔽一些token，以该机制阻止计算注意力&lt;/p&gt;
&lt;p&gt;最常用的就是通过Mask，遮蔽未来的信息，只允许模型利用历史信息&lt;/p&gt;
&lt;p&gt;如果待学习的文本序列是&lt;code&gt;[BOS] I like you [EOS]&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BOS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;【&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MASK&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;】【&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MASK&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;】【&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MASK&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;】【&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MASK&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;】&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BOS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;I&lt;/span&gt;   &lt;span class=&#34;err&#34;&gt;【&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MASK&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;】&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;【&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MASK&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;】【&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MASK&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;】&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BOS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;I&lt;/span&gt;     &lt;span class=&#34;n&#34;&gt;like&lt;/span&gt;  &lt;span class=&#34;err&#34;&gt;【&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MASK&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;】【&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MASK&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;】&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BOS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;I&lt;/span&gt;     &lt;span class=&#34;n&#34;&gt;like&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;you&lt;/span&gt;  &lt;span class=&#34;err&#34;&gt;【&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MASK&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;】&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BOS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;I&lt;/span&gt;     &lt;span class=&#34;n&#34;&gt;like&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;you&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;EOS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;模型能看到的内容就是未被MASK的token&lt;/p&gt;
&lt;p&gt;MASK是一个典型的上三角矩阵，因此我们可以创建一个上三角矩阵作为注意力掩码&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入：&lt;code&gt;(batch_size, seq_len, hidden_size)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;注意力掩码：&lt;code&gt;(1, seq_len, seq_len)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;batch中所有内容都可以通用（一般seq_len是一样的）&lt;/p&gt;
&lt;h3 id=&#34;multi-head-attention&#34;&gt;Multi-Head Attention
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;一次注意力计算只能拟合&lt;strong&gt;一种相关关系&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;代词关系、主谓关系、定语修饰……token之间的关系非常多余&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们希望能从&lt;strong&gt;多个维度&lt;/strong&gt;去寻找注意力的相关，自然引入&lt;strong&gt;多头注意力机制&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同时对一个语料进行&lt;strong&gt;多次注意力计算&lt;/strong&gt;，每次注意力计算都能拟合不同的关系&lt;/li&gt;
&lt;li&gt;最后的多次结果拼接起来作为最后的输出&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/happy-llm-part1-transformer/assets/image-20251115211906122.png&#34;
	width=&#34;579&#34;
	height=&#34;560&#34;
	srcset=&#34;https://example.com/p/happy-llm-part1-transformer/assets/image-20251115211906122_hu_720130ccf2a5fc62.png 480w, https://example.com/p/happy-llm-part1-transformer/assets/image-20251115211906122_hu_6b5712e82b4fab67.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Multi-Head Attention&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;103&#34;
		data-flex-basis=&#34;248px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;如图，不同的注意力查询，每个token所关注的其他token都不太一样&lt;/p&gt;
&lt;p&gt;假设文本的输入序列矩阵是$X$，对于第$i$个头&lt;/p&gt;
$$
Q_i = XW_i^Q, K_i=XW_i^K, V_i = XW_i^V
$$&lt;p&gt;
其对应的注意力为：&lt;/p&gt;
$$
\text{head}_i = \text{attention}(Q_i, K_i,V_i)
$$&lt;p&gt;
多头注意力表示为：&lt;/p&gt;
$$
\text{MultiHead}(Q,K,V) = \text{Concat}(head_i)W^O
$$</description>
        </item>
        <item>
        <title>TiDAR - Think in Diffusion, Talk in Autoregression</title>
        <link>https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/</link>
        <pubDate>Fri, 14 Nov 2025 16:11:00 +0800</pubDate>
        
        <guid>https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2502.09992&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Large Language Diffusion Models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro
&lt;/h2&gt;&lt;h3 id=&#34;memory-bound&#34;&gt;memory-bound
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;AR模型的Latency：每次predict next token，模型权重、KV Cache需要从显存中加载到GPU核心
&lt;ul&gt;
&lt;li&gt;瓶颈是&lt;strong&gt;显存带宽&lt;/strong&gt;，GPU计算密度远远不够&lt;/li&gt;
&lt;li&gt;因此单次decode越多的token，计算密度越高（在memory-bound的限制之下）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于单次推理&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AR：&lt;/li&gt;
&lt;/ul&gt;
$$
x_{t+1}=F(x_{&lt; t};x_t)
$$&lt;ul&gt;
&lt;li&gt;dLMs：&lt;/li&gt;
&lt;/ul&gt;
$$
x_{t+1},x_{t+2},...,x_{t+k+1} = F(x_{&lt; t};M_{t+1},M_{t+2},...,M_{t+k+1})
$$&lt;p&gt;&lt;strong&gt;只要没有触发到compute-bound&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;两者时间开销是一致的&lt;/p&gt;
&lt;p&gt;意味着多预测的部分$x_{t+2},&amp;hellip;,x_{t+k+1}$​是&lt;strong&gt;免费&lt;/strong&gt;的，没有额外的时间开销&lt;/p&gt;
&lt;p&gt;论文将这部分多预测出来的部分（在不增加开销的情况下），命名为&lt;strong&gt;Free Token Slots&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;什么是slots？&lt;/p&gt;
&lt;p&gt;模型的输出是多个token，&lt;strong&gt;其中需要计算kv的部分认为是slots&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;剩余已经计算过kv的token，以下实验证明了影响不大&lt;/p&gt;
&lt;p&gt;因此paper主要聚焦于slots&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;这里做了一个基于qwen3-32B的实验（Flash Attention 2、H100、batch size=1）&lt;/p&gt;
&lt;p&gt;三条线分别是prefix=1024、2048、4096（&lt;strong&gt;kv cache提前计算好&lt;/strong&gt;）&lt;/p&gt;
&lt;p&gt;输入：&lt;code&gt;token1 token2 ... token1023 token1024 [slots1] [slots2] ... [slotsn]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;输出：&lt;code&gt;logit1 logit2 ... logit1023 logit1024 logit1 logit2 ... logitn &lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;因此实际影响单次forward的是输入的slots的数量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251116143635413.png&#34;
	width=&#34;1240&#34;
	height=&#34;859&#34;
	srcset=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251116143635413_hu_828a060f8e157568.png 480w, https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251116143635413_hu_727a2630d7cf1aa2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Free Token Slots&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;144&#34;
		data-flex-basis=&#34;346px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Free Token Slots&lt;/strong&gt;：该区间（1 - 100）延迟基本不增加&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cheap Token Slots&lt;/strong&gt;：该区间延迟增加的不多，比较cheap&lt;/li&gt;
&lt;li&gt;蓝色区间：触发了compute-bound&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;independence&#34;&gt;independence
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;AR是条件概率，按照从左到右依次生成&lt;/li&gt;
&lt;li&gt;dLMs从加噪序列中decode所有的token
&lt;ul&gt;
&lt;li&gt;我们通过策略选择采样$k$个token进行保留，其他进行remask&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而被采样的token应该是多个边缘分布的乘积&lt;/p&gt;
$$
\prod_i p_\theta^i(x^i\mid x_t)
$$&lt;p&gt;
这些token都是基于解码前的加噪序列得到的条件概率生成&lt;/p&gt;
&lt;p&gt;彼此可以看成独立的&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这里不太认可。生成的时候并不是模型独立生成每一个token，而是同时生成&lt;/p&gt;
&lt;p&gt;你要说完全独立没关系我觉得是不对的&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;省流，从概率建模的角度解释dLMs的生成质量与$k$高度相关
&lt;ul&gt;
&lt;li&gt;$k=1$时，从左到右（因果掩码），退化成AR LLM&lt;/li&gt;
&lt;li&gt;$k$越小，质量越高&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;real-intro&#34;&gt;real-intro
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Challenge&lt;/strong&gt;：生成模型的&lt;strong&gt;质量-并行&lt;/strong&gt;问题&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;AR LLM：生成质量高，但是苦于memory-bound无法提升性能&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dLMs：由于token间的独立性假设，生成质量受限于并发量&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Contribution&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提出TiDAR架构，利用Free-token-slots，并行完成&lt;strong&gt;基于扩散的草稿&lt;/strong&gt;和&lt;strong&gt;基于自回归的采样&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;提供完整训练方案，进行全面评估，证明架构的优势&lt;/li&gt;
&lt;li&gt;进行详细的消融实验，验证核心设计。同时从扩散模型、投机采样角度进行分析&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;method&#34;&gt;Method
&lt;/h2&gt;&lt;p&gt;修改一下论文顺序，先写一下怎么推理&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为了利用&lt;code&gt;free-token-slots&lt;/code&gt;，需要Diffusion和AR同时在一次forward中同时出现&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fully-parallelizable-self-speculative-generation&#34;&gt;Fully Parallelizable Self-Speculative Generation
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251117162442502.png&#34;
	width=&#34;2031&#34;
	height=&#34;873&#34;
	srcset=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251117162442502_hu_e5b07fb0e1bbecb8.png 480w, https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251117162442502_hu_c78639f221d329ce.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;232&#34;
		data-flex-basis=&#34;558px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;整个过程类似投机采样，整体的思想如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先由Diffusion Model生成一个&lt;strong&gt;draft&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;由AR进行&lt;strong&gt;rejection sampling&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;如果和AR的prediction一致，则保留&lt;/li&gt;
&lt;li&gt;否则直接丢弃&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;In the each subsequent decoding step, draft tokens from the last step are rejectively sampled by checking &lt;strong&gt;whether they match the prediction&lt;/strong&gt; from the autoregressive joint distribution computed at current step using causal attention.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;概述整个算法（&lt;strong&gt;定义block_len为3（可调整）&lt;/strong&gt;），即我们会以三个token三个token为一组进行讨论&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step0：Draft初始化
&lt;ul&gt;
&lt;li&gt;输入Prefix Tokens（实质上就是Prompt）和block size（这里是3）个MASK&lt;/li&gt;
&lt;li&gt;为了兼容不同长度，同样调整了Attention Mask的顺序
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;(block_size + max_seq_len,block_size + max_seq_len)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;直接按照真实长度切出来&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251118223504302.png&#34;
	width=&#34;761&#34;
	height=&#34;551&#34;
	srcset=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251118223504302_hu_3c3a6f2560ea2832.png 480w, https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251118223504302_hu_72e15dca633e49ef.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Prefill&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;138&#34;
		data-flex-basis=&#34;331px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Step1: 输入&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prefix Token&lt;/strong&gt;：&lt;code&gt;ABC&lt;/code&gt;，表示为之前已有（被成功采样）的token序列，提前计算好KV-Cache&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Diffusion Draft&lt;/strong&gt;：由Diffusion生成的草稿&lt;code&gt;DEF&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Step2: 并行处理两件事&lt;/strong&gt;（实质上是一个Transformer模型的&lt;strong&gt;单次前向推理&lt;/strong&gt;）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;AR部分：基于Causal Attention，输出&lt;strong&gt;Diffusion Draft&lt;/strong&gt;部分对应的logits（&lt;strong&gt;带有shift&lt;/strong&gt;）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DLMs部分：假设&lt;strong&gt;所有拒绝采样的结果&lt;/strong&gt;，提前准备好对应的&lt;code&gt;[MASK]&lt;/code&gt;让DLM独立预测（生成下一轮使用的草稿）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251117212424712.png&#34;
	width=&#34;698&#34;
	height=&#34;297&#34;
	srcset=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251117212424712_hu_868041ff93ce9f34.png 480w, https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251117212424712_hu_6bed231ec807f8b1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;AR Shift&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;235&#34;
		data-flex-basis=&#34;564px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;因此我们本质上把&lt;code&gt;ABC DEF [M][M][M] [M][M][M] [M][M][M]&lt;/code&gt;作为输入&lt;/p&gt;
&lt;p&gt;送入到TiDAR中，做了一次前向传播&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;这里&lt;strong&gt;调整了Prefix的顺序&lt;/strong&gt;，方便&lt;strong&gt;复用Attention Mask矩阵&lt;/strong&gt;，&lt;strong&gt;新采样的token直接加到最后&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;也就是&lt;code&gt;DEF [M][M][M] [M][M][M] [M][M][M] ABC...&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;注意这里只是Attention Mask的顺序，并不是输入序列&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251117212940737.png&#34;
	width=&#34;1186&#34;
	height=&#34;687&#34;
	srcset=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251117212940737_hu_50c5c79ca3fde991.png 480w, https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251117212940737_hu_a36ef3f0139784d5.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Decode&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;172&#34;
		data-flex-basis=&#34;414px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;对于第一组&lt;code&gt;[M][M][M]&lt;/code&gt;：Attention能看见的是&lt;code&gt;ABC D [M][M][M]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;对于第二组&lt;code&gt;[M][M][M]&lt;/code&gt;：Attention能看见的是&lt;code&gt;ABC DE [M][M][M]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;对于第三组&lt;code&gt;[M][M][M]&lt;/code&gt;：Attention能看见的是&lt;code&gt;ABC DEF [M][M][M]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Step3:  Sampling&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;根据AR部分的logits输出，决定上一轮草稿保留的内容（例子是保留DE，舍去F）&lt;/li&gt;
&lt;li&gt;因此Prefix Token和KV-Cache会将&lt;code&gt;DE&lt;/code&gt;加入，得到&lt;code&gt;ABC DE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;下一轮的草稿为第二组&lt;code&gt;[M][M][M]&lt;/code&gt;的解码结果：&lt;code&gt;F&amp;quot;G&amp;quot;H&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Step4：输出&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prefix Token&lt;/strong&gt;：&lt;code&gt;ABC DE&lt;/code&gt;及其KV-Cache&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Diffusion Draft&lt;/strong&gt;：由Diffusion生成的草稿&lt;code&gt;F&amp;quot;G&amp;quot;H&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一些思考：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;显然&lt;code&gt;block_len&lt;/code&gt;是不能无限大的，结合Figure1，通过单个Transformer架构的slots需要在&lt;code&gt;Free-Token-Slots&lt;/code&gt;的范围内&lt;/li&gt;
&lt;li&gt;paper只为AR采样1、2、3个token做了准备草稿，&lt;strong&gt;默认接受至少一个&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;diffusion-ar-dual-mode-backbone-training&#34;&gt;Diffusion-AR Dual-mode Backbone Training
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;论文其实是先讲的这一部分，但是先看完推理后再回来看train比较好&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;前期工作Block Diffusion提出了一种&lt;strong&gt;块内双向注意力，块间因果掩码&lt;/strong&gt;的方法&lt;/p&gt;
&lt;p&gt;TiDAR进行了修改：&lt;strong&gt;保留最后一个块（双向注意力），其他内容（或者叫前缀）全部因果掩码&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;带来如下好处&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;允许我们像AR一样计算链式的联合概率分布$p(x_i\mid x_{&amp;lt;i})$，方便进行拒绝采样，保证高质量，并且计算似然和AR一样高效&lt;/li&gt;
&lt;li&gt;在预训练和微调过程中可以计算前缀部分的NTP损失，&lt;strong&gt;损失信号的密度更高&lt;/strong&gt;，充分利用数据中每一个token&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;AR部分：shifted by one position&lt;/li&gt;
&lt;li&gt;dLM部分：一一对齐&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TiDAR对于扩散部分的token，全部掩码为&lt;code&gt;[MASK]&lt;/code&gt;，直接消除选择哪一种掩码策略的思考&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提高了扩散损失的密度（每一个token都参与）&lt;/li&gt;
&lt;li&gt;平衡了AR和扩散的损失：&lt;strong&gt;强制两者参与损失计算的token数量都是相等的（序列长度）&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;先前框架的不平衡：dLM的信号容易被AR淹没
&lt;ul&gt;
&lt;li&gt;AR：稠密的（len-1个token参与）&lt;/li&gt;
&lt;li&gt;dLMs：损失取决于多少token被掩码（远少于len）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;平衡的好处：更容易通过一个简单的超参数（加权因子）进行控制&lt;/li&gt;
&lt;li&gt;允许在推理时&lt;strong&gt;一步扩散&lt;/strong&gt;，避免多步迭代&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251118015735020.png&#34;
	width=&#34;740&#34;
	height=&#34;747&#34;
	srcset=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251118015735020_hu_419e28ffa044b0e3.png 480w, https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251118015735020_hu_bf8733a3f8d1fc3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Train Mask&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;99&#34;
		data-flex-basis=&#34;237px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于输入序列，扩充相同的长度掩码&lt;code&gt;ABC DEF&lt;/code&gt; -&amp;gt; &lt;code&gt;MMM MMM&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;前一半序列的注意力就是Causal Attention&lt;/li&gt;
&lt;li&gt;对于Diffusion部分（后一半），按照block size逐块考虑（采用双向注意力）
&lt;ul&gt;
&lt;li&gt;第一组&lt;code&gt;MMM&lt;/code&gt;恢复目标是&lt;code&gt;ABC&lt;/code&gt;，前缀为空&lt;/li&gt;
&lt;li&gt;第二组&lt;code&gt;MMM&lt;/code&gt;恢复目标是&lt;code&gt;DEF&lt;/code&gt;，前缀为&lt;code&gt;ABC&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;若后续还有别的组，前缀会继续累积&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TiDAR的建模目标可以表示为：&lt;/p&gt;
$$
\mathcal{L}_{TiDAR}(\theta) = \frac{1}{\alpha+1}\left( \sum_{i=1}^{S-1}\frac{\alpha}{S-1}\cdot\mathcal{L}_{AR}(x_i,x_{i+1};\theta)+ \sum_{i=1}^{S-1}\frac{1}{S-1}\cdot \mathcal{L}_{Diff}(\left[mask\right],x_i;\theta)\right )
$$&lt;ul&gt;
&lt;li&gt;$\alpha \in[0,1]$，损失函数的平衡项（paper里设为1）&lt;/li&gt;
&lt;li&gt;$\left{x_i\right}_S$是输入序列&lt;/li&gt;
&lt;li&gt;AR和Diffusion都是做对应的交叉熵&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;experiment&#34;&gt;Experiment
&lt;/h2&gt;&lt;p&gt;（这里笔记忘记保存了，补一些重点）&lt;/p&gt;
&lt;p&gt;由于AR部分的logits是带label shift的，Diffusion部分没有&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251118224652148.png&#34;
	width=&#34;1063&#34;
	height=&#34;332&#34;
	srcset=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251118224652148_hu_d600df02d3f6d42f.png 480w, https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251118224652148_hu_e1f37bc07406f7ce.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;320&#34;
		data-flex-basis=&#34;768px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;实质上是一个模型，没有切割&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;自回归部分根据ABCD会进行一个&lt;code&gt;E&lt;/code&gt;的预测&lt;/p&gt;
&lt;p&gt;Diffusion部分的第一个Mask，也会根据attention得到相同的信息，预测&lt;code&gt;E&#39;&#39;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;所以这里涉及到了相信自回归还是相信Diffusion、或是兼顾的思考&lt;/p&gt;
&lt;p&gt;作者顺手做了一个实验&lt;/p&gt;
$$
\text{logits}_{\text{mix}} = \beta*\text{logits}_i^{\text{AR}} + (1-\beta)*\text{logits}_i^{\text{Diff}},i\in|\text{Vocab}|
$$&lt;p&gt;
通过$\beta$对齐了两个logits&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251118225438803.png&#34;
	width=&#34;788&#34;
	height=&#34;378&#34;
	srcset=&#34;https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251118225438803_hu_fe1528daa70accea.png 480w, https://example.com/p/tidar-think-in-diffusion-talk-in-autoregression/assets/image-20251118225438803_hu_21e4be9c18baf35a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;208&#34;
		data-flex-basis=&#34;500px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过$\alpha$控制loss比例，横轴是$\beta$&lt;/li&gt;
&lt;li&gt;总体没有明显性能差距，&lt;strong&gt;因此质量来源是拒绝采样，而非AR比DLM好&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;limitations&#34;&gt;Limitations
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Batch_Size：paper只做了1的情况（毕竟贴近推理，而不是吞吐量测试）&lt;/li&gt;
&lt;li&gt;长上下文：翻了一倍文本，压力比较大&lt;/li&gt;
&lt;li&gt;free token slots的探索：需要更加系统化的视角
&lt;ul&gt;
&lt;li&gt;cuda&lt;/li&gt;
&lt;li&gt;调度&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Awesome LLaDA</title>
        <link>https://example.com/p/awesome-llada/</link>
        <pubDate>Thu, 13 Nov 2025 12:56:00 +0800</pubDate>
        
        <guid>https://example.com/p/awesome-llada/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;content&#34;&gt;Content
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2511.06254&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2511.06254 LLaDA-Rec: Discrete Diffusion for Parallel Semantic ID Generation in Generative Recommendation&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;note&lt;/strong&gt;：&lt;a class=&#34;link&#34; href=&#34;https://aoijays.top/p/llada-rec-discrete-diffusion-for-parallel-semantic-id-generation-in-generative-recommendation/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;abstract&lt;/strong&gt;：生成式推荐与离散扩散模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2510.10481&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2510.10481 UltraLLaDA: Scaling the Context Length to 128K for Diffusion Large Language Models&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;note&lt;/strong&gt;：&lt;a class=&#34;link&#34; href=&#34;https://aoijays.top/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;abstract&lt;/strong&gt;：扩充LLaDA的长上下文&lt;/li&gt;
&lt;li&gt;ICLR 2026：6666&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2509.24389&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2509.24389 LLaDA-MoE: A Sparse MoE Diffusion Language Model&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;note&lt;/strong&gt;：&lt;a class=&#34;link&#34; href=&#34;https://aoijays.top/p/llada-moe-asparse-moediffusion-language-model/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;abstract&lt;/strong&gt;：修改了LLaDA的Dense Transformer为MoE架构&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2509.13866&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2509.13866 Masked Diffusion Models as Energy Minimization&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如何以理论可解释的方式为离散域的掩码扩散模型（MDM）设计最优采样调度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2505.19223&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2505.19223 LLaDA 1.5: Variance-Reduced Preference Optimization for Large Language Diffusion Models&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;note&lt;/strong&gt;：&lt;a class=&#34;link&#34; href=&#34;https://aoijays.top/p/diffusion-language-model-birdresearch-202510/#llada-15-variance-reduced-preference-optimization-for-large-language-diffusion-models&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;笔记（难度较高，未读完）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;abstract&lt;/strong&gt;：提出VRPO方法，对LLaDA进行强化学习&lt;/li&gt;
&lt;li&gt;ICLR 2026：642&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2505.16933&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2505.16933 LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;note&lt;/strong&gt;：&lt;a class=&#34;link&#34; href=&#34;https://aoijays.top/p/diffusion-language-model-birdresearch-202510/#llada-v-large-language-diffusion-models-with-visual-instruction-tuning&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;abstract&lt;/strong&gt;：实现了图片理解的多模态LLaDA模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2502.09992&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2502.09992 Large Language Diffusion Models&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;note&lt;/strong&gt;：&lt;a class=&#34;link&#34; href=&#34;https://aoijays.top/p/diffusion-language-model-%e8%ae%ba%e6%96%87%e7%ac%94%e8%ae%b0%e4%b8%80/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;abstract&lt;/strong&gt;：LLaDA&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>LLaDA-MoE ASparse MoEDiffusion Language Model</title>
        <link>https://example.com/p/llada-moe-asparse-moediffusion-language-model/</link>
        <pubDate>Tue, 11 Nov 2025 13:54:00 +0800</pubDate>
        
        <guid>https://example.com/p/llada-moe-asparse-moediffusion-language-model/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2502.09992&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Large Language Diffusion Models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251112212631894.png&#34;
	width=&#34;1088&#34;
	height=&#34;573&#34;
	srcset=&#34;https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251112212631894_hu_138266dd69e252e0.png 480w, https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251112212631894_hu_2d18d20e2a5afd97.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;189&#34;
		data-flex-basis=&#34;455px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLaDA-MoE：激活1.4B参数的情况下，超过先前8B的DLMs性能，取得DLMs的SOTA，与Qwen2.5-3B-Instruct性能相当&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;llada-moe&#34;&gt;LLaDA-MoE
&lt;/h2&gt;&lt;h3 id=&#34;architecture&#34;&gt;Architecture
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251112214355137.png&#34;
	width=&#34;1135&#34;
	height=&#34;647&#34;
	srcset=&#34;https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251112214355137_hu_180d8637e9b2a256.png 480w, https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251112214355137_hu_d25e444d5191aadc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;LLaDA-MoE&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;421px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RMSNorm、SwiGLU、RoPE、QK-LayerNorm&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;train&#34;&gt;Train
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251113103025656.png&#34;
	width=&#34;1896&#34;
	height=&#34;204&#34;
	srcset=&#34;https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251113103025656_hu_8e34c220d489d6dd.png 480w, https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251113103025656_hu_b33c90fba7bf100a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Pipeline&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;929&#34;
		data-flex-basis=&#34;2230px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pretrain Stage 1：从头开始训练，10T&lt;/li&gt;
&lt;li&gt;Pretrain Stage 2：从相同的底层数据重新采样10T（提高数学、代码的权重），继续训练&lt;/li&gt;
&lt;li&gt;Annealing Stage 1：从Pretrain Stage 2中最好的checkpoint开始，训练500B的高质量文本&lt;/li&gt;
&lt;li&gt;Annealing Stage 2：将RoPE的base从10000提高到50000（扩充4k到8k的上下文），500B&lt;/li&gt;
&lt;li&gt;SFT&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Annealing：用更高质量的数据让模型“收敛得更好”&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;训练阶段（预训练+SFT）的损失函数同LLaDA&lt;/li&gt;
&lt;li&gt;预训练1%是随机长度，99%是4096定长（同LLaDA）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;moe-routing&#34;&gt;MoE Routing
&lt;/h4&gt;$$
p_t = \text{Softmax}(\text{Router}(h_t))\\
o_t = \sum_i p_{t,i}E_i(h_t), \quad \text{where }p_{t,i} \in\text{Topk}(p_t) 
$$&lt;ul&gt;
&lt;li&gt;$h_t$是hidden state&lt;/li&gt;
&lt;li&gt;$E$是专家网络&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MoE选取p最大的k个专家网络进行加权&lt;/p&gt;
&lt;p&gt;为了平衡负载，采用了标准的MoE auxiliary loss&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Load Balancing Loss&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$P_i$：token级的专家$i$被分配的平均概率&lt;/li&gt;
&lt;li&gt;$f_i$：经过所有token每个专家被选中的频率&lt;/li&gt;
&lt;li&gt;$N$​：专家数&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
$$
\mathcal{L}_{LB} = N\sum_{i=1}^N f_iP_i
$$&lt;p&gt;通过该损失避免某个专家被频繁选中&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Z-Loss
&lt;ul&gt;
&lt;li&gt;$z_t$表示$\text{Router}(h_t)$&lt;/li&gt;
&lt;li&gt;$z_{t,j}$即为第$j$个专家的打分&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
$$
\mathcal{L}_Z=\frac{1}{T}\sum_{i=1}^T\left(\log \sum_{j=1}^N e^{z_{t,j}}\right)^2
$$&lt;p&gt;通过该损失抑制logits分布，防止softmax极端化&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LLaDA-MoE为LB设置0.01权重，为Z-Loss设定0.001&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251113121116877.png&#34;
	width=&#34;961&#34;
	height=&#34;287&#34;
	srcset=&#34;https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251113121116877_hu_26c4e1f6b4f9a486.png 480w, https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251113121116877_hu_724a9d33bf924a8f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;334&#34;
		data-flex-basis=&#34;803px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251113121209495.png&#34;
	width=&#34;860&#34;
	height=&#34;614&#34;
	srcset=&#34;https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251113121209495_hu_6189f9ed1a7edf66.png 480w, https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251113121209495_hu_eb3f3b8def23f671.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;base&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;140&#34;
		data-flex-basis=&#34;336px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251113121225582.png&#34;
	width=&#34;1074&#34;
	height=&#34;584&#34;
	srcset=&#34;https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251113121225582_hu_c121207b1204ea1a.png 480w, https://example.com/p/llada-moe-asparse-moediffusion-language-model/assets/image-20251113121225582_hu_36f1f7b89ca3b2db.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;SFT&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;183&#34;
		data-flex-basis=&#34;441px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>UltraLLaDA Scaling the Context Length to 128K for Diffusion Large Language Models</title>
        <link>https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/</link>
        <pubDate>Tue, 11 Nov 2025 13:54:00 +0800</pubDate>
        
        <guid>https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2502.09992&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Large Language Diffusion Models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro
&lt;/h2&gt;&lt;h3 id=&#34;现象&#34;&gt;现象
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;扩散语言模型的Local perception&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2506.14429&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111142128339.png&#34;
	width=&#34;1951&#34;
	height=&#34;1195&#34;
	srcset=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111142128339_hu_b92255c0ca39e7db.png 480w, https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111142128339_hu_1c32c04fe496d8df.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;163&#34;
		data-flex-basis=&#34;391px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://aoijays.top/p/diffusion-language-model-birdresearch-202510/#long-context-phenomenology-of-diffusion-llms&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;LongLLaDA · 大海捞针实验&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LongLLaDA观测到这个现象是&lt;strong&gt;RoPE+双向上下文&lt;/strong&gt;带来的&lt;/li&gt;
&lt;li&gt;提出了一种Training Free的方法，调整了RoPE机制，提升上下文能力&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;关键挑战&#34;&gt;关键挑战
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;如何将AR LLM的上下文扩展技术（不重新预训练）迁移到DLM&lt;/li&gt;
&lt;li&gt;training-free在AR方面证明了效果不如post-training，是否对DLM也是一致的
&lt;ul&gt;
&lt;li&gt;希望模型通过后训练，调整内部机制&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核心贡献&#34;&gt;核心贡献
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;a Diffusion-aware NTK method
&lt;ul&gt;
&lt;li&gt;无需从头训练&lt;/li&gt;
&lt;li&gt;受神经切线核（Neural Tangent Kernel, NTK）理论启发，开发了一个适配DLM的NTK方法&lt;/li&gt;
&lt;li&gt;能适应扩散模型的迭代去噪特性，使 RoPE 可以稳定外推到 128K tokens&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;比较了后训练过程中使用的mask策略，分析对优化稳定性和长程回忆的影响&lt;/li&gt;
&lt;li&gt;UltraLLaDA，与LongLLaDA、LLaDA进行benchmark，证明是SOTA&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminary-work&#34;&gt;Preliminary Work
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;RoPE&lt;/strong&gt;：通过旋转向量的方式引入位置信息，旋转角度与位置index是线性关系&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;为了增加上下文，RoPE需要外推到更远的Token&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;外插：直接应用到更大的index，但是会造成信号失真与混乱（模型没见过这么大的）&lt;/li&gt;
&lt;li&gt;内插：等比例缩放index到小窗口内，但是会比较模糊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
$$
\cos(k\alpha^{\frac{-2i}{d}})\\
\cos(\frac{k}{\lambda}\alpha^{\frac{-2i}{d}})
$$&lt;p&gt;&lt;strong&gt;序列位置$k$的编码向量（维度为$d$）的第$i$个分量&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;NTK-Aware Scaling&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;定义如下：&lt;/p&gt;
$$
\lambda = \left(\frac{T_{target}}{T_{train}}\right)^{\frac{d}{d-2}}
$$&lt;p&gt;
将原本的底数$\alpha$转化为$\alpha\lambda$&lt;/p&gt;
$$
\cos(k(\alpha\lambda)^{\frac{-2i}{d}}) = \cos(k\alpha^{\frac{-2i}{d}}\left(\frac{T_{target}}{T_{train}}\right)^{\frac{-2i}{d-2}})
$$&lt;ul&gt;
&lt;li&gt;低维度：$i$比较小，频率高，$\frac{-2i}{d-2}$接近1，式子近似为$\cos(k\alpha ^ {\frac{-2i}{d}})$&lt;/li&gt;
&lt;li&gt;高维度：$i$比较大，频率低，$\frac{-2i}{d-2}$接近-1，式子近似为$\cos(\frac{k}{\lambda}\alpha^{\frac{-2i}{d}})$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;省流：高频部分外插，低频部分内插&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;上面都是定性的理解&lt;/p&gt;
&lt;p&gt;正确的公式实际是：&lt;/p&gt;
$$
\lambda_{baseline} = b^{-1}\cdot\left ( \frac{T_{target}}{2\pi} \right)^{\frac{d}{d_{crit}}},  
d_{crit} = 2\left \lceil \frac{d}{2}\log_b \frac{T_{train}}{2\pi} \right \rceil
$$&lt;blockquote&gt;
&lt;p&gt;b通常是10000&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;输入：$T_{target}, T_{train}$&lt;/li&gt;
&lt;li&gt;输出：$\lambda$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;LongLLaDA将此方法从AR LLM迁移到DLM，并且不进行后训练&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method
&lt;/h2&gt;&lt;p&gt;从最开始的现象已经说明，RoPE + 双向上下文是不可或缺的&lt;/p&gt;
&lt;p&gt;但是LongLLaDA没有任何关于双向上下文的适配，潜力没有被开发完全&lt;/p&gt;
&lt;h3 id=&#34;diffusion-aware-ntk-in-ultrallada&#34;&gt;Diffusion-aware NTK in UltraLLaDA
&lt;/h3&gt;&lt;p&gt;AR和DLM能看见的上下文窗口是不一样的&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AR LLM：$[-T_{train}-1,0]$&lt;/li&gt;
&lt;li&gt;DLM：$[-(T_{train}-1), T_{train}-1]$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DLM的真实上下文信息应该是2倍，因此需要对NTK的输入进行修正：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入：$T_{Ecap} \approx 2T_{target}, T_{cap} \approx 2T_{train}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111183735012.png&#34;
	width=&#34;539&#34;
	height=&#34;416&#34;
	srcset=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111183735012_hu_b77c22bce8c79b7c.png 480w, https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111183735012_hu_d91afef18895f313.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;129&#34;
		data-flex-basis=&#34;310px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;带来更小的频率，该缩放机制增加了所有维度上的RoPE周期&lt;/p&gt;
&lt;p&gt;从而有效减缓 RoPE 旋转速度，并延长所有注意力维度上的位置波长&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;case-study-of-masking-for-diffusion-llm-context-extension&#34;&gt;Case Study of Masking for Diffusion LLM Context Extension
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;后训练数据准备&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;来源：PG19&lt;/li&gt;
&lt;li&gt;处理：短文档通过拼接到达64k，长文档切割成64k的chunk&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;存在问题：&lt;strong&gt;跨文档干扰&lt;/strong&gt;，跨越文档边界进行注意力计算，错误吸收上下文信息&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AR：由于Causal Mask，只能看见之前的文档，天然限制了部分干扰&lt;/li&gt;
&lt;li&gt;DLM：能看见所有的文档，干扰非常强&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;处理策略（idea来自AR LLM）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;baseline：直接拼接，什么都不做&lt;/li&gt;
&lt;li&gt;Adaptive Attention Masking：只计算文档内部的注意力&lt;/li&gt;
&lt;li&gt;End-of-document：文档之间插入special token（并没有显式地禁止注意力跨文档），采用Full Attention&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111185846564.png&#34;
	width=&#34;974&#34;
	height=&#34;397&#34;
	srcset=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111185846564_hu_1d6deb03ba28f546.png 480w, https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111185846564_hu_66dfca3e11b2ed50.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;245&#34;
		data-flex-basis=&#34;588px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;对三种策略都进行了训练（结合前文所提NTK）&lt;/p&gt;
&lt;p&gt;训练参数：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111190447991.png&#34;
	width=&#34;945&#34;
	height=&#34;397&#34;
	srcset=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111190447991_hu_8499a077ed252911.png 480w, https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111190447991_hu_2b3a3f07530dfbc5.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;238&#34;
		data-flex-basis=&#34;571px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对特定任务采用不同策略训练的UltraLLaDA模型&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;后续的实验证明：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;采用直接拼接后训练的模型常产生不连贯结果，这可能是由于无关内容相互渗透所致&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments
&lt;/h2&gt;&lt;h3 id=&#34;train-free-ntk&#34;&gt;Train-Free NTK
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;目的：在Train-Free的情况下，修正NTK的上下文长度参数输入的作用&lt;/li&gt;
&lt;li&gt;方法：未做后训练，只修改编码方式进行测试&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111184208987.png&#34;
	width=&#34;364&#34;
	height=&#34;127&#34;
	srcset=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111184208987_hu_f5cdab02acb4203.png 480w, https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111184208987_hu_38ee98da8172c1fc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;286&#34;
		data-flex-basis=&#34;687px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111184247848.png&#34;
	width=&#34;431&#34;
	height=&#34;278&#34;
	srcset=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111184247848_hu_cb0896b057c69228.png 480w, https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111184247848_hu_1e0ffc824f1ebd29.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;155&#34;
		data-flex-basis=&#34;372px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结论：引入&lt;strong&gt;双向覆盖&lt;/strong&gt;对于扩展DLM的上下文长度至关重要&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;niah&#34;&gt;NIAH
&lt;/h3&gt;&lt;p&gt;Needle-in-a-haystack long-context retrieval task&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;该任务将单个相关语句嵌入长达 128K 标记的干扰文本中，要求模型准确检索目标语句&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111155906820.png&#34;
	width=&#34;1846&#34;
	height=&#34;773&#34;
	srcset=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111155906820_hu_89aa3fc2ffca11cc.png 480w, https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111155906820_hu_e24da556f251259a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;238&#34;
		data-flex-basis=&#34;573px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;全部100%检索成功&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于模型缺陷，LongLLaDA 无法进行 32K 以上的评估&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结论：后训练方法即使在极长上下文（128K）中仍能保持卓越的检索能力，而Train-Free会随上下文长度增加快速失效&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ppl&#34;&gt;PPL
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;基于PG19中128K长度的文档的语言建模困惑度评估&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111190938213.png&#34;
	width=&#34;718&#34;
	height=&#34;147&#34;
	srcset=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111190938213_hu_a51476eaaa67873e.png 480w, https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111190938213_hu_311910ab80f2cabd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;488&#34;
		data-flex-basis=&#34;1172px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结论：UltraLLaDA的训练在超长序列建模中具有很强的鲁棒性&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;longbench&#34;&gt;LongBench
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;截断在16K上下文长度（大部分任务只有这么长）
&lt;ul&gt;
&lt;li&gt;单/多文档问答、摘要、上下文学习、合成推理任务、代码补全&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111191347098.png&#34;
	width=&#34;730&#34;
	height=&#34;138&#34;
	srcset=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111191347098_hu_d4f035a04a506e20.png 480w, https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111191347098_hu_5575a6a54efc253d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;528&#34;
		data-flex-basis=&#34;1269px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结论：长上下文训练不仅扩展了上下文长度，即使在 16K 范围内（基线模型能力范围内）也能在挑战性任务上&lt;strong&gt;实现质量增益&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;归因于后训练过程带来的长距离连贯性与理解能力的提升&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ruler&#34;&gt;RULER
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;在4K至32K上下文长度下（涵盖检索、聚合、问答及多跳变量追踪任务）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111191700298.png&#34;
	width=&#34;927&#34;
	height=&#34;382&#34;
	srcset=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111191700298_hu_b0e50245ee924e09.png 480w, https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111191700298_hu_90c35c7c37ac0654.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;242&#34;
		data-flex-basis=&#34;582px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在检索（NIAH）和追踪（VT）类别中均展现出强劲的扩展性&lt;/li&gt;
&lt;li&gt;在聚合（AGG）及部分问答任务（QA）上的提升相对有限&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;消融实验&#34;&gt;消融实验
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;针对NTK和跨文档策略进行消融实验&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111192035623.png&#34;
	width=&#34;743&#34;
	height=&#34;177&#34;
	srcset=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111192035623_hu_b25f67a29a91e17a.png 480w, https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111192035623_hu_498e5b060ad7574c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;419&#34;
		data-flex-basis=&#34;1007px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111192105448.png&#34;
	width=&#34;922&#34;
	height=&#34;360&#34;
	srcset=&#34;https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111192105448_hu_1bb19d9f27b01aaa.png 480w, https://example.com/p/ultrallada-scaling-the-context-length-to-128k-for-diffusion-large-language-models/assets/image-20251111192105448_hu_decefa29b95b392d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;256&#34;
		data-flex-basis=&#34;614px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;EOD 拼接策略在较短或中等长度下表现更优&lt;/li&gt;
&lt;li&gt;在更长序列中，自适应掩码策略会反超EOD拼接&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>强化学习的数学原理 · Chap6 · Stochastic Approximation and SGD</title>
        <link>https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap6-stochastic-approximation-and-sgd/</link>
        <pubDate>Tue, 04 Nov 2025 22:53:00 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap6-stochastic-approximation-and-sgd/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1sd4y167NS&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1sd4y167NS&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;以计算采样数据的平均数为例&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;采样大量数据，最后一次性计算平均值&lt;/li&gt;
&lt;li&gt;采样一个算一次，迭代计算，手上的均值最终会趋向真实&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们采样第二种方法，记：&lt;/p&gt;
$$
w_{k+1} = \frac{1}{k}\sum_{i=1}^k x_i
$$&lt;p&gt;
则：&lt;/p&gt;
$$
\begin{split}
w_{k+1} &amp;= \frac{1}{k}\sum_{i=1}^k x_i = \frac{1}{k}(\sum_{i=1}^{k-1}x_i+x_k)\\
&amp;= \frac{1}{k}\left [ (k-1)w_k + x_k \right ] = w_k - \frac{1}{k}(w_k-x_k)
\end{split}
$$&lt;h2 id=&#34;robbins-monro-algorithm&#34;&gt;Robbins-Monro Algorithm
&lt;/h2&gt;&lt;p&gt;对于一个方程：&lt;/p&gt;
$$
g(w) = 0
$$&lt;p&gt;
我们希望求出解$w^&lt;em&gt;$，使得$g(w^&lt;/em&gt;) = 0$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;为了简化问题，$g(w)$是一个单调递增的函数&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果函数已知，我们可以通过牛顿迭代法求解&lt;/p&gt;
&lt;p&gt;但是如果函数未知，我们通过采样：&lt;/p&gt;
$$
y_k = g(w_k)
$$&lt;p&gt;
往往带有噪声：&lt;/p&gt;
$$
\widetilde{g}(w_k,\eta_k) = g(w_k) + \eta_k
$$&lt;p&gt;
我们定义一个迭代过程：&lt;/p&gt;
$$
w_{k+1} = w_k - a_k\widetilde{g}(w_k,\eta_k)
$$&lt;ul&gt;
&lt;li&gt;当$w_k&amp;gt;w^*$时，$g(w_k)&amp;gt;0$时
&lt;ul&gt;
&lt;li&gt;$w_{k+1} = w_k - a_k\widetilde{g}(w_k,\eta_k) &amp;lt; w_k$&lt;/li&gt;
&lt;li&gt;所以会往$w^*$走一步&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;当$w_k&amp;lt;w^*$时，$g(w_k)&amp;lt;0$​时
&lt;ul&gt;
&lt;li&gt;$w_{k+1} = w_k - a_k\widetilde{g}(w_k,\eta_k) &amp;gt; w_k$&lt;/li&gt;
&lt;li&gt;所以会往$w^*$走一步&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;但其实这个非常理想，条件也比较苛刻，需要满足&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$0&amp;lt;c_1\leq \nabla g(w)\leq c_2,\text{ for all } w$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$c_1$保证函数单调递增，且必然存在0解&lt;/li&gt;
&lt;li&gt;$c_2$​保证梯度有界，防止垂直&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\sum a_k = \infty, \sum a_k^2 &amp;lt; \infty$​&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;促进探索：$a_k$​是步长，若不趋近无穷，代表调整幅度与范围是有限的&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;抑制噪声：噪声的方差大致是$\sum a_k^2 \mathbb{E}\left| \eta_k^2\right |$，$\sum a_k^2 &amp;lt; \infty$​保证方差不会发散&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同时暗含了$a_k\to 0$，使得最后的$w^*$趋于定值&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\mathbb{E}(\eta_k|\mathcal{H}_k) =0, \text{ and }\mathbb{E}(\eta_k^2|\mathcal{H}_k &amp;lt; \infty)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;噪声条件期望为0，可以保证噪声是不依赖于历史的（不会随着采样步数增加而增加/减少，即不存在系统性偏移）&lt;/li&gt;
&lt;li&gt;条件方差不会无穷大，从而避免出现极端大的扰动，保证理论分析（如大数定律、中心极限定理）可用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;懒得纠结太多了&lt;/p&gt;
&lt;h2 id=&#34;stochastic-gradient-descent&#34;&gt;Stochastic Gradient Descent
&lt;/h2&gt;&lt;p&gt;随机梯度下降的目标是：&lt;/p&gt;
$$
\min_w \mathcal{J}(w) = \mathbb{E}\left[f(w,X)\right]
$$&lt;p&gt;
是一个含有随机变量的式子，需要优化一个参数$w$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Method1：&lt;strong&gt;Gradient Descent&lt;/strong&gt;，沿梯度的反方向走一个步长&lt;/li&gt;
&lt;/ul&gt;
$$
w_{k+1} = w_k -\alpha_k \nabla_w \mathbb{E}[f(w_k,X)]
$$&lt;p&gt;
但是实际上我们很难获得所有样本分布$X$（数据是收集不完的）&lt;/p&gt;
&lt;p&gt;所以这是一个理想的情况&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Method2：&lt;strong&gt;Batch Gradient Descent&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;考虑使用一个Batch进行近似&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
$$
\mathbb{E}[\nabla_wf(w_k,X)] \approx \frac{1}{n}\sum_i^n\nabla_w f(w_k,x_i)\\
w_{k+1} = w_k - \alpha_k  \frac{1}{n}\sum_i^n\nabla_w f(w_k,x_i)
$$&lt;p&gt;
但是每次迭代，都需把每一个Batch进行扫描，并不是很轻松&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Method3：&lt;strong&gt;Stochastic Gradient Descent&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;其实就是batch变成1了&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
$$
w_{k+1} = w_k - \alpha_k  \nabla_w f(w_k,x_i)
$$&lt;p&gt;
为了证明SGD算法是收敛的，我们可以尝试构造一个方程：&lt;/p&gt;
$$
g(w) = \mathbb{E}\left[\nabla_w f(w,X)\right] = 0
$$&lt;p&gt;
我们使用RM算法求解，则有：&lt;/p&gt;
$$
\widetilde{g}(w,\eta) = g(w) + \eta = \mathbb{E}\left[\nabla_w f(w,X)\right] + \eta
$$&lt;p&gt;
则有迭代式：&lt;/p&gt;
$$
w_{k+1} = w_k - a_k\widetilde{g}(w_k,\eta_k) = w_k - a_k\nabla_wf(w_k,x_k) 
$$&lt;p&gt;
所以事实上SGD就是一个RM&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;截止到此，后续内容我应该不会继续深入，理论性比较强&lt;/p&gt;
&lt;p&gt;之后如果有涉猎到的话再进行学习&lt;/p&gt;
</description>
        </item>
        <item>
        <title>强化学习的数学原理 · Chap5 · Monte Carlo Learning</title>
        <link>https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap5-monte-carlo-learning/</link>
        <pubDate>Mon, 03 Nov 2025 01:10:34 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap5-monte-carlo-learning/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1sd4y167NS&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1sd4y167NS&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;model&#34;&gt;Model
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;model-based：概率模型已知&lt;/li&gt;
&lt;li&gt;model-free：概率模型未知&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;抛硬币模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;model-based: 基于0.5的概率直接把期望、分布全部都算出来&lt;/li&gt;
&lt;li&gt;model-free: 重复采样多次，以样本均值作为期望&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;mc-basic&#34;&gt;MC Basic
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;最简单的基于蒙特卡洛的强化学习算法&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;本质上是转化Policy Iteration为Model-Free&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中Policy Iteration中的一步：&lt;/p&gt;
$$
\pi_{k+1}=\arg \max_\pi \sum_a \pi(a|s){\color{red}q_{\pi_k}(s,a)}, \quad s\in \mathcal{S}
$$&lt;p&gt;
其中这一步的action value可以表示为：&lt;/p&gt;
$$
\begin{split}
q_{\pi_k}(s,a) &amp;=\sum_{r}p(r|s,a)r+\gamma\sum_{s&#39;}p(s&#39;|s,a)v_{\pi_k}(s&#39;) \\ 
&amp;= \mathbb{E}\left[ G_t \mid S_t = s, A_t = a\right]
\end{split}
$$&lt;p&gt;
第一个公式是依赖于模型$p$的，而第二个公式就可以通过采样去近似&lt;/p&gt;
&lt;p&gt;基于状态$s$采取动作$a$，依据策略$\pi_k$，生成一个episode，记return为$g(s,a)$&lt;/p&gt;
&lt;p&gt;则我们可以将$g(s,a)$看作一个$G_t$的采样&lt;/p&gt;
&lt;p&gt;因此我们大量重复采样，得到序列$\left { g^{(j)}(s,a)\right }$&lt;/p&gt;
&lt;p&gt;则可以近似：&lt;/p&gt;
$$
q_{\pi_k}(s,a) = \mathbb{E}\left [ G_t\mid S_t = s,A_t = a \right] \approx\frac{1}{N}\sum_jg^{(j)}(s,a)
$$&lt;blockquote&gt;
&lt;p&gt;没有模型的时候，你最好有数据（统计学叫Sample，强化学习叫Experience）&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;因此整个算法的流程：&lt;/p&gt;
&lt;p&gt;从$\pi_0$出发，迭代到$k$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step1：Policy Evaluation
&lt;ul&gt;
&lt;li&gt;本质上就是希望得到所有的$q$&lt;/li&gt;
&lt;li&gt;对&lt;strong&gt;每一个$(s,a)$对&lt;/strong&gt;，生成大量的episodes&lt;/li&gt;
&lt;li&gt;计算均值，作为$q_{\pi_k}(s,a)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step2：Policy Improvement
&lt;ul&gt;
&lt;li&gt;贪心策略：$\pi_{k+1}$基于最大的$q$去选择&lt;/li&gt;
&lt;li&gt;这里和model-based是一样的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;因此我们可以直接通过这个方法得到$\pi$，而不是state value&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;但是算法效率比较差 后续有优化&lt;/p&gt;
&lt;p&gt;甚至这个算法也只是一个idea 没有具体的名字&lt;/p&gt;
&lt;p&gt;是作者取的&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Eposide Length是重要的、需要够长：采样的步数太短，会导致均值不够准确&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;mc-exploring-starts&#34;&gt;MC Exploring Starts
&lt;/h2&gt;&lt;p&gt;MC Basic的数据采样效率非常低&lt;/p&gt;
&lt;p&gt;需要对每一个$(s,a)$对进行大量采样&lt;/p&gt;
$$
s_1,a_1 \to s_2,a_5 \to {\color{red}s_1,a_2} \to s_2,a_3 \to a_5,a_1 \to ...
$$&lt;p&gt;
在MC Basic中，这一条episode只会用来计算最开始的$s_1,a_1$​的action value&lt;/p&gt;
&lt;p&gt;但其实中间的$s,a$对是可以当成一次采样的&lt;/p&gt;
&lt;p&gt;我们可以从两个角度开始优化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;复用&lt;/strong&gt;：我们希望一整条episode都能被利用，有两个方法
&lt;ul&gt;
&lt;li&gt;First Visit：只采样每个episode中每个$(s,a)$​第一次出现
&lt;ul&gt;
&lt;li&gt;样本独立&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Every Visit：每次出现$(s,a)$​都当成一次采样
&lt;ul&gt;
&lt;li&gt;样本更多，但是相关性会变强&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;即时更新&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Basic：跑完所有的episode，统一做一次Policy Improvement&lt;/li&gt;
&lt;li&gt;但可以用单个 episode的return来立即更新action value
&lt;ul&gt;
&lt;li&gt;本质上可以看作是Truncated Policy Improvement&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;算法流程：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;初始化策略$\pi_0$​&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;“Exploring starts”&lt;/strong&gt; 意思是：所有 (s, a) 都有可能成为 episode 的起点。&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;随机选择一个起点$s_0,a_0$​​——&lt;strong&gt;Exploring Starts&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;需要保证所有的状态都是非0的概率能作为起点&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;按照当前策略$\pi$生成一个episode&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;反向更新&lt;/strong&gt;（相当于后缀和，方便计算return）
&lt;ul&gt;
&lt;li&gt;每个$s,a$​会维护一个列表&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;First Visit&lt;/strong&gt;：如果当前$s,a$对是$(s_0,a_0,s_1,a_1,s_2,a_2,&amp;hellip;)$中没有出现过的（第一次出现）
&lt;ul&gt;
&lt;li&gt;将当前的return加入到对应列表&lt;/li&gt;
&lt;li&gt;计算列表中的均值，更新$q(s,a)$&lt;/li&gt;
&lt;li&gt;根据$q$实时更新$\pi$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;mc-epsilon-greedy&#34;&gt;MC Epsilon Greedy
&lt;/h2&gt;&lt;p&gt;但现实中Exploring Starts难以实现，有时候我们很难自由选择一个起点开始采样&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;你总不能每次采样一个起点，就搬动机器人过去一次吧&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;前两个算法之所以要对不同的$s,a$做采样，本质原因是：&lt;/p&gt;
$$
\pi(a|s) = \begin{cases}
 1 &amp; \text{ if } a=a^*(s) \\
 0 &amp; \text{ if } a\neq a^*(s)
\end{cases}
$$&lt;p&gt;
我们的策略是greedy的，因此会导致从真实起点出发，非常多的状态无法被覆盖到&lt;/p&gt;
&lt;p&gt;因此无法针对单一起点做反复采样&lt;/p&gt;
&lt;p&gt;所以我们可以考虑引入一点随机性：&lt;/p&gt;
$$
\pi(a|s) = \begin{cases}
 1-\frac{\varepsilon}{|\mathcal{A}(s)|}(|\mathcal{A}(s)|-1) &amp; \text{ for the greedy action }\\
 \frac{\varepsilon}{|\mathcal{A}(s)|} &amp; \text{ for the other }|\mathcal{A}(s)|-1 \text{ actions} 
\end{cases} \\
\text{where } \varepsilon \in [0,1] \text{ and } |\mathcal{A}(s)| \text{ is the number of actions.}
$$&lt;p&gt;
假设有5个action，其中greedy action是$a_0$，定义$\varepsilon=0.2$&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;action&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;$a_0$&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;$a_1$&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;$a_2$&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;$a_3$&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;$a_4$&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;probability&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.84&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.04&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.04&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.04&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.04&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;同时，我们可以保证任意时刻greedy action的概率都是最大的&lt;/p&gt;
&lt;p&gt;$\varepsilon=1$时，所有action概率相同&lt;/p&gt;
$$
1-\frac{\varepsilon}{|\mathcal{A}(s)|}(|\mathcal{A}(s)|-1)=1-\varepsilon + \frac{\varepsilon}{|\mathcal{A}(s)|} \geq \frac{\varepsilon}{|\mathcal{A}(s)|}
$$&lt;p&gt;算法维持了一个平衡：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;探索性：越大的$\varepsilon$带来越强的探索性，只要episode足够长，就能探索所有状态&lt;/li&gt;
&lt;li&gt;最优性：越大的$\varepsilon$带来的策略自然是更差的，因为每一步走向greedy的概率变低了&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;可以动态调整，一开始大，逐渐变小&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;算法流程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;去掉了Exploring Starts的条件：&lt;strong&gt;需要保证所有的状态都是非0的概率能作为起点&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;修改策略更新的分布&lt;/li&gt;
&lt;/ul&gt;
$$
\pi(a|s) = \begin{cases}
 1-\frac{\varepsilon}{|\mathcal{A}(s)|}(|\mathcal{A}(s)|-1) &amp;  a=a^*(s)\\
 \frac{\varepsilon}{|\mathcal{A}(s)|} &amp;  a\neq a^*(s)
\end{cases} \\
$$&lt;p&gt;
其他都是和前文算法一致&lt;/p&gt;
</description>
        </item>
        <item>
        <title>强化学习的数学原理 · Chap4 · Value Iteration and Policy Iteration</title>
        <link>https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap4-value-iteration-and-policy-iteration/</link>
        <pubDate>Fri, 31 Oct 2025 14:05:34 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap4-value-iteration-and-policy-iteration/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1sd4y167NS&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1sd4y167NS&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;value-iteration&#34;&gt;Value Iteration
&lt;/h2&gt;&lt;p&gt;基于BOE：&lt;/p&gt;
$$
v = f(v) = \max_\pi(r_\pi+\gamma P_\pi v)
$$&lt;p&gt;
我们不断做迭代：&lt;/p&gt;
$$
v_{k+1} = f(v_k), k=1,2,3,...
$$&lt;p&gt;
这个就是&lt;strong&gt;value iteration&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;整个算法可以拆成以下步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step1：&lt;strong&gt;Policy Update&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
$$
\pi_{k+1} = \arg\max_\pi (r_\pi+\gamma P_\pi v_k)
$$&lt;p&gt;
基于上一步的state value，找出当前最优的策略&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step2：&lt;strong&gt;Value Update&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
$$
v_{k+1} = r_{\pi_{k+1}} + \gamma P_{\pi_{k+1}}v_k
$$&lt;p&gt;基于该策略，更新所有的state value&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;理论上$v_k$不能被称为state value&lt;/p&gt;
&lt;p&gt;由于所有的state都是在优化过程，因此不能保证所有state都符合贝尔曼公式&lt;/p&gt;
&lt;p&gt;因此只是一个临时状态&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;从代码实现的角度：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step0：若$\left| v_k - v_{k-1}\right | &amp;gt; \text{eps}$
&lt;ul&gt;
&lt;li&gt;否则结束，说明收敛&lt;/li&gt;
&lt;li&gt;对所有的state，计算出所有的$q(s,a)$&lt;/li&gt;
&lt;li&gt;得到$a^*_k(s,a) = \arg \max_a q_k(s,a)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step1：&lt;/li&gt;
&lt;/ul&gt;
$$
\pi_{k+1}(a|s) = \begin{cases}
 1 &amp; \text{ if } a=a^*_k(s) \\
 0 &amp; \text{ if } a\neq a^*_k(s)
\end{cases}
$$&lt;p&gt;
这是一个&lt;strong&gt;贪心的策略&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step2：&lt;/li&gt;
&lt;/ul&gt;
$$
v_{k+1}(s) = \max_a q_k(s,a)
$$&lt;hr&gt;
&lt;p&gt;Value Iteration从当前的state value出发，决定了下一个Policy&lt;/p&gt;
&lt;p&gt;使用新的Policy去更新state value&lt;/p&gt;
&lt;h2 id=&#34;policy-iteration&#34;&gt;Policy Iteration
&lt;/h2&gt;&lt;p&gt;与之相比，还有一种迭代方式是以Policy作为基础&lt;/p&gt;
&lt;p&gt;与Value Iteration不同，我们的出发点是一个初始策略$\pi_0$&lt;/p&gt;
&lt;p&gt;进行如下迭代：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step1：Policy Evaluation
&lt;ul&gt;
&lt;li&gt;计算基于当前策略$\pi_k$的state value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
$$
v_{\pi_k} = r_{\pi_k} + \gamma P_{\pi_k} v_{\pi_k}
$$&lt;blockquote&gt;
&lt;p&gt;这里的求解依赖于一个迭代的过程&lt;/p&gt;
&lt;p&gt;因此整个Policy Iteration，内含一个小的迭代&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Step2：Policy Improvement
&lt;ul&gt;
&lt;li&gt;基于当前state value，找出最优策略&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
$$
\pi_{k+1} = \arg \max_\pi (r_\pi + \gamma P_\pi v_{\pi_k})
$$&lt;hr&gt;
&lt;p&gt;从代码实现的角度&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step1：$v_{\pi_k}$基于策略$\pi_k$不断迭代，直到$v_{\pi_k}$收敛&lt;/li&gt;
&lt;li&gt;Step2：基于$v_{\pi_k}$算出所有的$q_{\pi_k}$
&lt;ul&gt;
&lt;li&gt;得到$a^*_k(s,a) = \arg \max_a q_k(s,a)$​&lt;/li&gt;
&lt;li&gt;同样做以下事情：&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
$$
\pi_{k+1}(a|s) = \begin{cases}
 1 &amp; \text{ if } a=a^*_k(s) \\
 0 &amp; \text{ if } a\neq a^*_k(s)
\end{cases}
$$&lt;hr&gt;
&lt;p&gt;策略迭代会出现一个现象：接近终点的策略会先变好&lt;/p&gt;
&lt;p&gt;因为一开始都是乱七八糟的，接近终点的策略会更先找到方向&lt;/p&gt;
&lt;h3 id=&#34;truncated-policy-iteration&#34;&gt;Truncated Policy Iteration
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;policy：基于$\pi$进行policy evaluation，得到$v_\pi$，再policy improvement得到新的$\pi$&lt;/li&gt;
&lt;li&gt;value：基于$v$做policy update更新得到当前最优$\pi$，根据$\pi$做value update得到新的$v$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap4-value-iteration-and-policy-iteration/assets/image-20251102232322563.png&#34;
	width=&#34;1123&#34;
	height=&#34;383&#34;
	srcset=&#34;https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap4-value-iteration-and-policy-iteration/assets/image-20251102232322563_hu_95e27971edd8aef.png 480w, https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap4-value-iteration-and-policy-iteration/assets/image-20251102232322563_hu_19b5b271771fb834.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;293&#34;
		data-flex-basis=&#34;703px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;对两个算法进行对齐&lt;/p&gt;
&lt;p&gt;前面说了：Policy Iteration是一个大的迭代包含一个小的迭代过程&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap4-value-iteration-and-policy-iteration/assets/image-20251102232520153.png&#34;
	width=&#34;1035&#34;
	height=&#34;516&#34;
	srcset=&#34;https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap4-value-iteration-and-policy-iteration/assets/image-20251102232520153_hu_aa0a2884d994f8cb.png 480w, https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap4-value-iteration-and-policy-iteration/assets/image-20251102232520153_hu_be811e6b22dd5706.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;200&#34;
		data-flex-basis=&#34;481px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;而value iteration的第一次迭代得到的$v_1$，&lt;strong&gt;事实上就是Policy iteration小迭代中的第一个中间量&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们显然不会在这里进行无穷次的迭代&lt;/p&gt;
&lt;p&gt;所以这个&lt;strong&gt;迭代次数&lt;/strong&gt;就可以一般化成&lt;strong&gt;Truncated Policy Iteration（截断策略迭代）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当迭代次数为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1次：value iteration&lt;/li&gt;
&lt;li&gt;无穷次：policy iteration（因此这个算法不存在）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以Truncated Policy Iteration是两个算法的一般化形式&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap4-value-iteration-and-policy-iteration/assets/image-20251102232946384.png&#34;
	width=&#34;523&#34;
	height=&#34;464&#34;
	srcset=&#34;https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap4-value-iteration-and-policy-iteration/assets/image-20251102232946384_hu_13a39a4c8381ed16.png 480w, https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap4-value-iteration-and-policy-iteration/assets/image-20251102232946384_hu_e384f76161ea82cf.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;112&#34;
		data-flex-basis=&#34;270px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>强化学习的数学原理 · Chap3 · Bellman Optimality Equation</title>
        <link>https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap3-bellman-optimality-equation/</link>
        <pubDate>Thu, 30 Oct 2025 23:38:34 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap3-bellman-optimality-equation/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1sd4y167NS&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1sd4y167NS&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;笔记丢失了一次&lt;/p&gt;
&lt;p&gt;这是补档版本，稍微粗略一点……心态小炸&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;optimal-policy&#34;&gt;Optimal Policy
&lt;/h2&gt;&lt;p&gt;当一个策略，在任意状态都比另一个策略的state value更好（或者相等）&lt;/p&gt;
&lt;p&gt;我们就认为这个策略优于另一个策略&lt;/p&gt;
&lt;p&gt;当一个策略比所有策略都好，它就是&lt;strong&gt;最优策略&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;bellman-optimality-equation&#34;&gt;Bellman Optimality Equation
&lt;/h2&gt;$$
\begin{split}
v(s) &amp;= {\color{red}\max_\pi} \sum_a \pi(a|s) \left( \sum_r p(r|s,a)r + \gamma \sum_{s&#39;} p(s&#39;|s,a)v(s&#39;)\right), \quad \forall s\in \mathcal{S} \\
&amp;= {\color{red}\max_\pi} \sum_a \pi(a|s) q(s,a), \quad \forall s\in \mathcal{S}
\end{split}
$$&lt;p&gt;
相比于贝尔曼公式，BOE实质上就是多了一个优化问题&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;已知：$p(r|s,a),p(s&amp;rsquo;|s,a)$&lt;/li&gt;
&lt;li&gt;未知：$v(s),v(s&amp;rsquo;)$，需要我们针对不同的$\pi$​去计算&lt;/li&gt;
&lt;li&gt;求解：$\pi$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自然有向量形式：&lt;/p&gt;
$$
v = \max_\pi (r_\pi + \gamma P_\pi v)
$$&lt;h3 id=&#34;maximization&#34;&gt;Maximization
&lt;/h3&gt;&lt;p&gt;我们先考虑固定$v$，看看能不能求解$\pi$​&lt;/p&gt;
$$
v = \max_\pi\sum_a \pi(a|s)q(s,a)
$$&lt;p&gt;
其中$q(s,a)$自然也是一个已知的量（所有的$v$都可以知道，自然可以算出$q$）&lt;/p&gt;
&lt;p&gt;同时有：&lt;/p&gt;
$$
\sum_a \pi(a|s) = 1
$$&lt;p&gt;
那么本质上$\sum_a \pi(a|s)q(s,a)$是对action value做加权平均&lt;/p&gt;
&lt;p&gt;为了最大化这一项，我们肯定需要给最大的$q$最多的权值，也就是1&lt;/p&gt;
&lt;p&gt;可以得到策略：选择action最大的行动$a^*$&lt;/p&gt;
$$
\pi(a|s) = \begin{cases}
 1 &amp; \text{ if } a= a^*\\
 0 &amp; \text{ if } a\neq a^*
\end{cases}
$$&lt;p&gt;
这样我们就能得到原式：&lt;/p&gt;
$$
v = \max_\pi\sum_a \pi(a|s)q(s,a) = \max_{a\in \mathcal{A}(s)}q(s,a) \\
\text{where }a^* = \arg \max_a q(s,a)
$$&lt;p&gt;
只要我们固定$v$，我们肯定就能得到最优策略，自然计算出右边的值&lt;/p&gt;
&lt;p&gt;因此右边的值可以直接表示成一个只关于$v$的函数：$v=f(v)$&lt;/p&gt;
&lt;p&gt;表达成向量形式：&lt;/p&gt;
$$
f(v):=\max_\pi (r_\pi+\gamma P_\pi v)
$$&lt;blockquote&gt;
&lt;p&gt;搜索一下不动点定理或叫Contraction mapping theorem&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;基于这个定理，可以证明$f(v)$是符合这个定理的条件的&lt;/p&gt;
&lt;p&gt;大概就是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;函数具有压缩性：有$\left|v_1-v_2\right | \leq \gamma\left|f(v_1)-f(v_2)\right |$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也就是满足这个条件，就会有&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;必然存在&lt;strong&gt;唯一的&lt;/strong&gt;一个不动点$f(v) =v$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，我们可以不断套用$v,f(v),f(f(v)),&amp;hellip;$&lt;/p&gt;
&lt;p&gt;最后会&lt;strong&gt;收敛得到不动点&lt;/strong&gt;，具体证明略过&lt;/p&gt;
&lt;p&gt;实际上的操作就是：&lt;/p&gt;
$$
v_{k+1}=f(v_k) =\max_\pi (r_\pi+\gamma P_\pi v_k)
$$&lt;p&gt;
那么如何证明最后收敛到的结果$v^*$就是最优解呢？&lt;/p&gt;
&lt;p&gt;固定$v=v^&lt;em&gt;$，自然可以得到当前的策略$\pi^&lt;/em&gt;$&lt;/p&gt;
$$
\pi^* = \arg \max_\pi (r_\pi+\gamma P_\pi v^*)
$$&lt;p&gt;
将$\pi^*$代入：&lt;/p&gt;
$$
v^* = \max_\pi (r_\pi+\gamma P_\pi v_*) = r_{\pi^*}+\gamma P_{\pi^*} v^*
$$&lt;p&gt;
你会发现变成state value的公式了&lt;/p&gt;
&lt;p&gt;也就是说$v^&lt;em&gt;$，就是策略$\pi^&lt;/em&gt;$​的state value&lt;/p&gt;
&lt;p&gt;我们考虑策略替换成任意其他的策略$\pi$时：&lt;/p&gt;
$$
v^* = r_{\pi^*}+\gamma P_{\pi^*} v^* \geq r_\pi + \gamma P_\pi v^*
$$&lt;p&gt;
令该策略对应state value的贝尔曼公式：&lt;/p&gt;
$$
v = r_{\pi}+\gamma P_{\pi} v
$$&lt;p&gt;
做一个减法则有：&lt;/p&gt;
$$
v^*-v \geq (r_\pi + \gamma P_\pi v^*)-(r_{\pi}+\gamma P_{\pi} v) = \gamma P_\pi(v^*-v)
$$&lt;p&gt;令$\Delta = v^*-v$，则有：&lt;/p&gt;
$$
\Delta \geq \gamma P_\pi\Delta
$$&lt;p&gt;
我们只需要把右边的$\Delta$不停代换为$\gamma P_\pi\Delta$：&lt;/p&gt;
$$
\Delta \geq \gamma P_\pi\Delta \geq \gamma^2 P_\pi^2\Delta \geq ...  \geq \gamma^n P_\pi^n\Delta \geq 0
$$&lt;p&gt;
故对于策略$\pi^*$，其state value始终是最大的&lt;/p&gt;
&lt;p&gt;因此是最优策略&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Change $r\to ar+b$会发生什么？
&lt;ul&gt;
&lt;li&gt;什么都不会发生&lt;/li&gt;
&lt;li&gt;可以证明 $v&amp;rsquo; = av^*+\frac{b}{1-\gamma}I$，所有state value的相对大小没有发生变化&lt;/li&gt;
&lt;li&gt;自然action value不会有其他选择，policy不改变&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;如何鼓励走最短路径？
&lt;ul&gt;
&lt;li&gt;其实不用一直给agent做-1（损失能量），催促agent&lt;/li&gt;
&lt;li&gt;$\gamma$本身就在催促agent尽快到终点，否则终点的贡献变少了&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>强化学习的数学原理 · Chap2 · Bellman Equation</title>
        <link>https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap2-bellman-equation/</link>
        <pubDate>Thu, 30 Oct 2025 20:25:34 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap2-bellman-equation/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1sd4y167NS&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1sd4y167NS&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;state-value&#34;&gt;State Value
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;return 用来衡量不同的trajectory的好坏&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;首先有如下定义&lt;/p&gt;
$$
S_t \overset{A_t}{\rightarrow}R_{t+1}, S_{t+1}
$$&lt;ul&gt;
&lt;li&gt;$t$表示时间步&lt;/li&gt;
&lt;li&gt;从状态$S_t$出发，采取$A_t$，转移到$S_{t+1}$，获得了$R_{t+1}$的奖励&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;$S,A,R$​这里表示的是一个&lt;strong&gt;随机变量&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;因此上述内容服从以下概率分布：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$S_t \to A_t$ ：$\pi(A_t| S_t)$&lt;/li&gt;
&lt;li&gt;$S_t, A_t \to R_{t+1}$：$p(R_{t+1}| S_t,A_t)$&lt;/li&gt;
&lt;li&gt;$S_t, A_t \to S_{t+1}$：$p(S_{t+1}| S_t,A_t)$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;推广到多步骤之后：&lt;/p&gt;
$$
S_t \overset{A_t}{\rightarrow}R_{t+1}, S_{t+1} \overset{A_{t+1}}{\rightarrow}R_{t+2}, S_{t+2}\overset{A_{t+2}}{\rightarrow}R_{t+3} ...
$$&lt;p&gt;
则可以定义这个trajectory的reward是：&lt;/p&gt;
$$
G_t = R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3} + ...
$$&lt;blockquote&gt;
&lt;p&gt;$G_t$也表示一个随机变量&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;我们定义所有从$t$出发的trajectory的期望$G_t$，即为&lt;code&gt;state-value function&lt;/code&gt;or&lt;code&gt;state value&lt;/code&gt;&lt;/p&gt;
$$
v_\pi(s) = \mathbb{E}(G_t| S_t = s)
$$&lt;blockquote&gt;
&lt;p&gt;return 针对单个、单次的尝试（确定性的）&lt;/p&gt;
&lt;p&gt;state value是一种平均情况&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;bellman-equation&#34;&gt;Bellman Equation
&lt;/h2&gt;&lt;h3 id=&#34;递推形式&#34;&gt;递推形式
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;描述不同state的state value之间的关系&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;对于单个trajectory：&lt;/p&gt;
$$
\begin{split} 
G_t &amp;= R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3} + ...\\
 &amp;= R_{t+1} + \gamma \left(   R_{t+2} + \gamma^2 R_{t+3} + ...\right)\\
&amp;=  R_{t+1} + \gamma G_{t+1}
\end{split}
$$&lt;p&gt;
非常动态规划（或者叫递推）的一个步骤&lt;/p&gt;
&lt;p&gt;因此可以推广到期望的情况（事实上可以直接写）&lt;/p&gt;
$$
\begin{split}
v_\pi(s) &amp;= \mathbb{E}(G_t| S_t = s) \\
&amp;= \mathbb{E}(R_{t+1} + \gamma G_{t+1}| S_t = s) \\
&amp;=  \mathbb{E}(R_{t+1}| S_t = s) + \gamma  \mathbb{E}(G_{t+1}| S_t = s)
\end{split}
$$&lt;p&gt;
我们考虑去代换两个期望符号&lt;/p&gt;
&lt;p&gt;对于第一个期望，其意义是：从$s$出发，得到奖励的均值&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;始终注意：$R_{t+1}$代表是一个随机变量&lt;/p&gt;&lt;/blockquote&gt;
$$
\begin{split}
\mathbb{E}(R_{t+1}| S_t = s) &amp;= \sum_{a} \pi(a|s) \mathbb{E}(R_{t+1}| S_t=s,A_t = a) \\
 &amp;=\sum_a \pi(a|s) \sum_r p(r|s,a) r
\end{split}
$$&lt;p&gt;
对于第二个期望，其意义是：从下一个时刻$t+1$出发可以得到的期望奖励&lt;/p&gt;
$$
\begin{split}
 \mathbb{E}(G_{t+1}| S_t = s) &amp;= \sum_{s&#39;} \mathbb{E}(G_{t+1}| S_{t+1} = s&#39;) p(s&#39;| s) \\
 &amp;=\sum_{s&#39;} \mathbb{E}(G_{t+1}| S_{t+1} = s&#39;) \sum_{a}\pi(a| s)p(s&#39;| s,a)\\
 &amp;=\sum_{s&#39;} v_{\pi}(s&#39;) \sum_{a}\pi(a| s)p(s&#39;| s,a)
\end{split}
$$&lt;p&gt;
综上，整理一下原式子：&lt;/p&gt;
$$
\begin{split}
v_\pi(s) &amp;=  \mathbb{E}(R_{t+1}| S_t = s) + \gamma  \mathbb{E}(G_{t+1}| S_t = s) \\\\
&amp;= \sum_a \pi(a|s) \sum_r p(r|s,a) r+\gamma\sum_{s&#39;} v_{\pi}(s&#39;) \sum_{a}\pi(a| s)p(s&#39;| s,a)\\
&amp;= \sum_a \pi(a| s) \left[ \sum_r p(r| s,a)r + \gamma \sum_{s&#39;}p(s&#39;| s,a){\color{Red} v_\pi(s&#39;)} \right], \forall s\in S
\end{split}
$$&lt;blockquote&gt;
&lt;p&gt;这里的$S$是state space&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这样我们就得到了贝尔曼公式，由两个部分组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;immediate reward&lt;/li&gt;
&lt;li&gt;future reward&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通常我们会使用给定的$\pi(a|s)$​，因此这个过程可以被视作&lt;strong&gt;Policy Evaluation&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;$p(r|s,a),p(s&amp;rsquo;|s,a)$在这里是已知的&lt;/p&gt;
&lt;p&gt;但其实不知道也有办法去求解&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;向量形式&#34;&gt;向量形式
&lt;/h3&gt;&lt;p&gt;我们先把贝尔曼公式进行重写，用一些其他符号进行替代：&lt;/p&gt;
$$
v_\pi(s) = r_\pi(s) + \gamma \sum_{s&#39;} p_\pi(s&#39;|s)v_\pi(s&#39;)
$$&lt;p&gt;
表示基于策略$\pi$获取的当前奖励，以及之后的期望奖励&lt;/p&gt;
&lt;p&gt;我们令所有的状态依次编号为：$1\to n$&lt;/p&gt;
&lt;p&gt;对于状态$s_i$，其state value表示为：&lt;/p&gt;
$$
v_\pi(s_i) = r_\pi(s_i) + \gamma \sum_{s_j} p_\pi(s_j|s_i)v_\pi(s_j)
$$&lt;p&gt;
把所有$s_i$写在一起，自然就是向量形式：&lt;/p&gt;
$$
v_\pi = r_\pi + \gamma P_\pi v_\pi
$$&lt;ul&gt;
&lt;li&gt;$v_\pi = \left[ v_\pi(s_1), &amp;hellip;,v_\pi(s_n) \right ]^T \in  \mathbb{R}^n$&lt;/li&gt;
&lt;li&gt;$r_\pi = \left[ r_\pi(s_1), &amp;hellip;,r_\pi(s_n) \right ]^T \in  \mathbb{R}^n$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;并且有：&lt;/p&gt;
$$
P_\pi \in \mathbb{R}^{n\times n}, \text{where} \space [P_\pi]_{i,j} = p_\pi(s_j|s_i)
$$&lt;p&gt;理解一下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap2-bellman-equation/assets/image-20251030221530292.png&#34;
	width=&#34;596&#34;
	height=&#34;430&#34;
	srcset=&#34;https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap2-bellman-equation/assets/image-20251030221530292_hu_52e37a69891d55fb.png 480w, https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap2-bellman-equation/assets/image-20251030221530292_hu_d861de99c469b5a0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;matrix&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;138&#34;
		data-flex-basis=&#34;332px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;solve-state-values&#34;&gt;Solve State Values
&lt;/h3&gt;&lt;p&gt;我们需要通过state value衡量当前的policy的表现&lt;/p&gt;
&lt;p&gt;因此需要进行求解&lt;/p&gt;
&lt;h4 id=&#34;method-1--closed-form-solution&#34;&gt;Method 1 · closed-form solution
&lt;/h4&gt;$$
v_\pi = r_\pi + \gamma P_\pi v_\pi\\
(I-\gamma P_\pi)v_\pi = r_\pi\\
v_\pi = (I-\gamma P_\pi)^{-1}r_\pi
$$&lt;p&gt;
但是由于需要求逆矩阵，计算量过高，这个方法一般不会使用&lt;/p&gt;
&lt;h4 id=&#34;method-2--iterative-solution&#34;&gt;Method 2 · iterative solution
&lt;/h4&gt;$$
v_{\pi, k+1} = r_\pi + \gamma P_\pi v_{\pi,k}\\
$$&lt;p&gt;
我们不断迭代这个等式，可以使得最后有：&lt;/p&gt;
$$
v_{\pi,k} \to v_\pi = (I-\gamma P_\pi)^{-1}r_\pi, k \to \infty
$$&lt;h2 id=&#34;action-value&#34;&gt;Action Value
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;与state value相比，不止固定了当前的状态，action value同时固定了当前执行的动作&lt;/li&gt;
&lt;li&gt;action value意义很大，有时候我们倾向于采取能带来最大value的action&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;定义如下：&lt;/p&gt;
$$
q_\pi(s,a) = \mathbb{E}\left[G_t|S_t=s，A_t=a\right]
$$&lt;p&gt;
同时有：&lt;/p&gt;
$$
\underbrace{\mathbb{E}[G_t \mid S_t = s]}_{v_{\pi}(s)} = \sum_{a} \underbrace{\mathbb{E}[G_t \mid S_t = s, A_t = a]}_{q_{\pi}(s,a)} \pi(a \mid s)
$$&lt;p&gt;
因此：&lt;/p&gt;
$$
{\color{Red} v_\pi(s)}  = \sum_a \pi(a|s){\color{Red} q_\pi(s,a)}\\
 q_\pi(s,a) = \sum_r p(r| s,a)r + \gamma \sum_{s&#39;}p(s&#39;| s,a){\color{Red} v_\pi(s&#39;)}
$$&lt;ul&gt;
&lt;li&gt;第一个式子：通过所有action value，求解当前state value&lt;/li&gt;
&lt;li&gt;第二个式子：通过所有state value，求解当前action value&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;求解的方式比较多样&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过state value&lt;/li&gt;
&lt;li&gt;通过数据采样进行求解（后文）&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>强化学习的数学原理 · Chap1 · 基本概念</title>
        <link>https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</link>
        <pubDate>Wed, 29 Oct 2025 23:38:34 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-chap1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1sd4y167NS&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1sd4y167NS&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;概念定义&#34;&gt;概念定义
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;State&lt;/strong&gt;：$s$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;state space: the set of states $S = \left{ s_i \right }$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Action&lt;/strong&gt;：$a$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;action space of &lt;strong&gt;a state&lt;/strong&gt;: $\mathcal{A}(s_i) = \left{a_i \right}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;State Transition&lt;/strong&gt;：$s_i \overset{a}{\rightarrow} s_j$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在确定性的情况，可以使用S+A的表格进行标识&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;State Transition Probability&lt;/strong&gt;：表示成条件概率分布&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Policy&lt;/strong&gt;: determine what actions to take at a state&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\pi$：对于不确定的情况，同样是一个条件概率&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reward&lt;/strong&gt;: a real number we get &lt;strong&gt;after taking an action&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;positive/negative: it represents encouragement or punishment&lt;/li&gt;
&lt;li&gt;corner case
&lt;ul&gt;
&lt;li&gt;zero reward: no punishment&lt;/li&gt;
&lt;li&gt;can positive mean punishment: 取决于怎么设计&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reward本质上是一种人机交互的接口&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Trajectory&lt;/strong&gt;: a &lt;strong&gt;state-action-reward&lt;/strong&gt; chain&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$s_i\xrightarrow[a_i]{r_i}s_{i+1}\xrightarrow[a_{i+1}]{r_{i+1}}s_{i+2}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;return&lt;/strong&gt;: the sum of all the rewards along a trajectory&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;discounted return&lt;/strong&gt;：trajectory可能会无限长（走到终点之后仍有奇怪多余的操作），导致reward发散到无穷
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;discount rate&lt;/strong&gt;: $\gamma \in [0,1)$&lt;/li&gt;
&lt;li&gt;防止return发散，通过指数级别的系数累乘，保证return是收敛的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Episode&lt;/strong&gt;: the agent may stop at some terminal states, the resulting trajectory is called an episode(or a trial)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Episodic task（有终止任务）&lt;/li&gt;
&lt;li&gt;Continuing task（持续任务）&lt;/li&gt;
&lt;li&gt;在数学上，可以通过把 &lt;strong&gt;episodic task 转换为 continuing task&lt;/strong&gt; 来统一处理两类任务
&lt;ul&gt;
&lt;li&gt;Option 1：吸收状态 (absorbing state)，当智能体到达目标状态后，就&lt;strong&gt;永远停留在那里&lt;/strong&gt;，之后的奖励永远设为0&lt;/li&gt;
&lt;li&gt;Option2：普通状态 (normal state)，智能体可以离开目标状态，任务会继续，每次进入目标状态时都会获得奖励&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;数学与建模上使用Option2会更方便、统一，$\gamma$会控制一切&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;markov-decision-process--mdp&#34;&gt;Markov Decision Process · MDP
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Sets&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;State: the set of states$\mathcal{S}$&lt;/li&gt;
&lt;li&gt;Action: the set of actions $\mathcal{A}(s)$ is associated for state$s \in \mathcal{S}$&lt;/li&gt;
&lt;li&gt;Reward: the set of rewards $\mathcal{R}(s,a)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Probability distribution&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;State transition probability: at state $s$, taking action $a$, the probability to transit to state $s&amp;rsquo;$ is $p(s&amp;rsquo;|s, a)$&lt;/li&gt;
&lt;li&gt;Reward probability: at state $s$, taking action $a$, the probability to get reward $r$ is $p(r|s, a)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Policy: at state $s$, the probability to choose action a is $\pi(a|s)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Markov property&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$p(s_{t+1} | a_{t+1}, s_t, &amp;hellip;, a_1, s_0) = p(s_{t+1} | a_{t+1}, s_t)$&lt;/li&gt;
&lt;li&gt;$p(r_{t+1} | a_{t+1}, s_t, &amp;hellip;, a_1, s_0) = p(r_{t+1} | a_{t+1}, s_t)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Markov decision process&lt;/strong&gt; becomes &lt;strong&gt;Markov process&lt;/strong&gt; once the policy is given.&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;似乎这里的定义和比较官方的定义有一些差别&lt;/p&gt;
&lt;p&gt;MDP是一个在马尔可夫性质上的时序决策模型，由一个五元组定义：&lt;/p&gt;
$$
S,A,P,R,\gamma
$$&lt;ul&gt;
&lt;li&gt;状态集合State Space&lt;/li&gt;
&lt;li&gt;动作集合Action Space&lt;/li&gt;
&lt;li&gt;状态转移概率Transition Probability&lt;/li&gt;
&lt;li&gt;奖励函数Reward&lt;/li&gt;
&lt;li&gt;折扣因子Discount Factor&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个MDP的动态过程可以描述为一个与时间交互的循环：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;处于某个状态&lt;/li&gt;
&lt;li&gt;执行一个动作&lt;/li&gt;
&lt;li&gt;根据状态转移概率转移到某个状态&lt;/li&gt;
&lt;li&gt;获得动作的即时奖励&lt;/li&gt;
&lt;li&gt;重复&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Multimodal Diffusion Language Model · BirdResearch · 202510</title>
        <link>https://example.com/p/multimodal-diffusion-language-model-birdresearch-202510/</link>
        <pubDate>Fri, 17 Oct 2025 13:39:00 +0800</pubDate>
        
        <guid>https://example.com/p/multimodal-diffusion-language-model-birdresearch-202510/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;mmada-multimodal-large-diffusion-language-models&#34;&gt;MMaDA: Multimodal Large Diffusion Language Models
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先前的多模态架构混合，不同模态需要不同组件、不同数据处理方式&lt;/li&gt;
&lt;li&gt;扩散模型后训练策略欠缺研究&lt;/li&gt;
&lt;li&gt;如何文本与视觉模态协同学习、各方面性能超过各领域现有模型&lt;/li&gt;
&lt;li&gt;如何确保模型具有泛化能力&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/multimodal-diffusion-language-model-birdresearch-202510/assets/image-20251021144451915.png&#34;
	width=&#34;1127&#34;
	height=&#34;554&#34;
	srcset=&#34;https://example.com/p/multimodal-diffusion-language-model-birdresearch-202510/assets/image-20251021144451915_hu_a5cdfff39a893f5f.png 480w, https://example.com/p/multimodal-diffusion-language-model-birdresearch-202510/assets/image-20251021144451915_hu_a6e35a99ffe8ad82.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;compared to other llms&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;203&#34;
		data-flex-basis=&#34;488px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;核心贡献&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;统一Diffusion架构：消除模态专用组件，保持跨任务性能&lt;/li&gt;
&lt;li&gt;混合Long-CoT的后训练：统一CoT格式，对齐跨模态推理过程，协同训练&lt;/li&gt;
&lt;li&gt;UniGRPO：专用的强化学习方法&lt;/li&gt;
&lt;li&gt;SOTA：文本推理、多模态理解、文生图三方面均是SOTA（AR、混合、扩散）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/multimodal-diffusion-language-model-birdresearch-202510/assets/image-20251021150351731.png&#34;
	width=&#34;987&#34;
	height=&#34;772&#34;
	srcset=&#34;https://example.com/p/multimodal-diffusion-language-model-birdresearch-202510/assets/image-20251021150351731_hu_7714d48219f97e9f.png 480w, https://example.com/p/multimodal-diffusion-language-model-birdresearch-202510/assets/image-20251021150351731_hu_c7254ad29497536a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;TASKs&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;127&#34;
		data-flex-basis=&#34;306px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;method&#34;&gt;Method
&lt;/h3&gt;&lt;h4 id=&#34;pretrain&#34;&gt;Pretrain
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Data Tokenization
&lt;ul&gt;
&lt;li&gt;文本：采用&lt;strong&gt;LLaDA&lt;/strong&gt;的tokenizer&lt;/li&gt;
&lt;li&gt;图像：采用&lt;strong&gt;Show-o&lt;/strong&gt;所使用的pretrained image quantizer
&lt;ul&gt;
&lt;li&gt;基于&lt;strong&gt;MAGVIT-v2&lt;/strong&gt;架构（一个图像离散化模型）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;MAGVIT-v2的输入与输出&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入：单张静态图片的像素阵列、由多帧图像组成的序列&lt;/li&gt;
&lt;li&gt;输出：一个token序列&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;论文中采用$F=16$的下采样因子&lt;/p&gt;
&lt;p&gt;对于$H\times W$的图像，转化为一维的$\frac{H\times W}{F^2}$长度序列&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;统一的概率建模与目标
&lt;ul&gt;
&lt;li&gt;定义MMaDA为一个Mask Token Predictor，直接预测文本与图像的&lt;code&gt;[MASK]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;仅在&lt;code&gt;[MASK]&lt;/code&gt;的图像或文本Token上做统一交叉熵损失&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
$$
L_{unity}(\theta) = -E_{t,x_0,x_t}\left[\frac{1}{t}\sum_{i=1}^L I(x_t^i = [MASK])\log p_\theta (x_0^i|x_t)\right]
$$&lt;h4 id=&#34;post-training-with-mixed-long-cot-finetuning&#34;&gt;Post-Training with Mixed Long-CoT Finetuning
&lt;/h4&gt;&lt;p&gt;MMaDA明确面向：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;推理密集型任务（例如数学）&lt;/li&gt;
&lt;li&gt;具备World-knowledge-aware的文生图
&lt;ul&gt;
&lt;li&gt;事实一致性非常重要&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/multimodal-diffusion-language-model-birdresearch-202510/assets/image-20251021161828920.png&#34;
	width=&#34;1344&#34;
	height=&#34;583&#34;
	srcset=&#34;https://example.com/p/multimodal-diffusion-language-model-birdresearch-202510/assets/image-20251021161828920_hu_6214c2797a50c125.png 480w, https://example.com/p/multimodal-diffusion-language-model-birdresearch-202510/assets/image-20251021161828920_hu_4b28f5ab45f1859e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Long-CoT Finetuning&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;230&#34;
		data-flex-basis=&#34;553px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;为进行稳定的后训练，论文整理了一个包含三类核心任务（文本推理、多模态推理、文本到图像生成）CoT数据集&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;利用这篇数据，在RL之前通过SFT做冷启动&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;统一的CoT格式：消除不同任务的输出异构性&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;|&amp;lt;special_token&amp;gt;| &amp;lt;reasoning_process&amp;gt; |&amp;lt;special_token&amp;gt;| &amp;lt;result&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;后续证明了有益于跨模态的协同训练与对齐&lt;/p&gt;
&lt;p&gt;希望文本推理逻辑指导图像生成&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;多样性、复杂性、准确性
&lt;ul&gt;
&lt;li&gt;通过已有的LLM、VLM，合成多样化的数据&lt;/li&gt;
&lt;li&gt;使用模型过滤，只保留高质量、长形式的CoT样本&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MMaDA进行了混合任务的CoT微调&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;保留提示词，对response进行加噪&lt;/li&gt;
&lt;li&gt;通过预训练得到的Predictor进行损失计算&lt;/li&gt;
&lt;/ul&gt;
$$
L_{Mixed-SFT}(\theta) = -E_{t,p_0,r_0,r_t}\left[\frac{1}{t}\sum_{i=1}^{L&#39;} I(r_t^i = [MASK])\log p_\theta (r_0^i|p_0,r_t)\right]
$$&lt;h4 id=&#34;post-training-with-unified-rl&#34;&gt;Post-Training with Unified RL
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/multimodal-diffusion-language-model-birdresearch-202510/assets/image-20251021163518810.png&#34;
	width=&#34;2085&#34;
	height=&#34;1055&#34;
	srcset=&#34;https://example.com/p/multimodal-diffusion-language-model-birdresearch-202510/assets/image-20251021163518810_hu_909d17c24076e0b.png 480w, https://example.com/p/multimodal-diffusion-language-model-birdresearch-202510/assets/image-20251021163518810_hu_a2527497ddba309b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Training&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;197&#34;
		data-flex-basis=&#34;474px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;自回归模型：每个Token的条件概率都非常好计算，适合RL&lt;/li&gt;
&lt;li&gt;Diffusion：过程复杂，无法直接使用传统强化学习方法
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;局部掩码依赖&lt;/strong&gt;：只有&lt;code&gt;[MASK]&lt;/code&gt;处有预测概率，其他位置已知&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;掩码比例敏感&lt;/strong&gt;：训练必须兼容不同噪声程度的恢复
&lt;ul&gt;
&lt;li&gt;LLaDA采样大量样本，造成RL开销巨大&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;非自回归序列似然&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;AR模型：句子概率可以通过token概率乘积计算&lt;/li&gt;
&lt;li&gt;Diffusion：很难计算&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;unigrpo&#34;&gt;UniGRPO
&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;这部分搁置一下 后续补一下RL的知识&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;主要有三个关键点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;结构化加噪策略&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;序列对数似然近似为：被遮位置对数概率的平均&lt;/li&gt;
&lt;li&gt;用&lt;strong&gt;旧策略&lt;/strong&gt;和&lt;strong&gt;当前策略&lt;/strong&gt;的“近似序列似然”做&lt;strong&gt;比值&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;UniGPRO的奖励是多样化的&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文本推理奖励
&lt;ul&gt;
&lt;li&gt;答案正确奖励&lt;/li&gt;
&lt;li&gt;格式奖励（&lt;code&gt;&amp;lt;think&amp;gt;&amp;lt;think&amp;gt;&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;多模态推理奖励
&lt;ul&gt;
&lt;li&gt;同上&lt;/li&gt;
&lt;li&gt;CLIP奖励：使用原始 CLIP 分数衡量文本-图像的语义一致性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;文生图奖励
&lt;ul&gt;
&lt;li&gt;同上&lt;/li&gt;
&lt;li&gt;图像奖励：反映人类偏好得分&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;inference&#34;&gt;Inference
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;文本生成：采用半自回归采样
&lt;ul&gt;
&lt;li&gt;Masking Schedule采用线性计划，与LLaDA一致&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;图像生成：采用低置信度重掩码
&lt;ul&gt;
&lt;li&gt;余弦噪声调度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;experiments&#34;&gt;Experiments
&lt;/h3&gt;&lt;p&gt;一般的benchmark跳过&lt;/p&gt;
</description>
        </item>
        <item>
        <title>WSL2部署</title>
        <link>https://example.com/p/wsl2%E9%83%A8%E7%BD%B2/</link>
        <pubDate>Thu, 16 Oct 2025 21:55:42 +0800</pubDate>
        
        <guid>https://example.com/p/wsl2%E9%83%A8%E7%BD%B2/</guid>
        <description>&lt;h2 id=&#34;安装wsl&#34;&gt;安装WSL
&lt;/h2&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wsl --install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;如果你的系统不支持 &lt;code&gt;wsl --install&lt;/code&gt; ，可手动启用功能&lt;/p&gt;
&lt;p&gt;系统 &amp;gt; 可选功能 &amp;gt; 更多 Wndows 功能，打开 &lt;strong&gt;Hyper-V&lt;/strong&gt; 和&lt;strong&gt;适用于 Linux 的 Windows子系统&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;设置为wsl2&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wsl --set-default-version 2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;查看发行版本：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wsl --list --online
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;例如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;C:\Users\95443&amp;gt;wsl --list --online
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;以下是可安装的有效分发的列表。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;使用“wsl.exe --install &amp;lt;Distro&amp;gt;”安装。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;NAME                            FRIENDLY NAME
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;AlmaLinux-8                     AlmaLinux OS 8
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;AlmaLinux-9                     AlmaLinux OS 9
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;AlmaLinux-Kitten-10             AlmaLinux OS Kitten 10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;AlmaLinux-10                    AlmaLinux OS 10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Debian                          Debian GNU/Linux
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;FedoraLinux-42                  Fedora Linux 42
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;SUSE-Linux-Enterprise-15-SP6    SUSE Linux Enterprise 15 SP6
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;SUSE-Linux-Enterprise-15-SP7    SUSE Linux Enterprise 15 SP7
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Ubuntu                          Ubuntu
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Ubuntu-24.04                    Ubuntu 24.04 LTS
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;archlinux                       Arch Linux
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kali-linux                      Kali Linux Rolling
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;openSUSE-Tumbleweed             openSUSE Tumbleweed
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;openSUSE-Leap-16.0              openSUSE Leap 16.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Ubuntu-20.04                    Ubuntu 20.04 LTS
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Ubuntu-22.04                    Ubuntu 22.04 LTS
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;OracleLinux_7_9                 Oracle Linux 7.9
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;OracleLinux_8_10                Oracle Linux 8.10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;OracleLinux_9_5                 Oracle Linux 9.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;openSUSE-Leap-15.6              openSUSE Leap 15.6
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;我这边安装&lt;code&gt;Ubuntu-22.04 &lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 安装 Ubuntu-22.04 到默认位置
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 但这个方式有点看网速 你先别
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wsl --install -d Ubuntu-22.04
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;建议从中这里开始&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;网址：https://cloud-images.ubuntu.com/releases/22.04/release/&lt;/p&gt;
&lt;p&gt;选择这个：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ubuntu-22.04-server-cloudimg-amd64-root.tar.xz 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;创建路径&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mkdir D:\wsl\Ubuntu-22.04
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;将下载的压缩包导入&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 导入到指定目录&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;wsl&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Ubuntu&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;22.04&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;D&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;\&lt;span class=&#34;n&#34;&gt;wsl&lt;/span&gt;\&lt;span class=&#34;n&#34;&gt;Ubuntu&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;22.04&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;\&lt;span class=&#34;n&#34;&gt;Users&lt;/span&gt;\&lt;span class=&#34;mi&#34;&gt;95443&lt;/span&gt;\&lt;span class=&#34;n&#34;&gt;Downloads&lt;/span&gt;\&lt;span class=&#34;n&#34;&gt;ubuntu&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;22.04&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cloudimg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;amd64&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tar&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xz&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;后面那个是你下载的地址&lt;/p&gt;
&lt;p&gt;启动：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wsl -d Ubuntu-22.04
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然后这个时候应该是root用户&lt;/p&gt;
&lt;p&gt;我们创建一个user&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 创建新用户并设置密码
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;adduser biribiribird
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 将用户添加到sudo组
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;usermod -aG sudo biribiribird
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# sudo vim /etc/wsl.conf
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;插入内容：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[user]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;default = biribiribird
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这样启动wsl的默认用户就确定了&lt;/p&gt;
&lt;p&gt;回到windows&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 关闭所有 WSL 实例
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wsl --shutdown
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# 重新启动 Ubuntu-22.04 生效默认用户
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wsl -d Ubuntu-22.04
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;设置一下默认的wsl&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wsl --set-default Ubuntu-22.04
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wsl -l -v # 检查
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>Vscode &#43; LaTeX</title>
        <link>https://example.com/p/vscode--latex/</link>
        <pubDate>Sun, 12 Oct 2025 01:20:42 +0800</pubDate>
        
        <guid>https://example.com/p/vscode--latex/</guid>
        <description>&lt;h2 id=&#34;安装tex&#34;&gt;安装TeX
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.tug.org/texlive/acquire-iso.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Acquiring TeX Live as an ISO image - TeX Users Group&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/vscode--latex/assets/image-20251012012138658.png&#34;
	width=&#34;1060&#34;
	height=&#34;402&#34;
	srcset=&#34;https://example.com/p/vscode--latex/assets/image-20251012012138658_hu_8585c01d881c09a.png 480w, https://example.com/p/vscode--latex/assets/image-20251012012138658_hu_34db2544ede245f3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;下载TeX&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;263&#34;
		data-flex-basis=&#34;632px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;选择&lt;code&gt;.iso&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/vscode--latex/assets/image-20251012012206663.png&#34;
	width=&#34;1119&#34;
	height=&#34;507&#34;
	srcset=&#34;https://example.com/p/vscode--latex/assets/image-20251012012206663_hu_28a9bef1128045c6.png 480w, https://example.com/p/vscode--latex/assets/image-20251012012206663_hu_cc9975be6a5879b2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;iso&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;220&#34;
		data-flex-basis=&#34;529px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;下载之后点击&lt;code&gt;.iso&lt;/code&gt;打开&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/vscode--latex/assets/image-20251012015346264.png&#34;
	width=&#34;731&#34;
	height=&#34;541&#34;
	srcset=&#34;https://example.com/p/vscode--latex/assets/image-20251012015346264_hu_ab08f1137428fdcd.png 480w, https://example.com/p/vscode--latex/assets/image-20251012015346264_hu_3ca8b5d893b6fa12.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;.bat&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;135&#34;
		data-flex-basis=&#34;324px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;安装脚本&lt;/p&gt;
&lt;h2 id=&#34;vscode&#34;&gt;Vscode
&lt;/h2&gt;&lt;p&gt;安装LaTex Workshop扩展&lt;/p&gt;
&lt;p&gt;setting.json&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;latex-workshop.latex.recipes&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;xelatex&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;tools&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;xelatex&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;xelatex&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;latex-workshop.latex.tools&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;xelatex&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;command&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;xelatex&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;args&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;-synctex=1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;-interaction=nonstopmode&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;-file-line-error&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;%DOC%&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;latex-workshop.latex.recipe.default&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;lastUsed&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;editor.mouseWheelZoom&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;latex-workshop.view.pdf.sidebar.view&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;null&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>Python · uv指南</title>
        <link>https://example.com/p/python-uv%E6%8C%87%E5%8D%97/</link>
        <pubDate>Thu, 02 Oct 2025 16:20:42 +0800</pubDate>
        
        <guid>https://example.com/p/python-uv%E6%8C%87%E5%8D%97/</guid>
        <description>&lt;h2 id=&#34;uv&#34;&gt;UV
&lt;/h2&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install uv
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;uv --version
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mkdir myproject &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; myproject
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;uv init
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;生成一个虚拟环境&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;uv venv
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/python-uv%E6%8C%87%E5%8D%97/assets/image-20251002162431959.png&#34;
	width=&#34;513&#34;
	height=&#34;80&#34;
	srcset=&#34;https://example.com/p/python-uv%E6%8C%87%E5%8D%97/assets/image-20251002162431959_hu_53d2e7fafb00b28b.png 480w, https://example.com/p/python-uv%E6%8C%87%E5%8D%97/assets/image-20251002162431959_hu_70ae41dae5734de.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;641&#34;
		data-flex-basis=&#34;1539px&#34;
	
&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt; .venv/bin/activate &lt;span class=&#34;c1&#34;&gt;# 启动环境&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;deactivate &lt;span class=&#34;c1&#34;&gt;# 关闭环境&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>Diffusion Language Model · BirdResearch · 202510</title>
        <link>https://example.com/p/diffusion-language-model-birdresearch-202510/</link>
        <pubDate>Wed, 01 Oct 2025 15:54:00 +0800</pubDate>
        
        <guid>https://example.com/p/diffusion-language-model-birdresearch-202510/</guid>
        <description>&lt;h2 id=&#34;ar-llm&#34;&gt;AR LLM
&lt;/h2&gt;&lt;p&gt;对于自回归模型，假设输入是：&lt;code&gt;[你, 好, ！]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;词汇表是：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0: &amp;lt;pad&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;1: 你
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;2: 好
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;3: 我
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;4: 很
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;5: 好
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;6: ！
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;7: &amp;lt;eos&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008181120131.png&#34;
	width=&#34;966&#34;
	height=&#34;655&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008181120131_hu_a8cad21da2d3ad7b.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008181120131_hu_7c248c0bc453526d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20251008181120131&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;147&#34;
		data-flex-basis=&#34;353px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;dream-7b-diffusion-large-language-models&#34;&gt;Dream 7B: Diffusion Large Language Models
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2508.15487&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2508.15487 Dream 7B: Diffusion Large Language Models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008113335209.png&#34;
	width=&#34;1492&#34;
	height=&#34;465&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008113335209_hu_640220d5a4a7936d.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008113335209_hu_ebb3f34c95380aba.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Performance&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;320&#34;
		data-flex-basis=&#34;770px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;问题：
&lt;ul&gt;
&lt;li&gt;AR模型对于需要整体考虑的任务（长期规划、多约束）场景表现差&lt;/li&gt;
&lt;li&gt;AR模型对于长文本的一致性较差&lt;/li&gt;
&lt;li&gt;在各类通用任务中，要达到与Qwen2.5等顶尖自回归模型相当的性能仍存在显著差距&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;贡献：
&lt;ul&gt;
&lt;li&gt;基于&lt;strong&gt;自回归的LLM 初始化&lt;/strong&gt;和&lt;strong&gt;上下文自适应噪声调度技术&lt;/strong&gt;来实现扩散语言模型的规模化&lt;strong&gt;训练&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Dream 7B Base和Dream 7B Instruct&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;approach&#34;&gt;Approach
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008193402415.png&#34;
	width=&#34;846&#34;
	height=&#34;343&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008193402415_hu_62334379a41411ae.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008193402415_hu_287610e7745136e9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Dream&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;246&#34;
		data-flex-basis=&#34;591px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用Transformer以偏移方式，预测所有&lt;code&gt;[MASK]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常规的MDM是直接预测对应位置的&lt;code&gt;[MASK]&lt;/code&gt;，需要重新训练一个新的Transformer&lt;/p&gt;
&lt;h4 id=&#34;ar-based-llm-initialization&#34;&gt;AR-based LLM Initialization
&lt;/h4&gt;&lt;p&gt;自回归模型的训练目标就是使用第$i$个隐藏状态预测$i+1$的token&lt;/p&gt;
&lt;p&gt;因此我们以偏移方式进行预测，没有打破这种位置关系&lt;/p&gt;
&lt;p&gt;因此将已有的自回归模型参数作为初始值&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;保留AR模型的知识&lt;/li&gt;
&lt;li&gt;加速收敛&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;context-adaptive-token-level-noise-rescheduling&#34;&gt;Context-Adaptive Token-Level Noise Rescheduling
&lt;/h4&gt;&lt;p&gt;先前衡量噪声程度一般都是句子级别的：LLaDA衡量某个句子在$t$时刻的权重是$\frac{1}{t}$&lt;/p&gt;
&lt;p&gt;本文发现不同token之间的上下文信息是不同的，因此需要对噪声的衡量更加精细，避免学习的不平衡&lt;/p&gt;
&lt;p&gt;公式化地，定义损失函数：&lt;/p&gt;
$$
L(\theta) = -\mathbb{E}_{x_0,t,x_t}\sum_{i=1}^{L}1\left [x_t^i=M\right] \cdot w(t,x_t,i) \cdot \log p_\theta(x_0^i\mid x_t)
$$&lt;p&gt;
对于LLaDA，其$w(t,x_t,i) = \frac{1}{t}$&lt;/p&gt;
&lt;p&gt;考虑对于某个token的上下文信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;距离越近的&lt;code&gt;unmask&lt;/code&gt;的token提供的信息越丰富&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此论文定义为：&lt;/p&gt;
$$
w(t,x_t,i) = \frac{1}{2}\sum_{j=1}^L\left [x_t^j\neq M\right] Geo(p, |i-j|-1)
$$&lt;p&gt;
其中$Geo$表示几何分布核：&lt;/p&gt;
$$
Geo(p,d) = (1-p)^d\cdot p, \quad d\geq 0
$$&lt;ul&gt;
&lt;li&gt;距离$d$越大，贡献越小&lt;/li&gt;
&lt;li&gt;超参数$p$：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008202642071.png&#34;
	width=&#34;1139&#34;
	height=&#34;602&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008202642071_hu_ad3745440641ea7f.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008202642071_hu_9cf88da2296088af.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;超参数p&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;189&#34;
		data-flex-basis=&#34;454px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;train&#34;&gt;Train
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Dream-7B采用了与Qwen2.5-7B完全相同的Transformer架构配置&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pretrain&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SFT&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;采用了之前的技巧，训练上与LLaDA没什么不同（注意损失函数）&lt;/p&gt;
&lt;h3 id=&#34;experiment&#34;&gt;Experiment
&lt;/h3&gt;&lt;h4 id=&#34;base模型&#34;&gt;Base模型
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008211344486.png&#34;
	width=&#34;1013&#34;
	height=&#34;712&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008211344486_hu_530b344c72b58167.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008211344486_hu_e41e555b15c86c6f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;benchmark&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;142&#34;
		data-flex-basis=&#34;341px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;推理任务中（ARC-E、ARC-C）表现良好&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;规划任务中领先幅度巨大&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;训练数据量非常小&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;结论：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;初始化策略和上下文自适应噪声调度有效性&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;dream-instruct&#34;&gt;Dream-Instruct
&lt;/h4&gt;&lt;p&gt;180万条数据，进行3轮微调&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008212201828.png&#34;
	width=&#34;1224&#34;
	height=&#34;556&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008212201828_hu_215f137c20397b9a.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008212201828_hu_de627354d9bd135e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;220&#34;
		data-flex-basis=&#34;528px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;论文中没做分析&lt;/li&gt;
&lt;li&gt;这里和LLaDA一样，SFT之后效果落后，甚至出现了性能下降&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;扩散大语言模型在遵循指令任务中具备与基于自回归的大语言模型相匹敌的潜力，为未来高级扩散大语言模型后训练方案奠定了基础&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;ar-initialization的贡献&#34;&gt;AR Initialization的贡献
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;验证：AR LLM初始化是有效的&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实验设计：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLaMA3.2-1B参数初始化的Dream-1B和从头训练的Dream1B&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008213718155.png&#34;
	width=&#34;1266&#34;
	height=&#34;825&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008213718155_hu_e7ebe20ad61e1c37.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008213718155_hu_81eed865a386611d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Loss 对比&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;153&#34;
		data-flex-basis=&#34;368px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Loss始终更低，证明了初始化是有效的&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同时在这个实验中，论文说明了学习率的影响非常大：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大的学习率：破坏AR LLM的有益特性&lt;/li&gt;
&lt;li&gt;小的学习率：阻碍学习扩散的过程&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（但似乎没写上下文自适应噪声调度机制的消融实验）&lt;/p&gt;
&lt;h4 id=&#34;planning-ability&#34;&gt;Planning Ability
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008214118368.png&#34;
	width=&#34;1535&#34;
	height=&#34;458&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008214118368_hu_87ecdcf0260af463.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008214118368_hu_66b211674994c51b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;规划能力对比&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;335&#34;
		data-flex-basis=&#34;804px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dream 模型在两项任务中始终优于其他同等规模的基线模型&lt;/li&gt;
&lt;li&gt;扩散语言模型在解决涉及多重约束或特定目标优化的问题时具有天然优势（？）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;trade-off&#34;&gt;Trade-off
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008214402200.png&#34;
	width=&#34;987&#34;
	height=&#34;692&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008214402200_hu_8669f15f499a63cc.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008214402200_hu_34d18c98a9954339.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Trade-off&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;142&#34;
		data-flex-basis=&#34;342px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Diffusion language models provide a unique advantage through their adjustable inference process&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;基于时间步长的方法为推理时缩放引入了新的维度，可与现有技术协同工作，例如 OpenAI o1和DeepSeek R1等大型语言模型中使用的思维链推理&lt;/li&gt;
&lt;li&gt;这种可调节的计算质量权衡代表了扩散模型区别于传统自回归模型的关键优势。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;llada-15-variance-reduced-preference-optimization-for-large-language-diffusion-models&#34;&gt;LLaDA 1.5: Variance-Reduced Preference Optimization for Large Language Diffusion Models
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2505.19223&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2505.19223 LLaDA 1.5: Variance-Reduced Preference Optimization for Large Language Diffusion Models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008221825427.png&#34;
	width=&#34;1719&#34;
	height=&#34;730&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008221825427_hu_d7188d0aed1b164.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008221825427_hu_6a39ec4afc25f7a1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;LLaDA1.5&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;235&#34;
		data-flex-basis=&#34;565px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;看不懂&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;大概就是通过VRPO这个方法，基于LLaDA的工作，对LLaDA-instruct进行RL&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008234343570.png&#34;
	width=&#34;877&#34;
	height=&#34;636&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008234343570_hu_66310da504c89ddc.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008234343570_hu_5e68522af6e9a73.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;LLaDA RL&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;137&#34;
		data-flex-basis=&#34;330px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;longllada-unlocking-long-context-capabilities-in-diffusion-llms&#34;&gt;LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2506.14429&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2506.14429  LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008235711746.png&#34;
	width=&#34;1304&#34;
	height=&#34;432&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008235711746_hu_cdf13d8671fc9b92.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251008235711746_hu_37b525e60acea430.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;长上下文对比&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;301&#34;
		data-flex-basis=&#34;724px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;核心问题：扩散型LLMs在长文本处理领域的研究空白&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为什么扩散LLM在直接长度外推时保持稳定的困惑度并呈现&lt;strong&gt;局部感知特性&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;针对自回归 LLM 建立的长度扩展技术能否迁移至扩散架构&lt;/li&gt;
&lt;li&gt;自回归基线相比，扩散 LLM 在长上下文基准测试中表现如何？会显现哪些独特能力或局限性？&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;贡献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;揭示了其在上下文外推过程中保持稳定困惑度和局部感知的独特特性，并通过RoPE机制进行了解释&lt;/li&gt;
&lt;li&gt;基于 NTK 的 RoPE 外推法与缩放定律可无缝迁移至扩散 LLMs，实现 6 倍上下文扩展&lt;/li&gt;
&lt;li&gt;benchmark表明：扩散 LLMs 在&lt;strong&gt;检索任务&lt;/strong&gt;中与自回归模型表现相当，在&lt;strong&gt;聚合任务&lt;/strong&gt;中稍显不足，但在&lt;strong&gt;问答任务&lt;/strong&gt;中表现卓越&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;long-context-phenomenology-of-diffusion-llms&#34;&gt;Long-Context Phenomenology of Diffusion LLMs
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;大海捞针测试（Needle-In-A-Haystack, NIAH）&lt;/p&gt;
&lt;p&gt;在一个超长的上下文（haystack，干草堆）里，研究者会插入一小段关键信息（needle，针）&lt;/p&gt;
&lt;p&gt;模型的任务是：在生成或问答过程中，能否准确地“找到”并使用这段信息。&lt;/p&gt;
&lt;p&gt;这类测试会改变针的位置（例如放在靠前、中间或靠后部分）以及上下文的总长度，用来观察模型在不同深度和不同长度下的表现。&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;实验目的：揭示扩散 LLM 在长上下文中出现的&lt;strong&gt;局部感知 (local perception)&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实验设计：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;输入：在不同长度（最多32k）的长上下文中插入一个needle&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;输出：限定模型输出最多32个token&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实验对象&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DLM：block size = 32，采样步数 = 32&lt;/li&gt;
&lt;li&gt;LLM：默认&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;评估指标&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;找到Needle的成功率&lt;/li&gt;
&lt;li&gt;模型在不同深度（前文、中间、后文）找到Needle的能力&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009004938065.png&#34;
	width=&#34;1135&#34;
	height=&#34;686&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009004938065_hu_335374cd5412e855.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009004938065_hu_befee1c766cd6b1e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;LLaDA与LLaMA系列实验结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;165&#34;
		data-flex-basis=&#34;397px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;附录中补充了其他DLM模型的实验&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;AR LLM在8K内的上下文表现完美，超过8K长度无法完成任何任务&lt;/li&gt;
&lt;li&gt;DLM出现了类似**滑动窗口（窗口长度为4k）**的表现&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DLM受采样步数影响较大，因此定量补充了实验：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009005810059.png&#34;
	width=&#34;1169&#34;
	height=&#34;749&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009005810059_hu_546e20570a7401cb.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009005810059_hu_181f5578c1ab51ce.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Sample Step&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;156&#34;
		data-flex-basis=&#34;374px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;表明扩散 LLMs 的长上下文性能虽受采样步数影响，但仍受限于模型支持的最大上下文长度&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;机制分析&#34;&gt;机制分析
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;自回归只能看见后续的：$[0, T_{train} - 1]$（LLaMA的$T_{train} = 8192$​）&lt;/li&gt;
&lt;li&gt;DLM是双向注意力：$[1-T_{train},T_{train}-1]$（LLaDA的$T_{train}=4096$）
&lt;ul&gt;
&lt;li&gt;对于单个token，可以同时出现在左边的上下文窗口，也可以出现在右边的上下文窗口&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009100213544.png&#34;
	width=&#34;1890&#34;
	height=&#34;919&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009100213544_hu_57b583127a349bfd.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009100213544_hu_9380a40281cc2024.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;context&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;205&#34;
		data-flex-basis=&#34;493px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;留坑：RoPE&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;LLaMA完全丢失了负相对位置的信息，外推能力受限&lt;/li&gt;
&lt;li&gt;LLaDA虽然$T_{train}$比较小，但是能够接受到一个负正窗口&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;LLaMA：只学习了从头往后一个个token读取的能力&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;它可以知道，第2个token是第1个token的后一个……第1000个token是第999个token的后一个……&lt;/p&gt;
&lt;p&gt;（像翻书一样可以一页一页翻）&lt;/p&gt;
&lt;p&gt;但是一旦碰到第10000页，它推理不出这是9999页过来的（超出上下文，没有学习过这种关系）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LLaDA：双向上下文&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可以推断出9999是10000的前一页&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;论文补充了t-SNE可视化实验&lt;/p&gt;
&lt;p&gt;观察了两个模型最后的Q和K states&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009140617445.png&#34;
	width=&#34;2054&#34;
	height=&#34;955&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009140617445_hu_3136df464a2be127.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009140617445_hu_d78712eecfc63560.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;t-SNE&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;215&#34;
		data-flex-basis=&#34;516px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLaDA随着上下文长度增加，仍然保持形状&lt;/li&gt;
&lt;li&gt;LLaMA出现了明显的聚类分离，表示内部出现了&lt;code&gt;distribution shift&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;context-extension&#34;&gt;Context Extension
&lt;/h3&gt;&lt;p&gt;将 &lt;strong&gt;NTK-based RoPE extrapolation&lt;/strong&gt;（一种在自回归 LLM 中已验证的旋转位置嵌入扩展方法）迁移到扩散式 LLM&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;缩放旋转基数 β0&lt;/strong&gt;，让正弦/余弦函数周期变长，相当于“拉伸坐标轴”，从而容纳更长的上下文&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009142455144.png&#34;
	width=&#34;1226&#34;
	height=&#34;718&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009142455144_hu_c1933c2297845371.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009142455144_hu_662f939c281b78cd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;base&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;170&#34;
		data-flex-basis=&#34;409px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009142511056.png&#34;
	width=&#34;1223&#34;
	height=&#34;702&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009142511056_hu_2f6517f50f9ebb35.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009142511056_hu_70ac19fca8c8e977.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;instruct&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;174&#34;
		data-flex-basis=&#34;418px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;小幅扩展有效&lt;/strong&gt;： 8k 或 16k，几乎在所有深度下都保持接近 100% 的检索准确率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;中等扩展出现性能下降&lt;/strong&gt;：24k ，出现lost-in-the-middle现象&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;自回归模型中同样有的现象&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;大规模扩展失败&lt;/strong&gt;：模型无法再有效外推，说明方法的实际上限已到达。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;附录中对同类的DLM做了相同的实验&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;experiment-1&#34;&gt;Experiment
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;SD、MD、Sum 和 Syn 分别代表单文档问答、多文档问答、摘要和合成任务&lt;/p&gt;
&lt;p&gt;Avg 是所有子任务按评估数据数量加权的平均得分&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009145901304.png&#34;
	width=&#34;2012&#34;
	height=&#34;745&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009145901304_hu_309eb6e92ee1f29a.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009145901304_hu_99cab5b931fefe45.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;LongBench&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;270&#34;
		data-flex-basis=&#34;648px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;平均得分媲美AR LLM&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;检索（NIAH）/聚合（AGG）/问答（QA)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009150019639.png&#34;
	width=&#34;1978&#34;
	height=&#34;1185&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009150019639_hu_a472d06a9de10b3a.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009150019639_hu_b08d80dfb6e4d0da.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Ruler&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;166&#34;
		data-flex-basis=&#34;400px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;检索任务：相当&lt;/li&gt;
&lt;li&gt;聚合任务：不如AR LLM&lt;/li&gt;
&lt;li&gt;问答任务：超过AR LLM&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;llada-v-large-language-diffusion-models-with-visual-instruction-tuning&#34;&gt;LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2505.16933&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009155310087.png&#34;
	width=&#34;1961&#34;
	height=&#34;949&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009155310087_hu_73052e8f451b3af2.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009155310087_hu_31fdd1ed720a7b25.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;206&#34;
		data-flex-basis=&#34;495px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;问题：完全基于扩散机制的多模态大语言模型能否达到与AR LLM相匹敌的性能？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;论文贡献&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首个完全基于扩散模型的多模态大语言模型&lt;/li&gt;
&lt;li&gt;在多个基准测试中展现出卓越的可扩展性&lt;/li&gt;
&lt;li&gt;在混合型及纯扩散式多模态大语言模型中均SOTA&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;visual-instruction-tuning&#34;&gt;Visual Instruction Tuning
&lt;/h3&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Vison Tower（CLIP或SigLIP）：图像转视觉表征&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MLP connector：嵌入LLM词空间&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Language Tower：LLM&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;主流的多模态大模型架构之一，只需要相对较少的数据（less than 100w 图文数据对）&lt;/p&gt;
&lt;p&gt;本文主要研究如何在DLM中进行Visual Instruction Tuning&lt;/p&gt;
&lt;h3 id=&#34;method&#34;&gt;Method
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Language Tower：LLaDA 8B（与LLaMA3-8B相当的语言模型）&lt;/li&gt;
&lt;li&gt;Vison Tower：SigLIP&lt;/li&gt;
&lt;li&gt;MLP Connector：a two-layer MLP&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;training&#34;&gt;Training
&lt;/h4&gt;&lt;p&gt;训练阶段引入了含有多轮对话的数据&lt;/p&gt;
&lt;p&gt;为了简化描述，文章以2轮对话的数据进行说明，定义符号：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mathcal{v}$：Vison Tower和MLP Connector生成的视觉表征向量&lt;/li&gt;
&lt;li&gt;$[M]$​：掩码标记&lt;/li&gt;
&lt;li&gt;数据：$(\mathcal{v}, p_0^1,r_0^1,p_0^2,r_0^2)$&lt;/li&gt;
&lt;li&gt;$p_0^1 = [ p_0^{1,i}]$：首轮提示文本&lt;/li&gt;
&lt;li&gt;$p_0^2 = [ p_0^{2,i}]$ ：次轮提示文本&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于一个二轮对话，训练目标定义为：&lt;/p&gt;
$$
L(\theta) = -\mathbb{E}_{\mathcal{v},t,p_0^1,r_0^1,r_t^1,p_0^2,r_0^2,r_t^2}\left[\frac{1}{t}\sum_{i=1}^{L_{p_1}}\sum_{j=1}^{L_{p_2}}1\left[r_t^{1,i}=M\wedge r_t^{2,j}=M\right] \cdot \log p_\theta(r_0^{1,i},r_0^{2,j}\mid \mathcal{v}, p_0^1,r_0^1,p_0^2,r_0^2 ) \right]
$$&lt;blockquote&gt;
&lt;p&gt;在多轮对话场景下，&lt;strong&gt;不同轮次的响应是强相关的&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用户的问题可能在第 1 轮，答案在第 2 轮&lt;/li&gt;
&lt;li&gt;推理链条往往横跨多个回合，不能只看单独的 token&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;模型必须在预测某个 token 时，同时考虑另一轮对话中的掩码 token&lt;/p&gt;
&lt;p&gt;这样就把 &lt;strong&gt;跨轮次的依赖关系&lt;/strong&gt; 学进去，而不是每轮单独学&lt;/p&gt;
&lt;p&gt;联合约束迫使模型去捕捉 &lt;strong&gt;对话轮次之间的因果逻辑&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;理论上这个式子在先前工作中已经被证明为整个任务的负对数似然上界&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在多轮对话中似乎可以采用causal mask，阻止早期对话轮次访问了后期的对话轮次&lt;/li&gt;
&lt;li&gt;后文消融实验证明双向注意力的效果更好（实现对整体对话语境的全面理解）&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;该机制在近期&lt;strong&gt;视频扩散模型&lt;/strong&gt;中已证实可有效提升生成视频的时间连贯性&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;本身训练的流程和LLaDA的SFT流程比较相似，加噪只会在Response中，且同时对多轮对话中的Response进行加噪&lt;/p&gt;
&lt;p&gt;一次性让模型恢复所有对话中的MASK&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009200659499.png&#34;
	width=&#34;1569&#34;
	height=&#34;545&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009200659499_hu_14f4dbdd112ab8a5.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009200659499_hu_55f6d0881c6145a4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;AR &amp;#43; Train &amp;#43; Inference&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;287&#34;
		data-flex-basis=&#34;690px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;training-strategies&#34;&gt;Training Strategies
&lt;/h4&gt;&lt;p&gt;整个训练过程参考了LLaVA的训练策略&lt;/p&gt;
&lt;p&gt;建立语言和视觉对齐关系并培养视觉指令跟随能力&lt;/p&gt;
&lt;p&gt;训练目标函数与上文相同&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;阶段一：语言-图像对齐
&lt;ul&gt;
&lt;li&gt;目的：图像与语言的分布不一致，如果直接做指令调优，模型学习跨模态语义很困难&lt;/li&gt;
&lt;li&gt;方法：&lt;strong&gt;将视觉表征与 LLaDA 的词向量进行对齐&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;冻结Vison Tower和Language Tower（这两个本身进行过预训练），只训练MLP Connector&lt;/li&gt;
&lt;li&gt;数据集：LLaVA-Pretrain&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;阶段二：视觉指令调优Visual Instruction Tuning
&lt;ul&gt;
&lt;li&gt;目的：（单图像训练）建立基本的图像理解能力，（多图像训练）扩展到时序和跨图像推理&lt;/li&gt;
&lt;li&gt;方法：（两个阶段）解冻所有层
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;单图像训练Single image&lt;/strong&gt;：在 &lt;strong&gt;1,000 万单图像样本&lt;/strong&gt;上训练，增强对单张图像的理解与响应能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;统一视觉训练阶段one vision&lt;/strong&gt;：在 &lt;strong&gt;约 200 万多模态样本&lt;/strong&gt;（包括单图、多图和视频）上训练，使模型具备处理复杂场景的能力&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;数据集：&lt;strong&gt;MAmmoTH-VL&lt;/strong&gt; 数据集&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;阶段三：多模态推理增强 Multimodal Reasoning Enhancement
&lt;ul&gt;
&lt;li&gt;目的：增强模型处理复杂任务的多模态推理能力，加入reasoning data提升数学、跨图像和逻辑推理任务的表现&lt;/li&gt;
&lt;li&gt;方法
&lt;ul&gt;
&lt;li&gt;推理训练：使用来自 VisualWebInstruct聚焦推理的多模态数据对 LLaDA-V 进行训练（90 万个问答对，详尽的推理链和最终答案）&lt;/li&gt;
&lt;li&gt;平衡训练：参考qwen系列，融合VisualWebInstruct（其中50%添加&lt;code&gt;\think&lt;/code&gt;）和MAmmoTH-VL(one vison部分，全部添加&lt;code&gt;\no_think&lt;/code&gt;，鼓励直接回答)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;inference&#34;&gt;Inference
&lt;/h4&gt;&lt;p&gt;推理时根据已有的对话记录，对当前的prompt进行单轮的response生成&lt;/p&gt;
&lt;p&gt;重掩码策略采用low-confidence strategy&lt;/p&gt;
&lt;h3 id=&#34;experiment-2&#34;&gt;Experiment
&lt;/h3&gt;&lt;p&gt;可扩展性&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLaDA-V 随着&lt;strong&gt;训练数据&lt;/strong&gt;增加性能持续提升&lt;/li&gt;
&lt;li&gt;在 &lt;strong&gt;多学科与数学推理任务&lt;/strong&gt; 上，LLaDA-V 扩展性明显优于 LLaMA3-V&lt;/li&gt;
&lt;li&gt;但在 &lt;strong&gt;图表/文档理解&lt;/strong&gt; 和 &lt;strong&gt;真实场景理解&lt;/strong&gt; 任务上，LLaMA3-V 表现更优&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009221821275.png&#34;
	width=&#34;1402&#34;
	height=&#34;695&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009221821275_hu_2a1887244b431296.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009221821275_hu_3b1ccaa0b03d7012.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;scalability&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;201&#34;
		data-flex-basis=&#34;484px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Benchmark&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于已有的混合或扩散模型，LLaDA-V是SOTA&lt;/li&gt;
&lt;li&gt;对比LLaMA3-V：6 个任务上超越&lt;/li&gt;
&lt;li&gt;对比Qwen2-VL：整体仍落后&lt;/li&gt;
&lt;li&gt;图表/文档理解和 RealWorldQA 上表现稍差&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009222242556.png&#34;
	width=&#34;1710&#34;
	height=&#34;757&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009222242556_hu_16fbc19e2c4d96ea.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009222242556_hu_c8031429e440442.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;benchmark&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;225&#34;
		data-flex-basis=&#34;542px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;消融实验&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对比了Causal Mask和无Mask（多轮对话）&lt;/li&gt;
&lt;li&gt;12个benchmark中7个更优&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009222503983.png&#34;
	width=&#34;953&#34;
	height=&#34;567&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009222503983_hu_d09e07717de8958f.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251009222503983_hu_d4cffbcd05dc86ef.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;消融实验&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;168&#34;
		data-flex-basis=&#34;403px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;图像接入SigLIP的方式比较简单，会丢失分辨率和信息，造成图表问题表现差&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;llada-medv-exploring-large-language-diffusion-models-for-biomedical-image-understanding&#34;&gt;LLaDA-MedV: Exploring Large Language Diffusion Models for Biomedical Image Understanding
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2508.01617&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2508.01617 LLaDA-MedV: Exploring Large Language Diffusion Models for Biomedical Image Understanding&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;没怎么看，大概是把LLaDA-V的工作调整到了垂类领域&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;一些比较有趣的实验分析：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DLM在一些垂类领域非常合适，可以&lt;strong&gt;显式地控制&lt;/strong&gt;一个大概的生成长度&lt;/li&gt;
&lt;li&gt;模型可能出现重复 token（如 “the the the …”）的问题，尤其在&lt;strong&gt;采样步数较少&lt;/strong&gt;或&lt;strong&gt;长度设定较大&lt;/strong&gt;时&lt;/li&gt;
&lt;li&gt;直接使用LLaDA-V的参数做微调的性能反而更差，需要从LLaDA-instruct出发，重新走3个步骤&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lavida-a-large-diffusion-language-model-for-multimodal-understanding&#34;&gt;LaViDa: A Large Diffusion Language Model for Multimodal Understanding
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2505.16839&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://arxiv.org/abs/2505.16839&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;问题：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;AR LLM对强双向上下文要求的任务（文本填充、从图像中提取信息填充到json格式）很弱&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;视觉语言场景中对输出模式的要求特别严格&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;标准扩散模型训练的数据效率低下，未被遮盖的token不参与损失函数计算，容易遗失关键语义信息（关键词）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;现有的推理方式缺少了KV cache的支持（双向上下文固有的缺陷）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;短文本环境中是可容忍的&lt;/li&gt;
&lt;li&gt;对于VLM任务无法接受，常常伴有数百个visual token&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;固定比例的&lt;code&gt;unmask&lt;/code&gt;在迭代次数较少时效果非常差&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;贡献：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;第一个DLM视觉语言模型&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;一种互补的mask方案，确保每个token都能参与到学习过程中，提高数据效率&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prefix-DLM decoding：缓存多模态的提示词与图像输入，从而加速推理过程&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;受文生图技术的启发，采用了时间步偏移策略，自适应调整每次迭代的解码数量&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;method-1&#34;&gt;Method
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251018171520779.png&#34;
	width=&#34;857&#34;
	height=&#34;381&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251018171520779_hu_83db3a345a7595c6.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251018171520779_hu_e775b30abb7e0603.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20251018171520779&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;224&#34;
		data-flex-basis=&#34;539px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Vision Encoder和DLM通过MLP进行连接&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;模型输入：图像$I$和文本$P$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;vision-encoder&#34;&gt;Vision Encoder
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;$I \to_{resize} 768\times 768$&lt;/li&gt;
&lt;li&gt;切分成四个不重叠的部分（$I_{1:4} = (384,384)$）；直接resize原图为$(384,384)$，得到$I_5$&lt;/li&gt;
&lt;li&gt;每一个子图被独立地通过Vision Encoder（SigLIP-400M ）进行编码
&lt;ul&gt;
&lt;li&gt;$I_i \to V_i, \text{size} = 27 \times 27$，五个子图总共产生了3645个embeddings&lt;/li&gt;
&lt;li&gt;$2\times 2$平均池化（缩短序列，提升训练效率）：$14\times 14$，总共980个embeddings&lt;/li&gt;
&lt;li&gt;经过MLP构成的Projection Network，Flatten到1D&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;这里是输出5个一维向量，还是拼在一起的1个一维向量？&lt;/p&gt;
&lt;p&gt;暂时没去研究&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;dlm&#34;&gt;DLM
&lt;/h4&gt;&lt;p&gt;DLM的输入：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;视觉嵌入向量&lt;/li&gt;
&lt;li&gt;文本提示词$P$&lt;/li&gt;
&lt;li&gt;带有掩码的$X_t$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;输出：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;概率分布，用于获取$X_0$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;论文采用LLaDA和Dream作为DLM&lt;/p&gt;
&lt;h4 id=&#34;complementary-mask&#34;&gt;Complementary Mask
&lt;/h4&gt;&lt;p&gt;文本中信息量非常密集，一般就是几个词&lt;/p&gt;
&lt;p&gt;对于之前的加噪方法，不一定能恰好遮蔽需要的词&lt;/p&gt;
&lt;p&gt;例如&lt;code&gt;The answer is dog.&lt;/code&gt;，加噪为：&lt;code&gt;The [MASK] [Mask] dog.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;事实上我们只需要引入它的互补形式：&lt;code&gt;[MASK] answer is [MASK]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020151759246.png&#34;
	width=&#34;1264&#34;
	height=&#34;883&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020151759246_hu_6bc6d2d986ad22ba.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020151759246_hu_3cdadd9f2c6fbffc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;complementary&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;343px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;同时，这份数据会直接copy视觉以及提示词部分的嵌入&lt;/p&gt;
&lt;p&gt;因此对实际训练开销的影响较小&lt;/p&gt;
&lt;h4 id=&#34;prefix-dlm&#34;&gt;Prefix-DLM
&lt;/h4&gt;&lt;p&gt;定义序列长度为$L$，推理的迭代次数$K$，我们有NFE（fraction of the number of functional evaluations）：&lt;/p&gt;
$$
\text{NFE} = \frac{K}{L}
$$&lt;ul&gt;
&lt;li&gt;NFE=100%时，每次迭代生成一个Token&lt;/li&gt;
&lt;li&gt;NFE=50%时，每次迭代生成2个Token&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;但实际上由于毫无推理优化，DLM的速度比自回归慢&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020161428365.png&#34;
	width=&#34;1423&#34;
	height=&#34;417&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020161428365_hu_754ba3cf8053a3da.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020161428365_hu_4f0aa1432c96e31f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Attention&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;341&#34;
		data-flex-basis=&#34;818px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Causal Mask：可以不断复用之前的token的kv矩阵（之前的token没有变化，且之前的token对未来的token不感兴趣）&lt;/li&gt;
&lt;li&gt;Full Mask：每个token都会看前后的内容，因此需要不断重新计算&lt;/li&gt;
&lt;li&gt;Prefix-DLM：I和P部分不会发生变化，遮蔽了对未来answer的token&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;schedule-shift&#34;&gt;Schedule Shift
&lt;/h4&gt;&lt;p&gt;喷了一下等步长的解码，提出了非线性的递推：&lt;/p&gt;
$$
t&#39;_i = \frac{\alpha t_i}{1+(\alpha -1)t_i}
$$&lt;p&gt;
设计一个时间重参数化的函数，要求满足：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$t_0 = 0,t_1 = 1$，仍然保持边界&lt;/li&gt;
&lt;li&gt;单调递增&lt;/li&gt;
&lt;li&gt;曲率可控，方便控制早晚阶段的速度&lt;/li&gt;
&lt;li&gt;简单，防止数值不稳定或梯度爆炸&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;论文希望早期降噪快，后期降噪慢&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;希望先快速搭建一个骨架，后面慢慢填充&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;对这个式子求导：&lt;/p&gt;
$$
\frac{dt_i&#39;}{dt_i} =   \frac{\alpha}{(1+(\alpha-1)t)^2}
$$&lt;p&gt;
当$t=0$，导数为$\alpha$，$t=1$，导数为$\frac{1}{\alpha}$&lt;/p&gt;
&lt;p&gt;可以通过$\alpha$​和1的大小关系，控制是先快后慢，还是先慢后快&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251021190931428.png&#34;
	width=&#34;739&#34;
	height=&#34;681&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251021190931428_hu_afa6e273813b0639.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251021190931428_hu_ba9745771f5c5b65.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;schedule&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;108&#34;
		data-flex-basis=&#34;260px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;experiments&#34;&gt;Experiments
&lt;/h3&gt;&lt;p&gt;略过benchmark部分&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251021202137371.png&#34;
	width=&#34;1530&#34;
	height=&#34;1237&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251021202137371_hu_43223d13feada0c0.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251021202137371_hu_2a6ba790d8bb9229.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;benchmark&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;123&#34;
		data-flex-basis=&#34;296px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;reasoning-distillation&#34;&gt;Reasoning Distillation
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020211558087.png&#34;
	width=&#34;519&#34;
	height=&#34;219&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020211558087_hu_73460ab98d2fb011.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020211558087_hu_aa6c53100831621.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;reasoning&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;236&#34;
		data-flex-basis=&#34;568px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;paper通过蒸馏VL-Rethinker-7B模型（19.2K CoT examples）&lt;/p&gt;
&lt;p&gt;训练得到LaViDa-Reason&lt;/p&gt;
&lt;p&gt;在MathVista、MathVerse和MathVision上均得到提升&lt;/p&gt;
&lt;h4 id=&#34;text-infilling&#34;&gt;Text Infilling
&lt;/h4&gt;&lt;p&gt;对于实际的文本填充任务，不需要生成所有内容，只需要填写需要填写的&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;任意时间步长开始生成&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;There is a [M][M][M][M] in the image.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这里我们希望是&lt;code&gt;dog&lt;/code&gt;或者&lt;code&gt;traffic light&lt;/code&gt;，也是就是variable-length completions&lt;/p&gt;
&lt;p&gt;因此利用了第二阶段（激活全部参数）的20%数据，进行第三阶段训练，得到LaViDa-FIM&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文本中插入&lt;strong&gt;随机长度&lt;/strong&gt;的&lt;code&gt;[S][S]……[S][FIM]&lt;/code&gt;序列&lt;/li&gt;
&lt;li&gt;推理时，在掩码段后面附加&lt;code&gt;[FIM]&lt;/code&gt;，得到&lt;code&gt;There is a [M][M][M][M][FIM] in the image.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;模型自然可以生成：
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;There is a dog[S][S][S][FIM] in the image.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;There is a traffic light[S][S][FIM] in the image.&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;约束性诗歌生成：模型根据图像生成一首诗，每行以特定音节开头&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;强调了结构性约束和上下文一致性，测试双向生成能力&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020215449484.png&#34;
	width=&#34;886&#34;
	height=&#34;492&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020215449484_hu_7654eb8df0de9790.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020215449484_hu_540b0ba14a6cc84c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;诗歌补全&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;180&#34;
		data-flex-basis=&#34;432px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020215153081.png&#34;
	width=&#34;506&#34;
	height=&#34;199&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020215153081_hu_6c166c051812bb1a.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020215153081_hu_f982c9463f0367e2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;poem completion&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;254&#34;
		data-flex-basis=&#34;610px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sentence：满足行级别的约束的比例&lt;/li&gt;
&lt;li&gt;Sample：满足样本级约束的比例&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;speed-vs-quality-trade-off&#34;&gt;Speed vs. Quality Trade off
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020224259620.png&#34;
	width=&#34;557&#34;
	height=&#34;572&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020224259620_hu_994630fc0b694545.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020224259620_hu_878a9a6de5bcea7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Quality-Speed&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;97&#34;
		data-flex-basis=&#34;233px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;设定长度固定32，通过调整迭代次数K，进行实验&lt;/p&gt;
&lt;p&gt;（数据集COCO2017图像描述 500张，生成图像标题）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NFE=100%，稍慢于AR LLM，但是性能更强&lt;/li&gt;
&lt;li&gt;50-75%的性能和速度都很不错&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020225129247.png&#34;
	width=&#34;560&#34;
	height=&#34;278&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020225129247_hu_10c5f2cf2970a1ff.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020225129247_hu_1bf8e32d51acfc60.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Prefix-DLM&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;201&#34;
		data-flex-basis=&#34;483px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有效的加速推理，性能下降少&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020225349258.png&#34;
	width=&#34;541&#34;
	height=&#34;233&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020225349258_hu_fdf1729242ac0fa8.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020225349258_hu_48f7899bb17d908d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Timestep-shifting&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;232&#34;
		data-flex-basis=&#34;557px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先快后慢是对的&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;消融实验部分&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;验证了互补掩码&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020230652797.png&#34;
	width=&#34;575&#34;
	height=&#34;285&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020230652797_hu_c22d64ad30e12606.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020230652797_hu_a75bfb12c4f27585.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Comp. Mask&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;201&#34;
		data-flex-basis=&#34;484px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;验证了图像分辨率的影响（输入分辨率）
&lt;ul&gt;
&lt;li&gt;OCR（上面四个）的提升更为明显&lt;/li&gt;
&lt;li&gt;一般视觉理解任务（最后一个）提升不多&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020231154771.png&#34;
	width=&#34;409&#34;
	height=&#34;247&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020231154771_hu_240c4baf6b5065ba.png 480w, https://example.com/p/diffusion-language-model-birdresearch-202510/assets/image-20251020231154771_hu_69ac30fdc1178978.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image revolution&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;165&#34;
		data-flex-basis=&#34;397px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;STOP，接下来需要进入any2any的调研&lt;/p&gt;
&lt;p&gt;这部分内容另开一篇&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Diffusion Language Model · 论文笔记（一）</title>
        <link>https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/</link>
        <pubDate>Fri, 26 Sep 2025 15:46:00 +0800</pubDate>
        
        <guid>https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2502.09992&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Large Language Diffusion Models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro
&lt;/h2&gt;&lt;p&gt;理想情况下，无限数据+无限模型容量+正确训练 ，可以收敛到真实分布&lt;/p&gt;
&lt;p&gt;因此不管是ARM还是DLM，只要是合格的条件生成模型，都能学到真实语言分布&lt;/p&gt;
&lt;p&gt;因此指令跟随、上下文学习并不是ARM的专利&lt;/p&gt;
&lt;h2 id=&#34;approach&#34;&gt;Approach
&lt;/h2&gt;&lt;h3 id=&#34;概率公式&#34;&gt;概率公式
&lt;/h3&gt;&lt;h4 id=&#34;前向过程forward-process&#34;&gt;前向过程Forward Process
&lt;/h4&gt;&lt;p&gt;序列中逐渐添加mask，直到所有序列全部masked&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个标记有一定概率masked，或者保持unmasked状态&lt;/li&gt;
&lt;li&gt;给定原始数据$x_0$，随机采样的一个时间点$t \in [0,1]$
&lt;ul&gt;
&lt;li&gt;$t=0$表示起点，全部token都是unmasked&lt;/li&gt;
&lt;li&gt;$t=1$表示终点，全部token都已经masked&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;序列中每个token的masked概率就是$t$&lt;/li&gt;
&lt;li&gt;该时刻的序列被定义为$x_t$​&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Bert的mask比例是固定的&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;反向过程reverse-process&#34;&gt;反向过程Reverse Process
&lt;/h4&gt;&lt;p&gt;参数为$\theta$的模型，生成序列$x_0$的概率$p_\theta(x_0)$就是我们需要训练的模型&lt;/p&gt;
&lt;p&gt;我们希望其尽可能接近真实数据的分布$p_{data}(x_0)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;反向过程的目标：$x_{t=1}$出发，恢复$x_0$&lt;/li&gt;
&lt;li&gt;方法：通过&lt;code&gt;mask predictor&lt;/code&gt;，逐步填充&lt;code&gt;masked token&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;mask-predictor&#34;&gt;Mask Predictor
&lt;/h4&gt;&lt;p&gt;LLaDA的核心是一个&lt;code&gt;mask predictor&lt;/code&gt;&lt;/p&gt;
$$
p_\theta\left (\cdot\mid x_t \right)
$$&lt;p&gt;
其中的&lt;code&gt;·&lt;/code&gt;表示一个占位符&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;I [MASK] cats.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;则$p_\theta(\cdot \mid [I,[MASK],cats])$ 就是一个基于词表的概率分布表&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;token&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;p&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;like&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.9&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;eat&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.1&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;此时&lt;code&gt;Mask Predictor&lt;/code&gt;会对所有&lt;code&gt;[MASK]&lt;/code&gt;进行预测&lt;/p&gt;
&lt;p&gt;不像ARM只预测一个token&lt;/p&gt;
&lt;p&gt;假设序列为：$(x_t^1, x_t^2,&amp;hellip;,x_t^L)$&lt;/p&gt;
&lt;p&gt;我们的目标即为，对于&lt;code&gt;masked&lt;/code&gt;位置$i$，最大化概率：&lt;/p&gt;
$$
p_\theta(x_0^i\mid x_t)
$$&lt;p&gt;其中$x_0^i$就是原序列的ground truth&lt;/p&gt;
&lt;h4 id=&#34;损失函数&#34;&gt;损失函数
&lt;/h4&gt;&lt;p&gt;对于单个&lt;code&gt;masked&lt;/code&gt;位置，我们希望概率尽可能大&lt;/p&gt;
&lt;p&gt;因此需要使用交叉熵损失&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;补习一下交叉熵&lt;/p&gt;
&lt;p&gt;假设真实分布是$q(y)$，模型分布是$p_\theta(y)$&lt;/p&gt;
&lt;p&gt;交叉熵定义为：&lt;/p&gt;
$$
H(q,p_\theta) = -\sum_y  q(y)\log{p_\theta(y)}
$$&lt;p&gt;
在该任务下，$q(y)$​是一个独热分布&lt;/p&gt;
$$
q(y) = \left\{\begin{matrix}
  1&amp;,y=x_0^i \\
  0&amp;,otherwise
\end{matrix}\right.
$$&lt;p&gt;
代入得&lt;/p&gt;
$$
\mathcal{L}(x_0^i,x_t) = -\log p_\theta(x_0^i\mid x_t)
$$&lt;p&gt;
故整体的损失就只需要对所有&lt;code&gt;masked&lt;/code&gt;位置求和&lt;/p&gt;
$$
\mathcal{L}(x_0,x_t) = -\sum_{i=1}^L1\left[ x^i_t=M\right] \log{p_\theta\left( x_0^i\mid x_t\right)}
$$&lt;p&gt;
其中$1\left[ x^i_t=M\right] $表示指示函数，确保代入计算的数值是&lt;code&gt;[MASK]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;但是这样是不合理的，序列中&lt;code&gt;[MASK]&lt;/code&gt;越多，损失似乎会越大&lt;/p&gt;
&lt;p&gt;因此需要做一下归一化&lt;/p&gt;
&lt;p&gt;对于$x_t$，其在该时刻会有$tL$个token被&lt;code&gt;masked&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;因此需要代入一个$\frac{1}{t}$​（值得一提的是，$\frac{1}{t} \geq 1$）&lt;/p&gt;
$$
\mathcal{L}(x_0,x_t) = -\frac{1}{t}\sum_{i=1}^L1\left[ x^i_t=M\right] \log{p_\theta\left( x_0^i\mid x_t\right)}
$$&lt;p&gt;
建立关于模型参数$\theta$的损失函数则有：&lt;/p&gt;
$$
L(\theta) \triangleq
 -\mathbb{E}_{t,x_0,x_t}\left[\frac{1}{t}\sum_{i=1}^L1\left[ x^i_t=M\right] \log{p_\theta\left( x_0^i\mid x_t\right)}\right]
$$&lt;ul&gt;
&lt;li&gt;$\triangleq$代表&lt;code&gt;定义为&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;这里不是在陈述一个“事实”，而是在&lt;strong&gt;引入损失函数的定义&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;如果写$=$，读者可能会以为“这是某个推导得到的等式”；&lt;/p&gt;
&lt;p&gt;如果写 $\triangleq$，读者一眼就知道：哦，这是“定义”，不是推导。&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;从均匀分布$U(0,1)$采样的任意$t$，从数据集中采样的任意数据$x_0$，根据前向传播方法得到的$x_t$&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;负对数似然的上界&#34;&gt;负对数似然的上界
&lt;/h4&gt;&lt;p&gt;我们本身的目标是使得$p_\theta(x_0)$的分布接近$p_{data}(x_0)$&lt;/p&gt;
&lt;p&gt;但是我们从未单独定义、训练$p_\theta(x)$这个模型&lt;/p&gt;
&lt;p&gt;而是定义了一个$p_\theta(x_0^i\mid x_t)$，不断重复迭代，起到了$p_\theta(x)$的作用&lt;/p&gt;
&lt;p&gt;因此我们上述内容得到的$L(\theta)$是作为模型$p_\theta(x_0^i\mid x_t)$的损失函数&lt;/p&gt;
&lt;p&gt;我们如何保证训练出这个模型，可以使得$p_\theta(x_0)$的分布接近$p_{data}(x_0)$？&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我们定义真实的似然函数是&lt;/p&gt;
$$
\mathcal{L}(\theta) = -\mathbb{E}_{p_{data}(x_0)}\left [\log{p_{\theta}(x_0)}\right]
$$&lt;ul&gt;
&lt;li&gt;按照真实分布，采样数据$x_0$，得到的似然函数期望&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们需要最小化这个式子&lt;/p&gt;
&lt;p&gt;定义前向加噪分布$q$：&lt;/p&gt;
$$
q(x_t\mid x_0) = \prod_{i=1}^L \left [ (1-t)\times 1(x_t^i=x_0^i) + t\times 1(x_t^i=M) \right]
$$&lt;p&gt;
其描述了通过已知的前向过程，从$x_0$得到$x_t$的概率&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;$q$是我们引入的噪声分布，并非需要训练的参数模型，不使用$p$定义&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;由于前向过程是已知的，我们考虑使用它表示$p_\theta$&lt;/p&gt;
$$
p_\theta(x_0) = \sum_{x_t}p_\theta(x_0\mid x_t)p_\theta(x_t)= \sum_{x_t}p_\theta(x_0, x_t) 
$$&lt;blockquote&gt;
&lt;p&gt;原始句子出现的总概率就是把所有可能路径的概率加起来。&lt;/p&gt;
&lt;p&gt;（先得到$x_t$，再生成$x_0$）&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;引入已知的$q$&lt;/p&gt;
$$
p_\theta(x_0) = \sum_{x_t}q(x_t\mid x_0)\frac{p_\theta(x_0,x_t)}{q(x_t\mid x_0)}
$$&lt;p&gt;
其中$\sum_{x_t}q(x_t\mid x_0)] \times (\cdot)$，可以理解为对$q(x_t\mid x_0)$的期望&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;离散情况下：$\mathbb{E}_{x\sim r}(g(x)) = \sum_x r(x)g(x)$&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;此时$x_0$是当作固定值，所有都可以看作关于$x_t$的函数&lt;/p&gt;
&lt;p&gt;因此则有：&lt;/p&gt;
$$
p_\theta(x_0) = \mathbb{E}_{ q(x_t\mid x_0)}\left[\frac{p_\theta(x_0,x_t)}{q(x_t\mid x_0)}\right]
$$&lt;blockquote&gt;
&lt;p&gt;任意从$q$分布中采样$x_t$&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;采样 Jensen不等式：&lt;/p&gt;
$$
\log \mathbb{E}(z) \geq \mathbb{E}(\log{z})
$$&lt;p&gt;
此时则有：&lt;/p&gt;
$$
\log{p_\theta}(x_0) = \log{\mathbb{E}_{ q(x_t\mid x_0)}\left[\frac{p_\theta(x_0,x_t)}{q(x_t\mid x_0)}\right]} \geq \mathbb{E}_{ q(x_t\mid x_0)}\left[\log{p_\theta(x_0,x_t)} - \log{q(x_t\mid x_0)} \right]
$$$$
-\log{p_\theta}(x_0) \leq -\mathbb{E}_{ q(x_t\mid x_0)}\log{p_\theta(x_0,x_t)} + \mathbb{E}_{ q(x_t\mid x_0)} \log{q(x_t\mid x_0)}
$$&lt;p&gt;
分解一下联合概率&lt;/p&gt;
$$
\log{p_\theta(x_0,x_t)} = \log{p_\theta(x_0\mid x_t)} + \log{p_\theta(x_t)}
$$&lt;p&gt;
代回则有：&lt;/p&gt;
$$
-\log{p_\theta}(x_0) \leq -\mathbb{E}_{ q(x_t\mid x_0)}\log{p_\theta(x_0\mid x_t)}-\mathbb{E}_{ q(x_t\mid x_0)}\log{p_\theta(x_t)} + \mathbb{E}_{ q(x_t\mid x_0)} \log{q(x_t\mid x_0)}
$$&lt;ul&gt;
&lt;li&gt;$p_\theta(x_t)$：其中$x_t$是前向过程人为生成的，因此与$\theta$无关&lt;/li&gt;
&lt;li&gt;$q(x_t\mid x_0)$是噪声项，与$\theta$无关&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此可以写成&lt;/p&gt;
$$
-\log{p_\theta}(x_0) \leq -\mathbb{E}_{ q(x_t\mid x_0)}\log{p_\theta(x_0\mid x_t)} + \text{const}
$$&lt;p&gt;
两边同时对真实数据计算期望&lt;/p&gt;
$$
-\mathbb{E}_{p_{data}(x_0)}(\log{p_\theta}(x_0) ) \leq -\mathbb{E}_{p_{data}(x_0)}(\mathbb{E}_{ q(x_t\mid x_0)}\log{p_\theta(x_0\mid x_t)}) + \text{const}
$$&lt;p&gt;
左边实质上就是我们需要优化的目标，命名为负对数似然$\text{NLL}$&lt;/p&gt;
&lt;p&gt;根据&lt;/p&gt;
$$
\log {p_\theta(x_0\mid x_t)} = \sum_{i=1}^L 1\left [ x^i_t=M\right ] \log{p_\theta}(x_0^i\mid x_t)
$$&lt;p&gt;
代入得：&lt;/p&gt;
$$
-\mathbb{E}_{p_{data}(x_0)}(\log{p_\theta}(x_0) ) \leq -\mathbb{E}_{p_{data}(x_0)}\mathbb{E}_{ q(x_t\mid x_0)}\left[\sum_{i=1}^L 1\left [ x^i_t=M\right ] \log{p_\theta}(x_0^i\mid x_t)\right] + \text{const}
$$&lt;p&gt;
事实上右边就是：&lt;/p&gt;
$$
-\mathbb{E}_{p_{data}(x_0)}\mathbb{E}_{ q(x_t\mid x_0)}\left[\sum_{i=1}^L 1\left [ x^i_t=M\right ] \log{p_\theta}(x_0^i\mid x_t)\right] = 
 -\mathbb{E}_{t,x_0,x_t}\left[\sum_{i=1}^L1\left[ x^i_t=M\right] \log{p_\theta\left( x_0^i\mid x_t\right)}\right] = tL(\theta)
$$&lt;p&gt;
上述内容都是正项（负概率对数），$t \in [0,1]$，因此满足&lt;/p&gt;
$$
-\mathbb{E}_{p_{data}(x_0)}\mathbb{E}_{ q(x_t\mid x_0)}\left[\sum_{i=1}^L 1\left [ x^i_t=M\right ] \log{p_\theta}(x_0^i\mid x_t)\right] + \text{const} \leq L(\theta) + \text{const}
$$&lt;p&gt;
则有：&lt;/p&gt;
$$
\text{NLL} = -\mathbb{E}_{p_{data}(x_0)}(\log{p_\theta}(x_0) ) \leq L(\theta) + \text{const}
$$&lt;p&gt;
至此，成功证明了$L(\theta)$决定了$\text{NLL}$​的上界（常数可以忽略）&lt;/p&gt;
&lt;h3 id=&#34;pre-training&#34;&gt;Pre-Training
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/x2.png&#34;
	width=&#34;1628&#34;
	height=&#34;456&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/x2_hu_9a85fb3e2f02f873.png 480w, https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/x2_hu_3f7bfef69b5c6f92.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;A Conceptual Overview of LLaDA.&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;357&#34;
		data-flex-basis=&#34;856px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入：&lt;code&gt;mask predictor&lt;/code&gt;$p_\theta$，训练数据$p_{data}$&lt;/li&gt;
&lt;li&gt;输出：$p_{\theta}$（收敛）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007220922976.png&#34;
	width=&#34;1570&#34;
	height=&#34;385&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007220922976_hu_f227ce11f9ed9b16.png 480w, https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007220922976_hu_7a4e250f2607c545.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Pre-Train Algorithm&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;407&#34;
		data-flex-basis=&#34;978px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mask predictor&lt;/code&gt;采用Transformer架构
&lt;ul&gt;
&lt;li&gt;不采用&lt;code&gt;causal mask&lt;/code&gt;，能看见双向上下文&lt;/li&gt;
&lt;li&gt;未使用KV Cache，采用标准的&lt;code&gt;Vanilla Multi-Head Attention&lt;/code&gt;，每个头单独一份&lt;code&gt;k,q,v&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Transformer架构尽量与LLaMA3对齐，从&lt;code&gt;attention&lt;/code&gt;和&lt;code&gt;FFN&lt;/code&gt;两个参数大头中，选择了减少&lt;code&gt;FFN&lt;/code&gt;的参数量，保持参数规模可以比较&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;在自回归 LLM 生成时，生成新 token 时可以复用之前的 K/V 矩阵（不用重新算整个序列的注意力）。&lt;/p&gt;
&lt;p&gt;这是 KV cache 的意义：极大加速推理，节省显存。&lt;/p&gt;
&lt;p&gt;但 LLaDA 每一步预测的是 &lt;strong&gt;全局被 mask 的位置（不是单个 token）&lt;/strong&gt;，所以每一步输入分布会变，全序列 K/V 都要重新计算 → KV cache 无法使用。&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;99%的数据固定长度4096&lt;/li&gt;
&lt;li&gt;1%的数据随机采样长度&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sft&#34;&gt;SFT
&lt;/h3&gt;&lt;p&gt;对于问答对$(p_0,r_0)$，我们不改变提问部分，只对&lt;strong&gt;回答部分&lt;/strong&gt;进行掩码加噪得到$r_t$&lt;/p&gt;
&lt;p&gt;损失函数设计为：&lt;/p&gt;
$$
-\mathbb{E}_{t,p_0,r_0,r_t}\left[\frac{1}{t}\sum_{i=1}^{L&#39;}1[r^i_t = M]p_\theta(r_0^i\mid p_0,r_t)\right]
$$&lt;ul&gt;
&lt;li&gt;$r_0$的长度是天然动态的，使用&lt;code&gt;EOS&lt;/code&gt;填充&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;inference&#34;&gt;Inference
&lt;/h3&gt;&lt;p&gt;给定$p_0$，我们从完全掩码的$r_1$开始&lt;/p&gt;
&lt;p&gt;设定超参数如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;迭代次数（采样步骤总数）：a trade off between efficency and quality&lt;/li&gt;
&lt;li&gt;生成长度：实质上是一个上界&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;假设我们从时间$t\in(0, 1]$转移到$s\in[0,t)$，需要做的事是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$p_0,r_t$作为模型的输入，预测$r_0$（模型会&lt;code&gt;unmask&lt;/code&gt;所有被掩码的token）&lt;/li&gt;
&lt;li&gt;由于我们只转移到$s$，因此需要保留$sL$个掩码
&lt;ul&gt;
&lt;li&gt;对预测出的$r_0$，从中&lt;strong&gt;随机&lt;/strong&gt;&lt;code&gt;remask&lt;/code&gt;$\frac{s}{t}L$个token&lt;/li&gt;
&lt;li&gt;得到$r_s$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$s = t, r_t = r_s$重复迭代&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;默认将$|t-s|$​是一个定值，以定长的步长进行迭代&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007222150257.png&#34;
	width=&#34;1647&#34;
	height=&#34;627&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007222150257_hu_539b4cf9daaad9c4.png 480w, https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007222150257_hu_3153327713f2069d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Reverse Process&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;262&#34;
		data-flex-basis=&#34;630px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;理论上remask策略是随机的&lt;/p&gt;
&lt;p&gt;但是论文给出了两种基于&lt;code&gt;退火&lt;/code&gt;的remask策略&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在生成过程中，需要随机性逐步递减，冻结高确定性的部分、把随机性集中在不确定区域&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;low-confidence remasking&lt;/strong&gt;：取置信度最低的$\frac{s}{t}L$个预测token进行remask&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;semi-autoregressive&lt;/strong&gt; remasking：对序列进行分块，从左到右顺序生成&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007222344789.png&#34;
	width=&#34;1473&#34;
	height=&#34;558&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007222344789_hu_c595a78f46bb5a31.png 480w, https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007222344789_hu_8789f573c459aaef.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;semi-autoregressive&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;263&#34;
		data-flex-basis=&#34;633px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments
&lt;/h2&gt;&lt;h3 id=&#34;实验1--scalability&#34;&gt;实验1 · Scalability
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;验证：LLaDA是否与自回归模型ARM具有相同的可拓展性&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;目的：证明论文的核心论点：&lt;/p&gt;
&lt;p&gt;​	理想情况下，无限数据+无限模型容量+正确训练 ，可以收敛到真实分布&lt;/p&gt;
&lt;p&gt;​	因此不管是ARM还是DLM，只要是合格的条件生成模型，都能学到真实语言分布&lt;/p&gt;
&lt;p&gt;​	因此指令跟随、上下文学习并不是ARM的专利&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;实验设计&#34;&gt;实验设计
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251003215457932.png&#34;
	width=&#34;1568&#34;
	height=&#34;583&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251003215457932_hu_4f064368af95b6bc.png 480w, https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251003215457932_hu_8bdc715fd4ddd50c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;架构&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;268&#34;
		data-flex-basis=&#34;645px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;针对MDM和ARM两类语言模型，进行如下控制变量&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型结构：采样同一套Transformer架构（优化器、参数量……各种机制），只修改了mask&lt;/li&gt;
&lt;li&gt;参数量：在1B规模下完全一致，在7B规模由于资源限制有一些不同
&lt;ul&gt;
&lt;li&gt;Transformer：causal mask&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;数据：预训练语料相同&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;唯一的实验的变量：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;FLOPs：使用6ND公式作为横轴
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;N&lt;/strong&gt; 是模型的非 embedding 参数量（固定，比如 1B 或 8B）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;D&lt;/strong&gt; 是训练过的 token 数量（数据量，可以变化）&lt;/li&gt;
&lt;li&gt;实验通过改变 D ，计算出 6 × N × D （即训练 FLOPs）作为横轴的计算预算&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实验指标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MMLU、ARC-C、CMMLU、PIQA、GSM8K、HumanEval&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（多任务、推理、中文、物理、数学、代码）&lt;/p&gt;
&lt;h4 id=&#34;实验结果&#34;&gt;实验结果
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251003214259678.png&#34;
	width=&#34;1472&#34;
	height=&#34;707&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251003214259678_hu_598efe4120660d9c.png 480w, https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251003214259678_hu_8ec2789b84388b8c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;实验结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;208&#34;
		data-flex-basis=&#34;499px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;部分任务体现优势&lt;/li&gt;
&lt;li&gt;对于性能稍逊的任务（PIQA），差距也在逐渐缩小&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同时喷了先前的一篇工作的结论：&lt;code&gt;达到相同的似然需要16倍算力&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;似然是间接指标（LLaDA的lower bound）&lt;/li&gt;
&lt;li&gt;先前的工作只有GPT2的参数量，本文提高到7-8B&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Nie, S., Zhu, F., Du, C., Pang, T., Liu, Q., Zeng, G., Lin, M., and Li, C. Scaling up masked diffusion models on text. arXiv preprint arXiv:2410.18514, 2024.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;结论：LLaDA 在相同训练规模与算力条件下，表现出与 ARM 相似甚至更强的可扩展性。&lt;/p&gt;
&lt;h3 id=&#34;实验2--benchmark&#34;&gt;实验2 · Benchmark
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;验证：LLaDA经过预训练和SFT之后是否能够和已有的ARM在&lt;strong&gt;上下文学习&lt;/strong&gt;与&lt;strong&gt;指令遵循能力&lt;/strong&gt;上进行竞争&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;实验设计-1&#34;&gt;实验设计
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;实验对象：LLaDA、一系列参数相当的模型
&lt;ul&gt;
&lt;li&gt;Base阶段：比较了所有模型的预训练base模型&lt;/li&gt;
&lt;li&gt;instruct阶段：LLaDA只进行了SFT，其他模型均完成了SFT+RL
&lt;ul&gt;
&lt;li&gt;原文：交给未来的工作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;任务：通用、数学科学、代码、中文等常见benchmark&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;实验结果-1&#34;&gt;实验结果
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007173251237.png&#34;
	width=&#34;1208&#34;
	height=&#34;717&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007173251237_hu_caa01b5802879200.png 480w, https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007173251237_hu_c7856aff322a4d51.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Base&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;168&#34;
		data-flex-basis=&#34;404px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在所有任务上超过LLaMA2 7B，与LLaMA3 8B相当&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;所有模型的训练数据存在差异&lt;/li&gt;
&lt;li&gt;作者认为LLaDA的优势区间与劣势区间的主要原因在数据质量与分布上&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GSM8K数据集上体现了显著的优势，论文针对这个情况做了补充实验，证明不存在数据泄露&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007173309440.png&#34;
	width=&#34;1205&#34;
	height=&#34;574&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007173309440_hu_db0f9cb7c5edf55e.png 480w, https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007173309440_hu_5dfaa65484da0854.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;SFT&amp;#43;RL&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;209&#34;
		data-flex-basis=&#34;503px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SFT数据质量较差，出现了性能下降（MMLU）&lt;/li&gt;
&lt;li&gt;没有采用RL，因此性能略微落后LLaMA3 8B&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;结论：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在数据集透明度不足的情况下，以丰富的标准化流程、多样化任务，足以证明LLaDA的性能卓越，是唯一具备竞争力的非自回归模型&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;实验2--补充实验&#34;&gt;实验2 · 补充实验
&lt;/h3&gt;&lt;p&gt;验证：LLaDA在GSM8K数据集中的优势不来源于数据泄露（data leakage），检测在全新数据集中仍然能保证推理能力&lt;/p&gt;
&lt;p&gt;省流：找了一个2024年的新数据集，模仿GSM8K的形式做一遍实验&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007201005145.png&#34;
	width=&#34;548&#34;
	height=&#34;173&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007201005145_hu_ad845088f2d886d0.png 480w, https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007201005145_hu_8a04e4c9a021371f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;iGSM Dataset&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;316&#34;
		data-flex-basis=&#34;760px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLaDA在所有难度（解题步骤数）中均显著优势&lt;/li&gt;
&lt;li&gt;两类模型随着难度上升准确度逐渐下降，但是LLaDA下降较慢&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;结论：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLaDA允许模型在每一步同时考虑全局 token 关系，因此在多变量方程、层次关系推理中优于单向自回归&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;实验3--reversal-reasoning-and-analyses&#34;&gt;实验3 · Reversal Reasoning and Analyses
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Reversal Curse（反向诅咒）：ARM从左到右生成序列，因此反向生成或逆序推理的表现很差&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;验证：LLaDA是否克服了反向诅咒&lt;/p&gt;
&lt;h4 id=&#34;实验设计-2&#34;&gt;实验设计
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;数据：496对著名中文诗句（上下两句），每一句子（A,B）构成两个任务
&lt;ul&gt;
&lt;li&gt;Forward：给定A预测B&lt;/li&gt;
&lt;li&gt;Backward：给定B预测A&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;窈窕淑女的下一句是什么？直接输出句子即可。 Answer: 君子好逑。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;不拘一格降人才的上一句是什么？直接输出句子即可。 Answer: 我劝天公重抖擞。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007205703318.png&#34;
	width=&#34;990&#34;
	height=&#34;401&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007205703318_hu_f6b1b119ec68bdcd.png 480w, https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007205703318_hu_9284f82611816e94.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Reversal Curse&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;246&#34;
		data-flex-basis=&#34;592px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GPT-4o 和 Qwen2.5 均有更大数据和RL优化，但仍失败&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LLaDA 虽仅 SFT，无RL，仍在 reversal 上大幅领先&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;附录补充&#34;&gt;附录补充
&lt;/h4&gt;&lt;p&gt;论文从三个角度补充了为什么LLaDA是无方向偏置的模型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;理论证明：LLaDA本质上等价于在所有生成顺序上做平均，从而消除方向偏置
&lt;ul&gt;
&lt;li&gt;解释为什么 diffusion 结构在数学上是方向对称的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;实现机制：理论正确的情况下，需要确保算法实现不出现&lt;strong&gt;从左到右&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;确保生成算法本身不引入方向信息&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;超参数层面：通过实验说明采样步数与效率不会干扰方向一致性
&lt;ul&gt;
&lt;li&gt;排除方向性差异由采样精度造成的可能性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;a2-inference&#34;&gt;A.2 Inference
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;目的：证明LLaDA训练和推理目标等价于&lt;strong&gt;对所有可能生成顺序的平均建模&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于训练时的核心目标函数：&lt;/p&gt;
$$
L(\theta) \triangleq
 -\mathbb{E}_{t,x_0,x_t}\left[\frac{1}{t}\sum_{i=1}^L1\left[ x^i_t=M\right] \log{p_\theta\left( x_0^i\mid x_t\right)}\right]
$$&lt;p&gt;
训练目标是：模型在任意mask模式下，都能预测出原token&lt;/p&gt;
&lt;p&gt;该训练模式不会看到任何固定方向的序列，故天然是双向建模的&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;推不动了，pass一下&lt;/p&gt;&lt;/blockquote&gt;
&lt;h5 id=&#34;remasking&#34;&gt;Remasking
&lt;/h5&gt;&lt;p&gt;反向过程的核心：预测 - 重新掩码 - 继续预测&lt;/p&gt;
&lt;p&gt;上文提到了三种不同的掩码策略&lt;/p&gt;
&lt;p&gt;论文使用GSM8K进行了消融实验&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;生成长度固定512&lt;/li&gt;
&lt;li&gt;采样步数固定256（长度的一半）&lt;/li&gt;
&lt;li&gt;block：32&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007223806549.png&#34;
	width=&#34;1329&#34;
	height=&#34;223&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007223806549_hu_a185194ec8c04b53.png 480w, https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007223806549_hu_9209def52fe04210.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;remask&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;595&#34;
		data-flex-basis=&#34;1430px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Base模型：最低置信度即可，半自回归是不需要的&lt;/li&gt;
&lt;li&gt;Instruct模型：必须是最低置信度+半自回归
&lt;ul&gt;
&lt;li&gt;单独最低置信度会严重降低性能&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;论文解释：SFT阶段引入了大量&lt;code&gt;EOS&lt;/code&gt;，模型一般会给&lt;code&gt;EOS&lt;/code&gt;较大的置信度。因此推理时&lt;code&gt;EOS&lt;/code&gt;会被大量生成，并且几乎不可能被&lt;code&gt;remask&lt;/code&gt;（置信度非常高）&lt;/p&gt;
&lt;p&gt;因此需要引入半自回归，保证每个块内收敛出连续的内容，抑制&lt;code&gt;EOS&lt;/code&gt;早产&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;尽管引入半自回归，但是块内仍然是并行的（？）&lt;/p&gt;
&lt;p&gt;补充一下，模型对生成长度这个超参数非常不敏感&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007225517980.png&#34;
	width=&#34;1607&#34;
	height=&#34;288&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007225517980_hu_496709f8b88b2255.png 480w, https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007225517980_hu_4144e169c1540880.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Length&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;557&#34;
		data-flex-basis=&#34;1339px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;但对采样步数非常敏感（生成长度1024）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007225835929.png&#34;
	width=&#34;1472&#34;
	height=&#34;508&#34;
	srcset=&#34;https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007225835929_hu_afc64e86f9a1bafe.png 480w, https://example.com/p/diffusion-language-model-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20251007225835929_hu_6b0c69ba2a7f9c56.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;采样&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;289&#34;
		data-flex-basis=&#34;695px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;结论：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLaDA不受自回归方向性的约束，具有更平衡的前后向建模能力&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;case-studies&#34;&gt;Case Studies
&lt;/h3&gt;&lt;p&gt;附录中展示了一些其他例子，说明生成的对话是出色的（单轮、多轮）&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Diffusion Model · 李宏毅2023</title>
        <link>https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/</link>
        <pubDate>Mon, 22 Sep 2025 20:32:34 +0800</pubDate>
        
        <guid>https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV19EVUzrEF4&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;【李宏毅】2025最新的Diffusion Model教程！1小时清楚扩散模型原理，简直不要太爽！人工智能|机器学习|OpenAI_哔哩哔哩_bilibili&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;denoise-model&#34;&gt;Denoise Model
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922205615821.png&#34;
	width=&#34;1584&#34;
	height=&#34;878&#34;
	srcset=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922205615821_hu_453fe11cd11c3e77.png 480w, https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922205615821_hu_2ca5d8c679f0be68.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Denoise&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;180&#34;
		data-flex-basis=&#34;432px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一步，从正态分布中随机一个二维向量（纯噪声）作为最开始的输入&lt;/li&gt;
&lt;li&gt;第二步，假设迭代次数为1000，将输入送入Denoise Model进行推理，得到新的图片&lt;/li&gt;
&lt;li&gt;不断重复步骤（同时需要输入当前step数字，表示噪声的严重程度，见图片下方）&lt;/li&gt;
&lt;li&gt;完成迭代，得到生成的图片&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;输入与输出&#34;&gt;输入与输出
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922205938120.png&#34;
	width=&#34;1427&#34;
	height=&#34;581&#34;
	srcset=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922205938120_hu_87c6f8cd75cf8030.png 480w, https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922205938120_hu_2a73b7b05d8477a1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Input and Output&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;245&#34;
		data-flex-basis=&#34;589px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;如果直接让模型输出denoise之后的图片，本质上需要让模型学会生成新的图片，实践证明是一件比较难的事情&lt;/p&gt;
&lt;p&gt;但是我们将模型训练成一个&lt;code&gt;Noise Predicter&lt;/code&gt;，推理出图片中的噪音是什么样的&lt;/p&gt;
&lt;p&gt;最后使用图片&lt;strong&gt;减去&lt;/strong&gt;噪音，则可以得到迭代出的图片&lt;/p&gt;
&lt;h3 id=&#34;train&#34;&gt;Train
&lt;/h3&gt;&lt;p&gt;数据可以自己造，迭代一定次数，每次生成一个正态分布随机出的噪声&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922210258582.png&#34;
	width=&#34;1587&#34;
	height=&#34;416&#34;
	srcset=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922210258582_hu_86784d3c57d0ab5b.png 480w, https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922210258582_hu_e58decbdfdec74a3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Forward Process&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;381&#34;
		data-flex-basis=&#34;915px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;生成的噪声就是ground truth&lt;/p&gt;
&lt;h3 id=&#34;text2img&#34;&gt;Text2Img
&lt;/h3&gt;&lt;p&gt;一般来说我们希望通过文字prompt生成想要的图片，而不是让模型自己决定生成什么样的图片&lt;/p&gt;
&lt;p&gt;&lt;del&gt;但其实也很简单&lt;/del&gt;，将文字作为输入送入到Denoise Model中即可&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922210650681.png&#34;
	width=&#34;1461&#34;
	height=&#34;667&#34;
	srcset=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922210650681_hu_a6406ef6f25440e6.png 480w, https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922210650681_hu_c0cd833da929db2d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;text2img Denoise Model&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;219&#34;
		data-flex-basis=&#34;525px&#34;
	
&gt; &lt;img src=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922210725023.png&#34;
	width=&#34;1515&#34;
	height=&#34;590&#34;
	srcset=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922210725023_hu_4269068570ae2bce.png 480w, https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922210725023_hu_2db49e2e8eff8032.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;text2img Denoise Model&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;256&#34;
		data-flex-basis=&#34;616px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;diffusion图片生成&#34;&gt;Diffusion图片生成
&lt;/h2&gt;&lt;p&gt;主流的图片生成模型Stable Diffusion、DALLE……的Framework基本都差不多&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922211223208.png&#34;
	width=&#34;1510&#34;
	height=&#34;666&#34;
	srcset=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922211223208_hu_def2addc8ac2b945.png 480w, https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922211223208_hu_fd84a22358b47845.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Framework&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;226&#34;
		data-flex-basis=&#34;544px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generation Model的输入来自于，最后输出一个类似压缩版本的图片向量
&lt;ul&gt;
&lt;li&gt;文字经过&lt;code&gt;text encoder&lt;/code&gt;得到向量&lt;/li&gt;
&lt;li&gt;从正态分布中随机一个初始向量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;通过Decoder生成高清图片&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;text-encoder&#34;&gt;Text Encoder
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922211718217.png&#34;
	width=&#34;1453&#34;
	height=&#34;652&#34;
	srcset=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922211718217_hu_5418abee0fb12839.png 480w, https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922211718217_hu_c76abe57cd04014c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Text Encoder对性能的影响&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;222&#34;
		data-flex-basis=&#34;534px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;文字Encoder对最终模型的影响远大于Noise Predictor，不管采用多大的U-Net，似乎效果没什么变&lt;/p&gt;
&lt;h3 id=&#34;decoder&#34;&gt;Decoder
&lt;/h3&gt;&lt;p&gt;取决于Framework中的技术路线&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Generation Model生成一张小图，Decoder进行高清图生成&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;找大量图片进行down sample，即可完成数据集制作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generation Model生成&lt;strong&gt;Latent representation（潜在表示）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用auto-encoder的方法进行训练&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922212322444.png&#34;
	width=&#34;1515&#34;
	height=&#34;589&#34;
	srcset=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922212322444_hu_7b613dd45f728dad.png 480w, https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922212322444_hu_35e1579bdfc731e6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;257&#34;
		data-flex-basis=&#34;617px&#34;
	
&gt;  &lt;img src=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922212458561.png&#34;
	width=&#34;1492&#34;
	height=&#34;758&#34;
	srcset=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922212458561_hu_12414711517716a6.png 480w, https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250922212458561_hu_1a550b46d2d6259b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;196&#34;
		data-flex-basis=&#34;472px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;generation-model&#34;&gt;Generation Model
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Diffusion Model
&lt;ul&gt;
&lt;li&gt;输出：图片&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Generation Model
&lt;ul&gt;
&lt;li&gt;输出：Latent Representation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同样会使用Forward Process进行数据生成&lt;/p&gt;
&lt;p&gt;因此随机的noise应该加在Latent Representation上&lt;/p&gt;
&lt;h2 id=&#34;数学推导&#34;&gt;数学推导
&lt;/h2&gt;&lt;h3 id=&#34;优化目标&#34;&gt;优化目标
&lt;/h3&gt;&lt;p&gt;图像生成的本质：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250923181904461.png&#34;
	width=&#34;1099&#34;
	height=&#34;415&#34;
	srcset=&#34;https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250923181904461_hu_184c20ea63b526c5.png 480w, https://example.com/p/diffusion-model-%E6%9D%8E%E5%AE%8F%E6%AF%852023/assets/image-20250923181904461_hu_8b01de306072e72f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;本质&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;264&#34;
		data-flex-basis=&#34;635px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;从一个高斯中随机出的向量$z$，通过生成网络$G(z)$得到的分布$x$，希望尽可能接近真实&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文字等其他信息作为condition（本质上是条件概率）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;记模型的参数为$\theta$，则模型的概率分布为$P_\theta{(x)}$，真实数据的分布为$P_{data}{(x)}$&lt;/p&gt;
$$
Sample \left\{ x^1, x^2, ..., x^m\right \} \space from \space P_{data}(x)\\
\theta^*=\arg \max_\theta \prod_{i=1}^{m}P_\theta{(x^i)}
$$&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;希望模型能以尽可能高的概率生成我们观察到的数据&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
$$
\theta^*=\arg \max_\theta \sum_{i=1}^{m}\log P_\theta{(x^i)} =\arg \max_\theta  \frac{1}{m}\sum_{i=1}^{m}\log P_\theta{(x^i)}
$$&lt;p&gt;
只要我们从真实数据中采样的数据量$m$​足够大，就可以用&lt;strong&gt;真实数据的期望&lt;/strong&gt;，代替&lt;strong&gt;样本的均值&lt;/strong&gt;&lt;/p&gt;
$$
\theta^*=\arg \max_\theta \mathbb{E}_{x\sim P_{data}}\left [ \log P_\theta(x) \right]
$$&lt;p&gt;转换成积分形式：&lt;/p&gt;
$$
\theta^*=\arg \max_\theta \int P_{data}(x)\log P_\theta(x) dx
$$&lt;blockquote&gt;
&lt;p&gt;概率乘上数值&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;kl散度&#34;&gt;KL散度
&lt;/h4&gt;&lt;p&gt;有两个概率分布：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;P分布&lt;/strong&gt;：代表真实的情况或我们观察到的数据分布。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Q分布&lt;/strong&gt;：代表我们模型预测的分布、一个近似分布&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;现在的问题是：&lt;strong&gt;如果我们使用Q分布来编码来自P分布的数据，会犯多大的“错误”？会损失多少信息？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用KL散度进行表示&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;KL散度是不对称的&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用Q近似P的损失 不等于 用P近似Q的损失&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;对于离散型变量：&lt;/p&gt;
$$
D_{KL}(P\mid\mid Q) = \sum_i P(i)\log (\frac{P(i)}{Q(i)})
$$&lt;ul&gt;
&lt;li&gt;$P(i)$是事件$i$在真实分布$P$中发生的概率。&lt;/li&gt;
&lt;li&gt;$Q(i)$是事件$i$在近似分布$Q$中发生的概率。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于连续型变量：&lt;/p&gt;
$$
D_{KL}(P\mid\mid Q) = \int_{-\infty}^{\infty}p(x)\log (\frac{p(x)}{q(x)})dx
$$&lt;p&gt;
这里使用的是概率密度函数&lt;/p&gt;
&lt;hr&gt;
$$
\int P_{data}(x)\log P_\theta(x) dx = \int P_{data}(x)\log P_\theta{(x)}dx - \int P_{data}(x) \log P_{data}(x)dx +  \int P_{data}(x) \log P_{data}(x)dx \\
= \int P_{data}(x)\log \frac{P_\theta(x)}{P_{data}(x)}dx +  \int P_{data}(x) \log P_{data}(x)dx
$$&lt;p&gt;
第二项是与$\theta$无关的一项（常数），这样不影响$\theta$​优化，因此可以直接舍弃&lt;/p&gt;
$$
\theta^* = \arg \max_\theta  \int P_{data}(x)\log \frac{P_\theta(x)}{P_{data}(x)}dx\\
= \arg \max_\theta  \left [ -\int P_{data}(x)\log \frac{P_{data}(x)}{P_\theta(x)}dx\right ]\\
= \arg \min_\theta  \left [ \int P_{data}(x)\log \frac{P_{data}(x)}{P_\theta(x)}dx\right ]\\
=  \arg \min_\theta  D_{KL}(P_{data}\mid\mid P_\theta)
$$&lt;h3 id=&#34;denoising-diffusion-probabilistic-models&#34;&gt;Denoising Diffusion Probabilistic Models
&lt;/h3&gt;&lt;p&gt;那么如何计算$P_\theta(x)$​呢？对于DDPM，图片是逐渐Denoise得到的&lt;/p&gt;
&lt;p&gt;我们假设最后得到的干净图片是$x_0$，一开始的随机噪声是$x_T \sim \mathcal{N}(0,I)$​&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;先补充一些数学&lt;/p&gt;
&lt;h4 id=&#34;马尔可夫性质离散时间&#34;&gt;马尔可夫性质（离散时间）
&lt;/h4&gt;&lt;p&gt;对于一个随机过程$\left { X_t   \right }_{t\in T}$，$T$是离散的时间序列$\left { 0,1,2,&amp;hellip;\right}$&lt;/p&gt;
&lt;p&gt;若对于任意时间点$t$，满足：&lt;/p&gt;
$$
P(X_t=x\mid X_{t-1}=x_{t-1},...,X_1=x_1) = P(X_t=x\mid X_{t-1}=x_{t-1})
$$&lt;p&gt;
也就是说，&lt;strong&gt;给定当前状态，未来状态与过去状态条件独立&lt;/strong&gt;。这就是“无记忆性”。&lt;/p&gt;
&lt;h4 id=&#34;重参数化技巧&#34;&gt;重参数化技巧
&lt;/h4&gt;&lt;p&gt;对于深度学习过程，若途中从高斯中进行采样，是不可导的，无法进行反向传播&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;normal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sigma&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;x的产生是随机的，&lt;strong&gt;无法写出关于参数的函数&lt;/strong&gt;，无法反向传播到mu和sigma&lt;/p&gt;
&lt;p&gt;因此我们希望引入一个具体的表达方式，方便求导&lt;/p&gt;
&lt;p&gt;可以采用的是：&lt;/p&gt;
$$
x = \mu + \sigma \odot \epsilon
$$&lt;p&gt;
其中$\epsilon \sim \mathcal{N} (0,I)$，$\odot$表示逐元素乘法，$I$是单位矩阵&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;A = [[1, 2],
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     [3, 4]]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;B = [[5, 6],
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     [7, 8]]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;A ⊙ B = [[1*5, 2*6],
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         [3*7, 4*8]] = [[5, 12],
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        [21, 32]]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;我们只需要学习$\mu,\sigma$，而$\epsilon$作为随机噪声，在单次的传播过程中是固定的，不影响求导&lt;/p&gt;
$$
\mu = \left [\mu_1, \mu_2, ..., \mu_d\right]\\
\sigma = \left [\sigma_1, \sigma_2, ..., \sigma_d\right]\\
\epsilon = \left [\epsilon_1, \epsilon_2, ..., \epsilon_d\right],\epsilon \sim \mathcal{N}(0,1)
$$&lt;p&gt;因此&lt;/p&gt;
$$
x = \mu + \sigma \odot \epsilon\\
x_i = \mu_i + \sigma_i \cdot \epsilon_i,\forall i\\
\therefore x_i\sim \mathcal{N}(\mu_i,\sigma^2_i)
$$&lt;p&gt;
各维度是独立的&lt;/p&gt;
&lt;h4 id=&#34;分布&#34;&gt;分布
&lt;/h4&gt;&lt;p&gt;假设你想知道&amp;quot;今天是否下雨了&amp;quot;（未知事物），但你无法直接看窗外。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;先验分布&lt;/strong&gt;：在没有任何证据时，你根据历史数据猜测&amp;quot;今天下雨的概率是20%&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;证据&lt;/strong&gt;：你听到有人说&amp;quot;地上是湿的&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;后验分布&lt;/strong&gt;：在知道&amp;quot;地上是湿的&amp;quot;这个证据后，你更新对&amp;quot;今天下雨&amp;quot;的概率判断（比如变成70%）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;正态分布高斯分布&#34;&gt;正态分布（高斯分布）
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;性质1：均值与方差的线性组合&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;若$z = ay+b$，且$y\sim \mathcal{N}(\mu, \sigma^2)$，其他均为常数&lt;/p&gt;
&lt;p&gt;则：&lt;/p&gt;
$$
z \sim \mathcal{N}(a\mu + b,a^2\sigma^2 )
$$&lt;ul&gt;
&lt;li&gt;性质2：独立正态分布的和&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;若$y_1,y_2$都是独立的正态分布变量，则他们的和$z=y_1+y_2$也是正态分布&lt;/p&gt;
$$
z\sim \mathcal{N}(\mu_1+\mu_2, \sigma^2_1+\sigma_2^2)
$$&lt;hr&gt;
&lt;h4 id=&#34;加噪&#34;&gt;加噪
&lt;/h4&gt;&lt;p&gt;加噪是一个正向过程&lt;/p&gt;
&lt;p&gt;从数据集的原始图片$x_0$出发，最终需要得到$x_T \sim \mathcal{N}(0,I)$&lt;/p&gt;
&lt;p&gt;如果每一步按照前文所说进行简单加噪&lt;/p&gt;
$$
x_t =x_{t-1} + \epsilon_t, \quad \epsilon_t\sim \mathcal{N}(0,\sigma^2I)
$$&lt;p&gt;
其中$\sigma$可以让我们自己定义&lt;/p&gt;
&lt;p&gt;故随着时间累计：&lt;/p&gt;
$$
x_t = x_0 + \sum_{i=1}^t\epsilon_i
$$&lt;p&gt;
$\epsilon_i$是独立同分布的，故&lt;/p&gt;
$$
x_t \sim \mathcal{N}\left ( x_0, t\sigma^2I \right)
$$&lt;p&gt;
这样无法保证最后$x^T$是一个标准正态分布&lt;/p&gt;
&lt;p&gt;且随着$t$增加，数值的不稳定性会上升&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;加噪目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最终是标准正态分布的纯噪声&lt;/li&gt;
&lt;li&gt;加噪可控、平滑过渡&lt;/li&gt;
&lt;li&gt;数值稳定&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;设计：&lt;/p&gt;
$$
x_t = \sqrt{1-\beta_t}\cdot x_{t-1} + \sqrt{\beta_t}\cdot \epsilon_t
$$&lt;p&gt;
其中$\beta_t$是&lt;strong&gt;预先设定&lt;/strong&gt;的缩放系数，在$(0,1)$之间&lt;/p&gt;
&lt;p&gt;从原理上能够解释为：衰减旧图片，添加新噪声&lt;/p&gt;
&lt;p&gt;推导一下方差：&lt;/p&gt;
$$
\text{Var}(x_t) = \text{Var}(\sqrt{1-\beta_t}\cdot x_{t-1} + \sqrt{\beta_t}\cdot \epsilon_t)\\
= (1-\beta_t)\text{Var}(x_{t-1}) + \beta_t\text{Var}(\epsilon_t)
$$&lt;p&gt;
如果$x_{t-1}$之前的方差都是按照某种方式保持的很好，方差为1&lt;/p&gt;
&lt;p&gt;同时我们知道$\epsilon_t$是标准正态分布，方差也是1&lt;/p&gt;
$$
\text{Var}(x_t)= (1-\beta_t)\text{Var}(x_{t-1}) + \beta_t\text{Var}(\epsilon_t) = 1-\beta_t + \beta_t = 1
$$&lt;p&gt;
所以后续按照此方法，能够始终保持数值稳定&lt;/p&gt;
&lt;h4 id=&#34;高效加噪&#34;&gt;高效加噪
&lt;/h4&gt;&lt;p&gt;一般迭代次数还是足够多的， 如果使用循环就会很慢&lt;/p&gt;
&lt;p&gt;我们可以对公式进行展开：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;迭代1次&lt;/li&gt;
&lt;/ul&gt;
$$
x_1 = \sqrt{1-\beta_1}\cdot x_0 + \sqrt{\beta_1}\cdot \epsilon_1
$$&lt;ul&gt;
&lt;li&gt;迭代2次&lt;/li&gt;
&lt;/ul&gt;
$$
x_2 = \sqrt{1-\beta_2}\cdot x_1 + \sqrt{\beta_2}\cdot \epsilon_2 \\
= \sqrt{1-\beta_2}\cdot (\sqrt{1-\beta_1}\cdot x_0 + \sqrt{\beta_1}\cdot \epsilon_1) + \sqrt{\beta_2}\cdot \epsilon_2 \\
= \sqrt{(1-\beta_1)(1-\beta_2)}x_0 + \sqrt{(1-\beta_2)\beta_1} \cdot \epsilon_1 + \sqrt{\beta_2} \cdot \epsilon_2
$$&lt;ul&gt;
&lt;li&gt;迭代3次&lt;/li&gt;
&lt;/ul&gt;
$$
x_3 = \sqrt{(1 - \beta_3)(1 - \beta_2)(1 - \beta_1)} \cdot x_0 + \sqrt{(1 - \beta_3)(1 - \beta_2)\beta_1} \cdot \epsilon_1 + \sqrt{(1 - \beta_3)\beta_2} \cdot \epsilon_2 + \sqrt{\beta_3} \cdot \epsilon_3
$$&lt;p&gt;令&lt;/p&gt;
$$
\alpha_i = 1-\beta_i,\quad \overline{\alpha}_t = \prod_{i=1}^{t}\alpha_i  
$$&lt;ul&gt;
&lt;li&gt;$x_0$的系数：$\sqrt{\overline{\alpha}_t}$&lt;/li&gt;
&lt;li&gt;$\epsilon_i$的系数：$\sqrt{\beta_i\prod_{j=i+1}^t \alpha_j} = \sqrt{\beta_i\cdot\frac{\overline{\alpha}_t}{\overline{\alpha}_i}}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;得：&lt;/p&gt;
$$
x_t = \sqrt{\overline{\alpha}_t}x_0 + \sum_{i=1}^t\sqrt{\beta_i\cdot\frac{\overline{\alpha}_t}{\overline{\alpha}_i}}\cdot \epsilon_i
$$&lt;p&gt;
左边是定值，右边显然服从某个正态分布&lt;/p&gt;
&lt;p&gt;并且方差完全取决于系数，令&lt;/p&gt;
$$
\sigma^2_t=\sum_{i=1}^t\beta_i\cdot\frac{\overline{\alpha}_t}{\overline{\alpha}_i} = \sum_{i=1}^t\beta_i\prod_{k=i+1}^t(1-\beta_k)
$$&lt;p&gt;此时有：$x_t\sim \mathcal{N}(0,\sigma^2_tI)$&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;这里有点跳跃，我们希望之间使用一个更简单的表示替换掉这个&lt;/p&gt;
&lt;p&gt;如果我们能够找到一个方差相等的一项，就可以替换&lt;/p&gt;
&lt;p&gt;这里智慧的假设是&lt;/p&gt;
$$
1-\overline{\alpha}_t
$$&lt;p&gt;
使用数学归纳法进行证明，当 $t=2$​时：&lt;/p&gt;
$$
1-\overline{\alpha}_t = 1-(1-\beta_1)(1-\beta_2) = \beta_1+\beta_2-\beta_1\beta_2\\
\sigma^2=\beta_1(1-\beta_2) + \beta_2 = \beta_1+\beta_2-\beta_1\beta_2
$$&lt;p&gt;
两者相等&lt;/p&gt;
&lt;p&gt;推导两者的递推关系&lt;/p&gt;
&lt;p&gt;前者：&lt;/p&gt;
$$
1-\overline{\alpha}_t = 1 - \overline{\alpha}_{t-1}\cdot(1-\beta_t) = (1-\beta_t)(1-\overline{\alpha}_{t-1}) + \beta_t
$$&lt;p&gt;
后者：&lt;/p&gt;
$$
\sigma_t^2 =\sum_{i=1}^t\beta_i\prod_{k=i+1}^t(1-\beta_k) \\
= \sum_{i=1}^{t-1}\beta_i(1-\beta_t)\prod_{k=i+1}^{t-1}(1-\beta_k) + \beta_t \\
= (1-\beta_t)\sum_{i=1}^{t-1}\beta_i\prod_{k=i+1}^{t-1}(1-\beta_k) + \beta_t \\
= (1-\beta_t)\sigma_{t-1}^2+\beta_t
$$&lt;p&gt;两者递推关系相同，故有：&lt;/p&gt;
$$
\sigma^2_t = 1-\overline{\alpha}_t
$$&lt;p&gt;
原噪声项满足&lt;/p&gt;
$$
\sum_{i=1}^t\sqrt{\beta_i\cdot\frac{\overline{\alpha}_t}{\overline{\alpha}_i}}\cdot \epsilon_i \sim \mathcal{N}(0,(1-\overline{\alpha}_t)I)
$$&lt;p&gt;
替换成满足同一个分布的噪声项&lt;/p&gt;
$$
\sqrt{ 1-\overline{\alpha}_t}\cdot \epsilon
$$&lt;p&gt;
依旧可以使得$x_t \sim \mathcal{N}(0, (1-\overline{\alpha}_t)I)$&lt;/p&gt;
&lt;p&gt;所以完全可以写成：&lt;/p&gt;
$$
x_t = \sqrt{\overline{\alpha}_t}x_0 +\sqrt{ 1-\overline{\alpha}_t}\cdot \epsilon, \quad \epsilon\sim\mathcal{N}(0,I)
$$&lt;p&gt;至此，我们可以通过该公式直接从一个干净的$x_0$得到一个加噪图片$x_t$，极大简化了训练过程&lt;/p&gt;
&lt;p&gt;并且该式符合重参数化的&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为什么上面的公式是$\epsilon$？&lt;/p&gt;
&lt;p&gt;由于我们保证数值稳定，因此本质上是加上关于$\epsilon_i$的一个线性组合（并且线性组合系数权重始终为1），因此等价于只加上一次的标准正态分布&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;去噪&#34;&gt;去噪
&lt;/h4&gt;&lt;p&gt;去噪是训练的核心步骤与目标&lt;/p&gt;
&lt;p&gt;定义真实的逆向分布：&lt;/p&gt;
$$
q\left(x_{t-1}\mid x_t\right)
$$&lt;p&gt;
由于上文所提到的运算关系，计算$q(x_t\mid x_{t-1})$​是没问题的&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;这里我们打断一下，不妨推导一下$q(x_t\mid x_{t-1})$的分布&lt;/p&gt;
&lt;p&gt;首先有如下关系：&lt;/p&gt;
$$
x_t = \sqrt{1-\beta_t}\cdot x_{t-1} + \sqrt{\beta_t}\cdot \epsilon_t
$$&lt;p&gt;
则有（已知$x_{t-1}$的情况推$x_t$，故可以把$x_{t-1}$看作定值，且$\epsilon \sim \mathcal{N}(0,I)$）：&lt;/p&gt;
$$
\mathbb{E}(x_t\mid x_{t-1}) = \sqrt{1-\beta_t}\mathbb{E}(x_{t-1}) + \sqrt{\beta_t}\mathbb{E}(\epsilon_t) = \sqrt{1-\beta_t}\cdot x_{t-1} \\
\text{Var}(x_t\mid x_{t-1}) = \beta_tI
$$&lt;p&gt;
故：&lt;/p&gt;
$$
q(x_t\mid x_{t-1})\sim \mathcal{N}(x_t;\sqrt{1-\beta_t}\cdot x_{t-1}, \beta_tI)
$$&lt;p&gt;
补充解释一下这个诡异的分号，其代表该分布是关于$x_t$的分布，即只有$x_t$是随机变量&lt;/p&gt;
&lt;p&gt;？？？？？？&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;但是反过来计算逆向分布是一件非常难的事情&lt;/p&gt;
&lt;p&gt;我们需要学一个模型，定义为：&lt;/p&gt;
$$
p_\theta\left(x_{t-1}|x_t\right)
$$</description>
        </item>
        <item>
        <title>Colab SSH指南</title>
        <link>https://example.com/p/colab-ssh%E6%8C%87%E5%8D%97/</link>
        <pubDate>Mon, 08 Sep 2025 16:18:42 +0800</pubDate>
        
        <guid>https://example.com/p/colab-ssh%E6%8C%87%E5%8D%97/</guid>
        <description>&lt;h1 id=&#34;colab-ssh&#34;&gt;Colab SSH
&lt;/h1&gt;&lt;p&gt;在colab中新建一个&lt;code&gt;init.sh&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install colab_ssh --upgrade
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在notebook中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 初始化colab ssh&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bash&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;drive&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MyDrive&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ssh&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;init&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sh&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然后挂载一下云盘&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 挂载云盘&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;google.colab&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;drive&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;drive&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/content/drive/&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;启动colab-ssh&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Install colab_ssh on google colab&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;colab_ssh&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;launch_ssh_cloudflared&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;init_git_cloudflared&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;launch_ssh_cloudflared&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;password&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;colab_passwd&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#这里改成你自己的密码&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;点击&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/colab-ssh%E6%8C%87%E5%8D%97/assets/image-20250908162438397.png&#34;
	width=&#34;1216&#34;
	height=&#34;518&#34;
	srcset=&#34;https://example.com/p/colab-ssh%E6%8C%87%E5%8D%97/assets/image-20250908162438397_hu_e025558ba4e8a9c0.png 480w, https://example.com/p/colab-ssh%E6%8C%87%E5%8D%97/assets/image-20250908162438397_hu_947d53edddd24c70.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;234&#34;
		data-flex-basis=&#34;563px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;然后下载对应的客户端&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/colab-ssh%E6%8C%87%E5%8D%97/assets/image-20250908162504719.png&#34;
	width=&#34;1460&#34;
	height=&#34;752&#34;
	srcset=&#34;https://example.com/p/colab-ssh%E6%8C%87%E5%8D%97/assets/image-20250908162504719_hu_23e2b62ae686fc86.png 480w, https://example.com/p/colab-ssh%E6%8C%87%E5%8D%97/assets/image-20250908162504719_hu_e8717bcbe47c736b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;194&#34;
		data-flex-basis=&#34;465px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;然后将这个程序存放到&lt;strong&gt;本地中的某个路径&lt;/strong&gt;，假设是&lt;code&gt;V:\colab\cloudflared-windows-amd64.exe&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;vs-code&#34;&gt;VS code
&lt;/h2&gt;&lt;p&gt;首先确保安装了插件&lt;code&gt;Remote - SSH&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;配置文件按colab给定的内容写，然后把路径替换，注意是&lt;strong&gt;绝对路径&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Host *.trycloudflare.com
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	HostName %h
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	User root
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	Port 22
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	ProxyCommand V:\colab\cloudflared-windows-amd64.exe access ssh --hostname %h
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然后复制这一串&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/colab-ssh%E6%8C%87%E5%8D%97/assets/image-20250908170930234.png&#34;
	width=&#34;1279&#34;
	height=&#34;435&#34;
	srcset=&#34;https://example.com/p/colab-ssh%E6%8C%87%E5%8D%97/assets/image-20250908170930234_hu_418bc8d1a3bbddb2.png 480w, https://example.com/p/colab-ssh%E6%8C%87%E5%8D%97/assets/image-20250908170930234_hu_ad07cd45644a0358.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;294&#34;
		data-flex-basis=&#34;705px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;作为连接命令去使用remote连一下就好了&lt;/p&gt;
</description>
        </item>
        <item>
        <title>大语言模型教育纠错 · 论文笔记（三）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/</link>
        <pubDate>Sat, 06 Sep 2025 20:45:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.alphaxiv.org/abs/2412.09416v2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Unifying AI Tutor Evaluation: An Evaluation Taxonomy for Pedagogical Ability Assessment of LLM-Powered AI Tutors | alphaXiv&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/kaushal0494/UnifyingAITutorEvaluation&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;kaushal0494/UnifyingAITutorEvaluation: An Evaluation Taxonomy for Pedagogical Ability Assessment of LLM-Powered AI Tutors&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;paper-cool&#34;&gt;Paper-Cool
&lt;/h2&gt;&lt;h3 id=&#34;q1-这篇论文试图解决什么问题&#34;&gt;&lt;strong&gt;Q1&lt;/strong&gt;: 这篇论文试图解决什么问题？
&lt;/h3&gt;&lt;p&gt;这篇论文试图解决的问题是如何有效地评估大型语言模型（LLMs）作为AI助教在教育对话中的表现，特别是在学生错误纠正方面。具体来说，论文试图解决以下几个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;评估标准的统一性&lt;/strong&gt;：之前对AI助教的评估工作受限于主观协议和基准，缺乏统一的评估框架。论文提出了一个基于学习科学原则的统一评估分类体系，包含八个教学维度，旨在评估LLM驱动的AI助教在数学领域的学生错误纠正中的教学价值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估的客观性和可靠性&lt;/strong&gt;：现有的评估方法往往依赖于主观评价，缺乏客观性和可比性。论文通过提出一个新的评估基准MRBench，并提供人工标注的八个教学维度，来提高评估的客观性和可靠性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI助教的实际教学能力&lt;/strong&gt;：论文通过对比不同LLMs作为AI助教的能力和人类助教的表现，揭示了当前LLMs在教学能力上的不足，并指出了改进的方向。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估过程的简化和标准化&lt;/strong&gt;：论文希望通过提出的分类体系、基准和人工标注的标签，简化AI助教的评估过程，并帮助跟踪AI助教发展的进步。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总的来说，这篇论文旨在通过提出一个新的评估框架和基准，来解决当前AI助教评估中存在的问题，推动AI助教的发展，并为未来的研究提供便利。&lt;/p&gt;
&lt;h3 id=&#34;q2-有哪些相关研究&#34;&gt;&lt;strong&gt;Q2&lt;/strong&gt;: 有哪些相关研究？
&lt;/h3&gt;&lt;p&gt;相关研究涵盖了以下几个领域：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;AI助教评估&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;Tack和Piech (2022) 以及 Tack 等人 (2023) 从教师语言、学生理解和帮助学生的角度评估模型的响应。&lt;/li&gt;
&lt;li&gt;Macina 等人 (2023) 专注于连贯性、正确性和公平教学来评估模型作为教师的响应。&lt;/li&gt;
&lt;li&gt;Wang 等人 (2024a) 评估了有用性、关怀和人类化。&lt;/li&gt;
&lt;li&gt;Daheim 等人 (2024) 集中于针对性、正确性和可执行性来评估教师响应的质量。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自然语言生成（NLG）和LLM基础评估&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;一般领域的NLG指标，如BLEU (Papineni et al., 2002)、BERTScore (Lin, 2004) 和 DialogRPT (Gao et al., 2020) 等，被用作衡量AI助教响应的连贯性和类人性，但这些指标不考虑教学价值，且常需要真实答案来评估匹配响应。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;面向教学的评估&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;传统学习科学中的评估方法主要设计用于评估人类教师，由于缺乏自我报告，不易直接应用于AI教师。&lt;/li&gt;
&lt;li&gt;研究人员考虑不同的教学维度及其相关定义 (Wollny et al., 2021; Tack et al., 2023; Denny et al., 2024)。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;学生错误纠正任务&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;专注于数学领域的教育对话，特别是学生的失误或困惑，AI教师的目标是回应以纠正这些错误或困惑。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些相关研究提供了评估AI助教的不同视角和方法，但存在评估方案和定义的差异，缺乏标准化，使得跟踪现有AI教师的进步和实际性能变得复杂。这篇论文提出的评估分类体系旨在统一这些评估方法，并提供一个基于学习科学原则的评估框架。&lt;/p&gt;
&lt;h3 id=&#34;q3-论文如何解决这个问题&#34;&gt;&lt;strong&gt;Q3&lt;/strong&gt;: 论文如何解决这个问题？
&lt;/h3&gt;&lt;p&gt;论文通过以下几个步骤解决AI助教评估的问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;提出统一评估分类体系&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文提出了一个基于学习科学原则的统一评估分类体系，包含八个教学维度，用于评估LLM驱动的AI助教在数学领域的学生错误纠正中的教学价值。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;构建评估基准MRBench&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文编译并发布了一个新的评估基准MRBench，该基准包含来自两个公共数据集的192个对话和1596个响应，这些响应来自七个最先进的基于LLM的和人类助教，并提供了八个教学维度的黄金标注。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;人类和LLM评估&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;利用部分对话历史，展示了学生的失误，生成了七个最先进的LLM作为助教的响应，并通过人类和LLM基础评估来评估这些模型的教学能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分析LLM作为评估者的可靠性&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文探讨了LLM作为评估者的可靠性，通过将LLM生成的评估与人类判断进行相关性分析，指出LLM在复杂教学维度上的评估是不可靠的。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;讨论改进方向&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文基于人类评估指出了LLMs在响应中表现出的特定教学能力的不足，并讨论了改进AI助教教学能力的最相关方向。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;资源公开&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文承诺将公开分类体系、基准和人类标注，以促进未来在这一重要领域的研究。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通过这些步骤，论文旨在简化AI助教的评估过程，并帮助跟踪AI助教发展的进步。此外，该研究还为创建和标注可用于强化学习和微调的数据集提供了可能性，帮助未来的AI助教与人类和教学价值观保持一致。&lt;/p&gt;
&lt;h3 id=&#34;q4-论文做了哪些实验&#34;&gt;&lt;strong&gt;Q4&lt;/strong&gt;: 论文做了哪些实验？
&lt;/h3&gt;&lt;p&gt;论文中进行了一系列实验来验证提出的评估分类体系的有效性，并评估不同LLM作为AI助教的教学能力。以下是主要的实验步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;评估分类体系验证&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;进行了验证实验，以确定提出的八个评估维度是否足够且无冗余。实验包括四名注释者对八个随机抽样的对话进行独立标注，并计算Fleiss&amp;rsquo; kappa值来衡量注释者间的一致性，结果表明有实质性的一致性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基准准备&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;从Bridge和MathDial数据集中编译了MRBench评估基准，并为192个实例生成了基于七个最先进的LLM的响应。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;人类标注&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;四名训练有素的标注者使用验证过的分类体系对MRBench进行了标注，每个标注者负责48个对话，总共192个实例被标注，其中40个实例由两名标注者独立标注，以计算标注者间的一致性，平均Cohen&amp;rsquo;s kappa得分为0.71，表明有实质性的一致性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LLM基础标注&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;使用Prometheus2 LLM作为评估者对MRBench进行标注，以评估LLM作为评估者的可靠性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估指标&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;使用期望标注匹配率（DAMR）和标注相关性（AC）两个关键指标来定量评估LLM和人类教师的教学效果，并进行比较分析。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;关键发现&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;基于人类和LLM对MRBench的评估，总结了不同LLM作为AI助教的教学能力的关键发现，并讨论了LLM作为评估者的可靠性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些实验步骤不仅验证了提出的评估分类体系的有效性，而且提供了对不同LLM在教学能力方面的深入分析，并探讨了LLM作为评估者的可行性。通过这些实验，论文展示了当前LLM作为AI助教的能力和局限性，并指出了未来改进的方向。&lt;/p&gt;
&lt;h3 id=&#34;q5-有什么可以进一步探索的点&#34;&gt;&lt;strong&gt;Q5&lt;/strong&gt;: 有什么可以进一步探索的点？
&lt;/h3&gt;&lt;p&gt;论文在最后部分提出了一些可以进一步探索的点，这些包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;扩展到其他任务和学科领域&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文提出的评估分类体系主要集中在数学领域的学生错误纠正任务上。未来的研究可以验证并可能适应这个分类体系，以应用于其他任务（如概念学习）和学科（如科学、语言学习等）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;考虑学生视角&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;目前的分类体系和标注方案关注于教师响应的适当性，但未考虑辅导对话对学生学习过程和学习成果的整体影响。未来的研究可以将评估扩展到对话层面，以更好地评估AI教师的教学能力对学生学习的影响。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用其他LLM作为评估者&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文中限制了LLM基础评估到Prometheus2 LLM作为批评者的使用。未来的研究可以探索更多先进的LLM作为批评者，并尝试使用多种提示模板。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;创建和标注数据集&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文提到，创建和标注可用于强化学习和微调的数据集，可以帮助未来的AI教师与人类和教学价值观保持一致。这是一个重要的研究方向，可以促进AI教师的发展。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;改进LLM的教学能力&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文的研究发现，即使是最先进的LLM也缺乏一些有效的教学能力。未来的研究可以探索如何改进LLMs，使其更符合教学的有效性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估LLM生成内容的伦理和风险&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;考虑到LLM可能生成事实上不正确、无意义或甚至冒犯的内容，未来的研究需要考虑评估LLM在教育领域使用时的伦理风险，并探索如何减轻这些问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些探索点为AI助教评估和开发的未来研究提供了明确的方向，并强调了需要进一步工作以提高AI教师的教学效果和可靠性。&lt;/p&gt;
&lt;h3 id=&#34;q6-总结一下论文的主要内容&#34;&gt;&lt;strong&gt;Q6&lt;/strong&gt;: 总结一下论文的主要内容
&lt;/h3&gt;&lt;p&gt;这篇论文的主要内容包括以下几个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;研究动机&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文探讨了当前最先进的大型语言模型（LLMs）是否能够作为有效的AI助教，并展示必要的教学能力，特别是在教育对话中纠正学生错误和困惑的场景。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估分类体系&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;提出了一个统一的评估分类体系，包含八个基于学习科学原则的教学维度，用于评估LLM驱动的AI助教在数学领域的学生错误纠正中的教学价值。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估基准MRBench&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;发布了一个新的评估基准MRBench，包含192个对话和1596个响应，这些响应来自七个最先进的基于LLM的和人类助教，并提供了八个教学维度的黄金标注。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;人类和LLM评估&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;通过人类和LLM基础评估，分析了不同LLM作为AI助教的教学能力，并讨论了LLM作为评估者的可靠性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;研究发现&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;发现尽管最先进的LLMs如GPT-4在回答问题方面表现良好，但作为教师时往往不够胜任，特别是在不立即透露答案和提供指导方面。&lt;/li&gt;
&lt;li&gt;Llama-3.1-405B在评估中表现最好，而GPT-4作为教师时太快透露答案，Gemini的响应不够连贯，Sonnet虽然注重人类化和鼓励性，但在其他维度上效果较差，Phi3的表现最差。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;结论和未来工作&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文得出结论，当前的LLMs作为AI教师还不够好，有很大的改进空间，并指出了最相关的改进方向。&lt;/li&gt;
&lt;li&gt;论文希望发布的资源能够简化评估过程，并帮助跟踪AI教师的发展。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;局限性和伦理声明&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文承认了研究的局限性，并强调了LLM输出可能带来的风险，尤其是在教育领域可能误导学生和传播偏见的问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这篇论文为AI助教的评估提供了一个统一的框架和基准，并通过对现有技术的评估，揭示了AI助教在教学能力上的不足和未来改进的方向。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>李宏毅机器学习2025 · Transformer</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-transformer/</link>
        <pubDate>Sat, 06 Sep 2025 17:39:34 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-transformer/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1aiADewEBC&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;李宏毅机器学习2025&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;transformer&#34;&gt;Transformer
&lt;/h1&gt;</description>
        </item>
        <item>
        <title>李宏毅机器学习2025 · Agent</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/</link>
        <pubDate>Wed, 03 Sep 2025 17:13:34 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1aiADewEBC&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;李宏毅机器学习2025&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;agent&#34;&gt;Agent
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;传统AI：给定明确步骤、指令，AI完成任务&lt;/p&gt;
&lt;p&gt;Agent：给定目标，由Agent想办法完成&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Agent将通过观察Environment，采取特定的Action&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;强化学习：通过强化学习方法得到的Agent是可行的，但是不具备通用能力（围棋Agent不能处理五子棋）&lt;/li&gt;
&lt;li&gt;LLM：通过文字描述进行交互，具备通用能力&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Goal、Environment1、Action1、Environment2、Action2……&lt;/p&gt;
&lt;p&gt;本质上也是在接龙&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;回合制的交互会比较好做，有时候会需要被实时打断&lt;/p&gt;
&lt;p&gt;即：Action执行时，Environment变化，会需要Agent中断Action，进行新的Action&lt;/p&gt;
&lt;p&gt;常见应用：语音聊天&lt;/p&gt;
&lt;h2 id=&#34;memory&#34;&gt;Memory
&lt;/h2&gt;&lt;p&gt;交互的次数足够多时，记忆量过大，会造成Agent性能下降&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903173912076.png&#34;
	width=&#34;979&#34;
	height=&#34;438&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903173912076_hu_367f3630cccba63d.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903173912076_hu_2b228b5efbfd68d5.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Relevant Experience&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;223&#34;
		data-flex-basis=&#34;536px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;因此针对相关经验做一些记忆的检索和筛选是必要的&lt;/p&gt;
&lt;p&gt;可以直接套RAG的技术&lt;/p&gt;
&lt;p&gt;但这里最好不要提供模型&lt;strong&gt;过去的错误例子&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这里的情景似乎没有做一些纠错任务，给了错误的例子性能会发生下降&lt;/p&gt;
&lt;p&gt;因此设计Agent时需要考虑一下哪些内容是应该提供或筛除的&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;模型的使用技巧：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;告诉模型&lt;strong&gt;应该做什么&lt;/strong&gt;比告诉模型&lt;strong&gt;不要做什么&lt;/strong&gt;效果更好&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903174906691.png&#34;
	width=&#34;996&#34;
	height=&#34;562&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903174906691_hu_f6af179a283dfdc5.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903174906691_hu_821175316e4721a6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;其他模块&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;425px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;从存储角度出发&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;有些记忆没有存储的必要，因此可以引入一个Write模型去分类筛选&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有些记忆可以被格式化、转化成更好、更通用的内容，可以引入Reflection模块做转化，存储到合适的载体中，方便Read去做RAG&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;function-call&#34;&gt;Function Call
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175717235.png&#34;
	width=&#34;914&#34;
	height=&#34;506&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175717235_hu_ed1a5d1a14bada8b.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175717235_hu_e71df3da242a3060.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;180&#34;
		data-flex-basis=&#34;433px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175818476.png&#34;
	width=&#34;917&#34;
	height=&#34;467&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175818476_hu_22c32e30ae66218a.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175818476_hu_5c8473782c8d6e9a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;196&#34;
		data-flex-basis=&#34;471px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;通常会把调用方法、工具列表放在System Prompt中&lt;/p&gt;
&lt;p&gt;让用户通过User Prompt进行交互&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Function过多时，可以参考上述的Memory方法去做选择&lt;/li&gt;
&lt;li&gt;Agent也可以自己做一个Function，放入Memory中&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;Agent有时候会过度相信工具&lt;/p&gt;
&lt;p&gt;因此需要看看模型自己是否有辨别的能力（室温10000°？不对，这里是工具出错了）&lt;/p&gt;
&lt;p&gt;但其实加一个Reflection也不错&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;课堂中探索了哪些信息是容易被模型采纳的&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903180638418.png&#34;
	width=&#34;1004&#34;
	height=&#34;447&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903180638418_hu_288966a3f1308ca0.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903180638418_hu_7fc90cbfb0772e7d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Ex1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;224&#34;
		data-flex-basis=&#34;539px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;当原始上下文逐渐被不切实际的值修改时，LLM（大语言模型）会越来越多地回归到其先验知识&lt;/li&gt;
&lt;li&gt;LLM坚持遵循上下文中检索到的信息的可能性，与其在没有上下文时对自身回复的信心呈负相关。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;省流：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;外部知识如果和模型知识差距越大，模型会对模型知识更有信心；差距越小，模型更愿意相信外部知识&lt;/li&gt;
&lt;li&gt;模型对模型知识的likelihood越大，对外部知识的likelihood越小&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181056340.png&#34;
	width=&#34;980&#34;
	height=&#34;345&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181056340_hu_9337652e32037257.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181056340_hu_4a48cefaca72e4f5.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Ex2&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;284&#34;
		data-flex-basis=&#34;681px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;AI和人类分别给出两个意见不同的文章，AI倾向于相信AI&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ex单独抽取了AI回答错误的例子（排除AI与AI回答类似，造成偏好的情况），但仍然是AI更相信AI&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体原因未知，猜测是AI的文章结构、表达上比人类更好&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2401.11911&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181530086.png&#34;
	width=&#34;992&#34;
	height=&#34;443&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181530086_hu_ce69793f148b679b.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181530086_hu_3f116d49e637459e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Ex3&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;223&#34;
		data-flex-basis=&#34;537px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;（这里首先都是用了AI生成的文章做实验，避免偏好问题，并且文章都是假的）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Meta Data会影响模型的采纳&lt;/li&gt;
&lt;li&gt;其中时间影响较大&lt;/li&gt;
&lt;li&gt;资料来源写Wikipedia还是其他来源，似乎没有什么影响（这里比较反直觉）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是实验做得似乎比较粗糙，看看就好&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;总结：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型总会犯错&lt;/li&gt;
&lt;li&gt;Function Call要不要采用取决模型本身能力，如果模型可以自己解决没必要Call&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;plan&#34;&gt;Plan
&lt;/h2&gt;&lt;p&gt;目前的Agent都喜欢做一个Plan，再开始Action&lt;/p&gt;
&lt;p&gt;但是Plan不能定太死&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;操作浏览器时突然出现一个广告弹窗&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182236824.png&#34;
	width=&#34;1040&#34;
	height=&#34;351&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182236824_hu_655a62e81b69f692.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182236824_hu_9d822b41853c3318.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Plan&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;296&#34;
		data-flex-basis=&#34;711px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;因此Plan需要灵活，一种方案是：每次思考一下Plan要不要重新制定&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;如何强化模型的规划能力？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182925762.png&#34;
	width=&#34;1036&#34;
	height=&#34;530&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182925762_hu_e0ecbc68cec78b03.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182925762_hu_c450aee5b61cfd30.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;搜索与剪枝&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;195&#34;
		data-flex-basis=&#34;469px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;让模型实际去探索一下（本质是搜索）&lt;/li&gt;
&lt;li&gt;可以剪枝（自问自答：当前还有机会完成任务吗？）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（不适合不容易回溯状态的任务，例如：订餐）&lt;/p&gt;
&lt;p&gt;（但是可以引入一个World Model，让模型扮演环境本身去做反馈，模拟）&lt;/p&gt;
&lt;p&gt;从Agent的角度去看待模型Thinking Mode：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903183347542.png&#34;
	width=&#34;1062&#34;
	height=&#34;542&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903183347542_hu_7409da7ba96a6ac5.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903183347542_hu_71f6bd0b8e42b3cb.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Thinking Mode&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;195&#34;
		data-flex-basis=&#34;470px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;一些杂谈：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;做benchmark或一些实验的时候，思考一下这个任务LLM会不会在互联网数据中提前得到&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>李宏毅机器学习2025 · 前言</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/</link>
        <pubDate>Tue, 02 Sep 2025 20:46:34 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1aiADewEBC&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;李宏毅机器学习2025&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;被手搓大模型橄榄了，写BPE写的心态爆了&lt;/p&gt;
&lt;p&gt;不如我们先停下来推一下一些比较有趣的课程&lt;/p&gt;
&lt;h1 id=&#34;前言&#34;&gt;前言
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;Those token could be anything.&lt;/p&gt;
&lt;p&gt;解析任何事物为若干有限的基本单位（token），你就可以使用生成式AI做任何事情&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;auto-regressive-generation&#34;&gt;Auto Regressive Generation
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;自回归生成（其实就是词语接龙）&lt;/li&gt;
&lt;/ul&gt;
$$
x_1,x_2,...,x_j \to y_1\\
x_1,x_2,...,x_j,y_1 \to y_2\\
x_1,x_2,...,x_j,y_1,y_2 \to ...\\
x_1,x_2,...,x_j,y_1,y_2,... \to \text{end token}\\
$$&lt;p&gt;token作为文字时：语言模型&lt;/p&gt;
&lt;p&gt;（但是不管是什么都会被称为语言模型，因为热度太大了）&lt;/p&gt;
&lt;p&gt;本质上都是在有限的选择中做出选择完成输出&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902210520749.png&#34;
	width=&#34;877&#34;
	height=&#34;483&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902210520749_hu_c6d279eefb5346cf.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902210520749_hu_8732fdb1d4ca93a8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;生成式AI&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;181&#34;
		data-flex-basis=&#34;435px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过Neural Network，得到的是各个token的概率分布
&lt;ul&gt;
&lt;li&gt;模型架构（超参数）：由人类确定&lt;/li&gt;
&lt;li&gt;模型参数：由数据决定&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;thinking-mode&#34;&gt;Thinking Mode
&lt;/h2&gt;&lt;p&gt;对于现实中的问题，往往足够复杂，哪怕模型足够巨大，层数足够多，可能也无法处理&lt;/p&gt;
&lt;p&gt;而带有思考能力的LLM表现良好，可以从模型层数的角度进行解释&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902210943599.png&#34;
	width=&#34;903&#34;
	height=&#34;427&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902210943599_hu_6aee250c4eea9f13.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902210943599_hu_dc25cb538fafd38d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Thinking Mode&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;211&#34;
		data-flex-basis=&#34;507px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;每次给定输入token集合，产生一个token的输出，模型会过一遍所有的Layer&lt;/p&gt;
&lt;p&gt;所以只要不断思考，本质上是一直在重复这个模型Layer的堆积&lt;/p&gt;
&lt;p&gt;因此思考长度足够，似乎是在使用一个&lt;strong&gt;巨深的模型&lt;/strong&gt;进行推理&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;训练时缩放（Training Time Scaling）&lt;/strong&gt;：通过训练来让模型变得更强大。这需要巨大的成本重新训练模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;增加模型参数量（scale up）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;增加训练数据&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;延长训练时间（增加计算量）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;测试时缩放（Testing Time Scaling）&lt;/strong&gt;：&lt;strong&gt;模型已经训练好了，参数固定不变。&lt;/strong&gt; 我们通过一些“技巧”，在&lt;strong&gt;使用&lt;/strong&gt;这个模型的时候投入更多的计算资源&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;生成多个答案然后挑最好的&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;更仔细地推理&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Testing Time Scaling：在不改变模型本身weights的情况下，仅通过改变inference或testing时的方法和计算量，就能显著提升模型性能的一种现象或技术集合。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902213913156.png&#34;
	width=&#34;928&#34;
	height=&#34;402&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902213913156_hu_492ada79126596e9.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902213913156_hu_6bb28dd1c56cb705.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;TTS&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;230&#34;
		data-flex-basis=&#34;554px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;本质上是在叠加模型层数，如图，思考的token开销越多，性能确实越好&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如何控制token？一个粗暴的方法，在结束的时候把end变成wait&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;development&#34;&gt;Development
&lt;/h2&gt;&lt;p&gt;模型的演变经历了专用模型到通用模型的趋势&lt;/p&gt;
&lt;p&gt;而通用模型的演变也非常迅速&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902215817397.png&#34;
	width=&#34;938&#34;
	height=&#34;485&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902215817397_hu_4de31912bfc26bb8.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902215817397_hu_83cd7663fa05fbf4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Encoder&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;464px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Encoder：将文本encode成向量
&lt;ul&gt;
&lt;li&gt;配套专用模型完成输出&lt;/li&gt;
&lt;li&gt;架构不同&lt;/li&gt;
&lt;li&gt;参数不同&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902220023151.png&#34;
	width=&#34;923&#34;
	height=&#34;486&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902220023151_hu_1a956035b96d2c2b.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902220023151_hu_8a168de1792f4caa.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Fine-tune&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;189&#34;
		data-flex-basis=&#34;455px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fine-Tune：通过微调适配不同任务
&lt;ul&gt;
&lt;li&gt;架构相同&lt;/li&gt;
&lt;li&gt;参数不同&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902220142932.png&#34;
	width=&#34;920&#34;
	height=&#34;482&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902220142932_hu_3f5c6b335bc46f46.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902220142932_hu_79525b51f8b740bb.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Prompt&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;190&#34;
		data-flex-basis=&#34;458px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prompt：直接给指令做不同任务
&lt;ul&gt;
&lt;li&gt;架构相同&lt;/li&gt;
&lt;li&gt;参数相同&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Homework1就不做了，一个RAG任务，之前做过类似的&lt;/p&gt;
</description>
        </item>
        <item>
        <title>大语言模型教育纠错 · 论文笔记（二）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/</link>
        <pubDate>Wed, 16 Jul 2025 02:45:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2406.19949&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2406.19949 Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro
&lt;/h2&gt;&lt;p&gt;存在的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;基于分类器的黑盒方法虽然准确，但无法提供解释性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;现有生成评分理由的方法（如AERA框架(&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2305.12962&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2305.12962 Distilling ChatGPT for Explainable Automated Student Answer Assessment&lt;/a&gt;）存在以下问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;评分准确性不如分类器方法。&lt;/li&gt;
&lt;li&gt;生成的评分理由可能不忠实于学生答案或评分标准。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;paper贡献&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提出一种新框架，通过模仿人类评分过程生成更忠实的评分理由，同时匹配或超越分类器方法的评分性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;paper方法&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;模仿人类评分过程&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用大语言模型（LLM）生成“思维树”（Thought Tree），将评分任务分解为中间决策步骤。&lt;/li&gt;
&lt;li&gt;每条树路径代表一个评分决策序列，最终汇总为评分理由。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;合成数据生成&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从思维树路径中提取合成评分理由和偏好数据。&lt;/li&gt;
&lt;li&gt;通过两阶段训练校准LLM：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;监督微调（SFT）&lt;/strong&gt;：使用合成的评分理由数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;偏好优化（DPO）&lt;/strong&gt;：使用合成的偏好数据，提升评分理由的准确性和忠实性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;paper贡献&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提出通过思维树生成更忠实的评分理由的方法。&lt;/li&gt;
&lt;li&gt;开发基于思维树路径正确性的合成偏好数据生成技术。&lt;/li&gt;
&lt;li&gt;实验表明，框架在QWK分数上比现有方法提升38%，同时生成更高质量的评分理由。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;framework&#34;&gt;Framework
&lt;/h2&gt;&lt;h3 id=&#34;problem-set-up&#34;&gt;Problem Set Up
&lt;/h3&gt;$$
D = \left \{ (x_i, y_i)\right \}
$$&lt;p&gt;
表示学生$i$对某道题目的答案与得分&lt;/p&gt;
&lt;p&gt;对于一道题目，可以划分出$M$个关键得分点$K = \left {k_j\right }$&lt;/p&gt;
$$
v(x_i, K)
$$&lt;p&gt;
该向量的第$j$维度若为1，则表示$x_i$成功回答了$k_j$，否则没有成功回答&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;独热向量 (One-hot Vector)&lt;/strong&gt;：用于表示一个样本&lt;strong&gt;只属于一个类别&lt;/strong&gt;的情况。例如，如果一个动物只能是“- 猫”或“狗”中的一种，那么“猫”可能表示为 &lt;code&gt;[1, 0]&lt;/code&gt;，“狗”表示为 &lt;code&gt;[0, 1]&lt;/code&gt;。向量中&lt;strong&gt;只有一个 1&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;多热向量 (Multi-hot Vector)&lt;/strong&gt;：用于表示一个样本&lt;strong&gt;可以同时属于多个类别&lt;/strong&gt;的情况。例如，一个人既是“学生”又是“运动员”，那么可能表示为 &lt;code&gt;[1, 1, 0]&lt;/code&gt;（假设第一个位置是学生，第二个是运动员）。向量中可以有&lt;strong&gt;多个 1&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
$$
y_i = f_r(v(x_i,K))
$$&lt;p&gt;
省流：问题的关键在如何判断$x_i$正确回答了$k_j$，记为$1_{x_i}(k_j)$，是一个二分类任务&lt;/p&gt;
&lt;h3 id=&#34;stage-1-imitate-human-assessment-process-via-thought-trees&#34;&gt;Stage 1: Imitate Human Assessment Process via Thought Trees
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/assets/image-20250716031327371.png&#34;
	width=&#34;961&#34;
	height=&#34;611&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/assets/image-20250716031327371_hu_72b7ba402e41067b.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/assets/image-20250716031327371_hu_9fdc14ddcae9f199.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Thought Trees&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;157&#34;
		data-flex-basis=&#34;377px&#34;
	
&gt;&lt;/p&gt;
$$
z_j^{(t)} = \text{LLM}_\theta(x_i, k_j), \quad t=1,2,...,n,\ \forall k_j \in K
$$&lt;p&gt;
$z_j^{(t)}$ 表示第 $t$ 次采样的决策&lt;/p&gt;
&lt;p&gt;我们将这些判定结果汇总，得到如下的平均决策概率：&lt;/p&gt;
$$
P(z_j^{\text{Yes}}) = \frac{|\{t : z_j^{(t)} = 1\}|}{n},\quad
P(z_j^{\text{No}}) = \frac{|\{t : z_j^{(t)} = 0\}|}{n}
$$&lt;p&gt;
为了后续聚合，我们为每个关键要素生成简洁的解释性理由 $r_j$，例如：&lt;/p&gt;
$$
r_j = \text{LLM}_\theta(x_i, k_j, z_j)
$$&lt;p&gt;
一旦所有关键要素评估完成，我们便能根据每一组决策 $\mathbf{Z}$ 构造路径。假设总共 $d$ 条路径（最多 $2^{M-1}$ 条），每条路径表示一种判定组合：&lt;/p&gt;
$$
\text{path}_l = \hat{\mathbf{v}}(\mathbf{Z}),\quad l=1,2,...,d
$$&lt;p&gt;其中，$\hat{\mathbf{v}}$ 是对向量 $\mathbf{v}$ 的估计，表示关键要素是否被覆盖；$\mathbf{Z}$ 是判定集合（由上面的判定概率组成）。路径的概率等于该路径上每个判定概率的乘积：&lt;/p&gt;
$$
P(\text{path}_l) = \prod_{j=1}^{M} P(z_j)
$$&lt;p&gt;
我们利用打分函数 $f_r$（例如程序化的rubric规则）对每条路径打分，获得预测得分：&lt;/p&gt;
$$
\hat{y}_{\text{path}_l} = f_r(\text{path}_l)
$$&lt;blockquote&gt;
&lt;p&gt;省流：蒙特卡洛树，从中抽取所有路径，计算概率和对应的分数，选择概率最高的&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;最后，选取概率最高的路径作为最终思维树输出结果：&lt;/p&gt;
$$
\hat{y}_{\text{tree}} = \hat{y}_{\text{path}_{l^*}} \quad l^* = \arg\max_l P(\text{path}_l)
$$&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;在实际操作中，我们使用LLM动态地将rubric文本转换为可执行Python代码，该代码以关键要素评估决策为输入，输出最终分数。&amp;rdquo;&lt;/p&gt;
&lt;p&gt;人话：LLM会将打分标准生成Python代码，直接传入关键要素的多热向量就可以直接算分&lt;/p&gt;&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>大语言模型数据清洗 · 论文笔记（五）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/</link>
        <pubDate>Thu, 10 Jul 2025 11:16:32 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&#34;essential-web-v10-24t-tokens-of-organized-web-data&#34;&gt;Essential-Web v1.0 24T tokens of organized web data
&lt;/h1&gt;&lt;h2 id=&#34;preview&#34;&gt;Preview
&lt;/h2&gt;&lt;p&gt;构建了多维度的分类体系，适合通过SQL等方式进行数据筛选出新的数据集&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用开源模型进行数据标签的标注，得到了EAI-Distill-0.5b&lt;/li&gt;
&lt;li&gt;推理清洗了23.6B的数据，花费了90000 AMD MI300x GPU-hours&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;The inference job ran on 512 AMD MI300x for about 1 week.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;分类体系：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个有限的类别集合 $T=\left { C_1, C_2, &amp;hellip;, C_k \right } $。&lt;/li&gt;
&lt;li&gt;每个类别$C_i$都有一个非空、有限的标签集$L_i$。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;标注形式为$T(d) = \left { (\lambda_1, \mu_1), &amp;hellip;\right}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其中，$λ_i\in L_i$ 是类别$C_i$的主要标签&lt;/li&gt;
&lt;li&gt;$\mu_i \in (L_i \setminus {\lambda_i}) \cup {\bot}$ 是一个可选的次要标签，必须与$\lambda_i$不同
&lt;ul&gt;
&lt;li&gt;当文档适合两个标签时非常有用&lt;/li&gt;
&lt;li&gt;$\bot$表示弃权（abstention）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;所有类别和标签集都是预先固定的，这允许训练一个单一的静态分类器&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/assets/image-20250710141259250.png&#34;
	width=&#34;923&#34;
	height=&#34;234&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/assets/image-20250710141259250_hu_35e32e8ea56e9d9f.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/assets/image-20250710141259250_hu_7dca944e0ae04e92.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;PipeLine&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;394&#34;
		data-flex-basis=&#34;946px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;实验设置&#34;&gt;实验设置
&lt;/h2&gt;&lt;blockquote&gt;
&lt;h2 id=&#34;chinchilla最优计算比例&#34;&gt;Chinchilla最优计算比例
&lt;/h2&gt;&lt;p&gt;Chinchilla缩放定律发现了一个最优比例：大约每个参数需要20个训练token &lt;a class=&#34;link&#34; href=&#34;https://epoch.ai/blog/chinchilla-scaling-a-replication-attempt&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Epoch AI&lt;/a&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.analyticsvidhya.com/blog/2024/09/chinchilla-scaling-law/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Analytics Vidhya&lt;/a&gt;。这个比例是DeepMind通过训练400多个语言模型得出的计算最优配置。&lt;/p&gt;
&lt;p&gt;具体来说：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chinchilla模型有70B参数，在1.4万亿tokens上训练，达到20 tokens per parameter的比例 &lt;a class=&#34;link&#34; href=&#34;https://epoch.ai/blog/chinchilla-scaling-a-replication-attempt&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Chinchilla Scaling: A Replication Attempt | Epoch AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;这个20:1的比例被认为是在给定计算预算下实现最佳性能的理想配置&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/assets/image-20250710142401273.png&#34;
	width=&#34;608&#34;
	height=&#34;269&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/assets/image-20250710142401273_hu_1c12a53edcfe7eaf.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/assets/image-20250710142401273_hu_1c71ffbb1c3f701e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Train&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;226&#34;
		data-flex-basis=&#34;542px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;所有数据集在训练前均使用了 13-gram Bloom Filter&lt;/p&gt;
&lt;p&gt;选用了两个2.3B模型对数据进行评估&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;预训练（3200亿Token）：该阶段帮助模型学到广泛的语言知识&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;General-base：仅使用网络数据（DCLM-baseline）做&lt;strong&gt;预训练&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Code-base：使用网络数据（DCLM-baseline）+代码数据（Stack v2 Dedup中的Python），各占50%做&lt;strong&gt;预训练&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;退火（800亿token）：为了评估特定领域数据集的性能，采用需要评估的新数据集&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;学习率接近零的目的是在新的领域数据上进行“微调”，而不是进行大规模的“重新训练”&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;每个模型总计处理 4000 亿 token 数据量，是Chinchilla的10倍数据&lt;/p&gt;
&lt;h2 id=&#34;蒸馏&#34;&gt;蒸馏
&lt;/h2&gt;&lt;h3 id=&#34;蒸馏方案&#34;&gt;蒸馏方案
&lt;/h3&gt;&lt;h4 id=&#34;数据来源与规模&#34;&gt;&lt;strong&gt;数据来源与规模&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;标注数据&lt;/strong&gt;：使用Qwen2.5-32B-Instruct对104.6M文档共82Btoken进行两轮标注，生成合成标签用于蒸馏训练。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;第一轮&lt;/strong&gt;：标注8个分类类别（如FDC、Document Type V1/V2等）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;第二轮&lt;/strong&gt;：扩展至12个类别（新增Bloom、Technical Correctness等）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;数据预处理&#34;&gt;&lt;strong&gt;数据预处理&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;子采样&lt;/strong&gt;：对超过30,000字符的文档，截取开头、随机中间段和结尾（Algorithm 12），避免长文本影响推理速度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;质量过滤&lt;/strong&gt;：通过统计和模型信号（如DCLM分类器）过滤低质量文档（Algorithm 1）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;模型架构&#34;&gt;&lt;strong&gt;模型架构&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;基础模型&lt;/strong&gt;：Qwen2.5-0.5b-Instruct（5亿参数），基于Gemma 3架构，使用QK-norm稳定注意力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;序列长度&lt;/strong&gt;：16,384 tokens，支持长上下文。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;训练参数&#34;&gt;&lt;strong&gt;训练参数&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优化器&lt;/strong&gt;：AdamW（β1=0.9, β2=0.95），权重衰减0.1。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;学习率&lt;/strong&gt;：峰值1e-4，线性预热2B tokens，余弦衰减至1e-5，最后线性退火至0。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;批量大小&lt;/strong&gt;：全局2M tokens，梯度累积实现大批次训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;训练量&lt;/strong&gt;：82B tokens（合成标签数据）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;损失计算&lt;/strong&gt;：仅对教师模型生成的标签token计算损失，输入文档和系统提示被掩码。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;教师模型选择&#34;&gt;&lt;strong&gt;教师模型选择&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;教师&lt;/strong&gt;：Qwen2.5-32B-Instruct，因其标注一致性（κ=0.74）与推理速度平衡（1.4 RPS/GPU）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;蒸馏步骤&#34;&gt;&lt;strong&gt;蒸馏步骤&lt;/strong&gt;
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;标签生成&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;教师模型生成多分类标签（如FDC层级、Document Type等），格式为&lt;code&gt;主标签,次标签&lt;/code&gt;（Algorithm 13）。&lt;/li&gt;
&lt;li&gt;压缩输出：从平均791 tokens缩短至51 tokens，提升推理速度50倍（Table 12）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;上下文蒸馏&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;移除教师模型的提示模板（Prompt 1/2），直接训练学生模型生成压缩格式标签。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;评估方案&#34;&gt;评估方案
&lt;/h3&gt;&lt;h4 id=&#34;metrics&#34;&gt;Metrics
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;正确性：多人分类的结果应该类似，验证模型打标签是否标准一致
&lt;ul&gt;
&lt;li&gt;使用GPT-4o和Claude Sonnet-3.5作为专家模型&lt;/li&gt;
&lt;li&gt;使用kappa系数作为指标&lt;/li&gt;
&lt;li&gt;取对4o的系数和对claude的系数的均值作为结果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;检测方式是验证模型与专家模型的标准是否一致，对于指标paper中进行了变种&lt;/p&gt;
&lt;p&gt;对于某个模型的分类结果$S\in \left { \phi, (\text{label}), (\text{label1, label2}) \right }$​&lt;/p&gt;
&lt;p&gt;最少是一个标签（主标签），有时可以加一个次标签&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;标注结果一致的判定：两模型的$S$​有交集&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然后套公式&lt;/p&gt;
&lt;p&gt;Qwen2.5-32B-Instruct ≈ 0.74&lt;/p&gt;
&lt;p&gt;EAI-Distill-0.5b ≈ 0.71~0.73&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;正交性：不同分类体系之间的标签应该是独立的
&lt;ul&gt;
&lt;li&gt;例如在某分类A下打了a，分类B始终是b，发生了绑定&lt;/li&gt;
&lt;li&gt;需计算互信息、香农熵&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
$$
&gt;\text{NMI}(X, Y) = \frac{2 I(X; Y)}{H(X) + H(Y)}
&gt;$$&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$p(x)$按$x$出现的频率，$p(x,y)$按$x,y$同时出现的频率计算&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;$I(X; Y)$：互信息&lt;/li&gt;
&lt;/ul&gt;
$$
&gt;  I(X; Y) = \sum_{x, y} p(x, y) \cdot \log \frac{p(x, y)}{p(x)p(y)}
&gt;  $$&lt;ul&gt;
&lt;li&gt;$H(X)$：X 的香农熵&lt;/li&gt;
&lt;/ul&gt;
$$
&gt;  H(X) = -\sum_{x} p(x) \cdot \log p(x)
&gt;  $$&lt;p&gt;Qwen2.5-32B 平均 NMI ≈ 0.079&lt;/p&gt;
&lt;p&gt;EAI-Distill-0.5b 平均 NMI ≈ 0.092&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Domain Recall
&lt;ul&gt;
&lt;li&gt;定了Golden URL（认为arxiv和……30 个 base URL的都是高质量数据）&lt;/li&gt;
&lt;li&gt;统计有多少能被模型召回&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;dataset&#34;&gt;Dataset
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Random Set：随机采样（需要避免撞车训练数据）&lt;/li&gt;
&lt;li&gt;STEM Set：从特定领域集合（科学领域）随机采样&lt;/li&gt;
&lt;li&gt;通过Golden URL采样&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>大语言模型教育纠错 · 论文笔记（一）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/</link>
        <pubDate>Mon, 23 Jun 2025 15:13:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2412.16838&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2412.16838 Ask-Before-Detection: Identifying and Mitigating Conformity Bias in LLM-Powered Error Detector for Math Word Problem Solutions&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;AED（Automatic Error Detection）
&lt;ul&gt;
&lt;li&gt;本文定义为：给定问题-解答的输入对，识别错误步骤以及错误类型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250623164618186.png&#34;
	width=&#34;1119&#34;
	height=&#34;594&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250623164618186_hu_529466cf46b0a084.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250623164618186_hu_44cdd8acc43cea4e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;188&#34;
		data-flex-basis=&#34;452px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;如图，paper点出传统的方法使用可以对问题的&lt;strong&gt;常规解法&lt;/strong&gt;进行正确错误检测&lt;/p&gt;
&lt;p&gt;但是单个问题的解法可以&lt;strong&gt;存在多个&lt;/strong&gt;，认为之前的做法泛用性较差&lt;/p&gt;
&lt;p&gt;常规解法与非常规解法会产生7%的性能差距，先进的闭源模型也无法避免&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLM错误检测器表现&lt;code&gt;conformity bias&lt;/code&gt;（从众偏差）
&lt;ul&gt;
&lt;li&gt;倾向“遵循主流答案（训练中经常出现的）”而忽略可能也正确但不常见的其他解法&lt;/li&gt;
&lt;li&gt;导致模型对标准答案的识别准确，却对非常规解法的识别薄弱&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;论文针对缓解模型的&lt;code&gt;conformity bias&lt;/code&gt;进行工作&lt;/p&gt;
&lt;p&gt;提出AskBD框架，为每个Solution自适应生成参考答案（合适的参考答案能显著提升性能）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;直接调用模型，无微调，拓展性强&lt;/li&gt;
&lt;li&gt;自适应方式高度契合给定Solution，降低Bias&lt;/li&gt;
&lt;li&gt;框架可协同CoT技术增强性能&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminary-study&#34;&gt;Preliminary Study
&lt;/h2&gt;&lt;p&gt;Paper构建了一个Alternative Solution数据集用于充分暴露模型的从众偏差效应，帮助进行后续的探索&lt;/p&gt;
&lt;h3 id=&#34;automatic-solution-permutation&#34;&gt;Automatic Solution Permutation
&lt;/h3&gt;&lt;p&gt;paper希望构建一个高质量的Alternative Solution数据集&lt;/p&gt;
&lt;p&gt;给定问题和Solution，希望替换掉整个解决方案为Alternative Solution&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;低质量&lt;/strong&gt;：对常规Solution只是简单的&lt;strong&gt;语义替换&lt;/strong&gt;，并没有深层的逻辑变换&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250623172108657.png&#34;
	width=&#34;1094&#34;
	height=&#34;316&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250623172108657_hu_c5b1e501f2aed034.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250623172108657_hu_c24cb789034894c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;346&#34;
		data-flex-basis=&#34;830px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ASP&lt;/strong&gt;（自动解法置换），如图，对应了Solution和数学表达式的关系，使用LLM prompt独立执行：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Extract：常规Solution -&amp;gt; 数学表达式，完成后需要执行运算，检查是否能够得到正确计算结果，否则剔除&lt;/li&gt;
&lt;li&gt;Permute：因式分解、分配律，重新排列表达式（同样需要运算检验）&lt;/li&gt;
&lt;li&gt;Explain：置换后的表达式输入到LLM，引导生成高质量Alternative Solution&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;paper采样GPT-4o，从GSM8K数据集抽取200组问答对，构建常规数据集D&lt;/p&gt;
&lt;p&gt;对D中的每个样本，3次ASP生成3个Alternative Solution，由教育系研究生评审质量，选择三个之中最优的一个&lt;/p&gt;
&lt;p&gt;完成替换数据集D&amp;rsquo;的制作&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;erroneous-solution-generation&#34;&gt;Erroneous Solution Generation
&lt;/h3&gt;&lt;p&gt;需要将错误注入到D和D‘之中，生成测试样本&lt;/p&gt;
&lt;p&gt;主要参考：&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2406.00755&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2406.00755 Evaluating Mathematical Reasoning of Large Language Models: A Focus on Error Identification and Correction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;paper引入了四种错误：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\varepsilon_C$：calculation errors
&lt;ul&gt;
&lt;li&gt;Operands in expressions are correct but an error occurs in the calculated results.（表达式正确，计算结果出错）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Each gust blows the leaf forward 5 feet, so 11 gusts will blow it forward 5 ×11 = 50 feet. &lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$\varepsilon_R$：reference errors
&lt;ul&gt;
&lt;li&gt;Expression are incorrectly referencing the question conditions or the results from prior steps.（错误引用了题目条件或之前的计算结果）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Each gust blows the leaf forward 5 feet, so 10 gusts will blow it forward 5 ×10 = 50 feet. &lt;/code&gt;（题目原条件是11，不是10）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$\varepsilon_M$ ：missing steps
&lt;ul&gt;
&lt;li&gt;Operands or expressions in the step that lack of references or support from the question conditions or prior steps.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Each swirl after a gust blows it back 2 feet, so 11 swirls will blow it back 2 ×11 = 22feet. Step 2. After 11 gusts, the leaf has traveled 55 − 22 = 33 feet down the sidewalk.&lt;/code&gt;（缺少了得到55这个数字的计算过程）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$\varepsilon_H$：hallucinations（幻觉）
&lt;ul&gt;
&lt;li&gt;Statements or operands in the listed expression are fabricated or inconsistent with the question’s conditions.（虚构或与条件不一致）&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;It is worth noting that this study specifically aims to explore conformity bias, and therefore, &lt;strong&gt;we do not include all possible error types.&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;针对D和D&amp;rsquo;的每个样本，随机错误步骤的位置编号，每个样本生成了四种不同错误类型的样本，总共2000条&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154336790.png&#34;
	width=&#34;473&#34;
	height=&#34;212&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154336790_hu_396c502f844b6a72.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154336790_hu_4f52005375b8ff83.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Table 5&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;223&#34;
		data-flex-basis=&#34;535px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;analysis-and-findings&#34;&gt;Analysis and Findings
&lt;/h3&gt;&lt;h4 id=&#34;conformity-bias-identification&#34;&gt;Conformity Bias Identification
&lt;/h4&gt;&lt;p&gt;评估指标：The evaluation metric is the identification accuracy across both correct and erroneous solutions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需要识别错误位置、错误类型&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Paper使用提示词进行纠错，明确LLM本题存在替代解法，强调所有合理解决方案应该被接受，并且明确定义错误类别&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Given the &amp;lt;question&amp;gt;, please judge whether each step in &amp;lt;solution&amp;gt; is correct. **During the judging process, you should know that the &amp;lt;question&amp;gt; does not always have only one standard solution, and any reasonable &amp;lt;solution&amp;gt; should be accepted. You should pay attention to both the expressions and the statements in each step, and take care about the logic consistency between different steps. Additionally, consider arithmetic expression equivalency and avoid rejecting solutions solely because they use equivalent expressions.**
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;In each step, if no errors are found, respond with Step X: &amp;lt;correct&amp;gt;. If you find that the operands in the listed expressions are correct but an error occurs in the calculated result, respond with Step X: &amp;lt;calculation error&amp;gt;. If you find statements or operands in the listed expression are incorrectly referencing the question conditions or the results from prior steps, respond with Step X: &amp;lt;reference error&amp;gt;. If you find operands or expressions in the step that is lack of references or support from the question conditions or prior steps, respond with Step X: &amp;lt;missing step&amp;gt;. If you find statements or operands in the listed expression are fabricated or inconsistent with the question’s conditions, respond with: Step X: &amp;lt;hallucination&amp;gt;. If an error is a follow-on issue due to mistakes in previous steps rather than an independent error, respond with: Step X: &amp;lt;secondary error&amp;gt;.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;question&amp;gt; [Question Text] &amp;lt;solution&amp;gt; [Solution Text]  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Now, please start to respond.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;参与测试的LLM：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154400250.png&#34;
	width=&#34;441&#34;
	height=&#34;436&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154400250_hu_926cdad944d5de03.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154400250_hu_488d9a30ae5b5c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Table 6&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;101&#34;
		data-flex-basis=&#34;242px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;平均错误检测准确率的测试结果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154615400.png&#34;
	width=&#34;423&#34;
	height=&#34;305&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154615400_hu_e91b30da751b4c25.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154615400_hu_4a904fb7a1a5feee.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Table 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;138&#34;
		data-flex-basis=&#34;332px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;证实了LLM在AED任务中存在明显的从众偏差&lt;/p&gt;
&lt;h4 id=&#34;solution-likelihood-score-analysis&#34;&gt;Solution Likelihood Score Analysis
&lt;/h4&gt;&lt;p&gt;对于当前问题$q$，我们可以计算LLM生成答案$s$的概率$P(s|q)$&lt;/p&gt;
&lt;p&gt;我们可以把$s$拆分成多个token：$s_i$&lt;/p&gt;
$$
P(s|q) = P(s_1, s_2, ...,s_{|s|} | q)
$$$$
P(s|q) = P(s_1|q) \times P(s_2|q,s_1) \times P(s_3|q,s_1,s_2) \times ...
$$$$
\log P(s|q) = \sum_{i=1}^{|s|} \log P(s_i|q,s_1:s_{i-1})
$$&lt;p&gt;
这个值就是&lt;strong&gt;对数似然分数&lt;/strong&gt; （Log-Likelihood Score）&lt;/p&gt;
&lt;p&gt;它衡量了模型在给定问题 &lt;em&gt;q&lt;/em&gt; 的情况下，对答案 &lt;em&gt;s&lt;/em&gt; 的“信任度”或理解程度&lt;/p&gt;
$$
\log L_{\theta}(s|q) = \frac{\log L_\theta(s|q)}{|s|}
$$&lt;p&gt;
其中$\theta$表示LLM的参数（闭源模型的似然分数无法获取，采取了开源模型的似然分数均值做伪指标）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163200484.png&#34;
	width=&#34;562&#34;
	height=&#34;478&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163200484_hu_9a5549ae053eac12.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163200484_hu_cfa275c0f051adca.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Advance Model&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;117&#34;
		data-flex-basis=&#34;282px&#34;
	
&gt; &lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163307581.png&#34;
	width=&#34;564&#34;
	height=&#34;480&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163307581_hu_49803f1626247f18.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163307581_hu_926314100216a0c1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Base Model&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;117&#34;
		data-flex-basis=&#34;282px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;同时喂入 了常规解法+替代解法，根据似然分数分成四个档进行对比&lt;/p&gt;
&lt;p&gt;显然似然值越高，Acc越高&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163347218.png&#34;
	width=&#34;577&#34;
	height=&#34;482&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163347218_hu_f8a58aeee4e02655.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163347218_hu_3fada5ac724549e7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Likehood Distribution&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;119&#34;
		data-flex-basis=&#34;287px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;对于开源模型，替代解法的似然分数显然低于常规解法&lt;/p&gt;
&lt;h4 id=&#34;reference-based-detection-findings&#34;&gt;Reference-based Detection Findings
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;不太可能直接提高替代Solution的似然值
&lt;ul&gt;
&lt;li&gt;通过改变数据集进行微调，但是无法解决根本问题，仍有可能碰见其他的未遇见情况&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考：&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2407.09136&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2407.09136 Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors&lt;/a&gt;，提出引入参考答案提升了常规解法的检测性能&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;将学生解题步骤与标准答案对齐&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;本paper尝试推广到替代解法，但是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;实际情况下，参考答案并不是总能获取&lt;/li&gt;
&lt;li&gt;即便能够获取，一般也是常规解法的参考答案&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;paper采用了两条技术路线进行对比：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用常规解法作为参考答案&lt;/li&gt;
&lt;li&gt;自适应使用对应解法作为参考答案（？细节不太清楚，后文兴许会说）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626171423880.png&#34;
	width=&#34;458&#34;
	height=&#34;343&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626171423880_hu_38c9f63332d673bf.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626171423880_hu_6c0b72c548df9ffd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;常规解法作为参考答案&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;  &lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626171459301.png&#34;
	width=&#34;459&#34;
	height=&#34;348&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626171459301_hu_a726c1661fa683e4.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626171459301_hu_a94969f7c01bb73c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;自适应选择参考答案&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;131&#34;
		data-flex-basis=&#34;316px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;根据与前文提示词的测试结果进行对比，引入参考答案对两个数据集的&lt;strong&gt;acc都有显著的提升&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;但是使用常规解法做参考答案加剧了bias，而自适应选择明显缓解了bias&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因此选择合适的参考答案是能起到关键作用的&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method
&lt;/h2&gt;&lt;p&gt;提出AskBD（Ask-Before-Detection）框架，在评分过程中为每个待评答案动态生成适配的参考解法&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626172743783.png&#34;
	width=&#34;1227&#34;
	height=&#34;482&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626172743783_hu_dcc20bd97ebdb160.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626172743783_hu_1c39f4b9cd82f898.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Pipeline&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;254&#34;
		data-flex-basis=&#34;610px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;输入：问题文本$q$，解答文本$s$，LLM$f$，提示词$p$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Condition and question extractor(CQE)
&lt;ul&gt;
&lt;li&gt;从问题文本中抽取条件$q_c$和提问文本$q_i$&lt;/li&gt;
&lt;li&gt;$(q_c, q_i) = f([p_{cqe}, q])$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Solution Step Inquirer(SSI)
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;为提高生成结果的稳定性，SSI 会先总结每个步骤的结论再构建对应问题。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;将解答文本转化为分步骤问题列表文本$Q$，&lt;strong&gt;末尾附加提问文本$q_i$&lt;/strong&gt;，以确保生成的参考解答能够回应原始问题的核心任务。&lt;/li&gt;
&lt;li&gt;$Q = [f([p_{ssi},s]), q_i]$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step Question Responder (SQR)
&lt;ul&gt;
&lt;li&gt;通过条件文本总结$Q$中每个问题的答案，生成参考答案$r$&lt;/li&gt;
&lt;li&gt;$r = f([p_{sqr},q_c, Q])$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reference-Enhanced Grader (REG)
&lt;ul&gt;
&lt;li&gt;根据$q, s, r$生成错误位置$y_s$和错误类型$y_e$&lt;/li&gt;
&lt;li&gt;$y=f([p_{reg},q,s,r])$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;输出：$y_s, y_e$&lt;/p&gt;
&lt;h2 id=&#34;experiment&#34;&gt;Experiment
&lt;/h2&gt;&lt;p&gt;实验目的是验证核心的三个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;是否缓解从众偏差&lt;/li&gt;
&lt;li&gt;是否有额外的性能优势&lt;/li&gt;
&lt;li&gt;与CoT等推理技术的兼容性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实验方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;采用前文数据集，相同的10个LLM，用于对比前两个问题&lt;/li&gt;
&lt;li&gt;整合了CoT技术，评估兼容性&lt;/li&gt;
&lt;li&gt;所有实验分别实验三种不同的随机seed，报告平均错误检测准确率&lt;/li&gt;
&lt;li&gt;前文测试和CoT方案作为两个baseline&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CoT的提示词&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Before the &amp;lt;response&amp;gt;, you should provide your step-by-step &amp;lt;thinking&amp;gt; about your judging process.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;lt;question&amp;gt; [Question Text] &amp;lt;solution&amp;gt; [Solution Text]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Now, please start to think first and then respond.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626175506489.png&#34;
	width=&#34;884&#34;
	height=&#34;476&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626175506489_hu_bb07b79c8d6c3c11.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626175506489_hu_5250d244aa5b549e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;实验结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;185&#34;
		data-flex-basis=&#34;445px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;对于问题1&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;重点分析M0和M2在$\Delta$列的差距
&lt;ul&gt;
&lt;li&gt;Base版本的优化并不明显，认为是模型推理能力不足，限制了框架效用&lt;/li&gt;
&lt;li&gt;对比M1与M2，CoT也有缓解Bias的能力，在多数Advance模型中，框架的优化能力强于CoT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于问题2&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在D、D&amp;rsquo;列对比M2和M0
&lt;ul&gt;
&lt;li&gt;框架确实提升了acc性能&lt;/li&gt;
&lt;li&gt;对比M1 M2，CoT也体现出了性能提升
&lt;ul&gt;
&lt;li&gt;在base模型中CoT技术更胜一筹&lt;/li&gt;
&lt;li&gt;在Advance模型中框架更强（……）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;针对问题3&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;M3和M1对比，确实变强了&lt;/li&gt;
&lt;li&gt;兼容性好&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;limitation&#34;&gt;Limitation
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;只考虑了四个错误类型，忽略了学生解答中那些更罕见却更具挑战性的错误类型&lt;/li&gt;
&lt;li&gt;仅聚焦于数学应用题&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>大语言模型教育纠错 · 论文笔记（零）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/</link>
        <pubDate>Fri, 20 Jun 2025 14:52:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&#34;temporal-consistency-for-llm-reasoning-process-error-identification&#34;&gt;Temporal Consistency for LLM Reasoning Process Error Identification
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2503.14495&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2503.14495 Temporal Consistency for LLM Reasoning Process Error Identification&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;无训练过程&lt;/li&gt;
&lt;li&gt;纯迭代反思&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;应用领域主要是大模型自己的解题步骤的错误检测&lt;/p&gt;
&lt;p&gt;算是一个比较通用的做法，数学题之外有分步性质的应该也ok&lt;/p&gt;
&lt;p&gt;可以借鉴一下其&lt;strong&gt;Reflection&lt;/strong&gt;的方法&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;输入定义如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$P$：题目原文（例如数学问题）；&lt;/li&gt;
&lt;li&gt;$S = [s_1, s_2, &amp;hellip;, s_n]$：模型生成的解题步骤，按步分段；&lt;/li&gt;
&lt;li&gt;$L$：目标是预测哪一段 $s_i$ 是 &lt;strong&gt;首个错误步骤&lt;/strong&gt;（或无错误）；&lt;/li&gt;
&lt;li&gt;$R_t$：第 $t$ 轮的模型判断（包含错误定位和解释）；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总共准备了K个模型并行进行推理，对于单个模型需要做以下事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;给定题目、解题步骤、自己的上轮判断&lt;/li&gt;
&lt;li&gt;模型需要结合该信息判断、解释&lt;/li&gt;
&lt;li&gt;持续迭代&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对K个模型投票，票数最多的即为结果&lt;/p&gt;
&lt;p&gt;设定的终止条件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单个模型连续$q$轮给出稳定结论&lt;/li&gt;
&lt;li&gt;K个模型的过去$q$轮的主体结果投票比例不能下降&lt;/li&gt;
&lt;li&gt;或者T轮迭代上限（防止死循环）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/assets/image-20250630152911616.png&#34;
	width=&#34;1790&#34;
	height=&#34;595&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/assets/image-20250630152911616_hu_d160ac2e2571813e.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/assets/image-20250630152911616_hu_970feda48933cee3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Pipeline&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;300&#34;
		data-flex-basis=&#34;722px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如图，三个模型进行迭代，最后得到一致的结果&lt;/p&gt;
&lt;p&gt;下面两个模型一开始不能得到正确答案，但是经过迭代得到正确结果&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;实验结果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/assets/image-20250630153824194.png&#34;
	width=&#34;501&#34;
	height=&#34;703&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/assets/image-20250630153824194_hu_1377b258bcc30ccd.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/assets/image-20250630153824194_hu_be26e3e2ea566e58.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Table&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;71&#34;
		data-flex-basis=&#34;171px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;todo&#34;&gt;Todo
&lt;/h1&gt;&lt;p&gt;2406.00755&lt;/p&gt;
</description>
        </item>
        <item>
        <title>大语言模型数据清洗 · 论文笔记（四）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E5%9B%9B/</link>
        <pubDate>Sat, 14 Jun 2025 16:35:54 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E5%9B%9B/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/html/2303.16854&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://arxiv.org/html/2303.16854&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;preview&#34;&gt;Preview
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;解释 - 标注 双阶段方法
&lt;ul&gt;
&lt;li&gt;LLM生成少量人类标注的解释&lt;/li&gt;
&lt;li&gt;自动构建思维链+fewshot提示词&lt;/li&gt;
&lt;li&gt;自动标注&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;approach&#34;&gt;Approach
&lt;/h2&gt;&lt;p&gt;从人类标注者的培训中可以发现，我们需要提供一定的引导、样例，才能规范人类标注一致性&lt;/p&gt;
&lt;p&gt;模型标注也是同理&lt;/p&gt;
&lt;h3 id=&#34;解释&#34;&gt;解释
&lt;/h3&gt;&lt;p&gt;使用GPT3.5进行生成解释：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Directions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Given&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;engine&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;google data studio sharepoint&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;first&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;consider&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;what&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;could&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;have&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mind&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;they&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;allow&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;misspellings&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;other&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ambiguity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;then&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;classify&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;sharepoint migration tool file share&amp;#34;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;into&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;one&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;following&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;categories&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Definitions&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;categories&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;This&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;can&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;include&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;broader&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;narrower&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;product&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;selection&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;competitor&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;alternative&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;products&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;accessories&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;products&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;often&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;purchased&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;together&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;related&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topics&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;well&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;direct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;matches&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;There&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;no&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relationship&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;between&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;This&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;includes&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;but&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;limited&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;incorrect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unrelated&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;product&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;unrelated&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wrong&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;location&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;location&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;important&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cannot&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;be&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;used&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;place&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;product&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nor&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;are&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;they&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;commonly&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;purchased&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;together&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;etc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Briefly&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;explain&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;why&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;length&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exceeding&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;构建提示词&#34;&gt;构建提示词
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Given&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;engine&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;first&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;consider&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;what&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;could&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;have&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mind&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;they&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;allow&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;misspellings&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;other&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ambiguity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;then&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;classify&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;into&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;one&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;following&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;categories&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;definitions&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;categories&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;are&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;This&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;can&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;include&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;broader&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;narrower&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;product&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;selection&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;competitor&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;alternative&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;products&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;accessories&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;products&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;often&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;purchased&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;together&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;related&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topics&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;well&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;direct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;matches&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;There&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;no&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relationship&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;between&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;This&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;includes&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;but&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;limited&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;incorrect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unrelated&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;product&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;unrelated&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wrong&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;location&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;location&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;important&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cannot&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;be&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;used&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;place&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;product&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nor&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;are&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;they&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;commonly&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;purchased&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;together&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;etc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Please&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predict&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;whether&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;answer&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;should&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;be&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exact&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;### Examples:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;google&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;studio&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sharepoint&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Keyword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sharepoint&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;migration&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tool&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;share&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Answer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;sharepoint migration tool file share&amp;#34;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;google data studio sharepoint&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;This&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;it&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pertains&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;different&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tool&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;technology&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SharePoint&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;that&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mentioned&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;focuses&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;on&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;migration&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tool&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SharePoint&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sharing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;focused&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;on&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Google&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Data&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Studio&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;There&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;no&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relationship&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;between&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;two&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;so&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Therefore&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;2.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;motorhomes&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sale&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Keyword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rv&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sale&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;used&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;c&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Answer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;rv sale used class c&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;rv sale used class c&amp;#34;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;information&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;motorhomes sale&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;It&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;includes&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;specific&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;motorhome&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;class c&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;that&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;being&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sold&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;used&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;which&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;product&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;selection&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Additionally&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;rv sale used class c&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;direct&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;match&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;commonly&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;purchased&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;together&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;products&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Therefore&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;3.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;southern&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exposure&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exchange&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;company&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Keyword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;uk&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;poppy&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seeds&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Answer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;uk poppy seeds&amp;#34;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;southern exposure seed exchange company&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;This&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;because&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;about&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exchange&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;company&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;uk poppy seeds&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;specific&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;that&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;could&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;be&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;offered&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;by&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;such&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;company&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Even&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;though&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;company&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mentioned&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;based&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;southern&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;hemisphere&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;they&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;may&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;still&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;offer&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seeds&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;other&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;regions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;including&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;UK&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;which&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;could&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;include&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;poppy&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seeds&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Therefore&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;4.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nissan&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parts&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;canada&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Keyword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;purchase&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tires&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Answer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;purchase tires&amp;#34;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;nissan parts canada&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;purchase tires&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;directly&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;related&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Nissan&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parts&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Canada&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Tires&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;are&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;part&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Nissan&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;car&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;therefore&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;are&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Nissan&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Additionally&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;does&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relate&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;common&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;purchase&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Nissan&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;it&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;substitute&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Therefore&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;### Task:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Keyword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Answer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>大语言模型数据清洗 · 论文笔记（三）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/</link>
        <pubDate>Tue, 10 Jun 2025 14:54:12 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/</guid>
        <description>&lt;h1 id=&#34;finerweb-10bt-refining-web-data-with-llm-based-line-level-filtering&#34;&gt;FinerWeb-10BT: Refining Web Data with LLM-Based Line-Level Filtering
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2501.07314&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2501.07314FinerWeb-10BT: Refining Web Data with LLM-Based Line-Level Filtering&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/TurkuNLP/finerweb-10bt&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/TurkuNLP/finerweb-10bt&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;概述&#34;&gt;概述
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;GPT-4o mini 对 FineWeb 中 20,000 份文档样本进行逐行标注，使模型能够为低质量文本行创建描述性标签&lt;/li&gt;
&lt;li&gt;标签被归纳为九大类别，并训练 DeBERTa-v3 分类器将过滤规模扩展至 FineWeb 的 100 亿 token 子集&lt;/li&gt;
&lt;li&gt;结果表明：使用过滤数据训练的模型在 HellaSwag 基准测试中准确率更高，且能以最多减少 25%的数据量更快达到性能目标&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;核心问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How well can an LLM identify low-quality content missed by &lt;strong&gt;heuristic filters&lt;/strong&gt;?&lt;/li&gt;
&lt;li&gt;Does LLM-based &lt;strong&gt;quality filtering&lt;/strong&gt; of training datasets &lt;strong&gt;improve model performance&lt;/strong&gt;?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;paper定义高质量数据为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;human-written, continuous English text from the main content of a website, reflecting natural language use across diverse contexts and domains.&lt;/p&gt;
&lt;p&gt;网站主体内容中人类撰写的连贯英文文本，能反映跨领域自然语言使用。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;典型实例包括访谈核心文本、论坛帖子、新闻文章、博客和食谱。&lt;/li&gt;
&lt;li&gt;与之相对，低质量内容则包含导航菜单、版权声明、编程代码和元数据等重复性元素。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;过滤分为三个级别：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文档级：基于简单规则整篇剔除文档
&lt;ul&gt;
&lt;li&gt;少于三句话的文档&lt;/li&gt;
&lt;li&gt;存在过度重复内容的文档&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;行级：
&lt;ul&gt;
&lt;li&gt;删除含&lt;code&gt;javascript&lt;/code&gt;等术语的行、纯数字行或低于长度阈值的行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;字符级：
&lt;ul&gt;
&lt;li&gt;移除维基百科常见的引用标记如&lt;code&gt;[1]&lt;/code&gt;和&lt;code&gt;[citation needed]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;现存的过滤方法具有数据集特异性，相关指标与数据集本身有关&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;行末标点比例≤0.12的文档（移除10.14% token，相比C4终止标点过滤的30%更高效）&lt;/li&gt;
&lt;li&gt;重复行字符比例≥0.1的文档（移除12.47% token）&lt;/li&gt;
&lt;li&gt;短行（&amp;lt;30字符）比例≥0.67的文档（移除3.73% token）&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;method&#34;&gt;Method
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;数据来源：Fineweb，构建来自 FineWeb 的 100 亿 token（约 1500 万文档）样本，称为 FineWeb-10BT&lt;/li&gt;
&lt;li&gt;抽样20,000份文档进行GPT-4o mini 标注
-   为每行生成描述性标签，分为高质量或低质量类别&lt;/li&gt;
&lt;li&gt;O1-preview将生成的大量标签归类为更小、更方便管理的集合&lt;/li&gt;
&lt;li&gt;训练基于encoder的分类器，scale到Fineweb10BT&lt;/li&gt;
&lt;li&gt;使用清洗前后的Fineweb10BT训练GPT-2，在HellaSwag上benchmark&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;全过程是数据驱动的，不依赖于固定的类别&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments
&lt;/h2&gt;&lt;h3 id=&#34;gpt-4o-mini-标签标注&#34;&gt;GPT-4o mini 标签标注
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;86
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 系统提示词&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;You are an expert text classifier specializing in LLM training data. Your task is to classify each line of text based on its suitability for inclusion in a language model training dataset. High-quality content is clean, meaningful, well-structured, and useful for training language models. Low-quality content includes boilerplate elements (e.g., navigation menus, footers), non-linguistic symbols, formatting tags, placeholders like &amp;#39;Lorem ipsum&amp;#39;, and spammy, irrelevant, or toxic language.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 用户提示词&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    **Instructions:**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    1. **Line Identification and Separation**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Each line starts with &amp;#34;Line X:&amp;#34; where X is the line number. Treat each &amp;#34;Line X:&amp;#34; as a single unit, regardless of length; do not split lines.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Lines are separated by newline characters (`&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;n`) and dashes (`------`). If there&amp;#39;s no newline character, treat the entire text as a single line.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    2. **Contextual Classification**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Use the context of all lines when classifying each one, as they are sequential and from the same document.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - For example, a line starting with a hyphen might be part of a list and should be classified as &amp;#34;Clean.&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    3. **Assigning Labels**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Assign **exactly one label** to each line.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - If the line is suitable for inclusion, label it **&amp;#34;Clean&amp;#34;**.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - If not, assign a specific and descriptive label explaining why it&amp;#39;s unsuitable.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - **Prefer labels from the provided list**. Only create a new label (max three words) if absolutely necessary.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - **Do not use vague labels** like &amp;#34;Low-Quality,&amp;#34; &amp;#34;Bad,&amp;#34; &amp;#34;Unsuitable,&amp;#34; etc. Labels must be specific and descriptive.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    4. **Focus on Linguistic Content**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Retain valuable and diverse linguistic content suitable for language model pre-training, including natural language patterns, standard advertising copy, commercial language, and promotional content written in natural language.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    5. **Tolerance for Minor Errors and Toxic Language**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Minor grammatical errors, typos, or small mistakes do not disqualify a line from being &amp;#34;Clean.&amp;#34; Only exclude lines with pervasive errors that significantly hinder understanding.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Mild expletives and controversial opinions do not disqualify a line from being &amp;#34;Clean.&amp;#34; Only exclude lines with blatantly hateful, harmful or toxic content.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    6. **Output Format**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Your output must have exactly the same number of lines as the input, matching each line number correctly.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Output only the line number followed by the label, separated by a colon.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Do not include any additional text or explanations.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Do not output dashes between the lines.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    **Guidelines for &amp;#34;Clean&amp;#34; Lines**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Assign &amp;#34;Clean&amp;#34; to lines that:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Represent natural language suitable for training language models.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Include informal internet language, grammatical errors, questions, partial sentences, and common online expressions.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Contain standard advertising or commercial language in natural sentences.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Have properly formatted titles, headings, and readable content, even with stylistic elements.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Include minor in-text elements like email addresses, dates, or URLs within natural sentences.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Are general promotional content written in natural language.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    **Guidelines for Non-&amp;#34;Clean&amp;#34; Lines**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Lines not classified as &amp;#34;Clean&amp;#34; need a specific and descriptive label. Examples include lines that:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Contain blatantly hateful or harmful language. 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Are long passages of non-English text (excluding common foreign phrases used in English).
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Include disclaimers, copyright notices, terms, and conditions.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Consist of menu items, login links, buttons, or navigation menus.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Contain random characters, garbled text, or excessive symbols.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Include programming code, HTML tags, or markup languages (when actual code or markup appears).
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Present keywords, tags, or similar data without sufficient context.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Are irrelevant or spam-like content not suitable for training.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Are **excessively** promotional without natural language structure (e.g., a list of product names and prices without sentences).
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    **Possible Labels for Non-&amp;#34;Clean&amp;#34; Lines**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;non_quality_labels&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    **Example Input:**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 1: Welcome to our website!
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    ------
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 2: Contact us at support@example.com.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    ------
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 3: ***** $$$$$
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    ------
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 4: &amp;lt;div&amp;gt;Content&amp;lt;/div&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    ------
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    **Example Output:**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 1: Clean  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 2: Clean  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 3: Encoding Errors  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 4: HTML Tags
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    **Now, classify the following lines:**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;指令&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;行标识与分隔&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;每行以&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;开头&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X为行号&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;将每个&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;视为一个独立单元&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;无论长度如何&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;；&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;请勿拆分&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;行之间用换行符&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（`&lt;/span&gt;\&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;`）&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;和短横线&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（`&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;------&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;`）&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;分隔&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;若无换行符&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;则将整个文本视为单行&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;2.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;上下文分类&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;分类时需考虑所有行的上下文&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;因为它们来自同一文档且顺序相关&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;例如&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;以连字符开头的行可能是列表的一部分&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;应标记为&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;3.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;标签分配&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;每行&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;必须分配一个标签&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;若适合纳入训练数据&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;标记为&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;若不适合&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;需提供具体描述性标签说明原因&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;优先使用提供的标签列表&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;仅在必要时创建新标签&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;最多三个单词&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;）。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;禁止使用模糊标签&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;如&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;低质量&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”、“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;差&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”、“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;不合适&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;等&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;标签必须具体明确&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;4.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;语言内容聚焦&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;保留对语言模型预训练有价值的多样化语言内容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;包括自然语言模式&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;标准广告文案&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;商业用语和自然语言编写的推广内容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;5.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;对轻微错误和毒性内容的容忍&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;轻微语法错误&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;拼写问题或小错误不影响标记为&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”。&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;仅当错误严重影响理解时才排除&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;轻度脏话或有争议的观点不影响标记为&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”。&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;仅排除明显仇恨&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;有害或毒性内容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;6.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;输出格式&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;输出行数必须与输入完全一致&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;且行号对应正确&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;每行输出格式为&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;标签&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;仅包含行号和标签&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;禁止额外解释或文本&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;行间禁止输出短横线&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;行标准&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;符合以下条件的行标记为&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;代表适合训练的自然语言&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;包含网络用语&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;语法错误&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;问题&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;不完整句子或常见网络表达&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;含有自然句式中的标准广告或商业用语&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;格式正确的标题&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;题头或可读内容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;即使包含样式元素&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;）。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;自然句子中的邮箱&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;日期或URL等次要元素&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;以自然语言编写的常规推广内容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;非&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;行标准&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;需提供具体描述性标签&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;例如&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;包含明显仇恨或有害内容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;大段非英语文本&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;英语中常用的外语短语除外&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;）。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;免责声明&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;版权声明&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;条款协议&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;菜单项&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;登录链接&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;按钮或导航菜单&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;随机字符&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;乱码或过多符号&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;编程代码&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HTML标签或标记语言&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;实际代码或标签出现时&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;）。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;缺乏上下文的关键词或标签&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;与训练无关的垃圾内容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;过度推广&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;且无自然语言结构&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;如纯产品名和价格列表&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;）。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;非&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;行标签示例&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;non_quality_labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;输入示例&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;欢迎访问我们的网站&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;！&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;联系支持邮箱&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;support&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@example.com&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*****&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$$$$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;div&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;内容&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;div&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;输出示例&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;编码错误&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;HTML标签&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;请对以下行进行分类&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;一开始并不提供任何的非Clean标签，由模型逐渐生成，优先使用已有的标签，否则进行扩充&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;未避免顺序带来的影响，每次迭代后随即打乱标签列表&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;文档最多被分割为多个chunk，每个chunk最多15行，方便结合上下文&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;单行不能超过200字符，否则按照标点进行切割为新的行&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;paper提到：超长行会导致模型的错误输出&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610184759762.png&#34;
	width=&#34;875&#34;
	height=&#34;596&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610184759762_hu_77126521573083f.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610184759762_hu_c2d6a7a748645646.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;50个最常见的标签 - 二维UMAP投影&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;146&#34;
		data-flex-basis=&#34;352px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;其中每个圆点的大小对应相应类别的相对出现频率&lt;/p&gt;
&lt;p&gt;法律文本出现在左上角，成人及有害内容集中于右上方中部，而参考文献则靠近底部。联系方式（如时间、日期和电话号码）松散分布在左侧，技术类内容（如编程代码）则位于中部。这些分布模式表明，LLM 生成的标签能够有效区分文本行质量，为我们最终构建分类体系提供了可靠依据。&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;83%的数据被标记为清洁&lt;/li&gt;
&lt;li&gt;547个生成的标签，其中部分只出现了一次
&lt;ul&gt;
&lt;li&gt;人工复查，直接标记为清洁&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;标签分组&#34;&gt;标签分组
&lt;/h3&gt;&lt;p&gt;对于实现剩下的382个标签，通过O1-preview（推理模型）归类为更简洁、更易管理的宽泛类别&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指导该模型创建清晰、明确的分类&lt;/li&gt;
&lt;li&gt;每个标签只能属于一个组别&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Categories&lt;/th&gt;
          &lt;th&gt;Lines&lt;/th&gt;
          &lt;th&gt;%&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Clean&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;283,267&lt;/td&gt;
          &lt;td&gt;86.24&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Formatting, Style &amp;amp; Errors 格式、风格与错误&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;13,150&lt;/td&gt;
          &lt;td&gt;4.00&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Bibliographical &amp;amp; Citation References 参考文献与引用规范&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;8,768&lt;/td&gt;
          &lt;td&gt;2.67&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Promotional &amp;amp; Spam Content 促销与垃圾内容&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;7,339&lt;/td&gt;
          &lt;td&gt;2.23&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Contact &amp;amp; Identification Information 联系与身份识别信息&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;3,898&lt;/td&gt;
          &lt;td&gt;1.19&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Navigation &amp;amp; Interface Elements 导航与界面元素&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;3,327&lt;/td&gt;
          &lt;td&gt;1.01&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Technical Specifications &amp;amp; Metadata 技术规范与元数据&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;3,298&lt;/td&gt;
          &lt;td&gt;1.00&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Legal &amp;amp; Administrative Content 法律与行政内容&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;2,992&lt;/td&gt;
          &lt;td&gt;0.91&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Offensive or Inappropriate Content 冒犯性或不当内容&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;2,433&lt;/td&gt;
          &lt;td&gt;0.74&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Total 总计&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;328,472&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;100&lt;/strong&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;模型可能会发生错误，例如未能分配全部标签、标签归入多个类别……&lt;/p&gt;
&lt;p&gt;人工修正一下即可&lt;/p&gt;
&lt;h4 id=&#34;inter-annotator-agreement--人工标注者一致性iaa实验&#34;&gt;Inter-Annotator Agreement  人工标注者一致性（IAA）实验
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;抽取50篇文档的726行，人工独立分类到九个标签之内&lt;/li&gt;
&lt;/ul&gt;
$$
\kappa = \frac{p_o - p_e}{1 - p_e}
$$&lt;blockquote&gt;
&lt;p&gt;假设两位标注员（A 和 B）对 100 条文本进行情感分类，标签为 &lt;strong&gt;正面（Positive）&lt;/strong&gt; 或 &lt;strong&gt;负面（Negative）&lt;/strong&gt;。他们的标注结果如下表：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;&lt;/th&gt;
          &lt;th&gt;B: Positive&lt;/th&gt;
          &lt;th&gt;B: Negative&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;总计&lt;/strong&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;A: Positive&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;50&lt;/td&gt;
          &lt;td&gt;10&lt;/td&gt;
          &lt;td&gt;60&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;A: Negative&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;20&lt;/td&gt;
          &lt;td&gt;20&lt;/td&gt;
          &lt;td&gt;40&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;总计&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;70&lt;/td&gt;
          &lt;td&gt;30&lt;/td&gt;
          &lt;td&gt;100&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;$p_o$是两位标注员&lt;strong&gt;实际一致的比例&lt;/strong&gt;，即对角线单元格的和除以总数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;两位标注员在 70 条样本上达成一致（50 条 Positive + 20 条 Negative），因此$p_o = 0.7$&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;$p_e$ 是假设两位标注员&lt;strong&gt;随机标注&lt;/strong&gt;时预期的一致比例。需分别计算每个类别随机一致的联合概率，再求和。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;A 标注 Positive 的概率&lt;/strong&gt;：$P_{\text{A+}} = \frac{60}{100} = 0.6$
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;A 标注 Negative 的概率&lt;/strong&gt;：$P_{\text{A-}} = \frac{40}{100} = 0.4$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;B 标注 Positive 的概率&lt;/strong&gt;：$P_{\text{B+}} = \frac{70}{100} = 0.7$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;B 标注 Negative 的概率&lt;/strong&gt;：$P_{\text{B-}} = \frac{30}{100} = 0.3$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;已知以上概率，接下来计算在随机标注的情况下，两人同时一致的概率：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;随机都标为 Positive 的概率：$P_{\text{A+}} \times P_{\text{B+}} = 0.6 \times 0.7 = 0.42$
&lt;ul&gt;
&lt;li&gt;随机都标为 Negative 的概率：$P_{\text{A-}} \times P_{\text{B-}} = 0.4 \times 0.3 = 0.12$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此：$p_e = 0.42 + 0.12 = 0.54$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解释&lt;/strong&gt;：&lt;br&gt;
如果两位标注员完全随机标注，预计会有 54% 的样本因巧合而一致。&lt;/p&gt;
&lt;hr&gt;
$$
&gt;   \kappa = \frac{p_o - p_e}{1 - p_e} = \frac{0.7 - 0.54}{1 - 0.54} = \frac{0.16}{0.46} \approx 0.348
&gt;   $$&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;κ ≈ 0.35&lt;/strong&gt;：介于 0.2~0.4 之间，说明两位标注员的一致性为“一般”（仅略高于随机水平）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对比简单一致率 70%&lt;/strong&gt;：若直接用 70% 会高估一致性，而 Cohen&amp;rsquo;s Kappa 通过剔除随机影响，给出了更严格的评估。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;\( p_o \)&lt;/strong&gt;：直接观察到的对角线比例。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;\( p_e \)&lt;/strong&gt;：基于边际分布的“随机一致”概率，反映巧合带来的虚假一致性。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Kappa 的意义&lt;/strong&gt;：量化了&lt;strong&gt;超越随机水平的一致性&lt;/strong&gt;，避免高估可靠性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;&lt;strong&gt;κ值范围&lt;/strong&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;&lt;strong&gt;一致性强度&lt;/strong&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;&lt;strong&gt;解释&lt;/strong&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;κ ≤ 0&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;比随机还差&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;一致性低于随机猜测（罕见，可能表示系统性分歧或标注错误）。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;0 &amp;lt; κ ≤ 0.2&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;轻微一致（可忽略）&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;一致性极低，几乎无实际意义。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;0.2 &amp;lt; κ ≤ 0.4&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;一般一致（弱）&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;一致性较弱，但高于随机水平（需谨慎对待结果）。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;0.4 &amp;lt; κ ≤ 0.6&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;中等一致&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;一致性适中，结果有一定可靠性（常见于人工标注任务）。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;0.6 &amp;lt; κ ≤ 0.8&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;高度一致&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;一致性较强，结果可靠（如专业医生诊断或严格标注流程）。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;0.8 &amp;lt; κ ≤ 1&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;几乎完全一致&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;一致性极高，接近完美（罕见，通常需检查是否过拟合或标注规则过于简单）。&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;通过IAA实验，得到：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;A1&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;strong&gt;A2&lt;/strong&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;strong&gt;Avg. 平均&lt;/strong&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;All labels 所有标签&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.79&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.60&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.70&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;Clean vs. Non-clean 清洁与非清洁&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.78&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.67&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.73&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;基于 LLM 的分类方法总体上能为 FineWeb 文本生成可接受的标签。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;分类器训练&#34;&gt;分类器训练
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;DeBERTa-v3&lt;/li&gt;
&lt;li&gt;Stella-en-400M-v5&lt;/li&gt;
&lt;li&gt;XLM-RoBERTa-base（支持多语言）&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;我们首先从文档中提取独立文本行，将每行作为单独样本。随后对数据进行随机打乱，并通过分层抽样划分为训练集（70%）、开发集（10%）和测试集（20%）。我们在每个模型上添加分类头，为每行文本生成 9 个类别的概率分布，同时微调分类头与基础模型。&lt;/p&gt;
&lt;p&gt;我们采用 bfloat16 精度，学习率设为 1e-5，批处理大小为 16。基于评估损失值实施早停机制（耐心值为 5），最大训练轮数设为 5 轮，但模型通常在首轮后即收敛。我们对交叉熵损失函数施加 0.1 的标签平滑处理以提升泛化能力。所有训练均在单块 A100 GPU 上完成。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610192229209.png&#34;
	width=&#34;899&#34;
	height=&#34;634&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610192229209_hu_9bd47b2a1e06ee33.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610192229209_hu_d11c68ec86e2dc63.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;分类器混淆矩阵&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;141&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大多数误分类样本被归入 Clean 类别，表明其他类别间具有较强区分度&lt;/li&gt;
&lt;li&gt;冒犯性或不当内容区分度最低，源于 LLM 训练数据中对冒犯性材料定义边界存在固有困难&lt;/li&gt;
&lt;li&gt;参考文献与引用类别因其易于识别的格式和内容特征，成为区分度最高的类别&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分类器更倾向于将低质量文本行误标为&amp;quot;清洁&amp;quot;&lt;/p&gt;
&lt;p&gt;而非错误地将高质量行标记为低质量&lt;/p&gt;
&lt;p&gt;这种偏差有助于降低从数据集中丢弃有价值数据的风险&lt;/p&gt;
&lt;h3 id=&#34;数据清洗&#34;&gt;数据清洗
&lt;/h3&gt;&lt;p&gt;Clean数据占比86%确实可能会带来模型预测过度自信的问题&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;采用 Platt 缩放法
&lt;ul&gt;
&lt;li&gt;在保留测试集上训练 Platt 逻辑回归模型&lt;/li&gt;
&lt;li&gt;在为 FineWeb-10BT 数据集预测质量分数时将其叠加应用于分类器之上&lt;/li&gt;
&lt;li&gt;留坑，先不研究&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对整个数据集进行分片，每个分片128行为一个批次&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;转化为分类问题，只判断是否为Clean&lt;/li&gt;
&lt;li&gt;阈值分别设为0.5或0.9&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610194623280.png&#34;
	width=&#34;701&#34;
	height=&#34;485&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610194623280_hu_f739427efcc7e2.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610194623280_hu_31a6a550d7d615f5.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;GPT-2训练结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;144&#34;
		data-flex-basis=&#34;346px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>大语言模型数据清洗 · 论文笔记（二）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/</link>
        <pubDate>Fri, 06 Jun 2025 13:12:32 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&#34;the-pile-an-800gb-dataset-of-diverse-text-for-language-modeling&#34;&gt;The Pile: An 800GB Dataset of Diverse Text for Language Modeling
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2101.00027&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;arXiv 2101.00027 The Pile: An 800GB Dataset of Diverse Text for Language Modeling&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/EleutherAI/the-pile&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Github EleutherAI/the-pile&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过合成多个数据集，提升多样性，提升大规模语言模型的跨领域通用知识与下游任务泛化能力&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;稍微看偏了，paper更多的精华在如何去衡量数据集对模型性能的提升水平&lt;/p&gt;
&lt;p&gt;和清洗关系不大&lt;/p&gt;
&lt;h2 id=&#34;the-pile-datasets&#34;&gt;The Pile Datasets
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;由22个部分组成&lt;/li&gt;
&lt;li&gt;由于不同数据集存在差异（维基百科质量更高），因此进行了加权处理
&lt;ul&gt;
&lt;li&gt;权重越高，被使用的概率越高（更可能被重复使用次数）&lt;/li&gt;
&lt;li&gt;例如维基百科重复采用3次&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;部分表格：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Dataset Name&lt;/th&gt;
          &lt;th&gt;Raw Size (before sampling)&lt;/th&gt;
          &lt;th&gt;Weight (%)&lt;/th&gt;
          &lt;th&gt;Epochs&lt;/th&gt;
          &lt;th&gt;Effective Size&lt;/th&gt;
          &lt;th&gt;Mean Document Size&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;Pile-CC&lt;/td&gt;
          &lt;td&gt;227.12 GiB&lt;/td&gt;
          &lt;td&gt;18.11%&lt;/td&gt;
          &lt;td&gt;1.0&lt;/td&gt;
          &lt;td&gt;227.12 GiB&lt;/td&gt;
          &lt;td&gt;4.33 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;PubMed Central&lt;/td&gt;
          &lt;td&gt;90.27 GiB&lt;/td&gt;
          &lt;td&gt;14.40%&lt;/td&gt;
          &lt;td&gt;2.0&lt;/td&gt;
          &lt;td&gt;180.55 GiB&lt;/td&gt;
          &lt;td&gt;30.55 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Books3&lt;/td&gt;
          &lt;td&gt;100.96 GiB&lt;/td&gt;
          &lt;td&gt;12.07%&lt;/td&gt;
          &lt;td&gt;1.5&lt;/td&gt;
          &lt;td&gt;151.44 GiB&lt;/td&gt;
          &lt;td&gt;538.36 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;OpenWebText2&lt;/td&gt;
          &lt;td&gt;62.77 GiB&lt;/td&gt;
          &lt;td&gt;10.01%&lt;/td&gt;
          &lt;td&gt;2.0&lt;/td&gt;
          &lt;td&gt;125.54 GiB&lt;/td&gt;
          &lt;td&gt;3.85 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ArXiv&lt;/td&gt;
          &lt;td&gt;56.21 GiB&lt;/td&gt;
          &lt;td&gt;8.96%&lt;/td&gt;
          &lt;td&gt;2.0&lt;/td&gt;
          &lt;td&gt;112.42 GiB&lt;/td&gt;
          &lt;td&gt;46.61 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Github&lt;/td&gt;
          &lt;td&gt;95.16 GiB&lt;/td&gt;
          &lt;td&gt;7.59%&lt;/td&gt;
          &lt;td&gt;1.0&lt;/td&gt;
          &lt;td&gt;95.16 GiB&lt;/td&gt;
          &lt;td&gt;5.25 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;FreeLaw&lt;/td&gt;
          &lt;td&gt;51.15 GiB&lt;/td&gt;
          &lt;td&gt;6.12%&lt;/td&gt;
          &lt;td&gt;1.5&lt;/td&gt;
          &lt;td&gt;76.73 GiB&lt;/td&gt;
          &lt;td&gt;15.06 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;StackExchange&lt;/td&gt;
          &lt;td&gt;32.20 GiB&lt;/td&gt;
          &lt;td&gt;5.13%&lt;/td&gt;
          &lt;td&gt;2.0&lt;/td&gt;
          &lt;td&gt;64.39 GiB&lt;/td&gt;
          &lt;td&gt;2.16 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;USPTO Backgrounds&lt;/td&gt;
          &lt;td&gt;22.90 GiB&lt;/td&gt;
          &lt;td&gt;3.65%&lt;/td&gt;
          &lt;td&gt;2.0&lt;/td&gt;
          &lt;td&gt;45.81 GiB&lt;/td&gt;
          &lt;td&gt;4.08 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;PubMed Abstracts&lt;/td&gt;
          &lt;td&gt;19.26 GiB&lt;/td&gt;
          &lt;td&gt;3.07%&lt;/td&gt;
          &lt;td&gt;2.0&lt;/td&gt;
          &lt;td&gt;38.53 GiB&lt;/td&gt;
          &lt;td&gt;1.30 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gutenberg (PG-19)&lt;/td&gt;
          &lt;td&gt;10.88 GiB&lt;/td&gt;
          &lt;td&gt;2.17%&lt;/td&gt;
          &lt;td&gt;2.5&lt;/td&gt;
          &lt;td&gt;27.19 GiB&lt;/td&gt;
          &lt;td&gt;398.73 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;OpenSubtitles&lt;/td&gt;
          &lt;td&gt;12.98 GiB&lt;/td&gt;
          &lt;td&gt;1.55%&lt;/td&gt;
          &lt;td&gt;1.5&lt;/td&gt;
          &lt;td&gt;19.47 GiB&lt;/td&gt;
          &lt;td&gt;30.48 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Wikipedia (en)&lt;/td&gt;
          &lt;td&gt;6.38 GiB&lt;/td&gt;
          &lt;td&gt;1.53%&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;3.0&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;19.13 GiB&lt;/td&gt;
          &lt;td&gt;1.11 KiB&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;Raw Size：采样前的大小&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weight ：采样后的大小占比&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Epochs：被采样次数&lt;/p&gt;
&lt;p&gt;Effective Size：采样后的有效大小&lt;/p&gt;
&lt;p&gt;Mean Document Size：平均文档大小&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;部分数据已被发布者清洗的很好，只进行了最小程度的预处理&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pile-cc&#34;&gt;Pile-CC
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;由CC数据集清洗得到&lt;/li&gt;
&lt;li&gt;使用justText清洗raw HTTP responses including page HTML，相比于&lt;code&gt;.WET&lt;/code&gt;的纯文本效果更好&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;others&#34;&gt;Others
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;分类&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;来源&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;学术文献&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;ArXiv、PubMed Central、NIH ExPorter&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;图书与出版物&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;Books3、Project Gutenberg (PG-19)、BookCorpus2&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;代码与技术文档&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;GitHub、StackExchange&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;法律与政府文件&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;FreeLaw、USPTO Backgrounds&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;多语言与翻译文本&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;EuroParl、OpenSubtitles&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;社交与对话数据&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;HackerNews、Ubuntu IRC、Enron Emails&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;特殊领域数据&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;DeepMind Mathematics、PhilPapers（哲学）、YouTube字幕&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;网络爬取内容&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;Pile-CC（新构建的Clean Common Crawl子集）&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;benchmarking-language-models-with-the-pile&#34;&gt;Benchmarking Language Models with the Pile
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;可以训练数据，同时因为涉及领域广泛，也可以基准测试&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;划分为训练集、验证集、测试集（$0.1%$测试集+验证集，虽然比例很低但是仍各自超过1G）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;尽管去重，但是肯定还是存在重复&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;paper中首选了BPB作为评测指标：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;输入：负对数似然损失（Negative Log-Likelihood Loss）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型在测试数据上输出一个损失值 $L$，表示其预测能力。&lt;/li&gt;
&lt;li&gt;越低的 $L$ 表示模型越能准确预测下一个词。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;转换为 BPB：&lt;/strong&gt;（bits per UTF-8 encoded byte）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用公式将损失 $L$ 转换为每字节的比特数&lt;/li&gt;
&lt;/ul&gt;
$$
    BPB = \frac{L_T}{L_B}\log_2 e^L = \frac{L_T}{L_B}\times \frac{L}{\ln2}
    $$&lt;ul&gt;
&lt;li&gt;其中：
&lt;ul&gt;
&lt;li&gt;$L_T$：数据集以 token 为单位的长度&lt;/li&gt;
&lt;li&gt;$L_B$：数据集以 UTF-8 编码字节为单位的长度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;和困惑度有一点相似，用于衡量模型对数据的压缩效率或预测能力&lt;/p&gt;
&lt;p&gt;与Bits per Character (bpc)不同的一点，字符不是一个很好的定义（Unicode 中字符的界定可能复杂（例如组合字符、emoji 等），导致统计不一致。）&lt;/p&gt;
&lt;p&gt;同时bpb不受到分词的影响，UTF-8的字节定义是准确的，适合基于不同模型、分词进行比较&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;指标&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;优点&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;缺点&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;适用场景&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Bits per Byte&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;分词无关、字节标准明确&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;对非字节级任务不直观&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;跨模型比较、数据压缩评估&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Bits per Char&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;更贴近人类理解&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Unicode 字符定义模糊&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;字符级生成任务（需统一字符定义）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Perplexity&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;直接反映预测不确定性&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;依赖分词、数值范围不稳定&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;单一模型调参、生成质量评估&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;更加完整的解释&#34;&gt;更加完整的解释
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;自信息：指的是当我们接收到一个消息时所获得的信息量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在信息论中，自信息衡量一个事件携带的信息量，由概率$p$决定。&lt;/p&gt;
$$
I(p) = -\log_2(p)
$$&lt;p&gt;为了编码这一事件，我们选择霍夫曼编码这类最优编码，同时为了最小化平均码长：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高频事件：分配短码&lt;/li&gt;
&lt;li&gt;低频事件：分配长码&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;如果事件 $A$ 的概率  $p = 1/2$ ，则  $I(A) = -\log_2(1/2) = 1$  比特。这表示需要用 1 位二进制码（如 &lt;code&gt;0&lt;/code&gt; 或 &lt;code&gt;1&lt;/code&gt;）编码。
-   如果事件  $B$  的概率  $p = 1/8$ ，则  $I(B) = -\log_2(1/8) = 3$  比特。需要用 3 位二进制码（如 &lt;code&gt;000&lt;/code&gt; 到 &lt;code&gt;111&lt;/code&gt; 之一）编码。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
$$
L = -\ln p
$$&lt;p&gt;
一般使用的是自然对数，同时其恰好表示了概率为$p$的事件的信息量（单位为纳特（底数取e））&lt;/p&gt;
$$
Bits = I(p) = -\log_2(p) =-\frac{\ln p}{\ln 2} =\frac{L}{\ln 2}
$$&lt;p&gt;
&lt;strong&gt;同时，模型的损失是基于token计算的，即每个token的预测损失&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以这里的单位是：Bits per token&lt;/p&gt;
$$
bpb =  \frac{L_T}{L_B}\times \frac{L}{\ln2}
$$&lt;p&gt;
这样就得到了：Bits per Byte，消除了分词器、语种编码等其他影响，可以直接衡量模型输出的质量&lt;/p&gt;
&lt;h2 id=&#34;评测&#34;&gt;评测
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;然后paper实验验证了一下用训练集训练过的模型会更nb&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;通过分析哪些Pile子数据集的表现最差，就知道模型的训练数据分布在这块比较浅，就可以使用pile这块数据集进行补充&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了探索哪些数据集是模型表现较差的，显然不能直接使用困惑度进行比较（数据集熵值不一样）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结构化的数据（熵值低）困惑度天然会比非结构化的更低&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;困惑度可以用于衡量一个数据集是否更接近另一个数据集&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如CCNet，在维基百科内训练一个模型，计算其他数据集的困惑度&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;所以如果要比较的话，可以通过模型的损失值，拟合得越好，说明训练数据中包含了这部分，否则就是缺失&lt;/p&gt;
&lt;p&gt;如果钱多的话，当然是直接把所有数据集用模型train一下，看看损失值，与没有train过的原模型（GPT-3），在测试集上比一下Loss&lt;/p&gt;
&lt;p&gt;paper这里钱不够，改用了GPT2做了一个trick：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;首先需要知道GPT3比GPT2强多少&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;参考数据集：OWT2（与GPT训练数据高度相似的一个数据集）&lt;/li&gt;
&lt;li&gt;用原生的GPT3和在Pile训练的GPT2进行比较&lt;/li&gt;
&lt;li&gt;得到一个基准差值&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
$$
L^{GPT-3}_{OWT2} - L^{GPT-2-Pile}_{OWT2}
$$&lt;ul&gt;
&lt;li&gt;
$$
L^{GPT-3}_{TargetSet} - L^{GPT-2-Pile}_{TargetSet}
$$&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;两个值作差：大概能衡量出在目标数据集上的提升水平&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/assets/image-20250606162030021.png&#34;
	width=&#34;1172&#34;
	height=&#34;571&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/assets/image-20250606162030021_hu_c35f4776da27d503.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/assets/image-20250606162030021_hu_a020da3b1c3d156d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;205&#34;
		data-flex-basis=&#34;492px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Books3等数据集与GPT-3训练数据高度相似，因此不会有过多的提升（0）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;清洗&#34;&gt;清洗
&lt;/h2&gt;&lt;p&gt;看不动了，以后再说，整理一下清洗的东西：&lt;/p&gt;
&lt;h3 id=&#34;c1-pile-ccclean-common-crawl&#34;&gt;C.1 Pile-CC（Clean Common Crawl）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Common Crawl 的 WARC 文件（2013–2020 年）。&lt;/li&gt;
&lt;li&gt;提取工具
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;jusText&lt;/code&gt; 提取网页正文，去除菜单、页脚等模板文本。&lt;/li&gt;
&lt;li&gt;对比了 &lt;code&gt;Trafilatura&lt;/code&gt;、&lt;code&gt;Newspaper&lt;/code&gt;、&lt;code&gt;Goose3&lt;/code&gt;、&lt;code&gt;DragNet&lt;/code&gt;，最终选择 &lt;code&gt;jusText&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;语言过滤
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;pycld2&lt;/code&gt; 检测网页语言，仅保留英文内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;质量控制
&lt;ul&gt;
&lt;li&gt;使用 FastText 分类器对 OpenWebText2 和 Common Crawl 进行分类，过滤低质量页面。&lt;/li&gt;
&lt;li&gt;参数 α = 3，使用 Pareto 分布阈值进行过滤。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;去重
&lt;ul&gt;
&lt;li&gt;使用 MinHash LSH 算法在内存中进行文档级去重。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;其他说明
&lt;ul&gt;
&lt;li&gt;未使用 WET 文件，因其包含大量模板文本。&lt;/li&gt;
&lt;li&gt;与 Brown et al. (2020) 类似，但只处理了部分 WARC 文件。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c2-pubmed-centralpmc&#34;&gt;C.2 PubMed Central（PMC）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：美国国家生物技术信息中心（NCBI）提供。&lt;/li&gt;
&lt;li&gt;格式转换
&lt;ul&gt;
&lt;li&gt;使用 Pandoc 将 JATS 格式转为 Markdown。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;清理步骤
&lt;ul&gt;
&lt;li&gt;删除以 &lt;code&gt;:::&lt;/code&gt; 开头的行（Pandoc 添加的 HTML 类标签）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c3-books3&#34;&gt;C.3 Books3
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：未具体说明，但为高质量书籍数据集。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;处理细节&lt;/strong&gt; ：无额外处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c4-openwebtext2owt2&#34;&gt;C.4 OpenWebText2（OWT2）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Reddit 提交链接。&lt;/li&gt;
&lt;li&gt;处理步骤
&lt;ul&gt;
&lt;li&gt;提取 URL 及其元数据。&lt;/li&gt;
&lt;li&gt;去除得分低于 3 的链接。&lt;/li&gt;
&lt;li&gt;使用 Newspaper 抓取网页内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;去重
&lt;ul&gt;
&lt;li&gt;使用 DataSketch 库进行文档级 MinHash LSH 去重。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c5-arxiv&#34;&gt;C.5 ArXiv
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：arXiv.org 学术论文。&lt;/li&gt;
&lt;li&gt;处理步骤
&lt;ul&gt;
&lt;li&gt;转换为纯文本。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;去重
&lt;ul&gt;
&lt;li&gt;使用与验证/测试集对比的方法去重。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c6-github&#34;&gt;C.6 GitHub
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：GitHub 上的开源项目。&lt;/li&gt;
&lt;li&gt;获取方式
&lt;ul&gt;
&lt;li&gt;收集星标数 &amp;gt; 100 的仓库。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;提取内容
&lt;ul&gt;
&lt;li&gt;提取可用于语言建模的文本（代码、README、注释等）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;限制条件
&lt;ul&gt;
&lt;li&gt;单个仓库克隆和提取时间不超过 300 秒。&lt;/li&gt;
&lt;li&gt;文件大小上限为 100KB（避免大文件中的重复自动生成内容）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c7-freelaw&#34;&gt;C.7 FreeLaw
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：法律数据库。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;未提供详细清洗步骤。&lt;/li&gt;
&lt;li&gt;数据来自已有结构化格式，可能已做过预处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c8-stack-exchange&#34;&gt;C.8 Stack Exchange
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Stack Overflow 等问答网站。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;提取问题、回答、评论。&lt;/li&gt;
&lt;li&gt;按照层级结构组织。&lt;/li&gt;
&lt;li&gt;保留 &lt;code&gt;/me&lt;/code&gt; 类型的动作描述，删除系统消息。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c9-uspto-backgrounds&#34;&gt;C.9 USPTO Backgrounds
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：美国专利商标局（USPTO）公开数据。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;处理 XML 格式的专利文件。&lt;/li&gt;
&lt;li&gt;提取“Background”部分内容。&lt;/li&gt;
&lt;li&gt;处理不同格式变化（APS → XML）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c10-pubmed-abstracts&#34;&gt;C.10 PubMed Abstracts
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：PubMed 数据库摘要。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;排除缺失或格式错误的条目。&lt;/li&gt;
&lt;li&gt;合并标题和摘要，去除版权信息。&lt;/li&gt;
&lt;li&gt;排除已在 PMC 中出现的内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c11-project-gutenbergpg-19&#34;&gt;C.11 Project Gutenberg（PG-19）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：古登堡计划电子书。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;处理方式&lt;/strong&gt; ：无额外处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c12-opensubtitles&#34;&gt;C.12 OpenSubtitles
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Tiedemann (2016) 提供的英文字幕数据。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;提取 XML 文件中的字幕文本。&lt;/li&gt;
&lt;li&gt;忽略元数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c13-wikipedia-en&#34;&gt;C.13 Wikipedia (en)
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Wikipedia English dataset from TensorFlow Datasets。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;wikipedia/20200301.en&lt;/code&gt; 数据集。&lt;/li&gt;
&lt;li&gt;在每篇文章开头添加标题。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c14-deepmind-mathematicsdm-math&#34;&gt;C.14 DeepMind Mathematics（DM Math）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：DeepMind 数学数据集。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;包含 Easy、Medium、Hard 难度。&lt;/li&gt;
&lt;li&gt;将每个题目拆分为 8 KiB 块。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c15-ubuntu-irc&#34;&gt;C.15 Ubuntu IRC
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Ubuntu IRC 日志（2004–2020）。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;删除系统消息（如加入、离开频道）。&lt;/li&gt;
&lt;li&gt;保留 &lt;code&gt;/me&lt;/code&gt; 动作。&lt;/li&gt;
&lt;li&gt;去除时间戳。&lt;/li&gt;
&lt;li&gt;每周日志合并为一个文档，按日期分隔。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c16-bookcorpus2&#34;&gt;C.16 BookCorpus2
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：基于 Kobayashi (2018) 方法重新构建。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;收集更多书籍（共 17,868 本，原版为 11,038 本）。&lt;/li&gt;
&lt;li&gt;使用修改后的 EPUB 解析器提取文本。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c17-europarl&#34;&gt;C.17 EuroParl
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：欧洲议会会议记录。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;已经是干净文本，无需额外清洗。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c18-hackernews&#34;&gt;C.18 HackerNews
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Hacker News 提交链接。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;提取文章标题、URL、子标题、作者。&lt;/li&gt;
&lt;li&gt;按照评论层级组织内容。&lt;/li&gt;
&lt;li&gt;使用 html2text 提取 HTML 文本。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c19-youtube-subtitles&#34;&gt;C.19 YouTube Subtitles
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：YouTube 视频字幕。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;三阶段构建：
&lt;ol&gt;
&lt;li&gt;GPT-3 生成搜索关键词。&lt;/li&gt;
&lt;li&gt;下载相关视频。&lt;/li&gt;
&lt;li&gt;提取字幕并按时间对齐。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;多语言字幕按分钟段落对齐，并标注语言。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c20-philpapers&#34;&gt;C.20 PhilPapers
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：PhilPapers 数据库（哲学论文）。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;使用 OAI-MPH 协议抓取元数据。&lt;/li&gt;
&lt;li&gt;转换为纯文本。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c21-nih-exporter&#34;&gt;C.21 NIH ExPorter
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：NIH Grant Application 数据。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;合并 ExPORTER 和 CRISP 数据。&lt;/li&gt;
&lt;li&gt;按申请 ID 去重。&lt;/li&gt;
&lt;li&gt;删除空或太短的摘要。&lt;/li&gt;
&lt;li&gt;去除行政模板内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c22-enron-emails&#34;&gt;C.22 Enron Emails
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Enron 公司邮件存档。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;mailparser&lt;/code&gt; 提取邮件正文作为文档。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>大语言模型数据清洗 · 论文笔记（一）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/</link>
        <pubDate>Fri, 06 Jun 2025 01:38:32 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/</guid>
        <description>&lt;h2 id=&#34;ccnet-extracting-high-quality-monolingual-datasets-from-web-crawl-data&#34;&gt;CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1911.00359&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ArXiv1911.00359 CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/facebookresearch/cc_net&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Github facebookresearch/cc_net: Tools to download and cleanup Common Crawl data&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;概述&#34;&gt;概述
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;为保证数据质量，倾向于通过维基百科等高质量数据来源合成&lt;code&gt;ad-hoc datasets&lt;/code&gt;（专门构建的数据集），但是低资源语言不好做&lt;/li&gt;
&lt;li&gt;paper从CC数据集出发，执行了FastText所提出的pipeline，但不同之处：
&lt;ul&gt;
&lt;li&gt;保留文档级别的结构，支持Bert等需要段落级别的模型训练
&lt;ul&gt;
&lt;li&gt;之前的方法切成单个句子，只关心局部上下文，切分成了n-gram&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;增加一个可选的&lt;strong&gt;单语言过滤&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;针对目标语言进行筛选&lt;/li&gt;
&lt;li&gt;筛选出接近维基百科风格的文档
&lt;ul&gt;
&lt;li&gt;在目标语言的维基百科等语料上训练一个语言模型&lt;/li&gt;
&lt;li&gt;通过困惑度进行文档打分，只保留那些 perplexity 较低的文档&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;与传统方法相比：
&lt;ul&gt;
&lt;li&gt;传统方法：多数只适用于英语的特殊方法，手动设置规则&lt;/li&gt;
&lt;li&gt;paper：通用性强，适用于多种语言&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;method&#34;&gt;Method
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250605191955047.png&#34;
	width=&#34;1142&#34;
	height=&#34;594&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250605191955047_hu_c0a8034b02c0e136.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250605191955047_hu_f79931d4cc592469.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Figure 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;192&#34;
		data-flex-basis=&#34;461px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;下载网页快照的.WET文件，为每个段落生成哈希值，转化为.bin的二进制文件&lt;/li&gt;
&lt;li&gt;独立处理每个WET下的文档，通过哈希进行去重，识别语言，计算困惑度&lt;/li&gt;
&lt;li&gt;按照语言和困惑度得分重新分组，保存为 JSON 格式的文件&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;预处理&#34;&gt;预处理
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;每个快照包含大约 20 到 30TB 的未压缩纯文本&lt;/li&gt;
&lt;li&gt;将 WET 文件分组为每个 5GB 的分片（shard），转化为json格式&lt;/li&gt;
&lt;li&gt;json中的每一条entry：记录了url、文本等信息，代表了一个网页的内容
&lt;ul&gt;
&lt;li&gt;文本中含有段落&lt;/li&gt;
&lt;li&gt;所以这里的逻辑是：快照（.WET） &amp;gt; shard &amp;gt; entry &amp;gt; 段落&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;去重&#34;&gt;去重
&lt;/h3&gt;&lt;p&gt;需要删除不同网页之间的重复段落（占了70%），为方便去重：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;标准化&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;字符全部小写&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;所有数字变成0&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;删除所有Unicode的Punctuation Marks（标点符号）、Accent Marks（重音符号），完成段落标准化&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;标点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;英文标点：&lt;code&gt;.,!?;:&amp;quot;&#39;()[]{}-–—…@#$%^&amp;amp;*&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;中文标点：&lt;code&gt;，。！？；：“”‘’（）【】《》……&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;法语标点：&lt;code&gt;«»&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;阿拉伯语标点：&lt;code&gt;،؛؟&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;日文标点：&lt;code&gt;、。，・「」『』&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Accent：表示发音变化或区分拼写&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;法语：&lt;code&gt;à, é, ô, ù, ç&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;西班牙语：&lt;code&gt;ñ, á, é&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;德语：&lt;code&gt;ä, ö, ü&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;波兰语：&lt;code&gt;ą, ę, ś, ź&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;希腊语：&lt;code&gt;ά, έ, ό&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;计算哈希
&lt;ul&gt;
&lt;li&gt;对每个shard的每个段落计算SHA哈希值（160位），保存为二进制文件&lt;code&gt;.bin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;每个段落的前64位作为其id便于维护&lt;/li&gt;
&lt;li&gt;对每个段落，查询处理过的**一些（见后文）**shard的二进制文件，若出现过则舍弃，否则保存在本shard二进制文件中&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于很多步骤都是独立的，因此支持并行&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于网页数据，需要去掉导航栏、cookie、联系信息等&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;语言识别&#34;&gt;语言识别
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;FastText模型，基于 Wikipedia、Tatoeba 和 SETimes 数据集进行训练&lt;/li&gt;
&lt;li&gt;支持176种语言，为每一种语言输出0-1的置信度（总和为1）&lt;/li&gt;
&lt;li&gt;若某语言得分超过0.5则进行确认，否则舍弃（无法识别语言）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;语言模型过滤&#34;&gt;语言模型过滤
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;对每种语言，训练了一个tokenizer和语言模型
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;KenLM 库&lt;/strong&gt;实现的5-gram模型（处理大量数据效率高）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;使用tokenizer对每一个entry进行分词，使用语言模型计算每个段落的困惑度&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;消融实验&#34;&gt;消融实验
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;先去重再语言识别
&lt;ul&gt;
&lt;li&gt;可以去除一些英文的Cookie警告，防止误识别为英文&lt;/li&gt;
&lt;li&gt;去重跨越的shard越多去除内容越多，去重效果越好，但是自然开销变大
&lt;ul&gt;
&lt;li&gt;选择50均衡了资源与性能&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;最终数据集的指标&#34;&gt;最终数据集的指标
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;使用训练好的语言模型对段落进行困惑度（perplexity）评分，作为衡量文本质量的代理指标。&lt;/li&gt;
&lt;li&gt;结果发现：
&lt;ul&gt;
&lt;li&gt;高质量内容（如新闻、写作规范的内容）通常位于数据集的“头部”（head）&lt;/li&gt;
&lt;li&gt;含有关键词列表或与 Wikipedia 差异较大的口语化内容会落在“尾部”（tail）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;不同语言的困惑度分布差异较大，这主要是由于训练语言模型所使用的 Wikipedia 数据大小不同，而不是某些语言本身缺乏高质量内容。&lt;/li&gt;
&lt;li&gt;因此，为每种语言设置了不同的困惑度阈值，将语料库划分为三个部分：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Head（头部）&lt;/strong&gt; ：高质量段落&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Middle（中部）&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tail（尾部）&lt;/strong&gt; ：较低质量段落&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了验证数据集的质量，作者使用 fastText 和 BERT 模型进行实验：&lt;/p&gt;
&lt;h4 id=&#34;fasttext-实验&#34;&gt;fastText 实验
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;对英语和波兰语的不同质量子集（head、mid、tail）训练词向量&lt;/li&gt;
&lt;li&gt;在标准的类比任务数据集（Mikolov et al., 2013）上评估性能&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;结果表明&lt;/strong&gt; ：随着从 tail 到 head 的变化，模型性能逐步提升，说明基于困惑度的过滤方法能有效提升数据质量&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;子集&lt;/th&gt;
          &lt;th&gt;英语总分&lt;/th&gt;
          &lt;th&gt;波兰语总分&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;head&lt;/td&gt;
          &lt;td&gt;77.9&lt;/td&gt;
          &lt;td&gt;65.3&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;mid&lt;/td&gt;
          &lt;td&gt;74.2&lt;/td&gt;
          &lt;td&gt;62.8&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;tail&lt;/td&gt;
          &lt;td&gt;62.0&lt;/td&gt;
          &lt;td&gt;59.9&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;bert-实验&#34;&gt;BERT 实验
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;分别使用 Wikipedia 和 CCNet 提取的 head 数据训练 BERT-BASE 模型&lt;/li&gt;
&lt;li&gt;训练语言包括：英语（en）、俄语（ru）、中文（zh）、乌尔都语（ur）&lt;/li&gt;
&lt;li&gt;使用 XNLI 任务评估模型表现&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;语言&lt;/th&gt;
          &lt;th&gt;Wikipedia 准确率&lt;/th&gt;
          &lt;th&gt;CCNet 准确率&lt;/th&gt;
          &lt;th&gt;提升幅度&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;en&lt;/td&gt;
          &lt;td&gt;82.8&lt;/td&gt;
          &lt;td&gt;85.0&lt;/td&gt;
          &lt;td&gt;+2.2&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ru&lt;/td&gt;
          &lt;td&gt;73.3&lt;/td&gt;
          &lt;td&gt;76.4&lt;/td&gt;
          &lt;td&gt;+3.1&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;zh&lt;/td&gt;
          &lt;td&gt;77.0&lt;/td&gt;
          &lt;td&gt;77.9&lt;/td&gt;
          &lt;td&gt;+0.9&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ur&lt;/td&gt;
          &lt;td&gt;57.3&lt;/td&gt;
          &lt;td&gt;64.3&lt;/td&gt;
          &lt;td&gt;+7.0 ✅（显著提升）&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;特别是对于低资源语言乌尔都语（ur），Wikipedia 数据太小导致模型几乎无效，而使用 CCNet 提取的数据训练后，准确率提升了 &lt;strong&gt;7 个百分点&lt;/strong&gt; ，证明了该数据集对低资源语言预训练的重要性。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;维基百科的数据不足，CCNet从CC中提取了高质量语言专用的数据，效果显著&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Python Rookie 扫盲 · 语法进阶</title>
        <link>https://example.com/p/python-rookie-%E6%89%AB%E7%9B%B2-%E8%AF%AD%E6%B3%95%E8%BF%9B%E9%98%B6/</link>
        <pubDate>Mon, 02 Jun 2025 20:15:32 +0800</pubDate>
        
        <guid>https://example.com/p/python-rookie-%E6%89%AB%E7%9B%B2-%E8%AF%AD%E6%B3%95%E8%BF%9B%E9%98%B6/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;面向对象&#34;&gt;面向对象
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;类：抽象概念定义
&lt;ul&gt;
&lt;li&gt;属性：用于描述对象&lt;/li&gt;
&lt;li&gt;方法：对象具有的行为&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;对象：类的实例&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;price&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 可以直接定义类变量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;price&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 使用类名进行调用&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;quality&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;good&amp;#39;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# # 可以直接定义类变量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;quality&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;所有实例对象公用一个类变量：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;price&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;price&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;price&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;price&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 200&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;若定义类的方法，则必须要有一个必要参数：&lt;code&gt;self&lt;/code&gt;，表示对象本身&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;eat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;I am eating an apple&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;eat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# &amp;#39;I am eating an apple&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;eat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# &amp;#39;I am eating an apple&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;其中实例可以有自己的属性（变量）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;eat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;I am eating an apple&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 与类变量一致 可以在外部进行定义&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 报错&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;但是这样的方法显然会让不同实例的属性不统一，需要进行自动化定义：&lt;/p&gt;
&lt;h3 id=&#34;构造函数__init__&#34;&gt;构造函数&lt;code&gt;__init__()&lt;/code&gt;
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;eat&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;I am an apple!&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;eat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;同样可以带上参数：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;eat&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;I am an apple!&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apple2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;析构函数__del__&#34;&gt;析构函数&lt;code&gt;__del__()&lt;/code&gt;
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;eat&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;I am an apple!&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__del__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Apple is being deleted!&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;del&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;垃圾回收机制：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python通过统计对象被引用次数（引用计数器），从而判断是否回收垃圾&lt;/li&gt;
&lt;li&gt;但是回收不是&amp;quot;立即&amp;quot;的， 由解释器在适当的时机，将垃圾对象占用的内存空间回收&lt;/li&gt;
&lt;li&gt;但是针对循环引用，会有额外的循环垃圾收集器&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;封装&#34;&gt;封装
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;隐藏对象中不希望被外部访问的属性或方法&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;隐藏属性也称：魔术方法、特殊方法，通过开头结尾加上两个下划线：&lt;code&gt;__&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;构造和析构都是一种隐藏属性&lt;/p&gt;
&lt;p&gt;对于变量，可以在开头加个&lt;code&gt;__&lt;/code&gt;，实现私有效果&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;public_age&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;__private_age&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;public_age&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;__private_age&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 报错&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;但是似乎留了一个后门：&lt;code&gt;_类名__隐藏属性&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;public_age&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;__private_age&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;public_age&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_Apple__private_age&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;标准的方式还是需要通过类的内部进行访问&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;public_age&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;__private_age&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;grow&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;__private_age&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;__private_age&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grow&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;有了私有，当然还有保护变量：单个下划线&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Fruit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;_banana&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;__cherry&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;fruit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Fruit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fruit&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;      &lt;span class=&#34;c1&#34;&gt;# True&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fruit&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_banana&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;# True&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fruit&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;__cherry&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;   &lt;span class=&#34;c1&#34;&gt;# AttributeError: &amp;#39;Fruit&amp;#39; object has no attribute &amp;#39;__cherry&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;私有变量只能被类内部的方法进行使用
&lt;ul&gt;
&lt;li&gt;建议别用，容易和python自带的属性冲突&lt;/li&gt;
&lt;li&gt;主要用于&lt;strong&gt;防止子类意外覆盖父类属性&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;保护变量可以被外部使用
&lt;ul&gt;
&lt;li&gt;建议只在内部使用，约定习惯，但是不禁止&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;公开变量无限制&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;类型&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;示例&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;特点&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;公开变量&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;var&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;可以直接访问，无任何限制&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;保护变量&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;_var&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;本身与子类可以访问，不能被其他文件from import&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;私有变量&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;__var&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;只允许本身访问&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;魔术方法&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;__var__&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;双下划线开头和结尾，Python的特殊方法&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;方法&#34;&gt;方法
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;静态方法&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Animal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;speak&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;times&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Animal speaks&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;times&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nd&#34;&gt;@staticmethod&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;eat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;times&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Animal eats&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;times&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Animal&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;eat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这样可以不创建实例直接用，同时不传self，减少内存&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;类方法&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Animal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Animal&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nd&#34;&gt;@classmethod&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;eat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;cls&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;cls&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Animal&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;eat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;两种方法都可以用于规避实例的创建，静态方法不能访问类和实例，类方法可以访问类本身&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;方法&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;参数&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;自动传参&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;访问&lt;/th&gt;
          &lt;th&gt;被调用&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;用途&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;实例方法&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;self&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;是&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;✅ 类属性 / ✅ 实例属性&lt;/td&gt;
          &lt;td&gt;✅ 实例&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;操作对象自身的状态&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;类方法&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;cls&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;是&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;✅ 类属性 / ❌ 实例属性&lt;/td&gt;
          &lt;td&gt;✅ 类 / ✅ 实例&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;工厂方法、操作类级别的数据&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;静态方法&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;无&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;否&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;❌ 类属性 / ❌ 实例属性&lt;/td&gt;
          &lt;td&gt;✅ 类 / ✅ 实例&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;与类相关的工具函数，不依赖类或实例&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这里的访问其实不是说无法访问，事实上&lt;code&gt;类名.属性&lt;/code&gt;都可以访问&lt;/p&gt;
&lt;p&gt;所以其实都是约定俗成&lt;/p&gt;
&lt;h3 id=&#34;继承&#34;&gt;继承
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Fruit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 其实默认继承object类（不然你以为默认自带的方法属性都是哪来的）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Fruit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 子类如果拓展了新的属性 ——&amp;gt; 派生类&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h4 id=&#34;重写&#34;&gt;重写
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;子类中定义与父类相同名称的方法（覆盖）&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Fruit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;I am a fruit&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Fruit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;I am a apple&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;重写可以用于拓展父类方法的功能：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Fruit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;I am a fruit&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Fruit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# Fruit.print(self) # 调用父类方法（需要传入self）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 更推荐这种方法&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# super(Apple, self).print() 等价&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;I am a apple&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Apple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;apple&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;理解上把&lt;code&gt;super()&lt;/code&gt;当成一个函数，返回的是父类，这样没什么问题&lt;/p&gt;
&lt;p&gt;实际上是创建了一个super类的实例，动态查找MRO链，返回一个代理对象&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;MRO = MRO（Method Resolution Order，方法解析顺序）是Python中决定类继承关系中方法调用顺序的规则。它是Python多继承机制的核心组成部分。&lt;/p&gt;&lt;/blockquote&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;方式&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;示例&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;区别&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;&lt;code&gt;super()&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;super().method()&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;动态查找 MRO 链，适用于多重继承&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;直接调用父类&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;Parent.method(self)&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;硬编码父类名，不适用于复杂继承&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;多继承&#34;&gt;多继承
&lt;/h4&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Father&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Father&amp;#39;s __init__&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__del__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Father&amp;#39;s __del__&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Father&amp;#39;s print&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Mother&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Mother&amp;#39;s __init__&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__del__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Mother&amp;#39;s __del__&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Mother&amp;#39;s print&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Child&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Mother&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Father&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Child&amp;#39;s __init__&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__del__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__del__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Child&amp;#39;s __del__&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;child&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Child&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;child&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;Mother&amp;#39;s __init__
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;Child&amp;#39;s __init__
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;Mother&amp;#39;s print
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;Mother&amp;#39;s __del__
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;Child&amp;#39;s __del__
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;构造与析构的顺序其实可以根据&lt;code&gt;super()&lt;/code&gt;去控制&lt;/p&gt;
&lt;p&gt;这里&lt;code&gt;print()&lt;/code&gt;和&lt;code&gt;super()&lt;/code&gt;默认都是就近的&lt;code&gt;Mother&lt;/code&gt;（写在第一个）&lt;/p&gt;
&lt;p&gt;调用其他父类需要显式的写出来&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;Mother&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;Father&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Child&amp;#39;s __init__&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;目测不实现构造函数应该也会自动实现：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Father&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Father&amp;#39;s __init__&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__del__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Father&amp;#39;s __del__&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Father&amp;#39;s print&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Mother&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Mother&amp;#39;s __init__&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__del__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Mother&amp;#39;s __del__&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Mother&amp;#39;s print&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Child&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Mother&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Father&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;child&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Child&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Child&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;vm&#34;&gt;__mro__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;Mother&amp;#39;s __init__
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;(&amp;lt;class &amp;#39;__main__.Child&amp;#39;&amp;gt;, &amp;lt;class &amp;#39;__main__.Mother&amp;#39;&amp;gt;, &amp;lt;class &amp;#39;__main__.Father&amp;#39;&amp;gt;, &amp;lt;class &amp;#39;object&amp;#39;&amp;gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;Mother&amp;#39;s __del__
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;多态&#34;&gt;多态
&lt;/h3&gt;&lt;p&gt;同一种行为多个表现形式&lt;/p&gt;
&lt;p&gt;需要基于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;继承&lt;/li&gt;
&lt;li&gt;重写&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Animal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;speak&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Animal speaks&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Dog&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Animal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;speak&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Dog barks&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Cat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Animal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;speak&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Cat meows&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dog&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Dog&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dog&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;speak&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 重写&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cat&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Cat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;speak&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 重写&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这里其实就只是重写&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;speak_loudly&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;animal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Animal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;animal&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;speak&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 多态&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;speak_loudly&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Dog&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 调用 Dog 的 speak 方法&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;speak_loudly&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Cat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 调用 Cat 的 speak 方法&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这样就可以体现多态&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Python Rookie 扫盲 · 语法基础</title>
        <link>https://example.com/p/python-rookie-%E6%89%AB%E7%9B%B2-%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/</link>
        <pubDate>Wed, 28 May 2025 16:38:32 +0800</pubDate>
        
        <guid>https://example.com/p/python-rookie-%E6%89%AB%E7%9B%B2-%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;深浅拷贝&#34;&gt;深浅拷贝
&lt;/h2&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Python&#34; data-lang=&#34;Python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 0 1 2 3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 0 1 2 3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 100 1 2 3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 1879915237696&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 1879915237696&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Python直接赋值相当于建立一个新的引用&lt;/p&gt;
&lt;h3 id=&#34;浅拷贝&#34;&gt;浅拷贝
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;创建新的对象，只复制原对象本身，不复制原对象内部的子对象&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;copy&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;copy&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;copy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;[0, 1, 2, 3]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;[0, 1, 2, 3]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;[0, 1, 2, 3] # a未发生改变
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;2752117477696 # 地址不一样
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;2752117479552
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;之所以是浅拷贝，会体现到含有子对象的情况：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;copy&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;copy&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;copy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ia&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ib&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;zip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ia&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ib&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;2955264350656 2955262793600
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;2956986749248 2956986749248 # 子对象未发生变化
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;2956986751104 2956986751104 # 子对象未发生变化
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;2955300137024 2955300137024 # 子对象未发生变化
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;拷贝速度、占用空间显然会比深拷贝快&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当只是简单创建副本，同时不存在内部资源修改时使用&lt;/p&gt;
&lt;h3 id=&#34;深拷贝&#34;&gt;深拷贝
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;copy&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;deepcopy&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;deepcopy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ia&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ib&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;zip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ia&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ib&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;1640473937792 1640472338688
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;1640049480000 1640052597184
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;1640049481856 1640049786560
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;1640509759936 1640049482304
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;所有子对象都会被重新创建&lt;/p&gt;
&lt;h3 id=&#34;函数传参&#34;&gt;函数传参
&lt;/h3&gt;&lt;p&gt;首先需要分两类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可变对象：列表、字典&lt;/li&gt;
&lt;li&gt;不可变对象：数值、&lt;strong&gt;字符串&lt;/strong&gt;、元组&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可变对象作为&lt;strong&gt;引用&lt;/strong&gt;进行传参，函数修改值，外部会发生改变&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;modify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;modify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Output: [1, 2, 3, 42]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;但是如果发生&lt;strong&gt;赋值&lt;/strong&gt;，则也是重新创建一个对象&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;modify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 新创建&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;modify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Output: [1, 2, 3]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;因此可以利用这个机制，使用&lt;code&gt;.copy&lt;/code&gt;一个副本，进行重新赋值&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;modify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;copy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;modify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;其中&lt;code&gt;.copy()&lt;/code&gt;是内置可变容器类型（如&lt;code&gt;list&lt;/code&gt;、&lt;code&gt;dict&lt;/code&gt;、&lt;code&gt;set&lt;/code&gt;）自带的&lt;strong&gt;浅拷贝&lt;/strong&gt;方法&lt;/p&gt;
&lt;p&gt;不可变对象相当于重新创建一个副本，和原来没有任何关系&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;modify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;niko&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;hello&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;modify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Output: hello 5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;函数&#34;&gt;函数
&lt;/h2&gt;&lt;h3 id=&#34;函数参数&#34;&gt;函数参数
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;位置参数：传入数量、位置需要一一对应&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;默认参数（缺省参数default）&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;注意默认参数需要按顺序写在最后面&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可变参数&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 加一个*就表示可变参数，args是约定俗成，可以更换其他名字&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 以元组形式打包&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# (1, 2, 3)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;关键字参数&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;hcf&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;school&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;dhu/ecnu&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Output: {&amp;#39;name&amp;#39;: &amp;#39;hcf&amp;#39;, &amp;#39;school&amp;#39;: &amp;#39;dhu/ecnu&amp;#39;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;以键值对的形式传入，打包成字典&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;combined_example&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;位置参数 (args):&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;关键字参数 (kwargs):&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;combined_example&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Alice&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;age&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;当两者一起使用时，函数可以接受&lt;strong&gt;任意数量和类型的参数&lt;/strong&gt;（位置参数 + 关键字参数）。
&lt;strong&gt;规则&lt;/strong&gt;：&lt;code&gt;*args&lt;/code&gt; 必须在 &lt;code&gt;**kwargs&lt;/code&gt; 之前。&lt;/p&gt;
&lt;h3 id=&#34;作用域&#34;&gt;作用域
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fun &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 200&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;函数内部的a是局部变量，与外部的a没有任何关系&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# print(a) error 局部变量超出作用域&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# ok 这里b不是全局变量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;所以这个和C++不太一样&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;global&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 声明这个是全局变量，这样后续赋值不会认为是新的变量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;300&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;lambda&#34;&gt;lambda
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;add_fun&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;add_fun&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 带默认参数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;fun&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;hcf&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;age&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;18&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;city&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;beijing&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# {&amp;#39;name&amp;#39;: &amp;#39;hcf&amp;#39;, &amp;#39;age&amp;#39;: 18, &amp;#39;city&amp;#39;: &amp;#39;beijing&amp;#39;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;内置函数&#34;&gt;内置函数
&lt;/h3&gt;&lt;p&gt;&lt;code&gt;zip&lt;/code&gt;之类的就不说了，写点自己不会的&lt;/p&gt;
&lt;h4 id=&#34;map&#34;&gt;map
&lt;/h4&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;fun&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;9&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;d&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;code&gt;map&lt;/code&gt;传入一个函数和若干个可迭代对象，把所有对象塞进去跑&lt;/p&gt;
&lt;p&gt;最后返回一个迭代器，可以直接&lt;code&gt;list&lt;/code&gt;转换&lt;/p&gt;
&lt;h3 id=&#34;解包&#34;&gt;解包
&lt;/h3&gt;&lt;p&gt;（不要管为什么放在这里）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;a1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a4&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 1 2 3 4&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 1 2 3 4&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# a = [1, 2, 3]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# a = [1, 2], b = 3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;first&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rest&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# first=1, rest=[2, 3]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# SyntaxError: starred assignment target must be in a list or tuple&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 因为这个写法非常奇怪，为什么不直接 a = [1,2,3]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;异常&#34;&gt;异常
&lt;/h2&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;raise&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;Exception&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Error in test.py&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 主动抛出异常&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;闭包与装饰器&#34;&gt;闭包与装饰器
&lt;/h2&gt;&lt;h3 id=&#34;闭包&#34;&gt;闭包
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;闭包就是&lt;strong&gt;函数&lt;/strong&gt;及其&lt;strong&gt;周边环境&lt;/strong&gt;的组合&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;outer_function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;msg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 外部函数的变量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;message&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;msg&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;inner_function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 内部函数访问外部函数的变量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 返回内部函数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inner_function&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 创建闭包&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;my_closure&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;outer_function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Hello, 闭包!&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;my_closure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 输出: Hello, 闭包!&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;本质上记住了&lt;code&gt;message = msg&lt;/code&gt;这一函数的中间状态，使得超出作用域时，仍然能正常运行&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;counter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;counter&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;increment&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;nonlocal&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;counter&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 声明为上一级的变量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;counter&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;counter:&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;counter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;increment&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;count&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;counter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 输出: counter: 1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 输出: counter: 2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 输出: counter: 3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;我们可以基于这个特性，使用闭包做一个计数器&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;power_factory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;exponent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;power&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;base&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;base&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exponent&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;power&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;square&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;power_factory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cube&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;power_factory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;square&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 输出 25&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cube&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;# 输出 125&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;同时可以用闭包预设一些参数，批量生成函数&lt;/p&gt;
&lt;h3 id=&#34;装饰器&#34;&gt;装饰器
&lt;/h3&gt;&lt;p&gt;装饰器可以给函数添加新功能，且满足：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不修改原函数代码&lt;/li&gt;
&lt;li&gt;不改变原函数调用方法&lt;/li&gt;
&lt;li&gt;本质是一个闭包函数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;首先我希望实现一个功能，在一个函数执行的前后，输出debug信息：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;debug start&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;fun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;debug end&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;test function&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;如果使用闭包的方法进行实现：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;wrapper&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;debug start&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;debug end&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wrapper&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;test function&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;closure&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;closure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这样就非常清新自然，把&lt;code&gt;test&lt;/code&gt;打包成另外一个带有调试信息的函数&lt;/p&gt;
&lt;p&gt;事实上有时候我们不需要引入额外的函数：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这样我们就可以完成函数功能的动态修改&lt;/p&gt;
&lt;p&gt;此时，还有一种更加简单的语法糖写法——装饰器，与之等效：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;wrapper&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;debug start&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;debug end&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wrapper&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@debug&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;test function&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;后续你只需要通过注释这行代码就能决定修不修改函数功能&lt;/p&gt;
&lt;p&gt;被装饰的函数携带参数并不影响：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 所以wrapper就是被装饰后的函数本身&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;wrapper&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# func需要什么参数全部一样传&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;debug start&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 传参数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;debug end&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wrapper&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@debug&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;test function&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;debug start
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;test function
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;(1, 2, 3)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;{&amp;#39;a&amp;#39;: 4, &amp;#39;b&amp;#39;: 5, &amp;#39;c&amp;#39;: 6}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;debug end
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h4 id=&#34;带参数的装饰器&#34;&gt;带参数的装饰器
&lt;/h4&gt;&lt;p&gt;&lt;code&gt;debug&lt;/code&gt;作为闭包函数，只能传入一个函数作为参数&lt;/p&gt;
&lt;p&gt;因此无法携带更多参数，所以我们为了能够给装饰器引入其他参数，需要再嵌套一层：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;decorator_with_args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arg1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;arg2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;wrapper&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;debug start&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Decorator arguments:&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;arg1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;arg2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 装饰器的参数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;debug end&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wrapper&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;debug&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@decorator_with_args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;arg1_value&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;arg2_value&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;test function&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h4 id=&#34;元信息&#34;&gt;元信息
&lt;/h4&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;test function&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;vm&#34;&gt;__name__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# test&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;wrapper&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;debug start&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;debug end&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wrapper&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@debug&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;test function&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;vm&#34;&gt;__name__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# wrapper&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;使用装饰器后，原函数的&lt;code&gt;__name__&lt;/code&gt;、&lt;code&gt;__doc__&lt;/code&gt;等元信息会被wrapper函数覆盖&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;functools&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wraps&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nd&#34;&gt;@wraps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 使用wraps（也是一个装饰器），把func作为参数传入&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;wrapper&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;debug start&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;debug end&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wrapper&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@debug&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;function test&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;vm&#34;&gt;__name__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# test&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;code&gt;wraps&lt;/code&gt;本身也是一个装饰器，功能大概是修改了&lt;code&gt;wrapper&lt;/code&gt;的元信息&lt;/p&gt;
&lt;h4 id=&#34;应用&#34;&gt;应用
&lt;/h4&gt;&lt;p&gt;应用上非常广泛&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;timing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nd&#34;&gt;@wraps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;wrapper&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;time&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;start_time&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;end_time&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Function &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;vm&#34;&gt;__name__&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt; took &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;end_time&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;start_time&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;.4f&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt; seconds&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wrapper&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@timing&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;function test&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;9&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;比如计时功能的添加&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@debug&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@timing&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kwargs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;function test&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;9&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;可以堆叠&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注意：装饰器的应用顺序是从下往上的，即最靠近函数的装饰器最先应用。&lt;/p&gt;&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>浅谈MinHash</title>
        <link>https://example.com/p/%E6%B5%85%E8%B0%88minhash/</link>
        <pubDate>Mon, 07 Apr 2025 16:31:31 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%B5%85%E8%B0%88minhash/</guid>
        <description>&lt;h1 id=&#34;浅谈minhash&#34;&gt;浅谈MinHash
&lt;/h1&gt;&lt;p&gt;常用于网页、文本去重&lt;/p&gt;
&lt;h2 id=&#34;前置知识&#34;&gt;前置知识
&lt;/h2&gt;&lt;h3 id=&#34;n-gram&#34;&gt;n-gram
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;通过分词将文本分解为连续的n个单词或字符序列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;This is an example sentence for n-gram extraction.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;表示为&lt;code&gt;3-gram&lt;/code&gt;：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;This&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;is&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;an&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;is&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;an&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;example&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;an&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;example&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;sentence&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;example&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;sentence&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;for&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;sentence&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;for&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;n-gram&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;for&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;n-gram&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;extraction&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;按照此方式可以将一段文本表示成一个n元组序列，每个元组可以考虑到一定的上下文&lt;/p&gt;
&lt;h3 id=&#34;jaccard相似度&#34;&gt;Jaccard相似度
&lt;/h3&gt;$$
\text{Jaccard}(A,B) = \frac{|A\cap B|}{|A \cup B|}
$$&lt;p&gt;
&lt;img src=&#34;https://example.com/p/%E6%B5%85%E8%B0%88minhash/assets/image-20250407164231880.png&#34;
	width=&#34;583&#34;
	height=&#34;433&#34;
	srcset=&#34;https://example.com/p/%E6%B5%85%E8%B0%88minhash/assets/image-20250407164231880_hu_a295d421056dd3e9.png 480w, https://example.com/p/%E6%B5%85%E8%B0%88minhash/assets/image-20250407164231880_hu_102364a62db2837c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;集合计算方式&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;134&#34;
		data-flex-basis=&#34;323px&#34;
	
&gt; &lt;img src=&#34;https://example.com/p/%E6%B5%85%E8%B0%88minhash/assets/image-20250407164305553.png&#34;
	width=&#34;598&#34;
	height=&#34;428&#34;
	srcset=&#34;https://example.com/p/%E6%B5%85%E8%B0%88minhash/assets/image-20250407164305553_hu_be5ba4658136a322.png 480w, https://example.com/p/%E6%B5%85%E8%B0%88minhash/assets/image-20250407164305553_hu_39367a95e7c76b9c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;可重集合计算方式&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;139&#34;
		data-flex-basis=&#34;335px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;假设一共有$N$篇文档，每篇文档大小都是$M$，我们想知道两两文档之间的Jaccard值的开销是$O(N^2M)$&lt;/p&gt;
&lt;p&gt;对于超大规模的文档，一般来说$M$会占大头，文档的大小都非常恐怖&lt;/p&gt;
&lt;h2 id=&#34;流程&#34;&gt;流程
&lt;/h2&gt;&lt;p&gt;因此MinHash的目标是将一篇大文档表示为一个较短的signature（假设大小为$\text{numHash}$）&lt;/p&gt;
&lt;p&gt;本质上在做数据降维&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;重要的前提&lt;/strong&gt;：两个集合&lt;strong&gt;非常相似&lt;/strong&gt;，那么对两个集合使用&lt;strong&gt;相同的变化&lt;/strong&gt;，得到的变化结果也是相似的&lt;/p&gt;
&lt;p&gt;例如对于$A,B$两个集合，同时使用函数$\min$，结果$\min(A),\min(B)$大概率也是相同的&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;基于hash的方法&#34;&gt;基于Hash的方法
&lt;/h3&gt;&lt;p&gt;假设哈希就用最简单的&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;hash&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;因为叫MinHash，所以取最小值&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;MinHash&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;document&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;hash&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;hash&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;document&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;$$
P(\text{minHash}(A) = \text{minHash}(B)) = \text{Jaccard}(A,B)
$$&lt;blockquote&gt;
&lt;p&gt;为什么这个公式是对的？&lt;/p&gt;
&lt;p&gt;假设有30个小朋友，有的会唱歌、有的会跳舞，有的什么都会&lt;/p&gt;
&lt;p&gt;定义：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A = 会唱歌的集合&lt;/li&gt;
&lt;li&gt;B = 会跳舞的集合&lt;/li&gt;
&lt;li&gt;A和B的并集即为全集&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们从A中挑选身高最高的小朋友，B中也挑选一个最高的小朋友&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;两个小朋友是同一个小朋友的概率，等价于从全班中挑选一个身高最高的小朋友，他同时属于A和B&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们还可以使用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;体重&lt;/li&gt;
&lt;li&gt;力气&lt;/li&gt;
&lt;li&gt;成绩&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;等多种方式（本质上是多种哈希），将所有元素投影到一个方向，完成近似&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;我们只要使用多个&lt;code&gt;hash&lt;/code&gt;函数进行测试，就可以估计出$\text{Jaccard}(A,B)$&lt;/p&gt;
$$
\text{Jaccard}(A,B) \approx  \frac{\sum^{numHash}[\text{minHash}(A,hash_i) = \text{minHash}(B,hash_i)]}{numHash}
$$&lt;p&gt;实际操作中略微复杂，会更偏向于使用随机打乱的方法&lt;/p&gt;
&lt;h3 id=&#34;基于随机打乱的方法&#34;&gt;基于随机打乱的方法
&lt;/h3&gt;&lt;p&gt;将$N$个文档中的所有token抽取出来去重，假设是一个长度为$M$的集合&lt;/p&gt;
&lt;p&gt;那么每个文档自然可以表示为一个$M$维的01向量&lt;/p&gt;
&lt;p&gt;我们把所有文档写在一起就是一个 $M\times N$的矩阵&lt;/p&gt;
&lt;p&gt;例如：&lt;code&gt;上山打老虎&lt;/code&gt;和&lt;code&gt;老虎不在家&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%B5%85%E8%B0%88minhash/assets/image-20250407171454621.png&#34;
	width=&#34;672&#34;
	height=&#34;383&#34;
	srcset=&#34;https://example.com/p/%E6%B5%85%E8%B0%88minhash/assets/image-20250407171454621_hu_381ba848fbf97651.png 480w, https://example.com/p/%E6%B5%85%E8%B0%88minhash/assets/image-20250407171454621_hu_b63953e24b8d3ab8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;原文档向量&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;421px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;也就是说每个token对应的下标顺序如果不一致，我们表示每个文档的向量也是不一样的&lt;/p&gt;
&lt;p&gt;我们进行一次打乱得到：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%B5%85%E8%B0%88minhash/assets/image-20250407171756704.png&#34;
	width=&#34;687&#34;
	height=&#34;368&#34;
	srcset=&#34;https://example.com/p/%E6%B5%85%E8%B0%88minhash/assets/image-20250407171756704_hu_6f3bd02675a840b1.png 480w, https://example.com/p/%E6%B5%85%E8%B0%88minhash/assets/image-20250407171756704_hu_761d79e565642fde.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;打乱后的向量&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;186&#34;
		data-flex-basis=&#34;448px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;此时我们的&lt;code&gt;Min&lt;/code&gt;选择表示向量出现&lt;strong&gt;第一个1的idx&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;例如第一张图：A是0，B是3；第二张图：A是0，B是1&lt;/p&gt;
&lt;p&gt;我们进行多次这样的打乱排序&lt;/p&gt;
&lt;p&gt;并统计他们相等的次数，除以总次数，就是估计出来的值&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在打乱前只执行一次Hash即可&lt;/strong&gt;，与前文的方法相比，是避免了多次hash计算，最终效果相似&lt;/p&gt;
</description>
        </item>
        <item>
        <title>FineWeb-Edu-Chinese数据集论文记录</title>
        <link>https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/</link>
        <pubDate>Thu, 03 Apr 2025 15:10:53 +0800</pubDate>
        
        <guid>https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/</guid>
        <description>&lt;h1 id=&#34;opencsg-chinese-corpus-a-series-of-highquality-chinese-datasets-for-llm-training&#34;&gt;OPENCSG CHINESE CORPUS A SERIES OF HIGHQUALITY CHINESE DATASETS FOR LLM TRAINING
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;Dataset：https://huggingface.co/collections/opencsg/chinese-fineweb-66cfed105f502ece8f29643e&lt;/p&gt;
&lt;p&gt;Code：https://github.com/yuyijiong/fineweb-edu-chinese&lt;/p&gt;
&lt;p&gt;Paper：[&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2501.08197&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2501.08197] OpenCSG Chinese Corpus: A Series of High-quality Chinese Datasets for LLM Training&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;fineweb-edu-chinese&#34;&gt;FineWeb-Edu-Chinese
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;Hugging Face的数据集主页有一些表述和论文是不同的&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/datasets/opencsg/chinese-fineweb-edu#chinese&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;opencsg/chinese-fineweb-edu · Datasets at Hugging Face&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;FineWeb-Edu-Chinese&lt;/code&gt; 数据集的构建流程在很大程度上遵循了&lt;code&gt;FineWeb-edu&lt;/code&gt;的策略
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;FineWeb-edu&lt;/code&gt;从15TB的&lt;code&gt;FineWeb&lt;/code&gt;语料库进行筛选&lt;/li&gt;
&lt;li&gt;重点关注数据的教育价值和内容质量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;中文数据相对匮乏，整合了&lt;strong&gt;多个开源中文语料库&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404183728532.png&#34;
	width=&#34;529&#34;
	height=&#34;341&#34;
	srcset=&#34;https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404183728532_hu_6b5bf4328244d6a6.png 480w, https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404183728532_hu_91007c4b67850578.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20250404183728532&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;155&#34;
		data-flex-basis=&#34;372px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;These datasets were selected for their &lt;strong&gt;diversity&lt;/strong&gt; and their &lt;strong&gt;educational and technical relevance.&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;由上述语料库构建了Original Data Pool&lt;/p&gt;
&lt;p&gt;首先从&lt;strong&gt;教育相关性的方向&lt;/strong&gt;进行过滤：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404183829384.png&#34;
	width=&#34;1465&#34;
	height=&#34;248&#34;
	srcset=&#34;https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404183829384_hu_947dd572a0ee599a.png 480w, https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404183829384_hu_78e526a76edc6a51.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20250404183829384&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;590&#34;
		data-flex-basis=&#34;1417px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从&lt;code&gt;CCI2&lt;/code&gt;数据集中抽取100万个条目&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;Qwen2-7b-instruct&lt;/code&gt;按照附录A.1的提示词，对样本的教育价值打分0-5，完成数据标注&lt;/li&gt;
&lt;li&gt;使用这些打分数据，微调&lt;code&gt;bge-rerank-zh&lt;/code&gt;，添加一个线性回归层，得到一个&lt;code&gt;filter&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;利用&lt;code&gt;filter&lt;/code&gt;排除&lt;strong&gt;所有语料库中&lt;/strong&gt;分数低于3的数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404185932046.png&#34;
	width=&#34;833&#34;
	height=&#34;204&#34;
	srcset=&#34;https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404185932046_hu_a9e1485c883dde75.png 480w, https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404185932046_hu_867ca48d44c08947.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20250404185932046&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;408&#34;
		data-flex-basis=&#34;980px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/datasets/opencsg/chinese-fineweb-v2-scorer-train-data&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;opencsg/chinese-fineweb-v2-scorer-train-data · Datasets at Hugging Face&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;同时为了去重，采用重叠阈值0.7的&lt;code&gt;Min-Hash&lt;/code&gt;算法（平衡计算效率、数据多样性）&lt;/p&gt;
&lt;p&gt;最后得到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt; Fineweb-Edu-Chinese&lt;/code&gt;数据集包含 8900 万个高质量样本，为教育和技术应用提供了丰富的资源。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;附录A.1提示词：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;以下是一段网页内容摘录。请使用以下5分制评分系统来评估该网页的写作水平、教育价值和实用性:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0分：如果网页没有提供任何教育价值,完全由无关信息(如广告、宣传材料、少儿不宜内容)组成。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;1分：如果网页提供了一些可能有教育价值的基本信息,即使包含一些无关或非学术内容(如广告和宣传材料)。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;2分：如果网页涉及某些与教育相关的元素,但与教育标准不太吻合。它可能将教育内容与非教育材料混杂,对潜在的有用的主题进行浅显概述,或以不连贯的写作风格呈现信息。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;3分：如果网页适合教育使用,并介绍了与某些学校课程中可能学到的关键概念，或对个人发展有用的实用信息。它的内容连贯但可能不全面,或包含一些无关信息。它可能类似于教科书的一小段节选,可以学习但有明显局限,如涉及过于复杂的概念、过于具体的不重要事件。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;4分：如果网页与教育高度相关，对个人学习发展有益,表现出清晰一致的写作风格。它可能类似于教科书的一个章节或教程,提供大量教育内容,极少包含无关信息,且概念对学生来说不会过于深奥。内容连贯、重点突出,对结构化学习有价值。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;5分：如果网页摘录在教育价值上表现极好,完全适合小学、中学或大学教学或专业人士学习。它遵循详细的推理过程,写作风格易于理解,对主题提供深刻而全面的见解,不包含任何非教育性或无实用意义内容。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;网页内容摘录:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{data}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;在审查这段网页摘录后：请简要地为您的评分进行合理的解释，最多不超过100字，最后以“教育得分：【分数】”的格式结束。请根据所列出的标准系统地赋予分数。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;fineweb-edu-chinese-v2&#34;&gt;FineWeb-Edu-Chinese-V2
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;进一步扩展了语料库，添加了这个那个和那个……数据集&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Qwen2.5-14b-instruct&lt;/code&gt;更换了&lt;code&gt;Qwen2-7b-instruct&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404184549881.png&#34;
	width=&#34;757&#34;
	height=&#34;455&#34;
	srcset=&#34;https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404184549881_hu_4ba66c4a7deb409d.png 480w, https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404184549881_hu_7bc36cccbc484b47.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20250404184549881&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;166&#34;
		data-flex-basis=&#34;399px&#34;
	
&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plain&#34; data-lang=&#34;plain&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;以下是一段网页内容摘录。请使用以下5分制评分系统来评估该网页的写作水平、教育价值和实用性:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0分：如果网页没有提供任何教育价值,完全由无关信息(如广告、宣传材料、少儿不宜内容)组成。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;1分：如果网页提供了一些可能有教育价值的基本信息,但包含较多的无关或非学术内容(如广告和宣传材料)。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;2分：如果网页涉及某些与教育相关的元素,但与教育标准不太吻合。它可能将教育内容与非教育材料混杂,对潜在的有用的主题进行浅显概述,或以不连贯的写作风格呈现信息。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;3分：如果网页适合教育使用,并介绍了与某些学校课程中可能学到的关键概念，或对个人发展有用的实用信息。它的内容连贯但可能不全面,或包含一些无关信息。它可能类似于教科书的一小段节选,可以学习但有明显局限,如涉及过于复杂的概念、过于具体的不重要事件。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;4分：如果网页与教育高度相关，对个人学习发展有益,表现出清晰一致的写作风格。它可能类似于教科书的一个章节或教程,提供大量教育内容,极少包含无关信息,且概念对学生来说不会过于深奥。内容连贯、重点突出,对结构化学习有价值。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;5分：如果网页摘录在教育价值上表现极好,完全适合小学、中学或大学教学或专业人士学习。它遵循详细的推理过程,写作风格易于理解,对主题提供深刻而全面的见解,不包含任何非教育性或无实用意义内容。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;网页内容摘录:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;在审查这段网页摘录后：请简要地为您的评分进行合理的解释，最多不超过100字，最后以“教育得分：&amp;lt;分数&amp;gt;”的格式结束。请根据所列出的标准系统地赋予分数。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;打分的分布如下，最终选择3以上的数据：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404190613997.png&#34;
	width=&#34;750&#34;
	height=&#34;556&#34;
	srcset=&#34;https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404190613997_hu_c9dbc47b61605e6f.png 480w, https://example.com/p/fineweb-edu-chinese%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/assets/image-20250404190613997_hu_a1660813e643fed0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20250404190613997&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;134&#34;
		data-flex-basis=&#34;323px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;cosmopedia-chinese&#34;&gt;Cosmopedia-Chinese
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;种子数据&lt;/strong&gt;来源：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;560万百度百科条目&lt;/li&gt;
&lt;li&gt;100万个知乎问答样本&lt;/li&gt;
&lt;li&gt;200万个技术博客条目&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;丰富领域知识、较高的信息密度&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;中文数据池中的网页文本：质量不够高，含有广告&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;种子数据：for example an extract from a web page&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Cosmopedia-v2的实验说明更大的模型生成数据有显著效果&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt; qwen2-7b-instruct&lt;/code&gt;、&lt;code&gt;yi-1.5-9b-chat&lt;/code&gt;：倾向于输出简洁、通用的内容，如摘要、大纲（提示词也没救）&lt;/li&gt;
&lt;li&gt;最终选择&lt;code&gt;glm4-9b-longwriter&lt;/code&gt;：教科书主要内容那样足够详细和具体的内容&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;生成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;生成了各种体裁的合成样本，如教科书单元、叙事故事和详细的 “操作指南”&lt;/li&gt;
&lt;li&gt;温度0.8保证多样性&lt;/li&gt;
&lt;li&gt;对2000万个样本进行Min-Hash去重，保留1500万个&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;这是一段来自网页的摘录：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;“{data}”
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;请编写一个针对大学生的足够详细的教科书课程单元，该单元与给定的摘录中的某个概念或多个概念相关。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;不需要包含摘录中的所有内容，只需要发掘其中适合作为教科书内容的部分。你可以自由补充其他相关知识。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;不能仅仅列出概念，而是要深入发展和详细探讨每个概念，因为我们优先考虑深入理解主题内容，而不是广度。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;要求：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	1. 严谨性：确保对概念/章节的深入覆盖。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	2. 吸引性：用学术、专业且引人入胜的语气撰写，以吸引兴趣。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	3. 应用：融入具体的实践例子，例如微积分中要给出公式、严格证明，历史中要给出关键日期和人物，计算机操作中要给出代码。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	4.不需要给出参考文献。内容中不应包含广告或涉及隐私的信息。注重主体内容，不需要其它格式化的内容。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;请记住，要针对大学生制作内容，他们可能拥有一些基础知识，但不是该领域的专家。内容应该详细且发人深省。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;请立即开始撰写教科书,不要使用图片,不要输出除了教科书以外的内容,不要以“课程单元”作为标题而是要有具体的标题｡
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;以及其他写故事、教程、教科书的提示词&lt;/p&gt;
&lt;h2 id=&#34;smoltalk-chinese&#34;&gt;Smoltalk-Chinese
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;基于&lt;code&gt; Magpie-ultra-1M&lt;/code&gt;和&lt;code&gt;Smoltalk&lt;/code&gt;的方法构建，提升任务多样性和对话深度&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;引入了 7 个额外的任务类别：格式约束、总结、改写、文档QA、安全QA、翻译和&lt;strong&gt;日常对话&lt;/strong&gt;。
&lt;ul&gt;
&lt;li&gt;确保了对与自然语言理解和生成相关的任务有更广泛的覆盖。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;Deepseek-V2.5&lt;/code&gt;、&lt;code&gt;Qwen2.5-72B-Insturct&lt;/code&gt;等较为先进的模型&lt;/li&gt;
&lt;li&gt;为&lt;code&gt;Magpie-ultra-1M&lt;/code&gt;使用的11个任务类别生成3轮对话、新任务类别（除日常对话）1轮对话、&lt;strong&gt;日常对话&lt;/strong&gt;5轮&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于质量筛选，首先要保证用户的第一个命令语句是流畅、连贯、清晰的，使用&lt;code&gt;Qwen2.5-7b-instruct&lt;/code&gt;打分，保留超过3分的&lt;/p&gt;
&lt;p&gt;使用&lt;code&gt;gte-zh-large&lt;/code&gt;编码的嵌入进行去重&lt;/p&gt;
</description>
        </item>
        <item>
        <title>FineWeb数据集论文记录</title>
        <link>https://example.com/p/fineweb%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/</link>
        <pubDate>Thu, 03 Apr 2025 15:10:42 +0800</pubDate>
        
        <guid>https://example.com/p/fineweb%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/</guid>
        <description>&lt;h2 id=&#34;the-fineweb-datasets-decanting-the-web-for-the-finest-text-data-at-scale&#34;&gt;The FineWeb Datasets Decanting the Web for the Finest Text Data at Scale
&lt;/h2&gt;&lt;p&gt;[&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2406.17557&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2406.17557] The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Common Crawl：网站快照集合，自 2007 年开始运行。截至撰写本文时，Common Crawl 已经生成了 100 个网页快照，数据总量达到 PB 级别。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;building-fineweb&#34;&gt;Building FineWeb
&lt;/h2&gt;&lt;h3 id=&#34;text-extraction&#34;&gt;Text Extraction
&lt;/h3&gt;&lt;p&gt;Common Crawl 数据有两种不同格式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;WARC&lt;/li&gt;
&lt;li&gt;WET（ WET 文件保留了过多的模板和菜单文本）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用开源的&lt;code&gt;trafilatura&lt;/code&gt;库从 WARC 文件中提取文本内容&lt;/p&gt;
&lt;p&gt;实验证明WARC明显效果好于WET&lt;/p&gt;
&lt;h3 id=&#34;base-filtering&#34;&gt;Base Filtering
&lt;/h3&gt;&lt;p&gt;采用了&lt;code&gt; RefinedWeb&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;URL Filter：通过url过滤成人内容&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fastText&lt;/code&gt; 语言分类器：保留得分大于等于0.65的英文文本&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MassiveText&lt;/code&gt;的质量和重复过滤器&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;分词器采用GPT-2 分词器&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;deduplication&#34;&gt;Deduplication
&lt;/h3&gt;&lt;p&gt;去重与提升模型性能、减轻预训练数据记忆负担相关&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;常见去重方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;哈希技术&lt;/li&gt;
&lt;li&gt;后缀数组&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;去重方法还可以分为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模糊：相似性度量&lt;/li&gt;
&lt;li&gt;精确：完全匹配&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;使用英文分词器提取每个文档&lt;code&gt;5-gram&lt;/code&gt;，使用112个哈希函数计算&lt;code&gt;MinHash&lt;/code&gt;值&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分成14个桶，每个桶8个哈希函数，识别相似度至少75%的文档&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;任意一个桶全部相同的哈希值，视为彼此的重复文档&lt;/p&gt;
&lt;p&gt;A、B重复，A、C重复，则根据传递性认为B、C重复（哪怕B、C没有哈希冲突）&lt;/p&gt;
&lt;p&gt;所有重复文档归为一个重复文档簇，最终随机保留一个&lt;/p&gt;
&lt;p&gt;按照这个方法从最新的快照开始，直到最旧的快照，对整个数据集（96个快照）进行全局的哈希处理&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;但是对1base filter1的提升效果不佳，与&lt;code&gt;RefinedWeb&lt;/code&gt;数据集效果落后明显&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;选择了某个快照进行对比实验：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A：全局去重后，取该快照进行去重后的数据&lt;/li&gt;
&lt;li&gt;B：这个快照被去除的数据，进行独立去重（不考虑其他快照）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;B效果明显比A好：原始保留数据包含更多广告、无序关键词列表和格式混乱的文本。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;因此方法更换为：&lt;strong&gt;对每个快照单独进行MinHash去重&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此时效果与&lt;code&gt;RefinedWeb&lt;/code&gt;相当&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;假设：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;去重的主要改进是移除了包含&lt;code&gt;10w&lt;/code&gt;以上规模的文档的大型重复文档&lt;/li&gt;
&lt;li&gt;对于少量重复文档（小于100），过度去重损害质量&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;c4-filter&#34;&gt;C4 Filter
&lt;/h3&gt;&lt;p&gt;Base Filter + Deduplication得到的数据集已经与&lt;code&gt;RefinedWeb&lt;/code&gt;相当&lt;/p&gt;
&lt;p&gt;但是C4数据集虽然更小，但是性能还是更强&lt;/p&gt;
&lt;p&gt;C4的过滤规则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;删除不以终止标点符号结尾的行&lt;/li&gt;
&lt;li&gt;删除提及&amp;quot;javascript&amp;quot;的行&lt;/li&gt;
&lt;li&gt;删除包含&amp;quot;使用条款&amp;quot;/&amp;ldquo;cookie政策&amp;quot;声明的行&lt;/li&gt;
&lt;li&gt;删除过短的文档&lt;/li&gt;
&lt;li&gt;删除包含&amp;quot;lorem ipsum&amp;quot;或花括号（{）的文档&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对这些规则分别进行消融实验，发现&lt;code&gt;删除不以终止标点符号结尾的行&lt;/code&gt;会导致过多数据损失&lt;/p&gt;
&lt;p&gt;删除此规则，保留其他规则&lt;/p&gt;
&lt;h3 id=&#34;developing-additional-heuristic-filters&#34;&gt;Developing additional heuristic filters
&lt;/h3&gt;&lt;p&gt;除了人工目视方法进行过滤，开发一套系统的启发式过滤器&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;收集了50多项高级统计指标，涵盖：
&lt;ul&gt;
&lt;li&gt;文档级指标（如行数、平均行/词长度等）&lt;/li&gt;
&lt;li&gt;文档间重复指标&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;选择某个快照的两个去重版本：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高质量：独立去重后的快照&lt;/li&gt;
&lt;li&gt;低质量：全局去重的快照&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过分析这些指标的&lt;strong&gt;直方图分布&lt;/strong&gt;，经验性地选择在&lt;strong&gt;低质量数据集频率明显高于对应高质量数据集的区间&lt;/strong&gt;设置阈值&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最终确定了16组候选的指标-阈值组合&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;“字符重复过滤器”：我们注意到存在一些包含大量无意义的字符重复（例如，连续重复的字母或符号）的文本片段&lt;/li&gt;
&lt;li&gt;“短单词过滤器”：非常短的单词（例如，只有一个或两个字符的单词）组成的文本行&lt;/li&gt;
&lt;li&gt;“特殊字符过滤器”：一些文本行包含大量的特殊字符&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;规则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;行末标点比例≤0.12的文档（移除10.14% token，相比C4终止标点过滤的30%更高效）&lt;/li&gt;
&lt;li&gt;重复行字符比例≥0.1的文档（移除12.47% token）&lt;/li&gt;
&lt;li&gt;短行（&amp;lt;30字符）比例≥0.67的文档（移除3.73% token）&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;这个过程避免了主观判断，而是根据数据系统地制定指标及其阈值&lt;/p&gt;
&lt;h3 id=&#34;final&#34;&gt;Final
&lt;/h3&gt;&lt;p&gt;通过整合前文各环节的设计决策，我们将完整的处理流程应用于96个Common Crawl快照，最终构建出包含15万亿token的FineWeb数据集。具体处理步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;文本提取&lt;/strong&gt;（3.2节）：从WARC文件提取文本内容&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基础过滤&lt;/strong&gt;（3.3节）：应用URL过滤、语言识别和质量筛选&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;单快照去重&lt;/strong&gt;（3.4节）：对每个快照独立进行MinHash去重&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;C4过滤规则&lt;/strong&gt;（3.5节）：采用精选的C4启发式过滤规则&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;定制过滤&lt;/strong&gt;（3.6节）：应用新开发的高效过滤规则&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;fineweb-edu&#34;&gt;FineWeb-Edu
&lt;/h2&gt;&lt;p&gt;使用LLM进行进一步的构建：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;由&lt;code&gt; Llama-3 70B-Instruct&lt;/code&gt; 生成的&lt;strong&gt;合成注释&lt;/strong&gt;所开发的&lt;strong&gt;教育质量分类器&lt;/strong&gt;对其进行过滤&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了构建合成注释：&lt;/p&gt;
&lt;p&gt;使用LLM对教育质量进行评分（0-5），发现&lt;strong&gt;累加评分量表&lt;/strong&gt;效果最好&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;累加评分量表允许大语言模型评估每个标准，并逐步得出评分&lt;/li&gt;
&lt;li&gt;为避免大语言模型偏爱诸如 arXiv 摘要和提交内容这类专业性很强的页面，我们提示它专注于小学和中学水平的知识&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;基础信息相关（+1分）：若摘录包含与教育主题相关的基本信息，即使掺杂广告等无关内容。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;部分教育相关但松散（+1分）：内容涉及教育元素但未紧密契合标准，可能混杂非教育材料或呈现零散。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;适合教学且引入关键概念（+1分）：内容连贯且符合课程要求，但可能不够全面或含额外信息，类似教科书基础章节。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;高度相关且有益（+1分）：内容清晰一致，适合小学至初中，含练习题等实质性材料，无关内容极少。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;教育价值突出（+1分）：内容深入透彻，完全适合目标学段，无无关或复杂信息。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;选择最低阈值为3分，高于此分数认为属于教育内容&lt;/p&gt;
</description>
        </item>
        <item>
        <title>CritiQ 工作文档</title>
        <link>https://example.com/p/critiq-%E5%B7%A5%E4%BD%9C%E6%96%87%E6%A1%A3/</link>
        <pubDate>Thu, 03 Apr 2025 15:06:24 +0800</pubDate>
        
        <guid>https://example.com/p/critiq-%E5%B7%A5%E4%BD%9C%E6%96%87%E6%A1%A3/</guid>
        <description>&lt;h1 id=&#34;critiq-记录&#34;&gt;CritiQ 记录
&lt;/h1&gt;&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;目标&#34;&gt;目标
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;训练模型，由模型判断语料文本数据的质量（高/低），完成质量检测，帮助后续模型训练&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;训练数据准备&#34;&gt;训练数据准备
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;至少需要300正例+300负例，希望是人类专家的标注&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在训练数据不足1w的情况，使用CritiQ去做数据标注&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;传统训练都是训练集&amp;gt;测试集&lt;/p&gt;
&lt;p&gt;这里是通过挖掘人类偏好，测试集合远大于训练集，使用训练集挖掘出来的指标，对测试集进行标注&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;当训练数据超过1w的时候，可以直接跳过这个部分去做分类模型训练&lt;/p&gt;
&lt;h3 id=&#34;knowledge-base&#34;&gt;Knowledge Base
&lt;/h3&gt;&lt;p&gt;对于数据质量评估，如果完全交由模型生成评估指标，从各个角度来说都很水&lt;/p&gt;
&lt;p&gt;参考：&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2502.19279&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2502.19279] CritiQ: Mining Data Quality Criteria from Human Preferences&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;workflow：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从huggingface的数据集中寻找参考论文列表&lt;/li&gt;
&lt;li&gt;从arxiv能找到的论文中爬取摘要&lt;/li&gt;
&lt;li&gt;通过制作agent分析摘要，判断论文中是否有关于数据集评价等内容&lt;/li&gt;
&lt;li&gt;提取评估指标&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最后论文作者得到了一个370+数量的指标&lt;/p&gt;
&lt;p&gt;根据不同的待测数据集，跑一遍，选择准确度较高的&lt;/p&gt;
&lt;p&gt;数量不够让模型生成&lt;/p&gt;
&lt;h2 id=&#34;training&#34;&gt;Training
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/KYLN24/CritiQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;github&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;环境&#34;&gt;环境
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;cuda 12.4 + torch 2.6 + Python3.10&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda create -n critiq_env &lt;span class=&#34;nv&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;3.10 -y
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda activate critiq_env
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip3 install torch torchvision torchaudio
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;python&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;import torch; print(&amp;#39;PyTorch版本:&amp;#39;, torch.__version__); print(&amp;#39;GPU可用:&amp;#39;, torch.cuda.is_available()); print(&amp;#39;GPU名称:&amp;#39;, torch.cuda.get_device_name(0) if torch.cuda.is_available() else &amp;#39;无可用GPU&amp;#39;)&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/KYLN24/CritiQ
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; CritiQ
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install -e &lt;span class=&#34;s2&#34;&gt;&amp;#34;.[vllm,train]&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;之后如果网络不太行，换一个源：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;environ&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;HF_ENDPOINT&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;https://hf-mirror.com&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;数据集&#34;&gt;数据集
&lt;/h3&gt;&lt;p&gt;Pair Data格式如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;PairData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TypedDict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;answer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Literal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;A&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;训练数据格式（保存为&lt;code&gt;train_reward.jsonl&lt;/code&gt;）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;A&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;金属的导热系数显著高于木材（铁约80 W/m·K vs 木材约0.1 W/m·K），根据傅里叶定律q=-k∇T，更高的导热系数导致更快的热传导速率，使手部热量迅速流失。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;金属传热特别快，能迅速把你手上的热量带走，所以摸起来凉；木头传热慢，热量不容易流失，感觉就没那么凉。就像夏天坐金属凳子比坐木凳子感觉更凉快。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;answer&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;A&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;由牛顿第一定律可知，物体保持原有运动状态。当汽车以加速度a减速时，乘客因惯性保持原速v，直到受到座椅摩擦力f=μN的作用才减速。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;因为你的身体想保持原来的运动状态。车停了，但你的身体还在往前，所以会往前倾。就像跑步时突然停下，身体还会往前冲一样。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;answer&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Reward模型输入格式（保存为&lt;code&gt;predict_reward.jsonl&lt;/code&gt;）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;金属的导热系数显著高于木材（铁约80 W/m·K vs 木材约0.1 W/m·K），根据傅里叶定律q=-k∇T，更高的导热系数导致更快的热传导速率，使手部热量迅速流失。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;金属传热特别快，能迅速把你手上的热量带走，所以摸起来凉；木头传热慢，热量不容易流失，感觉就没那么凉。就像夏天坐金属凳子比坐木凳子感觉更凉快。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;由牛顿第一定律可知，物体保持原有运动状态。当汽车以加速度a减速时，乘客因惯性保持原速v，直到受到座椅摩擦力f=μN的作用才减速。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;因为你的身体想保持原来的运动状态。车停了，但你的身体还在往前，所以会往前倾。就像跑步时突然停下，身体还会往前冲一样。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;光从光密介质（水，n=1.33）进入光疏介质（空气，n≈1）时发生折射，根据斯涅尔定律n₁sinθ₁=n₂sinθ₂，折射角大于入射角导致视觉偏移。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;因为光从水进入空气时会拐弯，让我们看到的位置和实际位置不一样，所以筷子看起来像是弯的。就像把吸管插进水里也会看起来弯折一样。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;一共准备了137条数据：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-txt&#34; data-lang=&#34;txt&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;请生成100个初中物理现象问题与解答，要求：  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;1. 每个问题包含两种回答：  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - **A**：专业严谨的物理解释（含公式、原理名称、数据等）  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - **B**：通俗易懂的讲解（用比喻、生活实例，语言口语化）  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - **answer**：固定标注&amp;#34;B&amp;#34;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;2. 数据格式：每行一个完整JSON对象，严格遵循以下结构：  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   {&amp;#34;A&amp;#34;: &amp;#34;...&amp;#34;, &amp;#34;B&amp;#34;: &amp;#34;...&amp;#34;, &amp;#34;answer&amp;#34;: &amp;#34;B&amp;#34;}  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;3. 内容要求：  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - 物理现象需贴近日常生活（如热学、光学、力学等）  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - B回答必须正确且易于理解，避免专业术语  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - 示例类比需直观（如&amp;#34;像磁铁吸住&amp;#34;&amp;#34;像气球爆炸&amp;#34;）  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;4. 输出：直接给出结果，无需注释，禁止使用```包裹  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;示例格式：  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{&amp;#34;A&amp;#34;: &amp;#34;金属导热系数较高（铁80 W/m·K），根据傅里叶定律q=-k∇T...&amp;#34;, &amp;#34;B&amp;#34;: &amp;#34;金属像‘传热快手’，迅速带走热量，所以摸起来更凉&amp;#34;, &amp;#34;answer&amp;#34;: &amp;#34;B&amp;#34;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;由模型生成&lt;/p&gt;
&lt;p&gt;先做一个预测：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python ./critiq/scripts/reward_predict.py --model Qwen/Qwen2.5-1.5B-Instruct --data ./data/predict_reward.jsonl --output_dir ./output
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;输出结果在&lt;code&gt;output&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;金属的导热系数显著高于木材（铁约80 W/m·K vs 木材约0.1 W/m·K），根据傅里叶定律q=-k∇T，更高的导热系数导致更快的热传导速率，使手部热量迅速流失。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9465966820716858&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;金属传热特别快，能迅速把你手上的热量带走，所以摸起来凉；木头传热慢，热量不容易流失，感觉就没那么凉。就像夏天坐金属凳子比坐木凳子感觉更凉快。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9046503901481628&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;由牛顿第一定律可知，物体保持原有运动状态。当汽车以加速度a减速时，乘客因惯性保持原速v，直到受到座椅摩擦力f=μN的作用才减速。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9736446738243103&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;因为你的身体想保持原来的运动状态。车停了，但你的身体还在往前，所以会往前倾。就像跑步时突然停下，身体还会往前冲一样。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9664104580879211&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;光从光密介质（水，n=1.33）进入光疏介质（空气，n≈1）时发生折射，根据斯涅尔定律n₁sinθ₁=n₂sinθ₂，折射角大于入射角导致视觉偏移。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9532749652862549&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;因为光从水进入空气时会拐弯，让我们看到的位置和实际位置不一样，所以筷子看起来像是弯的。就像把吸管插进水里也会看起来弯折一样。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9845753908157349&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;给的分数都很高，因为两种风格的文本质量都不低&lt;/p&gt;
&lt;p&gt;为了让模型出现人类的偏好，我们开始训练一下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python ./critiq/scripts/train_reward.py --data ./data/train_reward.jsonl --eval_steps 40
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;code&gt;eval_steps&lt;/code&gt;一定要开大一点……原代码是1，每一步保存一个模型，磁盘炸的很快&lt;/p&gt;
&lt;p&gt;训练的模型保存路径：&lt;code&gt;&amp;lt;output_dir&amp;gt;/&amp;lt;job_name&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;我这里是&lt;code&gt;./output/tmp&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;再跑一下预测：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python ./critiq/scripts/reward_predict.py --model ./output/tmp/checkpoint-109 --data ./data/predict_reward.jsonl --output_dir ./output
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;还没fixed的bug：&lt;/p&gt;
&lt;p&gt;predict不知道为什么给的结果永远是：0.9以上&lt;/p&gt;
&lt;p&gt;我直接修改了train.py，训练完直接跑预测，结果是对的（&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;突然关水龙头像‘管道撞车’，水流‘刹车不及’撞出巨响&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9999999586005831&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;磁致伸缩ΔL/L≈10^-5（镍），逆效应用于超声换能器&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;2.2827974365423323e-05&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;磁致伸缩材料像‘会呼吸的磁铁’，磁场一变就‘伸缩’&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9999999123574378&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;防晒霜氧化锌散射UV，粒径d≈20 nm最优&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.568953403843032e-05&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;物理防晒像‘纳米镜子’，把紫外线‘弹弹球’般反射&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9999999918479713&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;橡皮船浮力F=ρgV，PVC材料ρ≈1.4 g/cm³&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.0129980850990629e-05&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;充气船像‘塑料泡泡’，空气‘内胆’让它漂水面&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9999985406223194&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>Read Me</title>
        <link>https://example.com/p/read-me/</link>
        <pubDate>Thu, 03 Apr 2025 13:57:51 +0800</pubDate>
        
        <guid>https://example.com/p/read-me/</guid>
        <description>&lt;img src="https://example.com/p/read-me/bg.jpg" alt="Featured image of post Read Me" /&gt;&lt;h1 id=&#34;hugo--github-笔记&#34;&gt;Hugo + Github 笔记
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://sazerac-kk.github.io/p/%e6%95%99%e7%a8%8bhugo-github%e5%8d%9a%e5%ae%a2%e9%83%a8%e7%bd%b2/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;【教程】Hugo+Github博客部署&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;文章管理&#34;&gt;文章管理
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;放在最前面方便看&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;创建文章：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hugo new post/一级分类/二级分类……/post_name/index.md
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在&lt;code&gt;post/一级分类/二级分类……/post_name/&lt;/code&gt;下新建一个文件夹用于存图（typora自己建好了）&lt;/p&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;![&lt;span class=&#34;nt&#34;&gt;image-20250403143026963&lt;/span&gt;](&lt;span class=&#34;na&#34;&gt;./assets/image-20250403143026963.png&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;要改成：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;![&lt;span class=&#34;nt&#34;&gt;image-20250403143026963&lt;/span&gt;](&lt;span class=&#34;na&#34;&gt;assets/image-20250403143026963.png&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;否则识别不到&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;只有封面图片可以直接放在直接文件夹下&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;定义分类、标签：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;tags : [
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;markdown&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;css&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;html&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;themes&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;categories : [
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;themes&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;syntax&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;放在最前面的模板&lt;/p&gt;
&lt;p&gt;tag可以随便取，分类建议大一点&lt;/p&gt;
&lt;p&gt;不需要其他指令去单独建立tag或分类，直接文章里用到就会自动建立&lt;/p&gt;
&lt;h3 id=&#34;相册语法&#34;&gt;相册语法
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.typlog.com/en/article/markdown-images/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Images in Markdown - Typlog Docs&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;![&lt;span class=&#34;nt&#34;&gt;Photo by Florian Klauer on Unsplash&lt;/span&gt;](&lt;span class=&#34;na&#34;&gt;florian-klauer-nptLmg6jqDo-unsplash.jpg&lt;/span&gt;)  ![&lt;span class=&#34;nt&#34;&gt;Photo by Luca Bravo on Unsplash&lt;/span&gt;](&lt;span class=&#34;na&#34;&gt;luca-bravo-alS7ewQ41M8-unsplash.jpg&lt;/span&gt;) 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;![&lt;span class=&#34;nt&#34;&gt;Photo by Helena Hertz on Unsplash&lt;/span&gt;](&lt;span class=&#34;na&#34;&gt;helena-hertz-wWZzXlDpMog-unsplash.jpg&lt;/span&gt;)  ![&lt;span class=&#34;nt&#34;&gt;Photo by Hudai Gayiran on Unsplash&lt;/span&gt;](&lt;span class=&#34;na&#34;&gt;hudai-gayiran-3Od_VKcDEAA-unsplash.jpg&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;效果：
&lt;img src=&#34;https://example.com/p/read-me/assets/image-20250403143026963.png&#34;
	width=&#34;1170&#34;
	height=&#34;473&#34;
	srcset=&#34;https://example.com/p/read-me/assets/image-20250403143026963_hu_b97140770bfd4ebf.png 480w, https://example.com/p/read-me/assets/image-20250403143026963_hu_5baa32ae2cfc0c75.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20250403143026963&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;247&#34;
		data-flex-basis=&#34;593px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;install&#34;&gt;Install
&lt;/h2&gt;&lt;p&gt;先装一下git&lt;/p&gt;
&lt;p&gt;下载hugo的zip：&lt;a class=&#34;link&#34; href=&#34;https://github.com/gohugoio/hugo/releases&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Releases · gohugoio/hugo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;教程选的是&lt;code&gt;hugo_extended_xxx_windows&lt;/code&gt;版本&lt;/p&gt;
&lt;p&gt;把压缩包里的&lt;code&gt;hugo.exe&lt;/code&gt;拖到自己的某个文件夹内&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hugo new site sci-biribiri
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;创建文件夹&lt;/p&gt;
&lt;p&gt;然后cd进去，并且把&lt;code&gt;hugo.exe&lt;/code&gt;也拖进去这个文件夹方便使用&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cd sci-biribiri
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;运行服务：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hugo server -D
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这个时候某个端口就会开始运行hugo，不出意外显示一个&lt;code&gt;Page Not Found&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;主题部署&#34;&gt;主题部署
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://themes.gohugo.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Complete List | Hugo Themes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我选的这个主题：&lt;a class=&#34;link&#34; href=&#34;https://github.com/CaiJimmy/hugo-theme-stack&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CaiJimmy/hugo-theme-stack: Card-style Hugo theme designed for bloggers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在&lt;code&gt;releases&lt;/code&gt;下载&lt;code&gt;source code&lt;/code&gt;进行解压&lt;/p&gt;
&lt;p&gt;解压到&lt;code&gt;sci-biribiri/themes&lt;/code&gt;目录下&lt;/p&gt;
&lt;p&gt;把主题文件内的&lt;code&gt;exampleSite/content&lt;/code&gt;和&lt;code&gt;exampleSite/hugo.yaml&lt;/code&gt;直接复制到主文件夹&lt;code&gt;sci-biribiri&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如果你是&lt;code&gt;stack&lt;/code&gt;主题，请删掉&lt;code&gt;content/post/rich-content/&lt;/code&gt;，否则会无法启动&lt;/p&gt;
&lt;p&gt;删掉主文件夹&lt;code&gt;sci-biribiri&lt;/code&gt;的&lt;code&gt;hugo.toml&lt;/code&gt;，到此完成配置文件的替换&lt;/p&gt;
&lt;p&gt;注意到此时&lt;code&gt;hugo.yaml&lt;/code&gt;是这样的：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;baseurl&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://example.com/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;languageCode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;en-us&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;theme&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;hugo-theme-stack&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Example Site&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;copyright&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Example Person&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;识别的主题是：&lt;code&gt;hugo-theme-stack&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;因此要确保&lt;code&gt;sci-biribiri/themes&lt;/code&gt;下的主题文件夹的名字要对应上&lt;/p&gt;
&lt;p&gt;我这里修改&lt;code&gt;sci-biribiri/themes/hugo-theme-stack-3.30.0&lt;/code&gt;为&lt;code&gt;sci-biribiri/themes/hugo-theme-stack&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hugo server -D
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;后面就是慢慢自己调内容&lt;/p&gt;
&lt;p&gt;记得修改&lt;code&gt;archetypes\default.md&lt;/code&gt;，每次创建文章的模板是按照这个模板做的&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plain&#34; data-lang=&#34;plain&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;title: &amp;#34;{{ replace .Name &amp;#34;-&amp;#34; &amp;#34; &amp;#34; | title }}&amp;#34; # 标题，创建时自动填充
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;description: # 文章简介
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;date: {{ .Date }} # 日期，创建时自动填充，格式同 2023-01-15T12:00:00+08:00
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;image: # 文章的封面，留空就是没有，填文章所在位置的相对地址，通常放在同目录下，
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;math: # 是否启用 KaTex，填 true 启用
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;license: # 文章尾部显示的协议，false 为隐藏，其他作为内容，留空就是使用 config.yaml 里默认的
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hidden: false # 是否隐藏，一般用不到
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;comments: true # 因为 bug 所以这个属性只要存在，不管是 true 还是 false 都会导致回复无法显示，需要删掉
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;draft: true # 是否为草稿，建议改为 false 或者删掉这个属性以防止忘记修改，毕竟我们一般都是写好了才部署到服务器上
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;推荐：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;title: &amp;#34;{{ replace .Name &amp;#34;-&amp;#34; &amp;#34; &amp;#34; | title }}&amp;#34; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;description: 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;date: {{ .Date }} 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;image: 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;math: true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;draft: false 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;tags: []  # 双引号
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;categories: [] # 双引号
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>李宏毅机器学习2021 · L5</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/</link>
        <pubDate>Sun, 11 Aug 2024 18:19:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/</guid>
        <description>&lt;h1 id=&#34;l5-sequence-to-sequence&#34;&gt;L5. Sequence to Sequence
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML 2022 Spring (ntu.edu.tw)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1VN4y1P7Zj&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1VN4y1P7Zj&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;输出的长度取决于model&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Speech Recognition：语音到文本&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Machine Translation：文本到文本&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Speech Translation：语音到文本&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Seq2Seq = encoder + decoder&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;encoder：输入-&amp;gt;向量&lt;/li&gt;
&lt;li&gt;decoder：向量-&amp;gt;输出
&lt;ul&gt;
&lt;li&gt;接受encoder的输入，每次输出一个结果，输出的结果会影响下一个输出&lt;/li&gt;
&lt;li&gt;加入&lt;code&gt;&amp;lt;BOS&amp;gt;&lt;/code&gt;表示开始解码，&lt;code&gt;&amp;lt;EOS&amp;gt;&lt;/code&gt;表示结束&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;transformer---encoder&#34;&gt;Transformer - Encoder
&lt;/h2&gt;&lt;h3 id=&#34;block&#34;&gt;Block
&lt;/h3&gt;&lt;p&gt;Encoder内以block为单位&lt;/p&gt;
&lt;p&gt;每个block的设计：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240811211637233.png&#34;
	width=&#34;889&#34;
	height=&#34;674&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240811211637233_hu_55a57da4613ba746.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240811211637233_hu_f6a0922e617a6e3a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240811211637233&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;131&#34;
		data-flex-basis=&#34;316px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;encoder&#34;&gt;Encoder
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240811212043472.png&#34;
	width=&#34;875&#34;
	height=&#34;542&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240811212043472_hu_c192096579cafcb0.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240811212043472_hu_8a828276825b72b1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240811212043472&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;161&#34;
		data-flex-basis=&#34;387px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入需要Position Embedding&lt;/li&gt;
&lt;li&gt;重复N次block&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;这是原始的Transformer结构&lt;/p&gt;
&lt;p&gt;后续发现把LayerNorm放在Attention前和FC前，效果会更好&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;transformer---decoder&#34;&gt;Transformer - Decoder
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;BOS&lt;/code&gt;：Begin of Sentence&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EOS&lt;/code&gt;：End of Sentence&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;输入输出&#34;&gt;输入输出
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812165138109.png&#34;
	width=&#34;1001&#34;
	height=&#34;590&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812165138109_hu_c5d6168ca2a3590c.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812165138109_hu_d1da5003c355a59c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812165138109&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;407px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;结构&#34;&gt;结构
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Transformer的block中，相当于添加了一段新的，其他部分相似&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812165344664.png&#34;
	width=&#34;900&#34;
	height=&#34;782&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812165344664_hu_451be7ad9311e3f2.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812165344664_hu_33e6201df2f9a9d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812165344664&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;115&#34;
		data-flex-basis=&#34;276px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Masked Multi-Head Attention&lt;/strong&gt;：与encoder部分相比，有所改变
&lt;ul&gt;
&lt;li&gt;encoder可以拿到整个sequence，因此可以考虑全局&lt;/li&gt;
&lt;li&gt;而decoder只有前文，因此只会考虑出现过的向量（因为根本不存在）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812184952935.png&#34;
	width=&#34;858&#34;
	height=&#34;468&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812184952935_hu_861edc16f8fc0092.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812184952935_hu_57c4cdae96a73965.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812184952935&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;183&#34;
		data-flex-basis=&#34;440px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;EOS&lt;/code&gt;同时会作为预测内容之一，当输出一个结束符出现时，结束预测，生成的文本即为结果&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;autoregressive-vs-non-autoregressive&#34;&gt;Autoregressive vs. Non-Autoregressive
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;上面的内容被称为自回归&lt;/li&gt;
&lt;li&gt;非自回归：一次性喂入多个begin进行预测
&lt;ul&gt;
&lt;li&gt;方便控制长短
&lt;ul&gt;
&lt;li&gt;使用另一个分类器进行长度预测（对输出长度再做一次乘法、乘法，能直接调整）&lt;/li&gt;
&lt;li&gt;或生成足够数量的token，查看第一个end&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;方便并行&lt;/li&gt;
&lt;li&gt;效果会更差&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812185627178.png&#34;
	width=&#34;840&#34;
	height=&#34;562&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812185627178_hu_dec5913c41ec5b84.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812185627178_hu_82b9ba79636d7b3f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812185627178&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;149&#34;
		data-flex-basis=&#34;358px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;encoder---decoder&#34;&gt;Encoder - Decoder
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Transformer中多出来的一个block，起到了连接encoder的作用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812192024698.png&#34;
	width=&#34;866&#34;
	height=&#34;641&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812192024698_hu_135772fe63f99073.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812192024698_hu_7f4b9115f966cd44.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812192024698&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;135&#34;
		data-flex-basis=&#34;324px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812192821219.png&#34;
	width=&#34;772&#34;
	height=&#34;652&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812192821219_hu_507f7f24a45eb555.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812192821219_hu_5590ed3a161c41cc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812192821219&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;118&#34;
		data-flex-basis=&#34;284px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;堆叠Encoder和Decoder，我们就得到了Transformer&lt;/li&gt;
&lt;li&gt;原始论文中，decoder只拿了encoder最后一层的输出&lt;/li&gt;
&lt;li&gt;但事实上可以拿非常多&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812195611554.png&#34;
	width=&#34;774&#34;
	height=&#34;464&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812195611554_hu_1dfbf9401600acbd.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812195611554_hu_8c6c5a863128e6ad.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812195611554&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;166&#34;
		data-flex-basis=&#34;400px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;training&#34;&gt;Training
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;看作一个分类问题，使用交叉熵损失函数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812200133689.png&#34;
	width=&#34;742&#34;
	height=&#34;592&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812200133689_hu_c243da94af1ecddb.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812200133689_hu_b65b9fa9eb395d42.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812200133689&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;125&#34;
		data-flex-basis=&#34;300px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;但是我们需要强制喂入Decoder正确的输入，只有这样才能进行比较&lt;/li&gt;
&lt;li&gt;即我们不会每次把Decoder的输出作为新的输入，而是直接设定好&lt;/li&gt;
&lt;li&gt;这个过程叫做&lt;strong&gt;Teacher Forcing&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;在训练的时候进行Teacher Forcing，最后的误差自然会偏低&lt;/li&gt;
&lt;li&gt;而在做测试时是无法做到的，造成mismatching&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EOS&lt;/code&gt;也需要被当作预测字符进行预测&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812200243816.png&#34;
	width=&#34;791&#34;
	height=&#34;538&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812200243816_hu_8917f615c15d73d3.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812200243816_hu_6df1be959f522fc0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812200243816&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;147&#34;
		data-flex-basis=&#34;352px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;copy-mechanism&#34;&gt;Copy Mechanism
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Copy Mechanism指在文本生成领域，生成的输出是输入序列元素的复制或者指向。&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;有时候不需要自己创造输出&lt;/li&gt;
&lt;li&gt;直接从输入中进行复制&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对模型进行询问时含有一些“人名”（模型从未见过），此时需要直接复述这个人名作为指代&lt;/li&gt;
&lt;li&gt;文章摘要&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;guided-attention&#34;&gt;Guided Attention
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;有时候需要对输入输出进行引导&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812201931650.png&#34;
	width=&#34;879&#34;
	height=&#34;421&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812201931650_hu_ea03b83751307c7c.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812201931650_hu_c2407cf3e6900188.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812201931650&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;208&#34;
		data-flex-basis=&#34;501px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;例如语音合成等相关内容，Attention会产生一些奇怪的错误，而你又对整个流程有明确的认识，就需要对Attention加入限制进行引导
&lt;ul&gt;
&lt;li&gt;Monotonic Attention&lt;/li&gt;
&lt;li&gt;Location-aware Attention&lt;/li&gt;
&lt;li&gt;（没有详讲）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;beam-search&#34;&gt;Beam Search
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812202528908.png&#34;
	width=&#34;855&#34;
	height=&#34;430&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812202528908_hu_781ba3793bf4fc03.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812202528908_hu_a2c99505d8621105.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812202528908&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;198&#34;
		data-flex-basis=&#34;477px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每次都贪心选择概率最高的输出不一定是一件好事&lt;/li&gt;
&lt;li&gt;我们无法穷举每一种可能，可以考虑使用Beam Search&lt;/li&gt;
&lt;li&gt;基础版本：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812202748807.png&#34;
	width=&#34;789&#34;
	height=&#34;414&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812202748807_hu_99cf7db692a74b86.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812202748807_hu_bc608b919781a814.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812202748807&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;190&#34;
		data-flex-basis=&#34;457px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于答案明确的任务，Beam Search会有帮助（需要尽力找到较优的结果）&lt;/li&gt;
&lt;li&gt;对于发挥创造力（编故事），反而不是一件好事&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bleu-score&#34;&gt;BLEU Score
&lt;/h3&gt;&lt;p&gt;有时候会需要一些奇奇怪怪的NLP的评价指标去评估训练&lt;/p&gt;
&lt;p&gt;但是这些指标是很难进行微分的，所以很难用于训练&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对于很难微分的函数计算，我们可以考虑使用强化学习&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;exposure-bias&#34;&gt;Exposure Bias
&lt;/h3&gt;&lt;p&gt;回到前文，我们在训练时每次喂给decoder的都是绝对正确的&lt;/p&gt;
&lt;p&gt;但是在测试时只能看自己的输出，这个不一致的现象叫做Exposure Bias&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;解决方法：&lt;strong&gt;Scheduled Sampling&lt;/strong&gt;：我们在喂入decoder的时候，故意弄错一点东西（引入噪声）&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>李宏毅机器学习2021 · L4</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/</link>
        <pubDate>Sat, 10 Aug 2024 18:19:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/</guid>
        <description>&lt;h1 id=&#34;l4-sequence-as-input&#34;&gt;L4. Sequence as input
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML 2022 Spring (ntu.edu.tw)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1VN4y1P7Zj&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1VN4y1P7Zj&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;sequence&#34;&gt;Sequence
&lt;/h2&gt;&lt;p&gt;对于Sequence Labeling任务，我们需要对一段文本中的所有单词标注词性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;显然不能单独考虑一个单词，需要结合上下文
&lt;ul&gt;
&lt;li&gt;同一个单词在不同的上下文中会有不同的词性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810194910423.png&#34;
	width=&#34;725&#34;
	height=&#34;341&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810194910423_hu_b4c3e786061568e3.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810194910423_hu_49434ca865acf193.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810194910423&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;212&#34;
		data-flex-basis=&#34;510px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们考虑定义一个window：
&lt;ul&gt;
&lt;li&gt;每个Fully-Connected需要连接前后若干个单词作为输入&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810195115978.png&#34;
	width=&#34;793&#34;
	height=&#34;350&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810195115978_hu_67336028c4b58ca1.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810195115978_hu_b154a4988d89b434.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810195115978&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;226&#34;
		data-flex-basis=&#34;543px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;但是我们有时需要考虑整个Sequence去获得信息，我们很难通过扩大Window进行操作，复杂度会非常高&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;self-attention&#34;&gt;Self-Attention
&lt;/h2&gt;&lt;h3 id=&#34;概述&#34;&gt;概述
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;整个Sequence作为输入&lt;/li&gt;
&lt;li&gt;输出向量数量等于输入向量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810195453418.png&#34;
	width=&#34;544&#34;
	height=&#34;412&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810195453418_hu_b94113e0431d997.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810195453418_hu_ed091fc2bce1f6fb.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810195453418&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;132&#34;
		data-flex-basis=&#34;316px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每次完成Self-Attention后，喂入FC进行操作&lt;/li&gt;
&lt;li&gt;可以多次叠加&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dot-product&#34;&gt;Dot-Product
&lt;/h3&gt;&lt;p&gt;我们会对多个输入向量之间的相关性感兴趣&lt;/p&gt;
&lt;p&gt;Self-Attention常使用Dot-Product求出两个向量之间的相关性&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810200023586.png&#34;
	width=&#34;255&#34;
	height=&#34;339&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810200023586_hu_5e41e906266a2ca1.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810200023586_hu_a91a80d37809d1fa.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810200023586&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;75&#34;
		data-flex-basis=&#34;180px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;两个输入$\text{query},\text{key}$向量分别乘上$W_q,W_k$，得到向量$q,k$&lt;/li&gt;
&lt;li&gt;对向量$q,k$进行点积，得到$\alpha$，同时也被称为attention-score&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;forward&#34;&gt;Forward
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对于其中一个向量$i$，计算出自己作为查询向量的$q_i$值&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;所有向量都需要计算自己作为被查询向量的$k_j$值&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过Dot-Product，得到$\alpha_{i,j}$，即向量$i$对所有向量$j$的相关性&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;做一下Softmax，得到$\alpha&amp;rsquo;_{i,j}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810201234380.png&#34;
	width=&#34;1094&#34;
	height=&#34;736&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810201234380_hu_1320e3bf9098af04.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810201234380_hu_8cf9c8ca796957a1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810201234380&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;148&#34;
		data-flex-basis=&#34;356px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;每个向量都需要通过$W_v$矩阵计算出向量$v$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$v_j$乘上标量$\alpha_{i,j}$，求和&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
$$
    b_i = \sum_{j} \alpha&#39;_{i,j}v_j
    $$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810201306802.png&#34;
	width=&#34;1152&#34;
	height=&#34;667&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810201306802_hu_6bf721813feba1c.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810201306802_hu_531ed7686d8469c1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810201306802&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;172&#34;
		data-flex-basis=&#34;414px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;关联性越高的向量，它会$b$占有很大的成分&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;每个向量$a_i$得到$b_i$的计算过程是并行进行的&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;forward矩阵形式&#34;&gt;Forward（矩阵形式）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;$W_q,W_k,W_v$都是通用的，每个向量$a_i$都需要使用，因此很容易就能表示成矩阵形式&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810202311607.png&#34;
	width=&#34;794&#34;
	height=&#34;423&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810202311607_hu_72ee95972ffada7f.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810202311607_hu_adf156101d4570d1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810202311607&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;187&#34;
		data-flex-basis=&#34;450px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于$q_1$，我需要让它与所有$k_j$​进行点积运算&lt;/li&gt;
&lt;li&gt;实质上就是与$k_j^T$进行相乘&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203013199.png&#34;
	width=&#34;1112&#34;
	height=&#34;291&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203013199_hu_bd2da2dfc5eea667.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203013199_hu_9b21d2e03f26c228.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810203013199&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;382&#34;
		data-flex-basis=&#34;917px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于其他$q_i$也是同理，计算得到矩阵$A$&lt;/li&gt;
&lt;li&gt;通过矩阵$A$，每一列过一遍激活函数（softmax）得到$A&#39;$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203127438.png&#34;
	width=&#34;1127&#34;
	height=&#34;308&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203127438_hu_f738e457ecea9fec.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203127438_hu_8391eb3ad567e5ca.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810203127438&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;365&#34;
		data-flex-basis=&#34;878px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;计算输出矩阵&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203438473.png&#34;
	width=&#34;897&#34;
	height=&#34;296&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203438473_hu_85e1178bfe3d2945.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203438473_hu_91c768f2aa18f776.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810203438473&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;303&#34;
		data-flex-basis=&#34;727px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;整理一下：&lt;/li&gt;
&lt;/ul&gt;
$$
O = VA&#39; = (W_vI)\text{softmax}(A) \\
O =(W_vI)\text{softmax}( K^TQ ) = (W_vI)\text{softmax}( I^TW_k^TW_qI ) \\
$$&lt;ul&gt;
&lt;li&gt;$W_q,W_k,W_v$则是我们需要学习的参数矩阵&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multi-head-self-attention&#34;&gt;Multi-head Self-Attention
&lt;/h3&gt;&lt;p&gt;一般的Self-Attention只会有一种$W_q$得到的一组$q$向量，作为相关性的度量&lt;/p&gt;
&lt;p&gt;但是有时候需要丰富多个相关性指标&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810204713494.png&#34;
	width=&#34;975&#34;
	height=&#34;671&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810204713494_hu_31d8544143250997.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810204713494_hu_8a9dd5a40f386c4a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810204713494&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;145&#34;
		data-flex-basis=&#34;348px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;得到的多类$b_i$输出，拼起来乘一个矩阵，得到最后的输出&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810204910126.png&#34;
	width=&#34;533&#34;
	height=&#34;181&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810204910126_hu_75fef0d55220710a.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810204910126_hu_46d13f56e37d462.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810204910126&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;294&#34;
		data-flex-basis=&#34;706px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;position-encoding&#34;&gt;Position Encoding
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对于$a_1, a_2, a_3, a_4$，其对于上文算法来说，并没有距离的概念（交换位置后没什么差别）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;但对于实际文本来说，$a_1,a_4$是距离较远的向量，$a_2,a_3$​是距离较近的向量&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;（需要分析一下位置对实际要的输出是有影响，才会考虑引入Position Encoding）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在求解前，每个$a_i$需要加入一个位置向量$e_i$即可&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810205438276.png&#34;
	width=&#34;325&#34;
	height=&#34;223&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810205438276_hu_84b0b78f79197fed.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810205438276_hu_1131b67eb5afd669.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810205438276&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;145&#34;
		data-flex-basis=&#34;349px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hand-crafted（人为设置）：会使用一些三角函数进行组合
&lt;ul&gt;
&lt;li&gt;方式非常多，暂时没有最好的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// 好像自己写过这个东西
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;__global__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cu_matrixPositionalEmbedding&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;M&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;level&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;M&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;row&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;col&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;row&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;col&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;d_C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;M&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;powf2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;level&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;powf2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;powf2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;d_C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sinf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;val&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;M&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cosf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;val&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;M&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;learn from data：直接作为参数进行学习&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;非文本应用&#34;&gt;非文本应用
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;省流：只要是一个vector set，就可以进行self-attention&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Self-attention for Speech
&lt;ul&gt;
&lt;li&gt;声音讯号转换成向量会更加复杂&lt;/li&gt;
&lt;li&gt;导致整体的矩阵会变得非常大&lt;/li&gt;
&lt;li&gt;所以需要引入window，考虑一小段话进行识别&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Self-attention for Image
&lt;ul&gt;
&lt;li&gt;每个像素的所有通道值看作一个向量&lt;/li&gt;
&lt;li&gt;则我们可以得到分辨率数个向量，构成了一个vector set&lt;/li&gt;
&lt;li&gt;相比CNN来说，可以考虑整个图像的所有像素，而不是一个感受野
&lt;ul&gt;
&lt;li&gt;自动学习出附近哪些像素是相关的，本质上自动学习了感受野&lt;/li&gt;
&lt;li&gt;不需要人为设定感受野大小&lt;/li&gt;
&lt;li&gt;认为：Self-Attention经过调整可以做到CNN一样的事情，因此对于function set层面上，CNN被Self-Attention所包含，是有所限制的特例&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810210416541.png&#34;
	width=&#34;507&#34;
	height=&#34;447&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810210416541_hu_e57416002cfc86aa.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810210416541_hu_eb3d057bb450f72f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810210416541&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;113&#34;
		data-flex-basis=&#34;272px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Self-attention for Graph
&lt;ul&gt;
&lt;li&gt;对于有边的结点对，需要计算attention-score&lt;/li&gt;
&lt;li&gt;没有边可以直接认为无关，设为0&lt;/li&gt;
&lt;li&gt;改改就是GNN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810211514167.png&#34;
	width=&#34;955&#34;
	height=&#34;563&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810211514167_hu_9c17c9b31236adfb.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810211514167_hu_4da8238114914b0c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810211514167&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;407px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;rnn&#34;&gt;RNN
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;似乎被Self-Attention替代了&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;RNN没法并行&lt;/li&gt;
&lt;li&gt;普通的RNN只会考虑左边序列的输出，而Self-Attention考虑整个序列&lt;/li&gt;
&lt;li&gt;双向RNN需要大量memory去存储结果，才能做到考虑整个序列&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>李宏毅机器学习2021 · L3</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l3/</link>
        <pubDate>Sat, 27 Jul 2024 18:19:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l3/</guid>
        <description>&lt;h1 id=&#34;l3-image-as-input&#34;&gt;L3. Image as input
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML 2022 Spring (ntu.edu.tw)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1J94y1f7u5&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1J94y1f7u5&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;原则&#34;&gt;原则
&lt;/h2&gt;&lt;h3 id=&#34;局部性&#34;&gt;局部性
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;图片的识别往往需要注意一小块的特征&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&#34;assets/image-20240727181929979.png&#34; alt=&#34;image-20240727181929979&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;就算是人类也会根据局部特征，被误导进行分类（其实这是一只猫而不是一只鸟）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;图像会被切分成多个感受野，感受野之间需要有所重叠（否则会遗失边界上的信息）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l3/assets/image-20240727182325873.png&#34;
	width=&#34;1771&#34;
	height=&#34;1008&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l3/assets/image-20240727182325873_hu_96411596ecf6d855.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l3/assets/image-20240727182325873_hu_a95ad1230568f2d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727182325873&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;421px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;因此我们需要用感受野覆盖整个图像&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用一组神经元，识别同一个感受野，即负责这一块区域的图像识别&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;平移不变性&#34;&gt;平移不变性
&lt;/h3&gt;&lt;img src=&#34;assets/image-20240727201934526.png&#34; alt=&#34;image-20240727201934526&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;ul&gt;
&lt;li&gt;同一个特征可以出现在不同的位置，因此理论上识别同一个特征的单元应该有相同的参数&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&#34;assets/image-20240727202440749.png&#34; alt=&#34;image-20240727202440749&#34; style=&#34;zoom:67%;&#34; /&gt;
&lt;ul&gt;
&lt;li&gt;对于同一个感受野，它应该携带多个神经元，即多个识别单元filter，以识别不同的特征&lt;/li&gt;
&lt;li&gt;不同感受野的同一个filter，需要&lt;strong&gt;共享参数&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;卷积神经网络&#34;&gt;卷积神经网络
&lt;/h2&gt;&lt;h3 id=&#34;卷积层&#34;&gt;卷积层
&lt;/h3&gt;&lt;p&gt;我们从一般的全连接神经网络出发，引入了两个限制&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一组神经元只会接受图片上一块区域的张量（感受野）
&lt;ul&gt;
&lt;li&gt;断掉了这些神经元与其他位置的连接&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;不同组神经元的同一类识别单元需要共享参数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此时我们相当于对MLP大砍一刀，变成了一个限制非常大的神经网络，即卷积层&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;但实际实现我们其实对于一个filter，就是一个卷积核，直接让它扫一遍整个图像即可&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个卷积核会产生一个新的通道&lt;/p&gt;
&lt;img src=&#34;assets/image-20240727205533086.png&#34; alt=&#34;image-20240727205533086&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;如图，同样一个3*3的卷积核，恢复到原图像中，会对应上超过9个以上的像素&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;随着深度增加，一个卷积核的真实感受野也会变大&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;池化层&#34;&gt;池化层
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;大量的卷积核，产生大量的通道，因此对于原图像的尺寸来说参数会非常多&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我们考虑通过池化缩减原图像尺寸（通道数不变）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Max、Mean Pooling&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&#34;assets/image-20240727210158517.png&#34; alt=&#34;image-20240727210158517&#34; style=&#34;zoom:67%;&#34; /&gt;
&lt;p&gt;在计算量足够的时候，不一定需要使用Pooling（会丢失很多信息）&lt;/p&gt;
&lt;h3 id=&#34;数据增强&#34;&gt;数据增强
&lt;/h3&gt;&lt;p&gt;旋转、缩放图像，可能会使得CNN变得很差&lt;/p&gt;
&lt;p&gt;所以推荐在训练前使用数据增强&lt;/p&gt;
&lt;h3 id=&#34;spatial-transformer-layer&#34;&gt;Spatial Transformer Layer
&lt;/h3&gt;&lt;p&gt;但我们为什么不直接在网络结构中加一个层呢&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_39422642/article/details/78870629&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;详细解读Spatial Transformer Networks（STN）-一篇文章让你完全理解STN了-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;没学太明白，知道个大概&lt;/p&gt;
</description>
        </item>
        <item>
        <title>李宏毅机器学习2021 · L2</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/</link>
        <pubDate>Fri, 26 Jul 2024 20:45:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/</guid>
        <description>&lt;h1 id=&#34;l2-what-to-do-if-my-network-fails-to-train&#34;&gt;L2. What to do if my network fails to train
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML 2022 Spring (ntu.edu.tw)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1J94y1f7u5&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1J94y1f7u5&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;general-guide&#34;&gt;General Guide
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;检查Training Loss
&lt;ul&gt;
&lt;li&gt;Training Loss大
&lt;ul&gt;
&lt;li&gt;Model Bias
&lt;ul&gt;
&lt;li&gt;模型不够复杂&lt;/li&gt;
&lt;li&gt;提高模型复杂度即可&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Optimization
&lt;ul&gt;
&lt;li&gt;可以尝试使用浅层神经网络等容易优化的模型进行训练，若Train Loss比复杂模型更低，说明优化出问题了&lt;/li&gt;
&lt;li&gt;解释：复杂模型包含了简单模型（多出来的部分全部不训练，剩下的就是简单模型），因此简单模型能做到的Training Loss，对于复杂模型也需要做到&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Training Loss小
&lt;ul&gt;
&lt;li&gt;检查Testing Loss
&lt;ul&gt;
&lt;li&gt;Testing Loss小（这不结束了吗）&lt;/li&gt;
&lt;li&gt;Testing Loss大
&lt;ul&gt;
&lt;li&gt;Overfitting
&lt;ul&gt;
&lt;li&gt;增加训练数据&lt;/li&gt;
&lt;li&gt;数据增强（Data augmentation）&lt;/li&gt;
&lt;li&gt;减少模型复杂度&lt;/li&gt;
&lt;li&gt;Early Stopping&lt;/li&gt;
&lt;li&gt;Regularization&lt;/li&gt;
&lt;li&gt;Dropout&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mismatch
&lt;ul&gt;
&lt;li&gt;与过拟合不同，没法使用增加训练数据避免&lt;/li&gt;
&lt;li&gt;训练数据与测试数据有着不同的分布&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726002318989.png&#34;
	width=&#34;1146&#34;
	height=&#34;784&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726002318989_hu_e2a3a53f03528fce.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726002318989_hu_9e3a17f420fb61bc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240726002318989&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;146&#34;
		data-flex-basis=&#34;350px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;训练数据少，不足以限制模型&lt;/li&gt;
&lt;li&gt;模型太复杂，过于自由&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;optimization-failed&#34;&gt;Optimization Failed
&lt;/h2&gt;&lt;h3 id=&#34;critical-point&#34;&gt;Critical Point
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726212706358.png&#34;
	width=&#34;1432&#34;
	height=&#34;537&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726212706358_hu_23a27474b4a8738b.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726212706358_hu_5840c17e70f7cc2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240726212706358&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;266&#34;
		data-flex-basis=&#34;640px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;处于局部极值点（极大值、极小值）或鞍点时，梯度值为0，此时没有办法继续更新梯度&lt;/p&gt;
&lt;h4 id=&#34;tayler-series-approximation&#34;&gt;Tayler Series Approximation
&lt;/h4&gt;&lt;p&gt;为了判别&lt;code&gt;critical point&lt;/code&gt;，我们要是能够知道损失函数$L(\theta)$的形状就会非常容易&lt;/p&gt;
&lt;p&gt;我们考虑使用&lt;strong&gt;泰勒展开&lt;/strong&gt;，对参数$\theta&amp;rsquo;$周围的损失函数进行近似&lt;/p&gt;
$$
L(\theta) \approx L(\theta&#39;) + (\theta-\theta&#39;)g+\frac{1}{2}(\theta-\theta&#39;)^T\times H\times (\theta-\theta&#39;)
$$$$
L(\theta) \approx L(\theta&#39;) + \frac{1}{2}(\theta-\theta&#39;)^T\times H\times (\theta-\theta&#39;)
$$&lt;p&gt;
此时取决于最后一项：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;永远大于0，则$L(\theta) &amp;gt; L(\theta&amp;rsquo;)$，是局部极小值&lt;/li&gt;
&lt;li&gt;永远小于0，则$L(\theta) &amp;lt; L(\theta&amp;rsquo;)$，是局部极大值&lt;/li&gt;
&lt;li&gt;否则：鞍点&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;判断$\frac{1}{2}(\theta-\theta&amp;rsquo;)^T\times H\times (\theta-\theta&amp;rsquo;)$的正负是一个经典问题&lt;/p&gt;
&lt;p&gt;即$\forall v, v^THv &amp;gt; 0$，此时$H$被称为正定矩阵（特征值都是正值）&lt;/p&gt;
&lt;p&gt;反之，负定矩阵所有的特征值均小于0&lt;/p&gt;
&lt;p&gt;但是每次都需要计算矩阵及其特征值，是一件开销很大的事情&lt;/p&gt;
&lt;p&gt;我们考虑从其他方式进行规避鞍点&lt;/p&gt;
&lt;h4 id=&#34;batch-size&#34;&gt;Batch Size
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;大的Batch会花费更多时间进行计算，但是减少梯度更新次数&lt;/li&gt;
&lt;li&gt;小的Batch会花费更少时间进行计算，但是增加梯度更新次数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726221840015.png&#34;
	width=&#34;1764&#34;
	height=&#34;698&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726221840015_hu_ba30f46d87e548b6.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726221840015_hu_659b1db9b1480a48.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240726221840015&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;252&#34;
		data-flex-basis=&#34;606px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;得益于GPU并行计算，batch在不是非常大的时候，多条数据计算loss计算梯度是并行的，因此时间非常少&lt;/p&gt;
&lt;p&gt;但是小的batch确确实实需要更多次梯度更新，因此&lt;strong&gt;小的batch事实上在单个epoch上花费时间更大&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726222335373.png&#34;
	width=&#34;1869&#34;
	height=&#34;1099&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726222335373_hu_97093e71718a6005.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726222335373_hu_7824f9a4c08d3c6d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240726222335373&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;170&#34;
		data-flex-basis=&#34;408px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;​	&lt;strong&gt;但是似乎小的batch可以对Optimization带来更好的效果&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&#34;assets/image-20240726222828695.png&#34; alt=&#34;image-20240726222828695&#34; style=&#34;zoom: 50%;&#34; /&gt;
&lt;p&gt;每次使用不同batch的数据进行更新，某种程度上引入了噪声&lt;/p&gt;
&lt;p&gt;在第一份batch上进入鞍点，但是对于第二份就不一定是鞍点&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726223435549.png&#34;
	width=&#34;1670&#34;
	height=&#34;837&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726223435549_hu_4f1ea00d81182b5.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726223435549_hu_4c77eb55e35b5415.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240726223435549&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;199&#34;
		data-flex-basis=&#34;478px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;甚至你会发现，小batch训练出来的模型，泛化性能更好，在测试集上表现更好&lt;/p&gt;
&lt;p&gt;一种比较玄学的解释：&lt;/p&gt;
&lt;p&gt;极值点有平坦的、陡峭的两种（如图左、右）&lt;/p&gt;
&lt;p&gt;由于测试集多少与训练集有一些mismatch，如果是平坦的极值点，稍微的偏移不会引起损失函数变化太多&lt;/p&gt;
&lt;p&gt;而陡峭的极值点会表现糟糕&lt;/p&gt;
&lt;p&gt;小batch在训练时引入的噪声，非常跳脱，峡谷很难困住其更新方向&lt;/p&gt;
&lt;p&gt;而大batch的梯度下降方向稳定，因此容易进入陡峭的峡谷&lt;/p&gt;
&lt;h3 id=&#34;learning-rate&#34;&gt;Learning Rate
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727004526896.png&#34;
	width=&#34;1363&#34;
	height=&#34;641&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727004526896_hu_8c6188ae5b6c6c00.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727004526896_hu_8d76fccda6fb61f8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727004526896&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;212&#34;
		data-flex-basis=&#34;510px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;非常多时候Loss并不是卡在&lt;code&gt;critical point&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我们观察训练末期的梯度，发现并不是0&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;原因是在山谷之间来回跳动，无法下降&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727005023817.png&#34;
	width=&#34;1475&#34;
	height=&#34;561&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727005023817_hu_a86798eefc4da2cf.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727005023817_hu_a9d1d2bc213f1013.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727005023817&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;262&#34;
		data-flex-basis=&#34;631px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;学习率较大，会在山谷来回跳（左图）&lt;/li&gt;
&lt;li&gt;学习率较小，在稍微平坦的地方完全走不动（右图）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此一般的梯度下降很难进入&lt;code&gt;critical point&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;我们考虑自适应学习率&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;陡峭的地方学习率高&lt;/li&gt;
&lt;li&gt;平坦的地方学习率低&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;梯度的更新应该由&lt;/p&gt;
$$
\theta^{t+1} =\theta^t - \eta g^t
$$&lt;p&gt;
转变为：&lt;/p&gt;
$$
\theta^{t+1} =\theta^t - \frac{\eta}{\sigma^t}g^t
$$&lt;h4 id=&#34;root-mean-squareadagrad&#34;&gt;Root Mean Square（Adagrad）
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727011659380.png&#34;
	width=&#34;1754&#34;
	height=&#34;911&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727011659380_hu_cfce72f52008edc.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727011659380_hu_cf09cae5a88ea49e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727011659380&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;192&#34;
		data-flex-basis=&#34;462px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;及对应维度上的梯度均方根作为分母&lt;/p&gt;
&lt;p&gt;但是这样的方法不够灵活&lt;/p&gt;
&lt;p&gt;有时候同一个维度，在不同时间点可能又陡峭又平缓，因此需要更加灵活、动态变化的学习率&lt;/p&gt;
&lt;h4 id=&#34;rmspropadam&#34;&gt;RMSProp+Adam
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727012032761.png&#34;
	width=&#34;1620&#34;
	height=&#34;943&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727012032761_hu_19cf01196f551643.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727012032761_hu_54fdc8c1132da213.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727012032761&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;171&#34;
		data-flex-basis=&#34;412px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;定义权重$\alpha$，每次结合上一次的$\sigma^{t-1}$与当前梯度进行计算&lt;/p&gt;
$$
\sigma^{t} = \sqrt{\alpha(\sigma^{t-1})^2+(1-\alpha)(g^t)^2}
$$&lt;p&gt;但此时我们仍然无法解决卡在&lt;code&gt;critical point&lt;/code&gt;的问题&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Adam = RMSProp + Momentum&lt;/u&gt;&lt;/p&gt;
&lt;h4 id=&#34;momentum&#34;&gt;Momentum
&lt;/h4&gt;&lt;p&gt;我们考虑在优化时引入动量的概念&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726225731002.png&#34;
	width=&#34;1803&#34;
	height=&#34;933&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726225731002_hu_fe9931e5cd78a4dc.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726225731002_hu_ddf4c9f7bbf28d4d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240726225731002&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;463px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;物体在下降时，到达谷底仍拥有一定的动量，还会沿之前的方向继续冲一会&lt;/p&gt;
&lt;p&gt;这样有机会冲到更低的极值点&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726225918900.png&#34;
	width=&#34;970&#34;
	height=&#34;451&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726225918900_hu_e14983e0a01f82cf.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726225918900_hu_94e222b769489513.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240726225918900&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;215&#34;
		data-flex-basis=&#34;516px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;并且：每次移动的$m_i$都可以表示为之前所有梯度的综合（一个关于$g_0,g_1,&amp;hellip;$的式子）&lt;/p&gt;
&lt;h3 id=&#34;adam&#34;&gt;Adam
&lt;/h3&gt;&lt;p&gt;结合 RMSProp + Momentum，我们就得到了Adam&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Momentum：&lt;/strong&gt;&lt;/p&gt;
$$
\theta^t = \theta^{t-1} - \eta m^t\\
m^t = \beta m^{t-1} + (1-\beta)g^{t-1}
$$&lt;p&gt;
&lt;strong&gt;RMSProp:&lt;/strong&gt;&lt;/p&gt;
$$
\theta^t = \theta^{t-1} - \frac{\eta}{\sigma^t}g^{t-1}\\
\sigma^{t} = \sqrt{\alpha(\sigma^{t-1})^2+(1-\alpha)(g^t)^2}
$$&lt;p&gt;
结合一下，&lt;strong&gt;Adam&lt;/strong&gt;：&lt;/p&gt;
$$
\hat m^{t} = \frac{m^t}{1-\beta}\\
\hat \sigma^t = \sqrt{\frac{(\sigma^t)^2}{1-\alpha}}\\
\epsilon = 10^{-8}\\
\theta^t = \theta^{t-1} - \frac{\eta}{\hat \sigma^t + \epsilon}\hat m^{t}
$$&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;同时兼顾方向与步长&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Momentum 负责确定更新方向（加速收敛）：在陡峭的地方始终保持总体方向，防止偏航&lt;/li&gt;
&lt;li&gt;RMSProp 负责调整步长（自适应学习率）：调整每一步的大小，走的更稳&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;learning-rate-scheduling&#34;&gt;Learning Rate Scheduling
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727012518967.png&#34;
	width=&#34;718&#34;
	height=&#34;486&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727012518967_hu_48bc08e310f5f031.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727012518967_hu_19837198438541ad.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727012518967&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;147&#34;
		data-flex-basis=&#34;354px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;我们采用Adagrad，此时就可以进行正常的下降&lt;/p&gt;
&lt;p&gt;但是会出现奇怪的波动&lt;/p&gt;
$$
\sigma^{t} = \sqrt{\frac{1}{t+1}\sum_k (g^k)^2}
$$&lt;p&gt;
刚进入平坦区时，得益于一开始积累了下降的较高梯度&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013213318.png&#34;
	width=&#34;746&#34;
	height=&#34;424&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013213318_hu_5f5b3f52637abddf.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013213318_hu_6c632e041303e9a8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727013213318&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;422px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;$\sigma_y$仍然可以维持在一个比较大的范围&lt;/p&gt;
&lt;p&gt;但随着迭代次数增加，$\sigma_y$每次只能加上非常小的梯度，平均值不断变小，最终引起了学习率爆炸&lt;/p&gt;
&lt;p&gt;如何解决这个问题呢&lt;/p&gt;
$$
\theta^{t+1} =\theta^t - \frac{\eta}{\sigma^t}g^t
$$&lt;p&gt;
我们除了对$\sigma$进行变化，我们可以本身对$\eta$​进行变化&lt;/p&gt;
&lt;p&gt;即随着时间，$\eta$慢慢变小&lt;/p&gt;
&lt;p&gt;时间越长，本身肯定也已经离终点越来越近，因此就会抵消之前的梯度积累&lt;/p&gt;
&lt;p&gt;或者变大再变小&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Learning Rate Decay
&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013705566.png&#34;
	width=&#34;573&#34;
	height=&#34;301&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013705566_hu_d727239789cb5408.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013705566_hu_68a454e90ebbe697.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727013705566&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;190&#34;
		data-flex-basis=&#34;456px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;Warm Up&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013732870.png&#34;
	width=&#34;534&#34;
	height=&#34;308&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013732870_hu_9d6fba0554416a60.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013732870_hu_e11995cf98bfdded.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727013732870&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;173&#34;
		data-flex-basis=&#34;416px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Warm Up貌似更黑科技一点&lt;/p&gt;
&lt;p&gt;Warm Up可能的解释：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一开始希望多收集周围的梯度信息，因此不希望走太快&lt;/li&gt;
&lt;li&gt;信息足够后，开始正式的大踏步前进&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>Pytorch入门</title>
        <link>https://example.com/p/pytorch%E5%85%A5%E9%97%A8/</link>
        <pubDate>Wed, 29 May 2024 20:46:34 +0800</pubDate>
        
        <guid>https://example.com/p/pytorch%E5%85%A5%E9%97%A8/</guid>
        <description>&lt;h1 id=&#34;pytorch入门&#34;&gt;Pytorch入门
&lt;/h1&gt;&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;环境配置&#34;&gt;环境配置
&lt;/h2&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda create -n pytorch-learn &lt;span class=&#34;nv&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;3.8
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;查看cuda版本：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;nvcc --version
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;根据cuda版本进行选择：&lt;a class=&#34;link&#34; href=&#34;https://pytorch.org/get-started/locally/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Pytorch本地安装&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda install pytorch torchvision torchaudio pytorch-cuda&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;11.8 -c pytorch -c nvidia
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;安装检测&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pytorch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;learn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;aoijays&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;aoijays&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;ubuntu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;~/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Desktop&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;note&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;python&lt;/span&gt;                                       
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Python&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;3.8.19&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Mar&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2024&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;19&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;58&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;24&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;                                                      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GCC&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;11.2.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;::&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Anaconda&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Inc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;on&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;linux&lt;/span&gt;                                                             
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Type&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;help&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;copyright&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;credits&amp;#34;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;license&amp;#34;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;more&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;information&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;                              
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;                                                                                     
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cuda&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;is_available&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;True&lt;/span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;此时说明安装成功&lt;/p&gt;
&lt;h2 id=&#34;前言&#34;&gt;前言
&lt;/h2&gt;&lt;h3 id=&#34;法宝函数&#34;&gt;法宝函数
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 显示下属对象列表&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;help&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 显示当前对象的说明&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;## 但我更喜欢加两个问号??&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/pytorch%E5%85%A5%E9%97%A8/assets/image-20240529020547606.png&#34;
	width=&#34;941&#34;
	height=&#34;682&#34;
	srcset=&#34;https://example.com/p/pytorch%E5%85%A5%E9%97%A8/assets/image-20240529020547606_hu_e65791bc8b9e4df6.png 480w, https://example.com/p/pytorch%E5%85%A5%E9%97%A8/assets/image-20240529020547606_hu_2c2cbb497e1ef080.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240529020547606&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;137&#34;
		data-flex-basis=&#34;331px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;dataset&#34;&gt;Dataset
&lt;/h3&gt;&lt;p&gt;以&lt;a class=&#34;link&#34; href=&#34;https://www.kaggle.com/datasets/ajayrana/hymenoptera-data&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;蜜蜂蚂蚁数据集&lt;/a&gt;进行说明&lt;/p&gt;
&lt;p&gt;其文件目录：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;│   └── hymenoptera_data
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;│       ├── train
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;│       │   ├── ants
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;│       │   └── bees
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;│       └── val
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;│           ├── ants
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;│           └── bees
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;子文件夹小附有若干张jpg&lt;/p&gt;
&lt;p&gt;接下来我们需要使用torch的Dataset去加载数据集&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;|  An abstract class representing a :class:&lt;code&gt;Dataset&lt;/code&gt;.
|&lt;br&gt;
|  All datasets that represent &lt;u&gt;&lt;strong&gt;a map from keys to data samples&lt;/strong&gt;&lt;/u&gt; should subclass
|  it. All subclasses should overwrite :meth:&lt;code&gt;__getitem__&lt;/code&gt;, supporting fetching a
|  data sample for a given key. Subclasses could also optionally overwrite
|  :meth:&lt;code&gt;__len__&lt;/code&gt;, which is expected to return the size of the dataset by many
|  :class:&lt;code&gt;~torch.utils.data.Sampler&lt;/code&gt; implementations and the default options
|  of :class:&lt;code&gt;~torch.utils.data.DataLoader&lt;/code&gt;. Subclasses could also
|  optionally implement :meth:&lt;code&gt;__getitems__&lt;/code&gt;, for speedup batched samples
|  loading. This method accepts list of indices of samples of batch and returns
|  list of samples.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;省流：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需要继承&lt;/li&gt;
&lt;li&gt;必须重写&lt;code&gt;__getitem__&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;可以重写&lt;code&gt;__len__&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Dataset&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;PIL&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Image&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;MyDataet&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;root_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 自定义 怎么方便怎么来&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root_dir&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;root_dir&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 记录数据地址以及对应的标签&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;label&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imglist&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;listdir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 以列表形式展示文件夹内所有文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__getitem__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;img_name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imglist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;img_path&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;img_name&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;img&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;img_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 打开图片&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;label&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;img&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;label&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 返回数据与标签&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__len__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imglist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;train_ants&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MyDataet&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;../Dataset/hymenoptera_data/train/ants&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;ants&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;train_bees&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MyDataet&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;../Dataset/hymenoptera_data/train/bees&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;bees&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;train_data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_ants&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_bees&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 拼接数据集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_ants&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__len__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;  &lt;span class=&#34;n&#34;&gt;train_bees&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__len__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__len__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;123&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;124&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sep&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 124 121 245&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# (&amp;lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x775FB149ADF0&amp;gt;, &amp;#39;ants&amp;#39;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# (&amp;lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=311x387 at 0x775FB0EB29A0&amp;gt;, &amp;#39;bees&amp;#39;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;写法非常自由，你只要保证重写的函数返回正确结果即可&lt;/p&gt;
&lt;h3 id=&#34;tensorboard&#34;&gt;Tensorboard
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda install tensorboard
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h4 id=&#34;scalars&#34;&gt;Scalars
&lt;/h4&gt;&lt;p&gt;绘制一些图表，观察训练的loss变化&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.utils.tensorboard&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SummaryWriter&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;writer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SummaryWriter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;logs&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 创建对象 在logs文件夹下保存文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;writer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_scalar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;y = x&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 图像名 y值 x值&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;writer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_scalar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;y = x^2&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 图像名 y值 x值&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;writer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;close&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在终端中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;tensorboard --logdir&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;logs --port&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;6007&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 默认6006&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/pytorch%E5%85%A5%E9%97%A8/assets/image-20240529030116600.png&#34;
	width=&#34;1680&#34;
	height=&#34;841&#34;
	srcset=&#34;https://example.com/p/pytorch%E5%85%A5%E9%97%A8/assets/image-20240529030116600_hu_cc98f959101d55d5.png 480w, https://example.com/p/pytorch%E5%85%A5%E9%97%A8/assets/image-20240529030116600_hu_4d679944ea74fc67.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240529030116600&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;199&#34;
		data-flex-basis=&#34;479px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;images&#34;&gt;Images
&lt;/h4&gt;&lt;p&gt;可视化实际的训练效果，上传图片进行展示&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;img&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s1&#34;&gt;&amp;#39;../Dataset/hymenoptera_data/train/ants/0013035.jpg&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;img&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# &amp;lt;class &amp;#39;PIL.JpegImagePlugin.JpegImageFile&amp;#39;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 不支持此类型 需要转化为numpy对象&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;img_array&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;img&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;img_array&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# (512, 768, 3)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 高 宽 通道数 -&amp;gt; HWC&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 标题 添加的图像 步 格式&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;writer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;test&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;img_array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dataformats&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;HWC&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 我们可以第1步展示一张图，第2步展示一张图……&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 即可观察随着训练步数，图片发生变化&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/pytorch%E5%85%A5%E9%97%A8/assets/image-20240529031540127.png&#34;
	width=&#34;1012&#34;
	height=&#34;528&#34;
	srcset=&#34;https://example.com/p/pytorch%E5%85%A5%E9%97%A8/assets/image-20240529031540127_hu_1e8d14829efc7023.png 480w, https://example.com/p/pytorch%E5%85%A5%E9%97%A8/assets/image-20240529031540127_hu_fa717d5fb9533819.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240529031540127&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;191&#34;
		data-flex-basis=&#34;460px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;transforms&#34;&gt;Transforms
&lt;/h3&gt;&lt;p&gt;留个印象就好，能通过这个方法对数据、图片等进行互相转换、变化&lt;/p&gt;
&lt;p&gt;常见的有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ToTensor：转化为Tensor数据&lt;/li&gt;
&lt;li&gt;Normalize：归一化&lt;/li&gt;
&lt;li&gt;Resize：对图片数据进行缩放&lt;/li&gt;
&lt;li&gt;Compose：用列表记录多个变化，进行一次性操作&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可能用到的时候查一下就行&lt;/p&gt;
&lt;p&gt;适合对多个数据同时进行相同的处理&lt;/p&gt;
&lt;h3 id=&#34;torchvision数据集的下载与使用&#34;&gt;Torchvision数据集的下载与使用
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torchvision&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;train_set&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datasets&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CIFAR10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;../Dataset&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 训练集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test_set&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datasets&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CIFAR10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;../Dataset&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 测试集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_set&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;classes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;img&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test_set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;img&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;(&amp;lt;PIL.Image.Image image mode=RGB size=32x32 at 0x7202D3007670&amp;gt;, 6)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;[&amp;#39;airplane&amp;#39;, &amp;#39;automobile&amp;#39;, &amp;#39;bird&amp;#39;, &amp;#39;cat&amp;#39;, &amp;#39;deer&amp;#39;, &amp;#39;dog&amp;#39;, &amp;#39;frog&amp;#39;, &amp;#39;horse&amp;#39;, &amp;#39;ship&amp;#39;, &amp;#39;truck&amp;#39;]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;lt;PIL.Image.Image image mode=RGB size=32x32 at 0x7202D3007310&amp;gt; 3
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;此时我们得到的数据集都是&lt;code&gt;(PIL对象，标签索引)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;我们可以使用Transform统一把图片转化为Tensor，方便Pytorch使用&lt;/p&gt;
&lt;p&gt;最简单的方法：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dataset_transform&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Compose&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 封装所有需要进行的转换列表&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ToTensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 在加载数据时直接进行参数化修改&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;train_set&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datasets&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CIFAR10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;../Dataset&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dataset_transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 训练集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test_set&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datasets&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CIFAR10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;../Dataset&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dataset_transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 测试集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;dataloader&#34;&gt;DataLoader
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torchvision&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DataLoader&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test_set&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datasets&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CIFAR10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;../Dataset&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ToTensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 测试集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 除了官方数据集 也可以选择之前自己实例化的Dataset&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test_loader&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DataLoader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test_set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;shuffle&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;drop_last&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 按batch_size数量进行遍历&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;网络&#34;&gt;网络
&lt;/h2&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 需要从nn.Module进行继承&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 调用父类的初始化函数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 前向传播&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;output&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;卷积层&#34;&gt;卷积层
&lt;/h3&gt;&lt;p&gt;对于一张H*W的RGB图片，其通道数channel为3&lt;/p&gt;
&lt;p&gt;我们使用多少个卷积核，就会产生多少个out_channels&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Mycnn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 输入3通道 用6个3*3的卷积核得到6通道输出 步长为1 不填充&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;conv1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 前向传播&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;conv1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;output&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mycnn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Mycnn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;FloatTensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mycnn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;池化层&#34;&gt;池化层
&lt;/h3&gt;&lt;p&gt;卷积后的图像依旧比较大，可以通过池化层进行压缩&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;避免过拟合、去除冗余&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 池化&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Mycnn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;c1&#34;&gt;# ceil_mode 若有无法整除kernel_size 多余的部分按照ceil_mode决定是否保留&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;maxpool1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ceil_mode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 前向传播&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;maxpool1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;output&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mycnn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Mycnn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;float32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# x.shape&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mycnn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;我们可以喂入图片，就可以得到压缩画质版本的输出&lt;/p&gt;
&lt;h3 id=&#34;激活层&#34;&gt;激活层
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ReLU&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReLU&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReLU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 前向传播&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReLU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;output&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;其他&#34;&gt;其他
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;正则化层&lt;/li&gt;
&lt;li&gt;线性层……&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sequential&#34;&gt;Sequential
&lt;/h3&gt;&lt;p&gt;我们试图构建一个较大的网络对CIFAR10数据集进行推理&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/pytorch%E5%85%A5%E9%97%A8/assets/image-20240530152550478.png&#34;
	width=&#34;1860&#34;
	height=&#34;559&#34;
	srcset=&#34;https://example.com/p/pytorch%E5%85%A5%E9%97%A8/assets/image-20240530152550478_hu_73007145c79d8bc2.png 480w, https://example.com/p/pytorch%E5%85%A5%E9%97%A8/assets/image-20240530152550478_hu_75922e65417f4457.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240530152550478&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;332&#34;
		data-flex-basis=&#34;798px&#34;
	
&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Sequential&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sequential&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Flatten&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 将tensor张成一维张量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 模拟一个batch_size = 64中32*32的3通道数据集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ones&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;损失函数&#34;&gt;损失函数
&lt;/h2&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.nn&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;inputs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;float32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;float32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;loss1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;L1Loss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduction&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;sum&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;loss2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;L1Loss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduction&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mean&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;loss3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MSELoss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.nn&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 交叉熵损失函数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 假设 outputs 是模型的最后一层输出，shape 为 (batch_size, num_classes)，targets 是 ground truth labels&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;randn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 对于4分类问题的10个样本的不归一化的预测值&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;randint&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,))&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 对应的真实类别&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;loss_fn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss_fn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;反向传播&#34;&gt;反向传播
&lt;/h2&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 构建网络&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sequential&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Flatten&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 将tensor张成一维张量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 模拟一个batch_size = 64中32*32的3通道数据集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ones&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;output&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -------------------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 构建数据集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torchvision&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DataLoader&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test_set&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datasets&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CIFAR10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;../Dataset&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ToTensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 测试集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test_loader&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DataLoader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test_set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;shuffle&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;drop_last&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -------------------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 反向传播&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;loss_fn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 按batch_size数量进行遍历&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 计算得到损失函数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss_fn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 反向传播 沿计算图得到所有参数的梯度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;优化器&#34;&gt;优化器
&lt;/h2&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;loss_fn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;loss_sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 按batch_size数量进行遍历&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 正向推理&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 计算得到损失函数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss_fn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;optim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zero_grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 将所有参数进行梯度清零&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 反向传播 沿计算图得到所有参数的梯度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;optim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;step&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 优化&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;loss_sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loss_sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;我们可以进行多轮学习&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;loss_fn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;epochs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;epoch&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;epochs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;loss_sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 按batch_size数量进行遍历&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 正向推理&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 计算得到损失函数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss_fn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;optim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zero_grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 将所有参数进行梯度清零&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 反向传播 沿计算图得到所有参数的梯度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;optim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;step&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 优化&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;loss_sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;step&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;epoch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39; = &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss_sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;当loss收敛后，就完成了训练&lt;/p&gt;
&lt;h2 id=&#34;模型的修改&#34;&gt;模型的修改
&lt;/h2&gt;&lt;p&gt;除了自己的模型，其实也能修改别人训练完的模型&lt;/p&gt;
&lt;p&gt;以此网络为例：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sequential1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Flatten&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 将tensor张成一维张量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sequential2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;classfication&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;网络结构为：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sequential1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dilation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ceil_mode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dilation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ceil_mode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stride&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dilation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ceil_mode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Flatten&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;start_dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;end_dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sequential2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;classfication&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;添加&#34;&gt;添加
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;add_ReLU&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReLU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;Mynn(
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  (sequential1): Sequential(
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (6): Flatten(start_dim=1, end_dim=-1)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (7): Linear(in_features=1024, out_features=64, bias=True)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (8): Linear(in_features=64, out_features=10, bias=True)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  )
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  (sequential2): Linear(in_features=10, out_features=10, bias=True)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  (classficatipm): Sequential(
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (0): Linear(in_features=10, out_features=10, bias=True)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (1): Linear(in_features=10, out_features=10, bias=True)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (2): Linear(in_features=10, out_features=10, bias=True)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  )
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  (add_ReLU): ReLU()
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;修改&#34;&gt;修改
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;classfication&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReLU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;Mynn(
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  (sequential1): Sequential(
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (6): Flatten(start_dim=1, end_dim=-1)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (7): Linear(in_features=1024, out_features=64, bias=True)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (8): Linear(in_features=64, out_features=10, bias=True)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  )
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  (sequential2): Linear(in_features=10, out_features=10, bias=True)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  (classfication): Sequential(
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (0): Linear(in_features=10, out_features=10, bias=True)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (1): ReLU()
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;    (2): Linear(in_features=10, out_features=10, bias=True)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  )
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;  (add_ReLU): ReLU()
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;模型的保存与读取&#34;&gt;模型的保存与读取
&lt;/h2&gt;&lt;h3 id=&#34;save&#34;&gt;save
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;save&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;new_model.pth&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;my_model.pth&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;完整保存了模型的结构与参数，数据量大&lt;/p&gt;
&lt;h3 id=&#34;state_dict官方推荐&#34;&gt;state_dict（官方推荐）
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MyModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 需要保证与读取的模型是同一个类&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 以字典形式进行 更加方便&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;save&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;state_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;model_state_dict1.pth&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;state_dict&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;model_state_dict.pth&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load_state_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;state_dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;gpu训练&#34;&gt;GPU训练
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;损失函数&lt;/li&gt;
&lt;li&gt;数据&lt;/li&gt;
&lt;li&gt;模型&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;三种对象直接&lt;code&gt;x = x.cuda()&lt;/code&gt;即可放入GPU显存&lt;/p&gt;
&lt;p&gt;但是若GPU不存在，此时代码兼容性一般&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;cuda&amp;#34;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cuda&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;is_available&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;cpu&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;更推荐这种写法&lt;/p&gt;
&lt;h2 id=&#34;完整流程&#34;&gt;完整流程
&lt;/h2&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torchvision&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DataLoader&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 导入数据&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;train_set&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datasets&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CIFAR10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;../Dataset&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ToTensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 训练集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test_set&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datasets&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CIFAR10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;../Dataset&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ToTensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 测试集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;train_data_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test_data_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test_set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_data_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test_data_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 生成DataLoader&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;train_loader&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DataLoader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;shuffle&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;drop_last&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;test_loader&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DataLoader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test_set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;shuffle&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;drop_last&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;构建网络&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sequential&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Conv2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out_channels&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kernel_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Flatten&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 将tensor张成一维张量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;初始化&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;optim&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;loss_fn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;optim&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;optim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SGD&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parameters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1e-2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;训练&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.utils.tensorboard&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SummaryWriter&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;writer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SummaryWriter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;logs&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 创建对象 在logs文件夹下保存文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;epochs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;40&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;epochs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;-----------第&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;轮训练-------------&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;train_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;train_step&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;c1&#34;&gt;# 正向推理&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss_fn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;c1&#34;&gt;# 优化&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;optim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zero_grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;optim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;step&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;c1&#34;&gt;# 观察损失函数	&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;train_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;train_step&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;writer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_scalar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Train Loss&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_step&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_step&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;250&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;			&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt; Loss = &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_data_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;c1&#34;&gt;# 测试&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;total_loss&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;c1&#34;&gt;# 上下文管理器：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;c1&#34;&gt;# with 语句是一个上下文管理器，确保在其内部的代码块在启用了 torch.no_grad() 模式下执行。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;c1&#34;&gt;# 一旦代码块执行完毕，上下文管理器会恢复之前的状态，如果之前启用了梯度计算，则重新启用。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;c1&#34;&gt;# torch.no_grad() 纯推理 不需要记录梯度 节省时间&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;no_grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test_loader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;			&lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;			&lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;			
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;			&lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imgs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;			&lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss_fn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;			&lt;span class=&#34;n&#34;&gt;total_loss&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;writer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_scalar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Test Loss&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;total_loss&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test_data_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;测试集Loss = &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;total_loss&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test_data_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;save&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mynn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;./model/train_model&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;.pth&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;writer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;close&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;	 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;​&lt;/p&gt;
</description>
        </item>
        <item>
        <title>cuda编程 · 零</title>
        <link>https://example.com/p/cuda%E7%BC%96%E7%A8%8B-%E9%9B%B6/</link>
        <pubDate>Tue, 02 Apr 2024 20:46:34 +0800</pubDate>
        
        <guid>https://example.com/p/cuda%E7%BC%96%E7%A8%8B-%E9%9B%B6/</guid>
        <description>&lt;h1 id=&#34;cuda编程--零&#34;&gt;cuda编程 · 零
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV17K411K76C/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;蒙特卡洛的树 - Cuda编程Bilibili&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/keefeWu/cuda_learning&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Github: Cuda_Learning&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;基本步骤&#34;&gt;基本步骤
&lt;/h2&gt;&lt;p&gt;在进行运行之前，我们可以先查询一下设备中有多少块GPU&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gpuCount&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;cudaGetDeviceCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gpuCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;%d &amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gpuCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然后可以设置成最后一块显卡的ID&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cudaGetDevice&lt;/code&gt;可以得到当前正在使用的gpu&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gpuCount&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;cudaGetDeviceCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gpuCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;gpuCount = %d&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gpuCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// 1. 指定GPU设别
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;// 单GPU设备其实可以省略此步骤
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;cudaSetDevice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gpuCount&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;devideId&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;cudaGetDevice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;devideId&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;gpu = %d&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;devideId&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;当设置不存在的设备编号时，默认启动0号gpu&lt;/p&gt;
&lt;p&gt;基本步骤如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;stdlib.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;cuda_runtime_api.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__global__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;kernel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;argc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;char&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;argv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gpuCount&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;cudaGetDeviceCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gpuCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;gpuCount = %d&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gpuCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// 1. 指定GPU设别
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;// 单GPU设备其实可以省略此步骤
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;cudaSetDevice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gpuCount&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;devideId&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;cudaGetDevice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;devideId&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;gpu = %d&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;devideId&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// 2. 分配显存空间
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;aGPU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// cudaError_t cudaMalloc(void **devPtr, size_t size);
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;// void **devPtr 指向待分配内存空间指针的指针 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;// 		指针是通用的设备指针，可以指向任何类型的内存
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;// size_t size 分配的内存大小
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;cudaMalloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;aGPU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// 3. 分配内存空间
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// 4. 内存-&amp;gt;显存
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;// cudaError_t cudaMemcpy(void* dst, const void* src, size_t count, cudaMemcpyKind kind)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;// 目的地址, 源地址，需要复制的字节数量， 复制类型
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;        &lt;span class=&#34;c1&#34;&gt;//  cudaMemcpyHostToHost：从主机到主机的内存复制。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;        &lt;span class=&#34;c1&#34;&gt;//  cudaMemcpyHostToDevice：从主机到设备的内存复制。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;        &lt;span class=&#34;c1&#34;&gt;//  cudaMemcpyDeviceToHost：从设备到主机的内存复制。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;        &lt;span class=&#34;c1&#34;&gt;//  cudaMemcpyDeviceToDevice：从设备到设备的内存复制。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;cudaMemcpy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;aGPU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// 5. 设备代码
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;kernel&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;aGPU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// 6. 显存-&amp;gt;内存
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;cudaMemcpy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;aGPU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cudaMemcpyDeviceToHost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;%.2lf &amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// 7. 释放
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;cudaFree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;aGPU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// 释放申请的显存
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;cudaDeviceReset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// 重置设备
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;// 如果主机内存也有申请 也需要释放
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h4 id=&#34;gpu详细信息&#34;&gt;GPU详细信息
&lt;/h4&gt;&lt;p&gt;&lt;code&gt;cudaDeviceProp&lt;/code&gt;是cuda封装的一个显卡信息结构体&lt;/p&gt;
&lt;p&gt;我们可以通过这个结构体查看显卡信息&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;cudaDeviceProp&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// 指定0号显卡
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;cudaGetDeviceProperties&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;maxThreadsPerBLOCK: %d&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;maxThreadsPerBlock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;maxThreadsDim: %d&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;maxThreadsDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;maxGridSize: %d&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;maxGridSize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;totalConstMem: %d&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;totalConstMem&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;clockRate: %d&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;clockRate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;integrated: %d&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;integrated&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;还有一些别的东西&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// 程序可以在多个 CUDA 设备上运行时，可以使用这个函数来选择一个最合适的设备 device会变成被选中的设备编号 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// prop需要填写需求 自动匹配符合要求的设备
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cudaError_t&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cudaChooseDevice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cudaDeviceProp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// 传入一个编号数组和数组长度
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// 只有编号在其中的设备会是有效设备
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cudaError_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cudaSetValidDevices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device_arr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;cuda项目建立&#34;&gt;Cuda项目建立
&lt;/h2&gt;&lt;p&gt;建立项目文件夹，新建&lt;code&gt;CMakeLists.txt&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cmake&#34; data-lang=&#34;cmake&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cmake_minimum_required&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;VERSION&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;3.22&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;project&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;app&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;LANGUAGES&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;CUDA&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;CXX&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;find_package&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;CUDA&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;REQUIRED&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;CUDA_ADD_EXECUTABLE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;app&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;main.cu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;TARGET_LINK_LIBRARIES&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在同文件夹下建立一个&lt;code&gt;main.cu&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;stdlib.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;cuda_runtime_api.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__global__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;add&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;argc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;char&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;argv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bgpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cgpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cudaMalloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cudaMalloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bgpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cudaMalloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cgpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cudaMemcpy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cudaMemcpy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bgpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;c1&#34;&gt;// 加法
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;add&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bgpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cgpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cudaMemcpy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cgpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cudaMemcpyDeviceToHost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;add:&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;%d + %d = %d&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cudaFree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cudaFree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bgpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cudaFree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cgpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;cudaDeviceReset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;新建&lt;code&gt;build&lt;/code&gt;文件夹&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mkdir buid &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; build
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cmake ..
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;make -j3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;./app
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;手写卷积&#34;&gt;手写卷积
&lt;/h2&gt;&lt;p&gt;什么是卷积？&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1Vd4y1e7pj&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;【官方双语】那么……什么是卷积？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;首先需要添加一个新的东西：&lt;code&gt;CUDA_CHECK&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#define CUDA_CHECK(call) \
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;do { \
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;    cudaError_t err = call; \
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;    if (err != cudaSuccess) { \
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;        fprintf(stderr, &amp;#34;CUDA error at %s:%d code=%d(%s) \&amp;#34;%s\&amp;#34;\n&amp;#34;, \
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;                __FILE__, __LINE__, err, cudaGetErrorString(err), #call); \
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;        exit(EXIT_FAILURE); \
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;    } \
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;} while (0)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// 后续我们使用Cuda函数时 用宏进行包装
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// 即可及时报错
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CUDA_CHECK&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cudaMalloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;devPtr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;code见&lt;code&gt;code/src/code_2.cu&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;并行归约parallel-reduction&#34;&gt;并行归约Parallel Reduction
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;我们需要对一个数组进行并行算法的求和&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;交错寻址&#34;&gt;交错寻址
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/cuda%E7%BC%96%E7%A8%8B-%E9%9B%B6/assets/image-20240402123917253.png&#34;
	width=&#34;843&#34;
	height=&#34;459&#34;
	srcset=&#34;https://example.com/p/cuda%E7%BC%96%E7%A8%8B-%E9%9B%B6/assets/image-20240402123917253_hu_43ac0dfedf094112.png 480w, https://example.com/p/cuda%E7%BC%96%E7%A8%8B-%E9%9B%B6/assets/image-20240402123917253_hu_5cbf96bd37116d85.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240402123917253&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;183&#34;
		data-flex-basis=&#34;440px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;两两求和，逐渐合并&lt;/p&gt;
&lt;p&gt;但是这样寻址速度较慢&lt;/p&gt;
&lt;h3 id=&#34;连续地址&#34;&gt;连续地址
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/cuda%E7%BC%96%E7%A8%8B-%E9%9B%B6/assets/image-20240402124057146.png&#34;
	width=&#34;868&#34;
	height=&#34;518&#34;
	srcset=&#34;https://example.com/p/cuda%E7%BC%96%E7%A8%8B-%E9%9B%B6/assets/image-20240402124057146_hu_d005e5e14dbce07b.png 480w, https://example.com/p/cuda%E7%BC%96%E7%A8%8B-%E9%9B%B6/assets/image-20240402124057146_hu_70ee4934d213382b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240402124057146&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;167&#34;
		data-flex-basis=&#34;402px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;code见&lt;code&gt;code/src/code_3.cu&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;程序计时&#34;&gt;程序计时
&lt;/h2&gt;&lt;p&gt;推荐使用&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;sys/time.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;timeval&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;startTime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;endTime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;c1&#34;&gt;// 获取开始时间
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;gettimeofday&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;startTime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// 执行一些操作
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// 获取结束时间
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;gettimeofday&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;endTime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// 计算时间差
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;kt&#34;&gt;long&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;long&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;elapsedTime&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;endTime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tv_sec&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;startTime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tv_sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000000LL&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;endTime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tv_usec&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;startTime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tv_usec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Elapsed time: %lld microseconds&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;elapsedTime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;其中，&lt;code&gt;sys/time.h&lt;/code&gt; 是一个 C 标准库头文件，通常用于在 POSIX 操作系统中进行时间操作，因此在 POSIX 兼容的操作系统上使用时通常是可用的，比如 Linux 和 macOS 等。&lt;/p&gt;
&lt;p&gt;这里我们对手写卷积进行了测速&lt;/p&gt;
&lt;p&gt;code见&lt;code&gt;code/src/code_4.cu&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;并且我们发现，我们一个block一次计算，和一个thread一次计算&lt;/p&gt;
&lt;p&gt;效率基本一致&lt;/p&gt;
&lt;p&gt;并且放在thread可以共享内存，所以推荐放在thread里&lt;/p&gt;
&lt;h2 id=&#34;原子操作&#34;&gt;原子操作
&lt;/h2&gt;&lt;p&gt;原子操作是一种&lt;strong&gt;不可分割&lt;/strong&gt;的操作，它要么完全执行，要么完全不执行，没有中间状态。&lt;/p&gt;
&lt;p&gt;在并发编程中，原子操作是一种&lt;strong&gt;确保多个线程或进程安全访问共享资源&lt;/strong&gt;的机制。&lt;/p&gt;
&lt;p&gt;原子操作能够保证在多线程环境下不会出现数据竞争的情况，从而确保数据的一致性和正确性。&lt;/p&gt;
&lt;p&gt;原子操作的特性包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;不可分割性&lt;/strong&gt;：原子操作是一个不可分割的操作，它要么完全执行，要么完全不执行，不会被中断或分割成更小的部分。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;独占性&lt;/strong&gt;：在原子操作执行期间，其他线程或进程无法访问被操作的资源，直到原子操作执行完成。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;并发安全性&lt;/strong&gt;：多个线程或进程可以同时执行原子操作，而不会导致数据竞争或数据不一致的情况。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;银行转账，当钱被转出时若发生中断，则此时钱就少了&lt;/p&gt;
&lt;p&gt;因此转出和转入必须完整执行完毕&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;实例&#34;&gt;实例
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;统计每种数字出现多少次&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;如果在核函数中&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;hist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;由于会有多个核函数并行操作，每次hist的值都不一致&lt;/p&gt;
&lt;p&gt;会造成值操作的覆盖&lt;/p&gt;
&lt;p&gt;因此引入了&lt;code&gt;atomicAdd()&lt;/code&gt;，自动为数据上锁，在完成一次加法之间，不允许被其他thread使用&lt;/p&gt;
&lt;p&gt;code见&lt;code&gt;code/src/code_5.cu&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;共享内存&#34;&gt;共享内存
&lt;/h2&gt;&lt;p&gt;使用&lt;code&gt;__shared__&lt;/code&gt;进行声明&lt;/p&gt;
&lt;p&gt;同属于一个block的thread共享一个共享内存&lt;/p&gt;
&lt;h3 id=&#34;静态申请&#34;&gt;静态申请
&lt;/h3&gt;&lt;p&gt;如果我们一开始就确定要开多少共享内存数组&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__shared__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__shared__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// N is constexpr
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;动态申请&#34;&gt;动态申请
&lt;/h3&gt;&lt;p&gt;在核函数指定第三个执行配置参数，数值为需要申请的&lt;strong&gt;每个块&lt;/strong&gt;动态共享内存大小&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dynamicReverse&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在核函数内&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;extern&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;__shared__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[];&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// 此时s即为大小为指定值的数组
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;如果需要申请多个共享内存数组&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Kernel&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;g&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nI&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nF&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nC&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;char&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;申请的数值即为所有数组大小之和&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;extern&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;__shared__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;integerData&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                        &lt;span class=&#34;c1&#34;&gt;// nI ints
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;floatData&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;integerData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nI&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// nF floats
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;char&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;charData&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;char&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;floatData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nF&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;      &lt;span class=&#34;c1&#34;&gt;// nC chars
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;手动切割数组即可&lt;/p&gt;
&lt;h2 id=&#34;框架thrust&#34;&gt;框架thrust
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;cuda版本的STL&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;官方地址：https://github.com/NVIDIA/thrust&lt;/p&gt;
&lt;p&gt;记录几个比较简单的例子&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;thrust/host_vector.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;thrust/device_vector.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;c1&#34;&gt;// 在主机内存中申请 大小为10的vector
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;thrust&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;host_vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;auto&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&#34;nl&#34;&gt;e&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cin&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;auto&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&#34;nl&#34;&gt;e&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cout&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;c1&#34;&gt;// 基本和std::vector没什么差别
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;实例估算圆周率&#34;&gt;实例：估算圆周率
&lt;/h2&gt;&lt;p&gt;code见&lt;code&gt;code/src/code_6.cu&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;多个block的归约&#34;&gt;多个block的归约
&lt;/h2&gt;&lt;p&gt;例如我们要进行一个数组求和，但是数组元素个数远远多于线程&lt;/p&gt;
&lt;p&gt;一个block的线程数量有限，一般是1024（看具体设备）&lt;/p&gt;
&lt;p&gt;因此我们需要让多个block进行归约&lt;/p&gt;
&lt;p&gt;（估算圆周率的实例中，我们使用了1个block进行归约）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把数据切分为若干段，每段数量为总线程数&lt;/li&gt;
&lt;li&gt;第一次先把所有数据读到前总线程数个数字内&lt;/li&gt;
&lt;li&gt;再细分成block num段，每段thread_num个&lt;/li&gt;
&lt;li&gt;分别归约，得到blockNum个数字&lt;/li&gt;
&lt;li&gt;数量不会很多的情况下直接CPU计算，节省硬件传输&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;code见&lt;code&gt;code/src/code_7.cu&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;多维矩阵&#34;&gt;多维矩阵
&lt;/h2&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;size_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;width&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;120&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;height&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a_gpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pitch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;cudaMallocPitch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a_gpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pitch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;height&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;real = %zu&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;pitch = %zu&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;width&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pitch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;cudaFree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a_gpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// 当width*sizeof(float)&amp;lt;=512时 pitch=512
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// 超过512 pitch取最小的512的倍数
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;内存对齐，使得访问效率更高&lt;/p&gt;
&lt;p&gt;但是我们一行该放多少放多少，剩下的空间直接忽略&lt;/p&gt;
&lt;p&gt;暂时先不研究这个，感觉用处不大&lt;/p&gt;
&lt;h2 id=&#34;实例手写全加器&#34;&gt;实例：手写全加器
&lt;/h2&gt;&lt;p&gt;对于串行加法器&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cuda%E7%BC%96%E7%A8%8B-%E9%9B%B6/assets/image-20240405022231427.png&#34;
	width=&#34;521&#34;
	height=&#34;141&#34;
	srcset=&#34;https://example.com/p/cuda%E7%BC%96%E7%A8%8B-%E9%9B%B6/assets/image-20240405022231427_hu_4fca6a541fb284ae.png 480w, https://example.com/p/cuda%E7%BC%96%E7%A8%8B-%E9%9B%B6/assets/image-20240405022231427_hu_386a1dc50d15ea55.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240405022231427&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;369&#34;
		data-flex-basis=&#34;886px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;高位计算需要等待低位的进位&lt;/p&gt;
&lt;p&gt;令$A_i+B_i$的进位结果为$C_i$，计算结果为$S_i$&lt;/p&gt;
&lt;p&gt;则$C_i = 1 $的情况有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$A_i = 1, B_i = 1$同时为1&lt;/li&gt;
&lt;li&gt;$A_i \otimes B_i = 1, C_{i-1} = 1$只有一个1，存在进位1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此$C_i = A_iB_i + (A_i\otimes B_i)C_{i - 1}$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;$+$表示或，$\cdot$表示并&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cuda%E7%BC%96%E7%A8%8B-%E9%9B%B6/assets/image-20240405023017938.png&#34;
	width=&#34;521&#34;
	height=&#34;80&#34;
	srcset=&#34;https://example.com/p/cuda%E7%BC%96%E7%A8%8B-%E9%9B%B6/assets/image-20240405023017938_hu_fb59cecf242d02a0.png 480w, https://example.com/p/cuda%E7%BC%96%E7%A8%8B-%E9%9B%B6/assets/image-20240405023017938_hu_d2732738529ab482.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240405023017938&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;651&#34;
		data-flex-basis=&#34;1563px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;因此我们可以进行多次展开，每次的进位都可以由$C_0$直接确定&lt;/p&gt;
&lt;p&gt;一般来说我们每四位进行并行，然后总体串行即可&lt;/p&gt;
&lt;p&gt;code见&lt;code&gt;code/src/code_8.cu&lt;/code&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>CS231A：Computer Vision, From 3D Reconstruction to Recognition</title>
        <link>https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/</link>
        <pubDate>Tue, 26 Mar 2024 02:45:55 +0800</pubDate>
        
        <guid>https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/</guid>
        <description>&lt;h1 id=&#34;cs231acomputer-vision-from-3d-reconstruction-to-recognition&#34;&gt;CS231A：Computer Vision, From 3D Reconstruction to Recognition
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1LQ4y1r7ps/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1LQ4y1r7ps/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;l2-camera-models&#34;&gt;L2. Camera Models
&lt;/h2&gt;&lt;h3 id=&#34;pinhole-camera小孔成像---摄像机&#34;&gt;pinhole camera（小孔成像 - 摄像机）
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326032639070.png&#34;
	width=&#34;622&#34;
	height=&#34;215&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326032639070_hu_efaebb50cf08f6e0.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326032639070_hu_8ac03921d68d0b49.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326032639070&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;289&#34;
		data-flex-basis=&#34;694px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$f$：定义为相机焦距&lt;/li&gt;
&lt;/ul&gt;
$$
x&#39; = \frac{f}{z}x,y&#39; = \frac{f}{z}y
$$&lt;p&gt;
物理课的小知识&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;小孔越小，透光越少，但是画面清晰&lt;/li&gt;
&lt;li&gt;小孔越大，透光越多，但是画面模糊&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此为了全部都要，引入了Lens（透镜）&lt;/p&gt;
&lt;h3 id=&#34;lenses-and-cameras透镜和相机&#34;&gt;Lenses and Cameras（透镜和相机）
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326033557763.png&#34;
	width=&#34;608&#34;
	height=&#34;196&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326033557763_hu_2549720dc7fbbe79.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326033557763_hu_6b70e7121448f490.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326033557763&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;310&#34;
		data-flex-basis=&#34;744px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;除了通过中心的光线，其他光线都会被折射&lt;/li&gt;
&lt;li&gt;在一定距离，所有入射光线会被折射到图像的一点上&lt;/li&gt;
&lt;li&gt;少于或多于这段距离，光无法聚焦在一个点上（Out of focus）&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;景深（Depth of Field）则是指在摄影或者摄像中，一张图像中能够保持清晰度的距离范围。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326034355319.png&#34;
	width=&#34;561&#34;
	height=&#34;196&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326034355319_hu_19fae6f4fe47ff32.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326034355319_hu_d89771a1ab69b809.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326034355319&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;286&#34;
		data-flex-basis=&#34;686px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;定义参数等效焦距$z&amp;rsquo;=f + z_0$，$z_0$​为像距&lt;/p&gt;
$$
x&#39; = \frac{z&#39;}{z}x,y&#39; = \frac{z&#39;}{z}y
$$&lt;p&gt;
但由于工艺问题，透镜成像的边缘经常发生distortion（畸变）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326034749500.png&#34;
	width=&#34;340&#34;
	height=&#34;266&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326034749500_hu_3f155ab764b14aa1.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326034749500_hu_dbea4dd360a3a6c0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326034749500&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;127&#34;
		data-flex-basis=&#34;306px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;虚线为理想情况&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图1：聚焦偏外，越角落越边缘的图像越偏外&lt;/li&gt;
&lt;li&gt;图2：聚焦偏内，越角落越边缘的图像越偏内&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;the-geometry-of-pinhole-cameras几何&#34;&gt;The Geometry of Pinhole Cameras（几何）
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;只要距离足够，透镜和小孔成像都是同一个数学模型&lt;/p&gt;&lt;/blockquote&gt;
$$
p=\begin{bmatrix}x\\y\\z\end{bmatrix} \to p&#39;=\begin{bmatrix}x&#39;\\y&#39;\end{bmatrix}
$$&lt;p&gt;我们完成了三维世界到二维平面的投影&lt;/p&gt;
&lt;h4 id=&#34;coordinate-systems坐标系&#34;&gt;Coordinate systems（坐标系）
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326035659856.png&#34;
	width=&#34;638&#34;
	height=&#34;195&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326035659856_hu_860394ba096b6334.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326035659856_hu_ad944ccc6586450c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326035659856&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;327&#34;
		data-flex-basis=&#34;785px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Off Set：$(x,y,z)\to(\frac{f}{z}x+c_x,\frac{f}{z}y+c_y)$​
&lt;ul&gt;
&lt;li&gt;$(c_x,c_y)$的存在：相机由于工艺问题，无法保证焦点中心一定在图像中心，因此通过引入参数来进行矫正调整&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;From Metric to Pixels：$(x,y,z)\to(k\frac{f}{z}x+c_x,l\frac{f}{z}y+c_y)$​
&lt;ul&gt;
&lt;li&gt;我们更偏向乘上系数，使得长度单位变成像素（不同的系数解决了像素是长方形的情况）&lt;/li&gt;
&lt;li&gt;所以$(c_x,c_y)$也是像素单位&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当$z$​发生变化时，投影坐标并不是线性变化（倒数），不利于使用线代处理&lt;/p&gt;
&lt;p&gt;同时乘上$z$，会丢失$z$的信息&lt;/p&gt;
&lt;p&gt;因此引入Homogeneous Coordinates（齐次坐标）&lt;/p&gt;
&lt;h4 id=&#34;homogeneous-coordinates齐次坐标&#34;&gt;Homogeneous Coordinates（齐次坐标）
&lt;/h4&gt;$$
(x,y)\to \begin{bmatrix}x\\y\\1\end{bmatrix}
$$&lt;p&gt;我们对点坐标，额外增加一个新的维度（二维变三维，三维变四维）&lt;/p&gt;
$$
\begin{bmatrix}x\\y\\w\end{bmatrix}\to (\frac{x}{w},\frac{y}{w})
$$$$
(x,y,z)\to(k\frac{f}{z}x+c_x,l\frac{f}{z}y+c_y)\\
(x,y,z)\to(\alpha\frac{x}{z}+c_x,\beta\frac{y}{z}+c_y)
$$$$
\begin{bmatrix}
\alpha &amp; 0 &amp; c_x &amp; 0\\
0 &amp; \beta &amp; c_y &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0
\end{bmatrix}
\begin{bmatrix}x\\y\\z\\1\end{bmatrix}=\begin{bmatrix}
\alpha x+c_xz\\\beta y+c_y \\ z
\end{bmatrix}
$$$$
P_h&#39;=MP_h
$$&lt;p&gt;
$z$的信息就能得到很好的保存&lt;/p&gt;
&lt;h4 id=&#34;camera-matrix-k相机内参&#34;&gt;Camera Matrix K（相机内参）
&lt;/h4&gt;$$
M = \begin{bmatrix}
\alpha &amp; 0 &amp; c_x &amp; 0\\
0 &amp; \beta &amp; c_y &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0
\end{bmatrix} = K\begin{bmatrix}I &amp; 0\end{bmatrix}
$$&lt;p&gt;
但由于工艺问题，有时像素平面可能不是一个矩形，而是一个平行四边形，产生了旋转&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326155513409.png&#34;
	width=&#34;233&#34;
	height=&#34;211&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326155513409_hu_522b1a040f8712bc.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326155513409_hu_68975aac683aaccd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326155513409&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;110&#34;
		data-flex-basis=&#34;265px&#34;
	
&gt;&lt;/p&gt;
$$
K=\begin{bmatrix}
\alpha &amp; -\alpha\cot\theta &amp; c_x \\
0 &amp; \frac{\beta}{\sin\theta} &amp; c_y  \\
0 &amp; 0 &amp; 1 
\end{bmatrix}
$$&lt;blockquote&gt;
&lt;p&gt;懒得推导了&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;$\alpha,\beta,\theta,c_x,c_y$共五个自由度&lt;/li&gt;
&lt;li&gt;上三角矩阵&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;world-reference-system世界坐标系&#34;&gt;World Reference System（世界坐标系）
&lt;/h4&gt;&lt;p&gt;我们希望世界坐标系转化为相机坐标系，这里我们依旧使用齐次坐标&lt;/p&gt;
&lt;p&gt;我们先处理二维平面的情况&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;平移Translation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$$
    P&#39;\to\begin{bmatrix}x + t_x\\y + t_y\\1\end{bmatrix} = 
    \begin{bmatrix}
    1 &amp; 0 &amp; t_x\\
    0 &amp; 1 &amp; t_y \\
    0 &amp; 0 &amp; 1\\
    \end{bmatrix} 
    \begin{bmatrix}x \\y \\1\end{bmatrix}
    $$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;缩放Scaling&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;注意是围绕原点进行缩放&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;当$s_x=s_y$时，称为&lt;strong&gt;相似变换&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
$$
    P&#39;\to\begin{bmatrix}s_xx\\s_yy\\1\end{bmatrix} = 
    \begin{bmatrix}
    s_x &amp; 0 &amp; 0\\
    0 &amp; s_y &amp; 0 \\
    0 &amp; 0 &amp; 1\\
    \end{bmatrix} 
    \begin{bmatrix}x \\y \\1\end{bmatrix}
    $$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;旋转Rotation&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
$$
    P&#39;\to\begin{bmatrix}x&#39;\\y&#39;\\1\end{bmatrix} = 
    \begin{bmatrix}
    \cos\theta &amp; -\sin\theta &amp; 0\\
    \sin\theta &amp; \cos\theta &amp; 0 \\
    0 &amp; 0 &amp; 1\\
    \end{bmatrix} 
    \begin{bmatrix}x \\y \\1\end{bmatrix}
$$&lt;ul&gt;
&lt;li&gt;同样是围绕原点进行旋转&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可以组合上述的矩阵：同时进行平移缩放旋转&lt;/p&gt;
&lt;p&gt;即对$P$先后进行变换矩阵的左乘即可&lt;/p&gt;
&lt;p&gt;对于三维情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;平移Translation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$$
    P&#39;\to\begin{bmatrix}
    I &amp; T\\
    0 &amp; 1
    \end{bmatrix} 
    \begin{bmatrix}x \\y \\z \\1\end{bmatrix}
    $$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;缩放Scaling&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$$
    P&#39;\to
    \begin{bmatrix}
    S &amp; 0\\
    0 &amp; 1
    \end{bmatrix} 
    \begin{bmatrix}x \\y \\z\\1\end{bmatrix}
    $$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;旋转Rotation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;绕x轴旋转$\alpha$，绕y轴旋转$\beta$，绕z轴旋转$\gamma$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
$$
 R_x(\alpha)=
\begin{bmatrix}
1 &amp;0&amp;0\\
0 &amp; \cos\alpha &amp; -\sin\alpha \\
0 &amp; \sin\alpha &amp; \cos\alpha  \\
\end{bmatrix} \\
R_y(\beta)=\begin{bmatrix}
\cos\beta &amp; 0 &amp; -\sin\beta\\
0 &amp;1&amp;0\\
\sin\beta  &amp; 0&amp; \cos\beta  \\
\end{bmatrix} \\
R_z(\gamma)=\begin{bmatrix}
\cos\gamma&amp; -\sin\gamma &amp; 0 \\
\sin\gamma &amp; \cos\gamma  &amp; 0\\
0 &amp;0&amp;1\\
\end{bmatrix}
$$&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;任意绕轴旋转都可以进行分解成绕三轴先后旋转&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$R = R_x(\alpha)R_y(\beta)R_z(\gamma)$，合成三个矩阵&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
$$
    P&#39;\to
    \begin{bmatrix}
    R &amp; 0\\
    0 &amp; 1
    \end{bmatrix} 
    \begin{bmatrix}x \\y \\z\\1\end{bmatrix}
    $$&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在这里，我们一般不考虑缩放（刚体是不会缩放的）&lt;/p&gt;
$$
P&#39; \to \begin{bmatrix}R &amp; T \\ 0 &amp; 1\end{bmatrix}
$$&lt;p&gt;
即可完成旋转后，再平移&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326193012179.png&#34;
	width=&#34;632&#34;
	height=&#34;193&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326193012179_hu_cfbbdca8fed1234b.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326193012179_hu_c96fb118b54057f4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326193012179&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;327&#34;
		data-flex-basis=&#34;785px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从世界坐标系，通过$R,T$转化到相机坐标系&lt;/li&gt;
&lt;li&gt;从相机坐标系通过投影，转化为图像坐标系&lt;/li&gt;
&lt;/ul&gt;
$$
P&#39;=K\begin{bmatrix}I &amp; 0\end{bmatrix}P=K\begin{bmatrix}I &amp; 0\end{bmatrix}\begin{bmatrix}R &amp; T \\ 0 &amp; 1\end{bmatrix}P_w\\
P&#39;=K\begin{bmatrix}R &amp; T\end{bmatrix}P_w
$$&lt;p&gt;
其中$\begin{bmatrix}R &amp;amp; T\end{bmatrix}$被称为外参数&lt;/p&gt;
&lt;h5 id=&#34;weak-perspective-projection弱透视投影&#34;&gt;Weak Perspective Projection（弱透视投影）
&lt;/h5&gt;&lt;p&gt;当物体离相机足够远时，深度$z$其实可以近似为一个常数$z_0$，从而简化计算&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240328195920736.png&#34;
	width=&#34;986&#34;
	height=&#34;447&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240328195920736_hu_39c66bde6fb3f5f1.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240328195920736_hu_82958602ef591119.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240328195920736&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;220&#34;
		data-flex-basis=&#34;529px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;l8-fitting-and-matching&#34;&gt;L8: Fitting and Matching
&lt;/h2&gt;&lt;h3 id=&#34;fitting&#34;&gt;Fitting
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Choose a parametric model to fit a certain quantity from data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Estimate model parameters&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;critical-issues&#34;&gt;Critical issues
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;noisy data
&lt;ul&gt;
&lt;li&gt;数据中存在的随机误差或不确定性，测量、记录或传输过程中的各种因素引起&lt;/li&gt;
&lt;li&gt;对整体趋势影响较小&lt;/li&gt;
&lt;li&gt;处理噪声数据的方法包括平滑技术（如移动平均）、滤波方法、数据清洗等&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;outliers
&lt;ul&gt;
&lt;li&gt;数据集中与其他观测值&lt;strong&gt;明显不同&lt;/strong&gt;的值，测量错误、录入错误、实际现象的稀有事件&lt;/li&gt;
&lt;li&gt;具有明显的偏离，可能对分析结果产生较大的影响&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;missing data&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;techniques&#34;&gt;Techniques
&lt;/h4&gt;&lt;p&gt;目标：拟合点集$(x_i,y_i)$&lt;/p&gt;
&lt;h5 id=&#34;least-square-methods最小二乘法&#34;&gt;Least Square methods（最小二乘法）
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;直线模型：$y-mx-b = 0$&lt;/li&gt;
&lt;li&gt;找到$(m,b)$使得最小化误差$E = \sum(y_i-mx_i-b)^2$&lt;/li&gt;
&lt;/ul&gt;
$$
E = \sum(y_i-\begin{bmatrix}
x_i  &amp; 1
\end{bmatrix}
\begin{bmatrix}
  m\\b
\end{bmatrix})^2 \\
= \left \| \begin{bmatrix}
y_1  \\ ... \\ y_n
\end{bmatrix}- \begin{bmatrix}
x_1 &amp; 1 \\ ... &amp; 1\\ x_n &amp; 1
\end{bmatrix} \begin{bmatrix}
m \\ b
\end{bmatrix}\right \| ^2 \\
= \left \| Y - Xh \right \| ^2 \\
= (Y-Xh)^T(Y-Xh) \\
= Y^TY-2(Xh)^TY+(Xh)^TXh
$$&lt;p&gt;对$h$求导&lt;/p&gt;
$$
\frac{dE}{dh} = -2X^TY+2X^TXh=0
$$$$
h = (X^TX)^{-1}X^TY
$$&lt;p&gt;
但是这样是&lt;strong&gt;代数意义&lt;/strong&gt;上的最优解&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022250550.png&#34;
	width=&#34;1066&#34;
	height=&#34;882&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022250550_hu_ea26c5e7384b3a53.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022250550_hu_8fcd8001d050c35.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022250550&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;120&#34;
		data-flex-basis=&#34;290px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;考虑几何意义上的最优解：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022302839.png&#34;
	width=&#34;1089&#34;
	height=&#34;815&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022302839_hu_56efd3c2190f319c.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022302839_hu_167c22badd3abbc0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022302839&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
$$
dis=\frac{|ax+by+d|}{\sqrt{a^2+b^2}}
$$&lt;p&gt;
我们可以$a,b$的存在表示了斜率，因此我们可以通过类似归一化的操作，使得$\sqrt{a^2+b^2}$为1，或者为一个定值&lt;/p&gt;
&lt;p&gt;因此我们事实上只需要关心$|ax+by+d|$，代表了相对大小，不需要具体的真实值&lt;/p&gt;
&lt;p&gt;故定义：$E = \sum |ax+by+d|^2$&lt;/p&gt;
&lt;p&gt;我们需要寻找最优的$(a,b,d)$&lt;/p&gt;
&lt;p&gt;令矩阵&lt;/p&gt;
$$
A = \begin{bmatrix}
 x_1 &amp; y_1 &amp; 1 \\ x_2 &amp; y_2 &amp; 1 \\ ...&amp;...&amp;...\\x_n&amp;y_n&amp;1\end{bmatrix}\\
 h = \begin{bmatrix}
a\\b\\d\end{bmatrix}
$$&lt;p&gt;则问题转化为：最小化 $||Ah||$，并且限制$||h|| = 1$&lt;/p&gt;
&lt;p&gt;使用&lt;strong&gt;SVD分解&lt;/strong&gt;即可完成优化问题（留坑待填）&lt;/p&gt;
&lt;p&gt;最后：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;噪声：鲁棒的&lt;/li&gt;
&lt;li&gt;外点：影响巨大&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022314924.png&#34;
	width=&#34;1494&#34;
	height=&#34;634&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022314924_hu_c4c27030d0b11f52.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022314924_hu_8145b20ae8bfdea0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022314924&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;235&#34;
		data-flex-basis=&#34;565px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;conclusion: Least Square is not robust w.r.t. outliers.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ldquo;w.r.t.&amp;rdquo; 是英文表达中的缩写，意思是 &amp;ldquo;with respect to&amp;rdquo;，翻译成中文是 &amp;ldquo;关于&amp;rdquo;、&amp;ldquo;针对&amp;rdquo;、&amp;ldquo;就&amp;hellip;而言&amp;rdquo; 等等。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h5 id=&#34;least-squares-robust-estimators-鲁棒估计器&#34;&gt;Least Squares: Robust Estimators （鲁棒估计器）
&lt;/h5&gt;&lt;p&gt;令残差$\mu = ax+by-d$&lt;/p&gt;
$$
\rho(u;\sigma) = \frac{\mu^2}{\sigma^2+\mu^2}
$$&lt;p&gt;
&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022343561.png&#34;
	width=&#34;1207&#34;
	height=&#34;1234&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022343561_hu_80c54b30222ba984.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022343561_hu_60f451972b050627.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022343561&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;97&#34;
		data-flex-basis=&#34;234px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mu$越大，函数值接近1&lt;/li&gt;
&lt;li&gt;$\mu$越小，函数是一个关于$\mu^2$的函数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;较大的残差，原本会极大影响损失函数的值&lt;/p&gt;
&lt;p&gt;通过此方法，我们限制了大残差的贡献，从而降低了对损失函数的影响，故能拟合的鲁棒性提升&lt;/p&gt;
&lt;h5 id=&#34;random-sample-consensusransac&#34;&gt;RANdom SAmple Consensus(RANSAC)
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;假设1：嘈杂的数据不会为任何单一模型投一致的票&lt;/li&gt;
&lt;li&gt;假设2：有足够的数据点来商定一个好的模型&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们定义好阈值$\delta$，与给定直线的距离在阈值范围内的点，被称为内点；否则是外点&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022424569.png&#34;
	width=&#34;1105&#34;
	height=&#34;930&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022424569_hu_8bb8b0a352eb618f.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022424569_hu_c2b58dd1c6fe5e64.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022424569&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;118&#34;
		data-flex-basis=&#34;285px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;算法流程&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;随机选择出需要确定模型的最小数量的点（例如：确定直线需要两个点，因此随机两个点）&lt;/li&gt;
&lt;li&gt;对于随机选出的点，计算出模型&lt;/li&gt;
&lt;li&gt;计算出内点和外点&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;重复多次，外点数量最小的模型即为我们需要的&lt;/p&gt;
&lt;p&gt;因此我们比较好奇重复多少次可以基本保证能找到最优解&lt;/p&gt;
&lt;p&gt;设重复次数为$N$，算法成功概率为$p$（一般取0.99），$e$表示内点数量与点数之比，$s$表示采样点的数量&lt;/p&gt;
$$
1-p = (1-e^s)^N
$$$$
N = \frac{\log (1-p)}{\log (1-e^s)}
$$&lt;p&gt;
&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022438387.png&#34;
	width=&#34;1653&#34;
	height=&#34;545&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022438387_hu_52b28d76fea94918.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022438387_hu_f754c0fb80960ca9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022438387&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;303&#34;
		data-flex-basis=&#34;727px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;不管是需要采样的点变多，还是内点比例下降，都会使得次数增加&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;conclusion: Cannot be used if ratio inliers is too small&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;但对于大部分场景，外点是占较大部分的，因此很难使用&lt;/p&gt;
&lt;h5 id=&#34;hough-transform霍夫变换&#34;&gt;Hough transform(霍夫变换)
&lt;/h5&gt;&lt;p&gt;设一条直线：$y=mx+n$，其中$(x_i,y_i)$是该直线上一点&lt;/p&gt;
&lt;p&gt;我们考虑将$m,n$看作自变量与因变量：$n = -x_im-y_i$&lt;/p&gt;
&lt;p&gt;因此我们得到了&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022447459.png&#34;
	width=&#34;1417&#34;
	height=&#34;593&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022447459_hu_c52c9bb3ef21a383.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022447459_hu_508b964d7d915c2a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022447459&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;238&#34;
		data-flex-basis=&#34;573px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;经过霍夫变换后得到的被称为是霍夫空间&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;笛卡尔坐标系中的一个点，对应霍夫空间中的一条直线&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022457114.png&#34;
	width=&#34;1307&#34;
	height=&#34;519&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022457114_hu_6d682975f63f8fd.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022457114_hu_ed406c6eceb4432.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022457114&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;251&#34;
		data-flex-basis=&#34;604px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;同理，&lt;strong&gt;笛卡尔坐标系中的一条直线，对应霍夫空间中的一个点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022513705.png&#34;
	width=&#34;1826&#34;
	height=&#34;568&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022513705_hu_ce7972da00d8463.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022513705_hu_8d54b6de437ca92e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022513705&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;321&#34;
		data-flex-basis=&#34;771px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;因此在笛卡尔坐标系中，同一直线上的点，其在霍夫空间中将交于同一点&lt;/p&gt;
&lt;p&gt;理论上我们只需要知道哪些点被投票得最多，这条直线就是我们需要的&lt;/p&gt;
&lt;p&gt;但问题还很多：&lt;strong&gt;我们无法表示垂直的线&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;考虑切换为&lt;strong&gt;极坐标系&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022522360.png&#34;
	width=&#34;1557&#34;
	height=&#34;639&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022522360_hu_6295ba1bd4f2ee00.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022522360_hu_59a4f44a950135a6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022522360&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;243&#34;
		data-flex-basis=&#34;584px&#34;
	
&gt;&lt;/p&gt;
$$
x\cos\theta +y\sin\theta = \rho
$$&lt;p&gt;
&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022532822.png&#34;
	width=&#34;1581&#34;
	height=&#34;745&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022532822_hu_cfd5ad4322699b8a.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022532822_hu_44c15c8d9fc7f123.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022532822&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;212&#34;
		data-flex-basis=&#34;509px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;我们将霍夫空间看作一个网格&lt;/p&gt;
&lt;p&gt;其中高度为原图像对角线长度（$\rho$的最大值），宽度为$\theta$的最大值$2\pi$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022542627.png&#34;
	width=&#34;1086&#34;
	height=&#34;914&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022542627_hu_6729ac3eae5a4497.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022542627_hu_b2774d67ce126a12.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022542627&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;118&#34;
		data-flex-basis=&#34;285px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;枚举网格点，估计一下其中的交点数量&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对于高维数据非常难以处理&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;l9-detectors-and-descriptors&#34;&gt;L9. Detectors and descriptors
&lt;/h2&gt;&lt;h3 id=&#34;detectors&#34;&gt;Detectors
&lt;/h3&gt;&lt;h4 id=&#34;edge-detectors&#34;&gt;Edge detectors
&lt;/h4&gt;&lt;h5 id=&#34;edge产生的要素&#34;&gt;Edge产生的要素
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;深度&lt;/strong&gt;不连续性&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;表面方向&lt;/strong&gt;不连续性（物体表面不同部分的朝向或法线方向发生突然变化）&lt;/li&gt;
&lt;li&gt;反射率不连续性（即，表面材料性质的变化、颜色）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;光照&lt;/strong&gt;不连续性（例如，高光; 阴影）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;边缘检测的例子&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022552308.png&#34;
	width=&#34;586&#34;
	height=&#34;573&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022552308_hu_dd9253ef1936c03e.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022552308_hu_c4c6cd259ad7982e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022552308&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;102&#34;
		data-flex-basis=&#34;245px&#34;
	
&gt;&lt;/p&gt;
&lt;h5 id=&#34;检测标准&#34;&gt;检测标准
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;Good detection accuracy：不误检测噪声，漏检测真实边缘&lt;/li&gt;
&lt;li&gt;Good localization：检测边缘应该尽可能接近真实边缘&lt;/li&gt;
&lt;li&gt;Single response constraint：单一的回应&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022559357.png&#34;
	width=&#34;952&#34;
	height=&#34;504&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022559357_hu_3bb5856a04f766aa.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022559357_hu_7011cb969efe27e1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022559357&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;188&#34;
		data-flex-basis=&#34;453px&#34;
	
&gt;&lt;/p&gt;
&lt;h5 id=&#34;detectors的设计&#34;&gt;Detectors的设计
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;使用导数，定义了梯度较高（也就是变化较为激烈）的地方&lt;/li&gt;
&lt;li&gt;对图像进行了平滑处理，提取导数之前减少噪音&lt;/li&gt;
&lt;/ul&gt;
$$
\frac{df}{dx} = f_x - f_{x-1}
$$&lt;p&gt;
因为是离散的，所以单位长度是一个像素，我们对一个像素作一个差值就是变化率，即导数&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022607900.png&#34;
	width=&#34;976&#34;
	height=&#34;231&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022607900_hu_d931fa5ed9a52085.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022607900_hu_e56162696d6afb2d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022607900&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;422&#34;
		data-flex-basis=&#34;1014px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;考虑如上的一个图像，我们若直接求出导数图像，你会发现并没有特别显著的大导数&lt;/p&gt;
&lt;p&gt;原因是本身图像的波动大概就是5左右，而上升部分的差值也差不多是5&lt;/p&gt;
&lt;p&gt;所以你会发现导数基本都一样&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022615022.png&#34;
	width=&#34;1111&#34;
	height=&#34;523&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022615022_hu_8915f4b7694c7926.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022615022_hu_2e83d6200424dbd4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022615022&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;212&#34;
		data-flex-basis=&#34;509px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;因此我们使用高斯模糊的卷积核进行平滑处理&lt;/p&gt;
$$
S = \bigtriangledown(g\ast I) = (\bigtriangledown g)\ast I \\ =  \begin{bmatrix}
 \frac{\partial  g}{\partial  x} \\
 \frac{\partial  g}{\partial  y}
\end{bmatrix}\ast I = \begin{bmatrix}
g_x\ast I \\
 g_y\ast I
\end{bmatrix} \\
= \begin{bmatrix}
S_x &amp; S_y
\end{bmatrix}
$$&lt;h4 id=&#34;cornerblob-detectors&#34;&gt;Corner/blob detectors
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;可重复性&lt;/strong&gt;：尽管存在几何和光度变换，但同一特征可以在多幅图像中被找到。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;显著性&lt;/strong&gt;：每个特征都位于图像的“有趣”区域。（反正基本不是空白区域）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;局部性&lt;/strong&gt;：一个特征占据图像的“相对较小”区域。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;harris-corner-detector&#34;&gt;Harris corner detector
&lt;/h5&gt;&lt;p&gt;在窗口位置变化时探索窗口内的&lt;strong&gt;强度变化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022623347.png&#34;
	width=&#34;1282&#34;
	height=&#34;441&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022623347_hu_b6db5bd0224e4628.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022623347_hu_e1857047c55be46d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022623347&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;290&#34;
		data-flex-basis=&#34;697px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;flat：在所有方向上都没有变化&lt;/li&gt;
&lt;li&gt;edge：沿着边缘方向没有变化&lt;/li&gt;
&lt;li&gt;corner：在&lt;strong&gt;所有方向&lt;/strong&gt;上都有显著变化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022632821.png&#34;
	width=&#34;1319&#34;
	height=&#34;874&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022632821_hu_94886b8847ef9a75.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022632821_hu_8fcf6f8d9d766c47.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022632821&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;362px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我们无法知道corner的尺度变化&lt;/strong&gt;&lt;/p&gt;
&lt;h5 id=&#34;blob-detection&#34;&gt;Blob detection
&lt;/h5&gt;&lt;p&gt;回到边缘探测，我们可以把卷积后的结果的导数&lt;/p&gt;
&lt;p&gt;修改为二阶导&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022643978.png&#34;
	width=&#34;1390&#34;
	height=&#34;327&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022643978_hu_b1d7bb674c30fff1.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022643978_hu_538015615e28b923.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022643978&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;425&#34;
		data-flex-basis=&#34;1020px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;因此我们的高斯算子可以换成拉普拉斯算子（高斯的导数）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022651285.png&#34;
	width=&#34;1220&#34;
	height=&#34;224&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022651285_hu_619768f6ba5c3141.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022651285_hu_26fa020152e6952c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022651285&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;544&#34;
		data-flex-basis=&#34;1307px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;对原图像使用拉普拉斯算子进行处理即可&lt;/p&gt;
&lt;p&gt;因此对于一个比较宽的图形，两侧边缘会分别导出两个波动&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022658579.png&#34;
	width=&#34;1138&#34;
	height=&#34;286&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022658579_hu_736f5d6c0583a334.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022658579_hu_88c53341e8c6653.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022658579&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;397&#34;
		data-flex-basis=&#34;954px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;我们先尝试固定拉普拉斯算子，当图形宽度变化时&lt;/p&gt;
&lt;p&gt;某种情况下，两个波动会融合在一起，并且幅度最大值取在了图形中央&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022705631.png&#34;
	width=&#34;1452&#34;
	height=&#34;657&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022705631_hu_c25616eb9271c440.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022705631_hu_a3f856808087a3d4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022705631&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;221&#34;
		data-flex-basis=&#34;530px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;所以我们调一下参数，就可以找到幅度最大的点，从而估计出&lt;strong&gt;尺度大小&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022712160.png&#34;
	width=&#34;1322&#34;
	height=&#34;558&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022712160_hu_9b2b9afcc26f67d3.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022712160_hu_b514d7a41245bccc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022712160&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;236&#34;
		data-flex-basis=&#34;568px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;并且对于半径为$r$的圆，取到最大值的参数是可以计算的&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022719594.png&#34;
	width=&#34;946&#34;
	height=&#34;444&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022719594_hu_79df132facd27b87.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022719594_hu_8eb90fbc300a3c8d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022719594&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;213&#34;
		data-flex-basis=&#34;511px&#34;
	
&gt;&lt;/p&gt;
&lt;h5 id=&#34;dog&#34;&gt;DoG
&lt;/h5&gt;&lt;p&gt;高斯差分，你只需知道这个算子会更常用一点&lt;/p&gt;
&lt;h3 id=&#34;descriptors&#34;&gt;Descriptors
&lt;/h3&gt;&lt;p&gt;描述信息一般需要：&lt;/p&gt;
&lt;p&gt;特征保证&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;光照不变性（Invariant w.r.t Illumination）&lt;/strong&gt;：特征应该不受光照变化的影响。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;姿势不变性（Invariant w.r.t Pose）&lt;/strong&gt;：特征应该不受物体姿势变化的影响。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;尺度不变性（Invariant w.r.t Scale）&lt;/strong&gt;：特征应该不受尺度变化的影响。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;类内变异不变性（Invariant w.r.t Intraclass variability）&lt;/strong&gt;：特征应该能够在相同类别的不同实例之间保持稳定性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;特征要有&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;高度独特性（Highly distinctive）&lt;/strong&gt;：特征应该具有足够的独特性，以便在大型特征数据库中能够以高概率找到其正确匹配的特征。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;simplest-descriptor---patch&#34;&gt;Simplest Descriptor - Patch
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;图像中的一个小区域或局部区域，通常由一组相邻像素组成&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;将特征周围的像素$n\times m$的小图片展开为$[1,nm]$大小的一维向量$w$&lt;/p&gt;
$$
w = \frac{w-\bar{w}}{||w-\bar{w}||}
$$&lt;p&gt;
减去均值除以模长&lt;/p&gt;
&lt;p&gt;无论图像的光照条件如何变化，这种归一化保证了描述符的生成不会受到影响，从而增强了描述符的稳定性和可靠性&lt;/p&gt;
&lt;p&gt;缺点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于位置、姿势、尺度和类内变异的小变化敏感&lt;/li&gt;
&lt;li&gt;特征区分度较差&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;filter&#34;&gt;Filter
&lt;/h4&gt;&lt;p&gt;提供卷积核做点事情，然后提取特征&lt;/p&gt;
&lt;p&gt;只能说鲁棒性有所提升&lt;/p&gt;
&lt;h4 id=&#34;sift&#34;&gt;SIFT
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;大致理解即可，并不准确&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;使用DoG确定位置和特征尺度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于一个$N\times N$的窗口，我们对每个像素计算梯度&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022731222.png&#34;
	width=&#34;521&#34;
	height=&#34;473&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022731222_hu_cc18e1bcefc1aecb.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022731222_hu_19407029f81e9fc8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022731222&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;110&#34;
		data-flex-basis=&#34;264px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;我们把$[0,2\pi]$分成若干份，对所有方向进行计数&lt;/p&gt;
&lt;p&gt;数量最多的即为主方向&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022741296.png&#34;
	width=&#34;1329&#34;
	height=&#34;494&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022741296_hu_5763f0002aab630d.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022741296_hu_e64a24d12e9530b9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022741296&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;269&#34;
		data-flex-basis=&#34;645px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;那么只需要按照主方向的角度进行旋转即可&lt;/p&gt;
&lt;p&gt;打包后得到的向量即为描述符&lt;/p&gt;
&lt;p&gt;显然&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;强度：DoG的归一化、梯度足够处理&lt;/li&gt;
&lt;li&gt;姿势：按照主方向把所有箭头旋转成一样的角度，无视了姿势变化&lt;/li&gt;
&lt;li&gt;尺度：DoG处理完毕&lt;/li&gt;
&lt;li&gt;类内变异：直方图有一定的粗略计算，有一定鲁棒性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022751181.png&#34;
	width=&#34;1272&#34;
	height=&#34;380&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022751181_hu_89ced602842fe642.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022751181_hu_23e6fbf7d6bb0c7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022751181&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;334&#34;
		data-flex-basis=&#34;803px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;l11-visual-recognition&#34;&gt;L11. Visual recognition
&lt;/h2&gt;&lt;h2 id=&#34;数学补坑&#34;&gt;数学补坑
&lt;/h2&gt;&lt;h3 id=&#34;svd分解未完成&#34;&gt;SVD分解（未完成）
&lt;/h3&gt;&lt;h3 id=&#34;卷积&#34;&gt;卷积
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1Vd4y1e7pj&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;【官方双语】那么……什么是卷积？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022801282.png&#34;
	width=&#34;1218&#34;
	height=&#34;857&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022801282_hu_253be7fba8ef9085.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022801282_hu_b902826269466ced.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022801282&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;142&#34;
		data-flex-basis=&#34;341px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;在这里我们主要理解一下离散的情况即可&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022811109.png&#34;
	width=&#34;985&#34;
	height=&#34;898&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022811109_hu_52d23d38c2e65e60.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022811109_hu_f9fd1846fd7ade5b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022811109&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;109&#34;
		data-flex-basis=&#34;263px&#34;
	
&gt;&lt;/p&gt;
$$
P(n) = \sum_{i+j=n}a_ib_j
$$&lt;p&gt;
&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022819009.png&#34;
	width=&#34;1418&#34;
	height=&#34;773&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022819009_hu_eb05afcf21eedfde.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022819009_hu_994932f024e1ff45.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022819009&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;183&#34;
		data-flex-basis=&#34;440px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022828890.png&#34;
	width=&#34;1637&#34;
	height=&#34;891&#34;
	srcset=&#34;https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022828890_hu_99f33e8bebc6449a.png 480w, https://example.com/p/cs231acomputer-vision-from-3d-reconstruction-to-recognition/assets/image-20240326022828890_hu_d87c5b2cfc08e63e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240326022828890&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;183&#34;
		data-flex-basis=&#34;440px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;高斯模糊：&lt;/p&gt;
&lt;p&gt;在二维图像上，使用一个$n\times n$的卷积核，卷积核的值从中心开始符合二维高斯分布，对整个图像的颜色进行加权平均&lt;/p&gt;&lt;/blockquote&gt;
</description>
        </item>
        
    </channel>
</rss>
