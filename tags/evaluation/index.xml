<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Evaluation on BiribiriBird</title>
        <link>http://localhost:1313/tags/evaluation/</link>
        <description>Recent content in Evaluation on BiribiriBird</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>Example Person</copyright>
        <lastBuildDate>Thu, 10 Apr 2025 15:20:18 +0800</lastBuildDate><atom:link href="http://localhost:1313/tags/evaluation/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>大模型评估指南 · 2 自动化基准测试</title>
        <link>http://localhost:1313/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E5%8D%97-2-%E8%87%AA%E5%8A%A8%E5%8C%96%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95/</link>
        <pubDate>Thu, 10 Apr 2025 15:20:18 +0800</pubDate>
        
        <guid>http://localhost:1313/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E5%8D%97-2-%E8%87%AA%E5%8A%A8%E5%8C%96%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;什么是自动化基准测试&#34;&gt;什么是自动化基准测试
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Automated Benchmarks&lt;/strong&gt;是一种通过标准化数据集和指标来量化评估模型性能的方法&lt;/p&gt;
&lt;h3 id=&#34;核心组成&#34;&gt;&lt;strong&gt;核心组成&lt;/strong&gt;
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;数据集（a dataset, made of samples.）&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;包含输入样本（如问题、文本），部分附带参考答案（&amp;ldquo;黄金标准&amp;rdquo;）。&lt;/li&gt;
&lt;li&gt;需覆盖多样场景，例如测试分类任务时需包含边缘案例&lt;code&gt;hard edge cases&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估指标（a metric）&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;根据模型输出打分，常见方式：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;生成式评估&lt;/strong&gt;：直接比对模型生成的文本（如翻译、问答）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;概率式评估&lt;/strong&gt;：通过模型对选项的log概率（如MCQA、困惑度）评分。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;关键特点&#34;&gt;&lt;strong&gt;关键特点&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;一致性和可复现性&lt;/strong&gt;Consistency、reproducibility：相同测试多次运行结果稳定。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;低成本可扩展&lt;/strong&gt;：适合大规模模型评估。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;易解释&lt;/strong&gt;：如准确率、完全匹配等指标直观。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;局限性&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;复杂任务难量化&lt;/strong&gt;：例如“数学能力”需拆解为子任务（算术/逻辑等）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据污染风险&lt;/strong&gt;：公开数据集可能被模型训练时“见过”，导致分数虚高（过拟合）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;典型场景&#34;&gt;&lt;strong&gt;典型场景&lt;/strong&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;测试模型在&lt;strong&gt;新数据&lt;/strong&gt;上的泛化能力（如训练时未接触的医疗垃圾邮件分类）。&lt;/li&gt;
&lt;li&gt;避免过拟合：若模型仅死记训练数据（如学生背题），则测试失效。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;设计自动化评估方案&#34;&gt;设计自动化评估方案
&lt;/h2&gt;&lt;h3 id=&#34;数据集&#34;&gt;数据集
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;it&amp;rsquo;s very important to keep in mind that &lt;strong&gt;your evaluation result will only be as good as your evaluation dataset.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;评估结果的质量完全取决于评估数据集的质量。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;已有的数据集&#34;&gt;已有的数据集
&lt;/h4&gt;&lt;p&gt;检查创建过程&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;创建者：专家创建 &amp;gt; 有偿标注者创建 ~ 众包数据 &amp;gt; 公开平台野生数据集
&lt;ul&gt;
&lt;li&gt;注重&lt;code&gt;data card&lt;/code&gt;，标注者的人口统计信息可以帮助了解数据集的语言多样性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;是否经过审查（否则容易出现拼写错误、语法错误、荒谬答案）
&lt;ul&gt;
&lt;li&gt;标注意见一致&lt;/li&gt;
&lt;li&gt;作者是否检查过&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;是否有明确的数据创建指南
&lt;ul&gt;
&lt;li&gt;确保数据具有一致性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;样本抽查：随机取50样本进行人工检查&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;质量
&lt;ul&gt;
&lt;li&gt;prompts清晰、无歧义&lt;/li&gt;
&lt;li&gt;答案正确&lt;/li&gt;
&lt;li&gt;是否缺失信息&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;任务相关
&lt;ul&gt;
&lt;li&gt;与希望评估的任务类型一致&lt;/li&gt;
&lt;li&gt;场景相关&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;确保总数据的数量符合要求&lt;/p&gt;
&lt;h4 id=&#34;自行创建数据集&#34;&gt;自行创建数据集
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;聚合&lt;/strong&gt;：聚合不同来源的现有数据来评估任务相关能力。许多评估数据集（如MATH、LSAT等）就是通过聚合人类评估数据集构建的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;人工标注&lt;/strong&gt;：见&lt;code&gt;human-evaluation/using-human-annotators&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;合成数据&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;LLM：可参考&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/blog/cosmopedia&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Cosmopedia: how to create large-scale synthetic data for pre-training Large Language Models&lt;/a&gt;，务必随后人工检查/过滤/验证数据集（遵循上述步骤）&lt;/li&gt;
&lt;li&gt;基于规则的技术：如任务允许，这是获得近乎无限样本且避免污染的绝佳方式
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2312.14890&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2309.17167&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2309.17167https://arxiv.org/abs/2310.16049&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt; Article identifier not recognized&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;推理方法&#34;&gt;推理方法
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;生成模型：侧重生成连贯文本，其核心是预测下一个 token 的概率分布。&lt;/li&gt;
&lt;li&gt;推理模型：通过引导模型输出中间思考步骤，再得出最终答案 。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;对数概率推理log-probabilities&#34;&gt;对数概率推理log-probabilities
&lt;/h4&gt;&lt;p&gt;适用于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;封闭式&lt;/strong&gt;任务：多项选择题(MCQA, multi-choice question answer)、判断题&lt;/li&gt;
&lt;li&gt;典型用例：知识问答测试、校准能力评估&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;原理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将问题与选项拼接为固定模板（如&amp;quot;问题：&amp;hellip; 选项：A.xx B.xx&amp;hellip;&amp;quot;）&lt;/li&gt;
&lt;li&gt;计算模型对每个选项首字母（如A/B/C）的预测概率&lt;/li&gt;
&lt;li&gt;选择概率最高的选项作为答案&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;快速计算（只需要1个token的输出）&lt;/li&gt;
&lt;li&gt;避免生成无关内容&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;劣势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;选项顺序有一定影响&lt;/li&gt;
&lt;li&gt;高估小模型的能力、没有推理过程&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;生成式推理generative&#34;&gt;生成式推理generative
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;开放式&lt;/strong&gt;任务：问答、文本创作、复杂推理&lt;/li&gt;
&lt;li&gt;典型用例：聊天机器人、编程助手、论文润色&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;原理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入问题或指令（如&amp;quot;解释相对论&amp;quot;）&lt;/li&gt;
&lt;li&gt;模型自由生成完整文本回答&lt;/li&gt;
&lt;li&gt;通过人工或自动指标（如ROUGE）评估质量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;反映真实应用水平&lt;/li&gt;
&lt;li&gt;支持多轮交互&lt;/li&gt;
&lt;li&gt;展现逻辑链能力&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;劣势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;评估指标设计复杂&lt;/li&gt;
&lt;li&gt;计算成本高（尤其长文本）&lt;/li&gt;
&lt;li&gt;可能生成冗余/错误内容&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;综上：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;维度&lt;/th&gt;
          &lt;th&gt;对数概率推理优先&lt;/th&gt;
          &lt;th&gt;生成式推理优先&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;任务类型&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;封闭式选择题&lt;/td&gt;
          &lt;td&gt;开放式创作/推理&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;评估速度&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;需快速批量测试时&lt;/td&gt;
          &lt;td&gt;可接受延迟的精细评估&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;模型规模&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;小模型（&amp;lt;10B参数）&lt;/td&gt;
          &lt;td&gt;大模型（&amp;gt;50B参数）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;资源限制&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;计算资源有限&lt;/td&gt;
          &lt;td&gt;具备充足GPU显存&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;核心目标&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;测试知识准确性&lt;/td&gt;
          &lt;td&gt;测试综合生成能力&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;提示词&#34;&gt;提示词
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;给模型传达了多少任务信息&lt;/li&gt;
&lt;li&gt;信息的表达方式如何&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MCQA 或 QA 的提示词通常包括以下部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;任务说明（可选）：介绍任务&lt;/li&gt;
&lt;li&gt;上下文（context）：提供题目的背景信息
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;例：摘要任务中提供原始文本，信息抽取任务中提供源内容&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;问题本身&lt;/li&gt;
&lt;li&gt;如果是多项选择题，附带选项&lt;/li&gt;
&lt;li&gt;一些连接词，如 &lt;code&gt;Question&lt;/code&gt;、&lt;code&gt;Context&lt;/code&gt;、&lt;code&gt;Choice&lt;/code&gt; 等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意事项：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;即使语义相同的小改动，也可能导致模型结果波动较大（&lt;code&gt;troubleshooting/troubleshooting-reproducibility&lt;/code&gt;）
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;缓解方式&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;更高成本：用不同提示格式重复评估&lt;/li&gt;
&lt;li&gt;更低成本：对等难度样本使用不同提示模板&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;你可以为模型**提供示例（few-shot）**来帮助它理解格式，&lt;strong&gt;连接词&lt;/strong&gt;也很有帮助&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2407.07890&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt; Training on the Test Task Confounds Evaluation and Emergence&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;现在模型往往过拟合某些提示格式&lt;/p&gt;
&lt;p&gt;在 Open LLM Leaderboard 2 中，发现 Llama 3.2 和 Qwen 2.5 在 few-shot 情境下甚至不再遵循提示格式&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;某些评估指标需要非常受限的输出格式（&lt;code&gt;general-knowledge/model-inference-and-evaluation&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;评估指标&#34;&gt;评估指标
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;对数概率评估：准确率
&lt;ul&gt;
&lt;li&gt;需要对长度做归一化（字符、token、PMI）&lt;/li&gt;
&lt;li&gt;也可以用 perplexity（困惑度）、召回率、F1 等补充分析&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;在计算对数概率时，长文本的&lt;strong&gt;累积概率值天然更大&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;若不归一化，模型可能因生成更长（或更短）的选项而获得不公平的优势。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;参考信息：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对于多选题中选项仅为单个字符（A/B/C/D）时仍存在&lt;strong&gt;长文本影响&lt;/strong&gt;的原因及机制解析如下：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;一影响来源&#34;&gt;一、&lt;strong&gt;影响来源&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;即使选项本身是单个字符，实际输入模型的完整文本包含&lt;strong&gt;题干+选项&lt;/strong&gt;的组合。例如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;#34;问题：量子纠缠现象违背了哪个物理定律？选项：A.能量守恒 B.相对论 C.局域实在性 D.热力学第二定律&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;此时模型接收的输入是完整的文本序列，选项字符的预测概率会受到&lt;strong&gt;题干复杂度&lt;/strong&gt;和&lt;strong&gt;上下文语义关联强度&lt;/strong&gt;的影响。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;二具体影响机制&#34;&gt;二、&lt;strong&gt;具体影响机制&lt;/strong&gt;
&lt;/h3&gt;&lt;h4 id=&#34;1-注意力稀释效应&#34;&gt;1. &lt;strong&gt;注意力稀释效应&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;长题干&lt;/strong&gt;导致模型在处理选项时注意力分散，尤其当题干包含复杂术语或长句时，模型可能无法精准捕捉关键信息与选项的关联。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;示例&lt;/em&gt;：&lt;br&gt;
题干若包含200个token的量子物理描述，模型在预测选项时，可能因前文信息过载而降低对正确选项字符的注意力权重。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-概率累积偏差&#34;&gt;2. &lt;strong&gt;概率累积偏差&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;对数概率计算基于&lt;strong&gt;完整输入序列&lt;/strong&gt;的联合概率如下，长题干会增加模型预测路径的分支数，导致选项字符的边际概率产生累积误差。&lt;/li&gt;
&lt;/ul&gt;
$$
&gt;    \log P(\text{选项}| \text{题干}) = \sum_{i=1}^N \log P(\text{token}_i | \text{上下文}) 
&gt;   $$&lt;h4 id=&#34;3-位置编码衰减&#34;&gt;3. &lt;strong&gt;位置编码衰减&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Transformer模型的位置编码对长序列末端的token（如选项字符）表征能力下降，可能削弱模型对选项的逻辑判断能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;三影响表现形式&#34;&gt;三、&lt;strong&gt;影响表现形式&lt;/strong&gt;
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;影响维度&lt;/th&gt;
          &lt;th&gt;具体表现&lt;/th&gt;
          &lt;th&gt;示例场景&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;选项顺序偏差&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;模型对靠后选项（如D）的预测概率系统性偏低&lt;/td&gt;
          &lt;td&gt;题干过长时，模型更倾向优先选项A/B&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;语义干扰&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;题干中的关键词与错误选项产生意外关联&lt;/td&gt;
          &lt;td&gt;题干出现&amp;quot;热力学&amp;quot;导致错误选D的倾向&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;计算稳定性&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;长输入导致概率值波动增大，评估结果方差升高&lt;/td&gt;
          &lt;td&gt;同一问题重复评估时准确率差异显著[1]&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 id=&#34;四解决方案&#34;&gt;四、&lt;strong&gt;解决方案&lt;/strong&gt;
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;输入标准化&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;统一题干长度（如截断至固定token数）&lt;/li&gt;
&lt;li&gt;将选项提前插入题干中间位置（如&amp;quot;[选项：A/B/C/D] 问题：&amp;hellip;&amp;quot;）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;概率校准技术&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用温度缩放（Temperature Scaling）调整输出概率分布&lt;/li&gt;
&lt;li&gt;对长题干任务单独训练校准层&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;评估指标改进&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;引入&lt;strong&gt;长度惩罚因子&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;采用动态加权注意力（Dynamic Weighted Attention）增强选项区域的关注度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
$$
&gt;   \text{Score} = \frac{\log P(\text{选项})}{\sqrt{\text{题干token数}}}
&gt;   $$&lt;hr&gt;
&lt;h3 id=&#34;五实验验证案例&#34;&gt;五、&lt;strong&gt;实验验证案例&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;在MMLU基准测试中，将题干从50token增至300token后：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型对正确选项的平均概率下降12.7%&lt;/li&gt;
&lt;li&gt;选项D的预测频率比短题干时降低9.3%&lt;br&gt;
（数据来源：[4]）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这表明&lt;strong&gt;题干长度&lt;/strong&gt;与&lt;strong&gt;选项预测稳定性&lt;/strong&gt;存在显著负相关。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;点间互信息（PMI, Pointwise Mutual Information）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;计算方式：PMI = log(P(选项)) - log(P(基线))&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基线通常为随机猜测概率（如四选一任务中，基线概率=0.25）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;适用场景&lt;/strong&gt;：多选题（MCQA）中量化选项间的相对置信度差异&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;示例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;若选项A的预测概率为0.6，PMI = log(0.6) - log(0.25) ≈ 0.47&lt;/li&gt;
&lt;li&gt;选项B的预测概率为0.3，PMI = log(0.3) - log(0.25) ≈ 0.04
&lt;em&gt;结果&lt;/em&gt;：PMI明确显示A的置信度显著高于B 。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;生成式评估
&lt;ul&gt;
&lt;li&gt;是否要对生成内容做预处理、归一化
&lt;ul&gt;
&lt;li&gt;若归一化方式设计不当，可能导致不公平评分（详见 &lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/blog/open-llm-leaderboard-drop&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hugging Face 博文&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;某些任务（如数学题）需要从&lt;strong&gt;格式化结果&lt;/strong&gt;中提取答案&lt;/li&gt;
&lt;li&gt;若采用推理链（Chain of Thought）评估，也需移除中间推理部分，仅提取最终答案&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;与参考答案进行对比
&lt;ul&gt;
&lt;li&gt;精确匹配、前缀匹配&lt;/li&gt;
&lt;li&gt;总结/翻译任务中的 ROUGE、BLEU、字符 N-Gram&lt;/li&gt;
&lt;li&gt;参考 Hugging Face 提供的 &lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/lighteval&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;指标列表&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在选择指标时，请牢记你的任务目标。&lt;/p&gt;
&lt;p&gt;如果是医疗、客服等高风险场景，你更应该关注模型的最差表现（例如错误回答、产生有害内容等）。&lt;/p&gt;
&lt;p&gt;推荐阅读 &lt;a class=&#34;link&#34; href=&#34;https://ehudreiter.com/2024/07/10/challenges-in-evaluating-llms/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;这个博客&lt;/a&gt;，它进一步探讨了这一点。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>大模型评估指南 · 1 前言</title>
        <link>http://localhost:1313/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E5%8D%97-1-%E5%89%8D%E8%A8%80/</link>
        <pubDate>Thu, 10 Apr 2025 15:11:40 +0800</pubDate>
        
        <guid>http://localhost:1313/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E5%8D%97-1-%E5%89%8D%E8%A8%80/</guid>
        <description>&lt;p&gt;&lt;code&gt;evaluation-guidebook&lt;/code&gt;是一个关于大语言模型（LLM）评估的指南手册，为不同水平的用户提供了全面的评估知识和实用技巧，帮助用户确保 LLM 在特定任务上表现良好。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;仓库地址：&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;huggingface/evaluation-guidebook: Sharing both practical insights and theoretical knowledge about LLM evaluation that we gathered while managing the Open LLM Leaderboard and designing lighteval!&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;概述&#34;&gt;概述
&lt;/h2&gt;&lt;p&gt;该指南手册涵盖了多种评估模型的方法，提供了设计自定义评估的指导，以及来自实践经验的技巧和窍门。无论是生产模型的使用者、研究人员还是爱好者，都能从中找到所需的信息。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;初学者&lt;/strong&gt;：建议从各章节的 &lt;code&gt;Basics&lt;/code&gt; 部分开始，同时可以在 &lt;code&gt;General knowledge&lt;/code&gt; 中找到关于重要 LLM 主题的解释，如模型推理和分词。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高级用户&lt;/strong&gt;：可以重点关注 &lt;code&gt;Tips and Tricks&lt;/code&gt; 和 &lt;code&gt;Troubleshooting&lt;/code&gt; 章节，以及 &lt;code&gt;Designing&lt;/code&gt; 部分。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;目录结构&#34;&gt;目录结构
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;自动基准测试（Automatic benchmarks）
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/automated-benchmarks/basics.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基础（Basics）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/automated-benchmarks/designing-your-automatic-evaluation.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;设计自动评估（Designing your automatic evaluation）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/automated-benchmarks/some-evaluation-datasets.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一些评估数据集（Some evaluation datasets）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/automated-benchmarks/tips-and-tricks.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;技巧和窍门（Tips and tricks）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;人工评估（Human evaluation）
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/human-evaluation/basics.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基础（Basics）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/human-evaluation/using-human-annotators.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;使用人类标注员（Using human annotators）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/human-evaluation/tips-and-tricks.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;技巧和窍门（Tips and tricks）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;使用大语言模型作为评判者（LLM-as-a-judge）
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/model-as-a-judge/basics.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基础（Basics）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/model-as-a-judge/getting-a-judge-llm.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;获取评判大语言模型（Getting a Judge-LLM）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/model-as-a-judge/designing-your-evaluation-prompt.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;设计评估提示（Designing your evaluation prompt）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/model-as-a-judge/evaluating-your-evaluator.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;评估评估器（Evaluating your evaluator）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/model-as-a-judge/what-about-reward-models.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;奖励模型相关内容（What about reward models）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/model-as-a-judge/tips-and-tricks.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;技巧和窍门（Tips and tricks）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;故障排除（Troubleshooting）
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/troubleshooting/troubleshooting-inference.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;推理故障排除（Troubleshooting inference）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/troubleshooting/troubleshooting-reproducibility.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;可重复性故障排除（Troubleshooting reproducibility）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;通用知识（General knowledge）
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/general-knowledge/model-inference-and-evaluation.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;模型推理和评估（Model inference and evaluation）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/general-knowledge/tokenization.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;分词（Tokenization）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;示例（Examples）
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/evaluation-guidebook/blob/main/contents/examples/comparing_task_formulations.ipynb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;评估期间比较任务表述（Comparing task formulations during evaluation）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        
    </channel>
</rss>
