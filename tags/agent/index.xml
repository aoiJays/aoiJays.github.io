<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Agent on BiribiriBird</title>
        <link>https://example.com/tags/agent/</link>
        <description>Recent content in Agent on BiribiriBird</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>Example Person</copyright>
        <lastBuildDate>Wed, 03 Sep 2025 17:13:34 +0800</lastBuildDate><atom:link href="https://example.com/tags/agent/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>李宏毅机器学习2025 · Agent</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/</link>
        <pubDate>Wed, 03 Sep 2025 17:13:34 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1aiADewEBC&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;李宏毅机器学习2025&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;agent&#34;&gt;Agent
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;传统AI：给定明确步骤、指令，AI完成任务&lt;/p&gt;
&lt;p&gt;Agent：给定目标，由Agent想办法完成&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Agent将通过观察Environment，采取特定的Action&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;强化学习：通过强化学习方法得到的Agent是可行的，但是不具备通用能力（围棋Agent不能处理五子棋）&lt;/li&gt;
&lt;li&gt;LLM：通过文字描述进行交互，具备通用能力&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Goal、Environment1、Action1、Environment2、Action2……&lt;/p&gt;
&lt;p&gt;本质上也是在接龙&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;回合制的交互会比较好做，有时候会需要被实时打断&lt;/p&gt;
&lt;p&gt;即：Action执行时，Environment变化，会需要Agent中断Action，进行新的Action&lt;/p&gt;
&lt;p&gt;常见应用：语音聊天&lt;/p&gt;
&lt;h2 id=&#34;memory&#34;&gt;Memory
&lt;/h2&gt;&lt;p&gt;交互的次数足够多时，记忆量过大，会造成Agent性能下降&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903173912076.png&#34;
	width=&#34;979&#34;
	height=&#34;438&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903173912076_hu_367f3630cccba63d.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903173912076_hu_2b228b5efbfd68d5.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Relevant Experience&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;223&#34;
		data-flex-basis=&#34;536px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;因此针对相关经验做一些记忆的检索和筛选是必要的&lt;/p&gt;
&lt;p&gt;可以直接套RAG的技术&lt;/p&gt;
&lt;p&gt;但这里最好不要提供模型&lt;strong&gt;过去的错误例子&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这里的情景似乎没有做一些纠错任务，给了错误的例子性能会发生下降&lt;/p&gt;
&lt;p&gt;因此设计Agent时需要考虑一下哪些内容是应该提供或筛除的&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;模型的使用技巧：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;告诉模型&lt;strong&gt;应该做什么&lt;/strong&gt;比告诉模型&lt;strong&gt;不要做什么&lt;/strong&gt;效果更好&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903174906691.png&#34;
	width=&#34;996&#34;
	height=&#34;562&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903174906691_hu_f6af179a283dfdc5.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903174906691_hu_821175316e4721a6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;其他模块&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;425px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;从存储角度出发&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;有些记忆没有存储的必要，因此可以引入一个Write模型去分类筛选&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有些记忆可以被格式化、转化成更好、更通用的内容，可以引入Reflection模块做转化，存储到合适的载体中，方便Read去做RAG&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;function-call&#34;&gt;Function Call
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175717235.png&#34;
	width=&#34;914&#34;
	height=&#34;506&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175717235_hu_ed1a5d1a14bada8b.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175717235_hu_e71df3da242a3060.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;180&#34;
		data-flex-basis=&#34;433px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175818476.png&#34;
	width=&#34;917&#34;
	height=&#34;467&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175818476_hu_22c32e30ae66218a.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175818476_hu_5c8473782c8d6e9a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;196&#34;
		data-flex-basis=&#34;471px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;通常会把调用方法、工具列表放在System Prompt中&lt;/p&gt;
&lt;p&gt;让用户通过User Prompt进行交互&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Function过多时，可以参考上述的Memory方法去做选择&lt;/li&gt;
&lt;li&gt;Agent也可以自己做一个Function，放入Memory中&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;Agent有时候会过度相信工具&lt;/p&gt;
&lt;p&gt;因此需要看看模型自己是否有辨别的能力（室温10000°？不对，这里是工具出错了）&lt;/p&gt;
&lt;p&gt;但其实加一个Reflection也不错&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;课堂中探索了哪些信息是容易被模型采纳的&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903180638418.png&#34;
	width=&#34;1004&#34;
	height=&#34;447&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903180638418_hu_288966a3f1308ca0.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903180638418_hu_7fc90cbfb0772e7d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Ex1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;224&#34;
		data-flex-basis=&#34;539px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;当原始上下文逐渐被不切实际的值修改时，LLM（大语言模型）会越来越多地回归到其先验知识&lt;/li&gt;
&lt;li&gt;LLM坚持遵循上下文中检索到的信息的可能性，与其在没有上下文时对自身回复的信心呈负相关。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;省流：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;外部知识如果和模型知识差距越大，模型会对模型知识更有信心；差距越小，模型更愿意相信外部知识&lt;/li&gt;
&lt;li&gt;模型对模型知识的likelihood越大，对外部知识的likelihood越小&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181056340.png&#34;
	width=&#34;980&#34;
	height=&#34;345&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181056340_hu_9337652e32037257.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181056340_hu_4a48cefaca72e4f5.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Ex2&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;284&#34;
		data-flex-basis=&#34;681px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;AI和人类分别给出两个意见不同的文章，AI倾向于相信AI&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ex单独抽取了AI回答错误的例子（排除AI与AI回答类似，造成偏好的情况），但仍然是AI更相信AI&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体原因未知，猜测是AI的文章结构、表达上比人类更好&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2401.11911&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181530086.png&#34;
	width=&#34;992&#34;
	height=&#34;443&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181530086_hu_ce69793f148b679b.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181530086_hu_3f116d49e637459e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Ex3&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;223&#34;
		data-flex-basis=&#34;537px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;（这里首先都是用了AI生成的文章做实验，避免偏好问题，并且文章都是假的）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Meta Data会影响模型的采纳&lt;/li&gt;
&lt;li&gt;其中时间影响较大&lt;/li&gt;
&lt;li&gt;资料来源写Wikipedia还是其他来源，似乎没有什么影响（这里比较反直觉）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是实验做得似乎比较粗糙，看看就好&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;总结：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型总会犯错&lt;/li&gt;
&lt;li&gt;Function Call要不要采用取决模型本身能力，如果模型可以自己解决没必要Call&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;plan&#34;&gt;Plan
&lt;/h2&gt;&lt;p&gt;目前的Agent都喜欢做一个Plan，再开始Action&lt;/p&gt;
&lt;p&gt;但是Plan不能定太死&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;操作浏览器时突然出现一个广告弹窗&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182236824.png&#34;
	width=&#34;1040&#34;
	height=&#34;351&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182236824_hu_655a62e81b69f692.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182236824_hu_9d822b41853c3318.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Plan&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;296&#34;
		data-flex-basis=&#34;711px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;因此Plan需要灵活，一种方案是：每次思考一下Plan要不要重新制定&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;如何强化模型的规划能力？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182925762.png&#34;
	width=&#34;1036&#34;
	height=&#34;530&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182925762_hu_e0ecbc68cec78b03.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182925762_hu_c450aee5b61cfd30.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;搜索与剪枝&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;195&#34;
		data-flex-basis=&#34;469px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;让模型实际去探索一下（本质是搜索）&lt;/li&gt;
&lt;li&gt;可以剪枝（自问自答：当前还有机会完成任务吗？）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（不适合不容易回溯状态的任务，例如：订餐）&lt;/p&gt;
&lt;p&gt;（但是可以引入一个World Model，让模型扮演环境本身去做反馈，模拟）&lt;/p&gt;
&lt;p&gt;从Agent的角度去看待模型Thinking Mode：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903183347542.png&#34;
	width=&#34;1062&#34;
	height=&#34;542&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903183347542_hu_7409da7ba96a6ac5.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903183347542_hu_71f6bd0b8e42b3cb.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Thinking Mode&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;195&#34;
		data-flex-basis=&#34;470px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;一些杂谈：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;做benchmark或一些实验的时候，思考一下这个任务LLM会不会在互联网数据中提前得到&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        
    </channel>
</rss>
