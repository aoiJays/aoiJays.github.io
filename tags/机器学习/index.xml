<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>机器学习 on BiribiriBird</title>
        <link>https://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
        <description>Recent content in 机器学习 on BiribiriBird</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>Example Person</copyright>
        <lastBuildDate>Sun, 11 Aug 2024 18:19:55 +0800</lastBuildDate><atom:link href="https://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>李宏毅机器学习2021 · L5</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/</link>
        <pubDate>Sun, 11 Aug 2024 18:19:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/</guid>
        <description>&lt;h1 id=&#34;l5-sequence-to-sequence&#34;&gt;L5. Sequence to Sequence
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML 2022 Spring (ntu.edu.tw)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1VN4y1P7Zj&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1VN4y1P7Zj&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;输出的长度取决于model&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Speech Recognition：语音到文本&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Machine Translation：文本到文本&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Speech Translation：语音到文本&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Seq2Seq = encoder + decoder&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;encoder：输入-&amp;gt;向量&lt;/li&gt;
&lt;li&gt;decoder：向量-&amp;gt;输出
&lt;ul&gt;
&lt;li&gt;接受encoder的输入，每次输出一个结果，输出的结果会影响下一个输出&lt;/li&gt;
&lt;li&gt;加入&lt;code&gt;&amp;lt;BOS&amp;gt;&lt;/code&gt;表示开始解码，&lt;code&gt;&amp;lt;EOS&amp;gt;&lt;/code&gt;表示结束&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;transformer---encoder&#34;&gt;Transformer - Encoder
&lt;/h2&gt;&lt;h3 id=&#34;block&#34;&gt;Block
&lt;/h3&gt;&lt;p&gt;Encoder内以block为单位&lt;/p&gt;
&lt;p&gt;每个block的设计：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240811211637233.png&#34;
	width=&#34;889&#34;
	height=&#34;674&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240811211637233_hu_55a57da4613ba746.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240811211637233_hu_f6a0922e617a6e3a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240811211637233&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;131&#34;
		data-flex-basis=&#34;316px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;encoder&#34;&gt;Encoder
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240811212043472.png&#34;
	width=&#34;875&#34;
	height=&#34;542&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240811212043472_hu_c192096579cafcb0.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240811212043472_hu_8a828276825b72b1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240811212043472&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;161&#34;
		data-flex-basis=&#34;387px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入需要Position Embedding&lt;/li&gt;
&lt;li&gt;重复N次block&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;这是原始的Transformer结构&lt;/p&gt;
&lt;p&gt;后续发现把LayerNorm放在Attention前和FC前，效果会更好&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;transformer---decoder&#34;&gt;Transformer - Decoder
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;BOS&lt;/code&gt;：Begin of Sentence&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EOS&lt;/code&gt;：End of Sentence&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;输入输出&#34;&gt;输入输出
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812165138109.png&#34;
	width=&#34;1001&#34;
	height=&#34;590&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812165138109_hu_c5d6168ca2a3590c.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812165138109_hu_d1da5003c355a59c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812165138109&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;407px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;结构&#34;&gt;结构
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Transformer的block中，相当于添加了一段新的，其他部分相似&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812165344664.png&#34;
	width=&#34;900&#34;
	height=&#34;782&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812165344664_hu_451be7ad9311e3f2.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812165344664_hu_33e6201df2f9a9d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812165344664&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;115&#34;
		data-flex-basis=&#34;276px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Masked Multi-Head Attention&lt;/strong&gt;：与encoder部分相比，有所改变
&lt;ul&gt;
&lt;li&gt;encoder可以拿到整个sequence，因此可以考虑全局&lt;/li&gt;
&lt;li&gt;而decoder只有前文，因此只会考虑出现过的向量（因为根本不存在）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812184952935.png&#34;
	width=&#34;858&#34;
	height=&#34;468&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812184952935_hu_861edc16f8fc0092.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812184952935_hu_57c4cdae96a73965.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812184952935&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;183&#34;
		data-flex-basis=&#34;440px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;EOS&lt;/code&gt;同时会作为预测内容之一，当输出一个结束符出现时，结束预测，生成的文本即为结果&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;autoregressive-vs-non-autoregressive&#34;&gt;Autoregressive vs. Non-Autoregressive
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;上面的内容被称为自回归&lt;/li&gt;
&lt;li&gt;非自回归：一次性喂入多个begin进行预测
&lt;ul&gt;
&lt;li&gt;方便控制长短
&lt;ul&gt;
&lt;li&gt;使用另一个分类器进行长度预测（对输出长度再做一次乘法、乘法，能直接调整）&lt;/li&gt;
&lt;li&gt;或生成足够数量的token，查看第一个end&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;方便并行&lt;/li&gt;
&lt;li&gt;效果会更差&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812185627178.png&#34;
	width=&#34;840&#34;
	height=&#34;562&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812185627178_hu_dec5913c41ec5b84.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812185627178_hu_82b9ba79636d7b3f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812185627178&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;149&#34;
		data-flex-basis=&#34;358px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;encoder---decoder&#34;&gt;Encoder - Decoder
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Transformer中多出来的一个block，起到了连接encoder的作用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812192024698.png&#34;
	width=&#34;866&#34;
	height=&#34;641&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812192024698_hu_135772fe63f99073.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812192024698_hu_7f4b9115f966cd44.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812192024698&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;135&#34;
		data-flex-basis=&#34;324px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812192821219.png&#34;
	width=&#34;772&#34;
	height=&#34;652&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812192821219_hu_507f7f24a45eb555.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812192821219_hu_5590ed3a161c41cc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812192821219&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;118&#34;
		data-flex-basis=&#34;284px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;堆叠Encoder和Decoder，我们就得到了Transformer&lt;/li&gt;
&lt;li&gt;原始论文中，decoder只拿了encoder最后一层的输出&lt;/li&gt;
&lt;li&gt;但事实上可以拿非常多&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812195611554.png&#34;
	width=&#34;774&#34;
	height=&#34;464&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812195611554_hu_1dfbf9401600acbd.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812195611554_hu_8c6c5a863128e6ad.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812195611554&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;166&#34;
		data-flex-basis=&#34;400px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;training&#34;&gt;Training
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;看作一个分类问题，使用交叉熵损失函数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812200133689.png&#34;
	width=&#34;742&#34;
	height=&#34;592&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812200133689_hu_c243da94af1ecddb.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812200133689_hu_b65b9fa9eb395d42.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812200133689&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;125&#34;
		data-flex-basis=&#34;300px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;但是我们需要强制喂入Decoder正确的输入，只有这样才能进行比较&lt;/li&gt;
&lt;li&gt;即我们不会每次把Decoder的输出作为新的输入，而是直接设定好&lt;/li&gt;
&lt;li&gt;这个过程叫做&lt;strong&gt;Teacher Forcing&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;在训练的时候进行Teacher Forcing，最后的误差自然会偏低&lt;/li&gt;
&lt;li&gt;而在做测试时是无法做到的，造成mismatching&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EOS&lt;/code&gt;也需要被当作预测字符进行预测&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812200243816.png&#34;
	width=&#34;791&#34;
	height=&#34;538&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812200243816_hu_8917f615c15d73d3.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812200243816_hu_6df1be959f522fc0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812200243816&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;147&#34;
		data-flex-basis=&#34;352px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;copy-mechanism&#34;&gt;Copy Mechanism
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Copy Mechanism指在文本生成领域，生成的输出是输入序列元素的复制或者指向。&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;有时候不需要自己创造输出&lt;/li&gt;
&lt;li&gt;直接从输入中进行复制&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对模型进行询问时含有一些“人名”（模型从未见过），此时需要直接复述这个人名作为指代&lt;/li&gt;
&lt;li&gt;文章摘要&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;guided-attention&#34;&gt;Guided Attention
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;有时候需要对输入输出进行引导&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812201931650.png&#34;
	width=&#34;879&#34;
	height=&#34;421&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812201931650_hu_ea03b83751307c7c.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812201931650_hu_c2407cf3e6900188.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812201931650&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;208&#34;
		data-flex-basis=&#34;501px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;例如语音合成等相关内容，Attention会产生一些奇怪的错误，而你又对整个流程有明确的认识，就需要对Attention加入限制进行引导
&lt;ul&gt;
&lt;li&gt;Monotonic Attention&lt;/li&gt;
&lt;li&gt;Location-aware Attention&lt;/li&gt;
&lt;li&gt;（没有详讲）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;beam-search&#34;&gt;Beam Search
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812202528908.png&#34;
	width=&#34;855&#34;
	height=&#34;430&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812202528908_hu_781ba3793bf4fc03.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812202528908_hu_a2c99505d8621105.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812202528908&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;198&#34;
		data-flex-basis=&#34;477px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每次都贪心选择概率最高的输出不一定是一件好事&lt;/li&gt;
&lt;li&gt;我们无法穷举每一种可能，可以考虑使用Beam Search&lt;/li&gt;
&lt;li&gt;基础版本：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812202748807.png&#34;
	width=&#34;789&#34;
	height=&#34;414&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812202748807_hu_99cf7db692a74b86.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l5/assets/image-20240812202748807_hu_bc608b919781a814.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240812202748807&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;190&#34;
		data-flex-basis=&#34;457px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于答案明确的任务，Beam Search会有帮助（需要尽力找到较优的结果）&lt;/li&gt;
&lt;li&gt;对于发挥创造力（编故事），反而不是一件好事&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bleu-score&#34;&gt;BLEU Score
&lt;/h3&gt;&lt;p&gt;有时候会需要一些奇奇怪怪的NLP的评价指标去评估训练&lt;/p&gt;
&lt;p&gt;但是这些指标是很难进行微分的，所以很难用于训练&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对于很难微分的函数计算，我们可以考虑使用强化学习&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;exposure-bias&#34;&gt;Exposure Bias
&lt;/h3&gt;&lt;p&gt;回到前文，我们在训练时每次喂给decoder的都是绝对正确的&lt;/p&gt;
&lt;p&gt;但是在测试时只能看自己的输出，这个不一致的现象叫做Exposure Bias&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;解决方法：&lt;strong&gt;Scheduled Sampling&lt;/strong&gt;：我们在喂入decoder的时候，故意弄错一点东西（引入噪声）&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>李宏毅机器学习2021 · L4</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/</link>
        <pubDate>Sat, 10 Aug 2024 18:19:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/</guid>
        <description>&lt;h1 id=&#34;l4-sequence-as-input&#34;&gt;L4. Sequence as input
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML 2022 Spring (ntu.edu.tw)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1VN4y1P7Zj&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1VN4y1P7Zj&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;sequence&#34;&gt;Sequence
&lt;/h2&gt;&lt;p&gt;对于Sequence Labeling任务，我们需要对一段文本中的所有单词标注词性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;显然不能单独考虑一个单词，需要结合上下文
&lt;ul&gt;
&lt;li&gt;同一个单词在不同的上下文中会有不同的词性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810194910423.png&#34;
	width=&#34;725&#34;
	height=&#34;341&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810194910423_hu_b4c3e786061568e3.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810194910423_hu_49434ca865acf193.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810194910423&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;212&#34;
		data-flex-basis=&#34;510px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们考虑定义一个window：
&lt;ul&gt;
&lt;li&gt;每个Fully-Connected需要连接前后若干个单词作为输入&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810195115978.png&#34;
	width=&#34;793&#34;
	height=&#34;350&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810195115978_hu_67336028c4b58ca1.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810195115978_hu_b154a4988d89b434.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810195115978&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;226&#34;
		data-flex-basis=&#34;543px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;但是我们有时需要考虑整个Sequence去获得信息，我们很难通过扩大Window进行操作，复杂度会非常高&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;self-attention&#34;&gt;Self-Attention
&lt;/h2&gt;&lt;h3 id=&#34;概述&#34;&gt;概述
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;整个Sequence作为输入&lt;/li&gt;
&lt;li&gt;输出向量数量等于输入向量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810195453418.png&#34;
	width=&#34;544&#34;
	height=&#34;412&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810195453418_hu_b94113e0431d997.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810195453418_hu_ed091fc2bce1f6fb.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810195453418&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;132&#34;
		data-flex-basis=&#34;316px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每次完成Self-Attention后，喂入FC进行操作&lt;/li&gt;
&lt;li&gt;可以多次叠加&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dot-product&#34;&gt;Dot-Product
&lt;/h3&gt;&lt;p&gt;我们会对多个输入向量之间的相关性感兴趣&lt;/p&gt;
&lt;p&gt;Self-Attention常使用Dot-Product求出两个向量之间的相关性&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810200023586.png&#34;
	width=&#34;255&#34;
	height=&#34;339&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810200023586_hu_5e41e906266a2ca1.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810200023586_hu_a91a80d37809d1fa.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810200023586&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;75&#34;
		data-flex-basis=&#34;180px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;两个输入$\text{query},\text{key}$向量分别乘上$W_q,W_k$，得到向量$q,k$&lt;/li&gt;
&lt;li&gt;对向量$q,k$进行点积，得到$\alpha$，同时也被称为attention-score&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;forward&#34;&gt;Forward
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对于其中一个向量$i$，计算出自己作为查询向量的$q_i$值&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;所有向量都需要计算自己作为被查询向量的$k_j$值&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过Dot-Product，得到$\alpha_{i,j}$，即向量$i$对所有向量$j$的相关性&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;做一下Softmax，得到$\alpha&amp;rsquo;_{i,j}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810201234380.png&#34;
	width=&#34;1094&#34;
	height=&#34;736&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810201234380_hu_1320e3bf9098af04.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810201234380_hu_8cf9c8ca796957a1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810201234380&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;148&#34;
		data-flex-basis=&#34;356px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;每个向量都需要通过$W_v$矩阵计算出向量$v$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$v_j$乘上标量$\alpha_{i,j}$，求和&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
$$
    b_i = \sum_{j} \alpha&#39;_{i,j}v_j
    $$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810201306802.png&#34;
	width=&#34;1152&#34;
	height=&#34;667&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810201306802_hu_6bf721813feba1c.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810201306802_hu_531ed7686d8469c1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810201306802&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;172&#34;
		data-flex-basis=&#34;414px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;关联性越高的向量，它会$b$占有很大的成分&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;每个向量$a_i$得到$b_i$的计算过程是并行进行的&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;forward矩阵形式&#34;&gt;Forward（矩阵形式）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;$W_q,W_k,W_v$都是通用的，每个向量$a_i$都需要使用，因此很容易就能表示成矩阵形式&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810202311607.png&#34;
	width=&#34;794&#34;
	height=&#34;423&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810202311607_hu_72ee95972ffada7f.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810202311607_hu_adf156101d4570d1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810202311607&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;187&#34;
		data-flex-basis=&#34;450px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于$q_1$，我需要让它与所有$k_j$​进行点积运算&lt;/li&gt;
&lt;li&gt;实质上就是与$k_j^T$进行相乘&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203013199.png&#34;
	width=&#34;1112&#34;
	height=&#34;291&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203013199_hu_bd2da2dfc5eea667.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203013199_hu_9b21d2e03f26c228.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810203013199&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;382&#34;
		data-flex-basis=&#34;917px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于其他$q_i$也是同理，计算得到矩阵$A$&lt;/li&gt;
&lt;li&gt;通过矩阵$A$，每一列过一遍激活函数（softmax）得到$A&#39;$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203127438.png&#34;
	width=&#34;1127&#34;
	height=&#34;308&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203127438_hu_f738e457ecea9fec.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203127438_hu_8391eb3ad567e5ca.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810203127438&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;365&#34;
		data-flex-basis=&#34;878px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;计算输出矩阵&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203438473.png&#34;
	width=&#34;897&#34;
	height=&#34;296&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203438473_hu_85e1178bfe3d2945.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810203438473_hu_91c768f2aa18f776.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810203438473&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;303&#34;
		data-flex-basis=&#34;727px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;整理一下：&lt;/li&gt;
&lt;/ul&gt;
$$
O = VA&#39; = (W_vI)\text{softmax}(A) \\
O =(W_vI)\text{softmax}( K^TQ ) = (W_vI)\text{softmax}( I^TW_k^TW_qI ) \\
$$&lt;ul&gt;
&lt;li&gt;$W_q,W_k,W_v$则是我们需要学习的参数矩阵&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multi-head-self-attention&#34;&gt;Multi-head Self-Attention
&lt;/h3&gt;&lt;p&gt;一般的Self-Attention只会有一种$W_q$得到的一组$q$向量，作为相关性的度量&lt;/p&gt;
&lt;p&gt;但是有时候需要丰富多个相关性指标&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810204713494.png&#34;
	width=&#34;975&#34;
	height=&#34;671&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810204713494_hu_31d8544143250997.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810204713494_hu_8a9dd5a40f386c4a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810204713494&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;145&#34;
		data-flex-basis=&#34;348px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;得到的多类$b_i$输出，拼起来乘一个矩阵，得到最后的输出&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810204910126.png&#34;
	width=&#34;533&#34;
	height=&#34;181&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810204910126_hu_75fef0d55220710a.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810204910126_hu_46d13f56e37d462.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810204910126&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;294&#34;
		data-flex-basis=&#34;706px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;position-encoding&#34;&gt;Position Encoding
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对于$a_1, a_2, a_3, a_4$，其对于上文算法来说，并没有距离的概念（交换位置后没什么差别）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;但对于实际文本来说，$a_1,a_4$是距离较远的向量，$a_2,a_3$​是距离较近的向量&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;（需要分析一下位置对实际要的输出是有影响，才会考虑引入Position Encoding）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在求解前，每个$a_i$需要加入一个位置向量$e_i$即可&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810205438276.png&#34;
	width=&#34;325&#34;
	height=&#34;223&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810205438276_hu_84b0b78f79197fed.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810205438276_hu_1131b67eb5afd669.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810205438276&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;145&#34;
		data-flex-basis=&#34;349px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hand-crafted（人为设置）：会使用一些三角函数进行组合
&lt;ul&gt;
&lt;li&gt;方式非常多，暂时没有最好的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// 好像自己写过这个东西
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;__global__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cu_matrixPositionalEmbedding&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;M&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;level&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;M&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;row&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;col&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;row&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;col&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;d_C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;M&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;powf2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;level&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;powf2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;powf2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;d_C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sinf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;val&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;M&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cosf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;val&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;M&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;learn from data：直接作为参数进行学习&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;非文本应用&#34;&gt;非文本应用
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;省流：只要是一个vector set，就可以进行self-attention&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Self-attention for Speech
&lt;ul&gt;
&lt;li&gt;声音讯号转换成向量会更加复杂&lt;/li&gt;
&lt;li&gt;导致整体的矩阵会变得非常大&lt;/li&gt;
&lt;li&gt;所以需要引入window，考虑一小段话进行识别&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Self-attention for Image
&lt;ul&gt;
&lt;li&gt;每个像素的所有通道值看作一个向量&lt;/li&gt;
&lt;li&gt;则我们可以得到分辨率数个向量，构成了一个vector set&lt;/li&gt;
&lt;li&gt;相比CNN来说，可以考虑整个图像的所有像素，而不是一个感受野
&lt;ul&gt;
&lt;li&gt;自动学习出附近哪些像素是相关的，本质上自动学习了感受野&lt;/li&gt;
&lt;li&gt;不需要人为设定感受野大小&lt;/li&gt;
&lt;li&gt;认为：Self-Attention经过调整可以做到CNN一样的事情，因此对于function set层面上，CNN被Self-Attention所包含，是有所限制的特例&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810210416541.png&#34;
	width=&#34;507&#34;
	height=&#34;447&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810210416541_hu_e57416002cfc86aa.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810210416541_hu_eb3d057bb450f72f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810210416541&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;113&#34;
		data-flex-basis=&#34;272px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Self-attention for Graph
&lt;ul&gt;
&lt;li&gt;对于有边的结点对，需要计算attention-score&lt;/li&gt;
&lt;li&gt;没有边可以直接认为无关，设为0&lt;/li&gt;
&lt;li&gt;改改就是GNN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810211514167.png&#34;
	width=&#34;955&#34;
	height=&#34;563&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810211514167_hu_9c17c9b31236adfb.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l4/assets/image-20240810211514167_hu_4da8238114914b0c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240810211514167&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;407px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;rnn&#34;&gt;RNN
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;似乎被Self-Attention替代了&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;RNN没法并行&lt;/li&gt;
&lt;li&gt;普通的RNN只会考虑左边序列的输出，而Self-Attention考虑整个序列&lt;/li&gt;
&lt;li&gt;双向RNN需要大量memory去存储结果，才能做到考虑整个序列&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>李宏毅机器学习2021 · L3</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l3/</link>
        <pubDate>Sat, 27 Jul 2024 18:19:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l3/</guid>
        <description>&lt;h1 id=&#34;l3-image-as-input&#34;&gt;L3. Image as input
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML 2022 Spring (ntu.edu.tw)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1J94y1f7u5&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1J94y1f7u5&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;原则&#34;&gt;原则
&lt;/h2&gt;&lt;h3 id=&#34;局部性&#34;&gt;局部性
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;图片的识别往往需要注意一小块的特征&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&#34;assets/image-20240727181929979.png&#34; alt=&#34;image-20240727181929979&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;就算是人类也会根据局部特征，被误导进行分类（其实这是一只猫而不是一只鸟）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;图像会被切分成多个感受野，感受野之间需要有所重叠（否则会遗失边界上的信息）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l3/assets/image-20240727182325873.png&#34;
	width=&#34;1771&#34;
	height=&#34;1008&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l3/assets/image-20240727182325873_hu_96411596ecf6d855.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l3/assets/image-20240727182325873_hu_a95ad1230568f2d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727182325873&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;421px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;因此我们需要用感受野覆盖整个图像&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用一组神经元，识别同一个感受野，即负责这一块区域的图像识别&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;平移不变性&#34;&gt;平移不变性
&lt;/h3&gt;&lt;img src=&#34;assets/image-20240727201934526.png&#34; alt=&#34;image-20240727201934526&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;ul&gt;
&lt;li&gt;同一个特征可以出现在不同的位置，因此理论上识别同一个特征的单元应该有相同的参数&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&#34;assets/image-20240727202440749.png&#34; alt=&#34;image-20240727202440749&#34; style=&#34;zoom:67%;&#34; /&gt;
&lt;ul&gt;
&lt;li&gt;对于同一个感受野，它应该携带多个神经元，即多个识别单元filter，以识别不同的特征&lt;/li&gt;
&lt;li&gt;不同感受野的同一个filter，需要&lt;strong&gt;共享参数&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;卷积神经网络&#34;&gt;卷积神经网络
&lt;/h2&gt;&lt;h3 id=&#34;卷积层&#34;&gt;卷积层
&lt;/h3&gt;&lt;p&gt;我们从一般的全连接神经网络出发，引入了两个限制&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一组神经元只会接受图片上一块区域的张量（感受野）
&lt;ul&gt;
&lt;li&gt;断掉了这些神经元与其他位置的连接&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;不同组神经元的同一类识别单元需要共享参数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此时我们相当于对MLP大砍一刀，变成了一个限制非常大的神经网络，即卷积层&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;但实际实现我们其实对于一个filter，就是一个卷积核，直接让它扫一遍整个图像即可&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个卷积核会产生一个新的通道&lt;/p&gt;
&lt;img src=&#34;assets/image-20240727205533086.png&#34; alt=&#34;image-20240727205533086&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;如图，同样一个3*3的卷积核，恢复到原图像中，会对应上超过9个以上的像素&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;随着深度增加，一个卷积核的真实感受野也会变大&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;池化层&#34;&gt;池化层
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;大量的卷积核，产生大量的通道，因此对于原图像的尺寸来说参数会非常多&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我们考虑通过池化缩减原图像尺寸（通道数不变）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Max、Mean Pooling&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&#34;assets/image-20240727210158517.png&#34; alt=&#34;image-20240727210158517&#34; style=&#34;zoom:67%;&#34; /&gt;
&lt;p&gt;在计算量足够的时候，不一定需要使用Pooling（会丢失很多信息）&lt;/p&gt;
&lt;h3 id=&#34;数据增强&#34;&gt;数据增强
&lt;/h3&gt;&lt;p&gt;旋转、缩放图像，可能会使得CNN变得很差&lt;/p&gt;
&lt;p&gt;所以推荐在训练前使用数据增强&lt;/p&gt;
&lt;h3 id=&#34;spatial-transformer-layer&#34;&gt;Spatial Transformer Layer
&lt;/h3&gt;&lt;p&gt;但我们为什么不直接在网络结构中加一个层呢&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_39422642/article/details/78870629&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;详细解读Spatial Transformer Networks（STN）-一篇文章让你完全理解STN了-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;没学太明白，知道个大概&lt;/p&gt;
</description>
        </item>
        <item>
        <title>李宏毅机器学习2021 · L2</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/</link>
        <pubDate>Fri, 26 Jul 2024 20:45:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/</guid>
        <description>&lt;h1 id=&#34;l2-what-to-do-if-my-network-fails-to-train&#34;&gt;L2. What to do if my network fails to train
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML 2022 Spring (ntu.edu.tw)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1J94y1f7u5&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1J94y1f7u5&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;general-guide&#34;&gt;General Guide
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;检查Training Loss
&lt;ul&gt;
&lt;li&gt;Training Loss大
&lt;ul&gt;
&lt;li&gt;Model Bias
&lt;ul&gt;
&lt;li&gt;模型不够复杂&lt;/li&gt;
&lt;li&gt;提高模型复杂度即可&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Optimization
&lt;ul&gt;
&lt;li&gt;可以尝试使用浅层神经网络等容易优化的模型进行训练，若Train Loss比复杂模型更低，说明优化出问题了&lt;/li&gt;
&lt;li&gt;解释：复杂模型包含了简单模型（多出来的部分全部不训练，剩下的就是简单模型），因此简单模型能做到的Training Loss，对于复杂模型也需要做到&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Training Loss小
&lt;ul&gt;
&lt;li&gt;检查Testing Loss
&lt;ul&gt;
&lt;li&gt;Testing Loss小（这不结束了吗）&lt;/li&gt;
&lt;li&gt;Testing Loss大
&lt;ul&gt;
&lt;li&gt;Overfitting
&lt;ul&gt;
&lt;li&gt;增加训练数据&lt;/li&gt;
&lt;li&gt;数据增强（Data augmentation）&lt;/li&gt;
&lt;li&gt;减少模型复杂度&lt;/li&gt;
&lt;li&gt;Early Stopping&lt;/li&gt;
&lt;li&gt;Regularization&lt;/li&gt;
&lt;li&gt;Dropout&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mismatch
&lt;ul&gt;
&lt;li&gt;与过拟合不同，没法使用增加训练数据避免&lt;/li&gt;
&lt;li&gt;训练数据与测试数据有着不同的分布&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726002318989.png&#34;
	width=&#34;1146&#34;
	height=&#34;784&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726002318989_hu_e2a3a53f03528fce.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726002318989_hu_9e3a17f420fb61bc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240726002318989&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;146&#34;
		data-flex-basis=&#34;350px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;训练数据少，不足以限制模型&lt;/li&gt;
&lt;li&gt;模型太复杂，过于自由&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;optimization-failed&#34;&gt;Optimization Failed
&lt;/h2&gt;&lt;h3 id=&#34;critical-point&#34;&gt;Critical Point
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726212706358.png&#34;
	width=&#34;1432&#34;
	height=&#34;537&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726212706358_hu_23a27474b4a8738b.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726212706358_hu_5840c17e70f7cc2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240726212706358&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;266&#34;
		data-flex-basis=&#34;640px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;处于局部极值点（极大值、极小值）或鞍点时，梯度值为0，此时没有办法继续更新梯度&lt;/p&gt;
&lt;h4 id=&#34;tayler-series-approximation&#34;&gt;Tayler Series Approximation
&lt;/h4&gt;&lt;p&gt;为了判别&lt;code&gt;critical point&lt;/code&gt;，我们要是能够知道损失函数$L(\theta)$的形状就会非常容易&lt;/p&gt;
&lt;p&gt;我们考虑使用&lt;strong&gt;泰勒展开&lt;/strong&gt;，对参数$\theta&amp;rsquo;$周围的损失函数进行近似&lt;/p&gt;
$$
L(\theta) \approx L(\theta&#39;) + (\theta-\theta&#39;)g+\frac{1}{2}(\theta-\theta&#39;)^T\times H\times (\theta-\theta&#39;)
$$$$
L(\theta) \approx L(\theta&#39;) + \frac{1}{2}(\theta-\theta&#39;)^T\times H\times (\theta-\theta&#39;)
$$&lt;p&gt;
此时取决于最后一项：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;永远大于0，则$L(\theta) &amp;gt; L(\theta&amp;rsquo;)$，是局部极小值&lt;/li&gt;
&lt;li&gt;永远小于0，则$L(\theta) &amp;lt; L(\theta&amp;rsquo;)$，是局部极大值&lt;/li&gt;
&lt;li&gt;否则：鞍点&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;判断$\frac{1}{2}(\theta-\theta&amp;rsquo;)^T\times H\times (\theta-\theta&amp;rsquo;)$的正负是一个经典问题&lt;/p&gt;
&lt;p&gt;即$\forall v, v^THv &amp;gt; 0$，此时$H$被称为正定矩阵（特征值都是正值）&lt;/p&gt;
&lt;p&gt;反之，负定矩阵所有的特征值均小于0&lt;/p&gt;
&lt;p&gt;但是每次都需要计算矩阵及其特征值，是一件开销很大的事情&lt;/p&gt;
&lt;p&gt;我们考虑从其他方式进行规避鞍点&lt;/p&gt;
&lt;h4 id=&#34;batch-size&#34;&gt;Batch Size
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;大的Batch会花费更多时间进行计算，但是减少梯度更新次数&lt;/li&gt;
&lt;li&gt;小的Batch会花费更少时间进行计算，但是增加梯度更新次数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726221840015.png&#34;
	width=&#34;1764&#34;
	height=&#34;698&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726221840015_hu_ba30f46d87e548b6.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726221840015_hu_659b1db9b1480a48.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240726221840015&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;252&#34;
		data-flex-basis=&#34;606px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;得益于GPU并行计算，batch在不是非常大的时候，多条数据计算loss计算梯度是并行的，因此时间非常少&lt;/p&gt;
&lt;p&gt;但是小的batch确确实实需要更多次梯度更新，因此&lt;strong&gt;小的batch事实上在单个epoch上花费时间更大&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726222335373.png&#34;
	width=&#34;1869&#34;
	height=&#34;1099&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726222335373_hu_97093e71718a6005.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726222335373_hu_7824f9a4c08d3c6d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240726222335373&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;170&#34;
		data-flex-basis=&#34;408px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;​	&lt;strong&gt;但是似乎小的batch可以对Optimization带来更好的效果&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&#34;assets/image-20240726222828695.png&#34; alt=&#34;image-20240726222828695&#34; style=&#34;zoom: 50%;&#34; /&gt;
&lt;p&gt;每次使用不同batch的数据进行更新，某种程度上引入了噪声&lt;/p&gt;
&lt;p&gt;在第一份batch上进入鞍点，但是对于第二份就不一定是鞍点&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726223435549.png&#34;
	width=&#34;1670&#34;
	height=&#34;837&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726223435549_hu_4f1ea00d81182b5.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726223435549_hu_4c77eb55e35b5415.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240726223435549&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;199&#34;
		data-flex-basis=&#34;478px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;甚至你会发现，小batch训练出来的模型，泛化性能更好，在测试集上表现更好&lt;/p&gt;
&lt;p&gt;一种比较玄学的解释：&lt;/p&gt;
&lt;p&gt;极值点有平坦的、陡峭的两种（如图左、右）&lt;/p&gt;
&lt;p&gt;由于测试集多少与训练集有一些mismatch，如果是平坦的极值点，稍微的偏移不会引起损失函数变化太多&lt;/p&gt;
&lt;p&gt;而陡峭的极值点会表现糟糕&lt;/p&gt;
&lt;p&gt;小batch在训练时引入的噪声，非常跳脱，峡谷很难困住其更新方向&lt;/p&gt;
&lt;p&gt;而大batch的梯度下降方向稳定，因此容易进入陡峭的峡谷&lt;/p&gt;
&lt;h3 id=&#34;learning-rate&#34;&gt;Learning Rate
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727004526896.png&#34;
	width=&#34;1363&#34;
	height=&#34;641&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727004526896_hu_8c6188ae5b6c6c00.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727004526896_hu_8d76fccda6fb61f8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727004526896&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;212&#34;
		data-flex-basis=&#34;510px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;非常多时候Loss并不是卡在&lt;code&gt;critical point&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我们观察训练末期的梯度，发现并不是0&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;原因是在山谷之间来回跳动，无法下降&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727005023817.png&#34;
	width=&#34;1475&#34;
	height=&#34;561&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727005023817_hu_a86798eefc4da2cf.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727005023817_hu_a9d1d2bc213f1013.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727005023817&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;262&#34;
		data-flex-basis=&#34;631px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;学习率较大，会在山谷来回跳（左图）&lt;/li&gt;
&lt;li&gt;学习率较小，在稍微平坦的地方完全走不动（右图）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此一般的梯度下降很难进入&lt;code&gt;critical point&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;我们考虑自适应学习率&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;陡峭的地方学习率高&lt;/li&gt;
&lt;li&gt;平坦的地方学习率低&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;梯度的更新应该由&lt;/p&gt;
$$
\theta^{t+1} =\theta^t - \eta g^t
$$&lt;p&gt;
转变为：&lt;/p&gt;
$$
\theta^{t+1} =\theta^t - \frac{\eta}{\sigma^t}g^t
$$&lt;h4 id=&#34;root-mean-squareadagrad&#34;&gt;Root Mean Square（Adagrad）
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727011659380.png&#34;
	width=&#34;1754&#34;
	height=&#34;911&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727011659380_hu_cfce72f52008edc.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727011659380_hu_cf09cae5a88ea49e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727011659380&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;192&#34;
		data-flex-basis=&#34;462px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;及对应维度上的梯度均方根作为分母&lt;/p&gt;
&lt;p&gt;但是这样的方法不够灵活&lt;/p&gt;
&lt;p&gt;有时候同一个维度，在不同时间点可能又陡峭又平缓，因此需要更加灵活、动态变化的学习率&lt;/p&gt;
&lt;h4 id=&#34;rmspropadam&#34;&gt;RMSProp+Adam
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727012032761.png&#34;
	width=&#34;1620&#34;
	height=&#34;943&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727012032761_hu_19cf01196f551643.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727012032761_hu_54fdc8c1132da213.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727012032761&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;171&#34;
		data-flex-basis=&#34;412px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;定义权重$\alpha$，每次结合上一次的$\sigma^{t-1}$与当前梯度进行计算&lt;/p&gt;
$$
\sigma^{t} = \sqrt{\alpha(\sigma^{t-1})^2+(1-\alpha)(g^t)^2}
$$&lt;p&gt;但此时我们仍然无法解决卡在&lt;code&gt;critical point&lt;/code&gt;的问题&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Adam = RMSProp + Momentum&lt;/u&gt;&lt;/p&gt;
&lt;h4 id=&#34;momentum&#34;&gt;Momentum
&lt;/h4&gt;&lt;p&gt;我们考虑在优化时引入动量的概念&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726225731002.png&#34;
	width=&#34;1803&#34;
	height=&#34;933&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726225731002_hu_fe9931e5cd78a4dc.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726225731002_hu_ddf4c9f7bbf28d4d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240726225731002&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;463px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;物体在下降时，到达谷底仍拥有一定的动量，还会沿之前的方向继续冲一会&lt;/p&gt;
&lt;p&gt;这样有机会冲到更低的极值点&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726225918900.png&#34;
	width=&#34;970&#34;
	height=&#34;451&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726225918900_hu_e14983e0a01f82cf.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240726225918900_hu_94e222b769489513.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240726225918900&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;215&#34;
		data-flex-basis=&#34;516px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;并且：每次移动的$m_i$都可以表示为之前所有梯度的综合（一个关于$g_0,g_1,&amp;hellip;$的式子）&lt;/p&gt;
&lt;h3 id=&#34;adam&#34;&gt;Adam
&lt;/h3&gt;&lt;p&gt;结合 RMSProp + Momentum，我们就得到了Adam&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Momentum：&lt;/strong&gt;&lt;/p&gt;
$$
\theta^t = \theta^{t-1} - \eta m^t\\
m^t = \beta m^{t-1} + (1-\beta)g^{t-1}
$$&lt;p&gt;
&lt;strong&gt;RMSProp:&lt;/strong&gt;&lt;/p&gt;
$$
\theta^t = \theta^{t-1} - \frac{\eta}{\sigma^t}g^{t-1}\\
\sigma^{t} = \sqrt{\alpha(\sigma^{t-1})^2+(1-\alpha)(g^t)^2}
$$&lt;p&gt;
结合一下，&lt;strong&gt;Adam&lt;/strong&gt;：&lt;/p&gt;
$$
\hat m^{t} = \frac{m^t}{1-\beta}\\
\hat \sigma^t = \sqrt{\frac{(\sigma^t)^2}{1-\alpha}}\\
\epsilon = 10^{-8}\\
\theta^t = \theta^{t-1} - \frac{\eta}{\hat \sigma^t + \epsilon}\hat m^{t}
$$&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;同时兼顾方向与步长&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Momentum 负责确定更新方向（加速收敛）：在陡峭的地方始终保持总体方向，防止偏航&lt;/li&gt;
&lt;li&gt;RMSProp 负责调整步长（自适应学习率）：调整每一步的大小，走的更稳&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;learning-rate-scheduling&#34;&gt;Learning Rate Scheduling
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727012518967.png&#34;
	width=&#34;718&#34;
	height=&#34;486&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727012518967_hu_48bc08e310f5f031.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727012518967_hu_19837198438541ad.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727012518967&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;147&#34;
		data-flex-basis=&#34;354px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;我们采用Adagrad，此时就可以进行正常的下降&lt;/p&gt;
&lt;p&gt;但是会出现奇怪的波动&lt;/p&gt;
$$
\sigma^{t} = \sqrt{\frac{1}{t+1}\sum_k (g^k)^2}
$$&lt;p&gt;
刚进入平坦区时，得益于一开始积累了下降的较高梯度&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013213318.png&#34;
	width=&#34;746&#34;
	height=&#34;424&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013213318_hu_5f5b3f52637abddf.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013213318_hu_6c632e041303e9a8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727013213318&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;422px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;$\sigma_y$仍然可以维持在一个比较大的范围&lt;/p&gt;
&lt;p&gt;但随着迭代次数增加，$\sigma_y$每次只能加上非常小的梯度，平均值不断变小，最终引起了学习率爆炸&lt;/p&gt;
&lt;p&gt;如何解决这个问题呢&lt;/p&gt;
$$
\theta^{t+1} =\theta^t - \frac{\eta}{\sigma^t}g^t
$$&lt;p&gt;
我们除了对$\sigma$进行变化，我们可以本身对$\eta$​进行变化&lt;/p&gt;
&lt;p&gt;即随着时间，$\eta$慢慢变小&lt;/p&gt;
&lt;p&gt;时间越长，本身肯定也已经离终点越来越近，因此就会抵消之前的梯度积累&lt;/p&gt;
&lt;p&gt;或者变大再变小&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Learning Rate Decay
&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013705566.png&#34;
	width=&#34;573&#34;
	height=&#34;301&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013705566_hu_d727239789cb5408.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013705566_hu_68a454e90ebbe697.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727013705566&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;190&#34;
		data-flex-basis=&#34;456px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;Warm Up&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013732870.png&#34;
	width=&#34;534&#34;
	height=&#34;308&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013732870_hu_9d6fba0554416a60.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02021-l2/assets/image-20240727013732870_hu_e11995cf98bfdded.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240727013732870&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;173&#34;
		data-flex-basis=&#34;416px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Warm Up貌似更黑科技一点&lt;/p&gt;
&lt;p&gt;Warm Up可能的解释：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一开始希望多收集周围的梯度信息，因此不希望走太快&lt;/li&gt;
&lt;li&gt;信息足够后，开始正式的大踏步前进&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
</description>
        </item>
        
    </channel>
</rss>
