<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>LLM on BiribiriBird</title>
        <link>https://example.com/tags/llm/</link>
        <description>Recent content in LLM on BiribiriBird</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>Example Person</copyright>
        <lastBuildDate>Sat, 06 Sep 2025 20:45:55 +0800</lastBuildDate><atom:link href="https://example.com/tags/llm/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>大语言模型教育纠错 · 论文笔记（三）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/</link>
        <pubDate>Sat, 06 Sep 2025 20:45:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.alphaxiv.org/abs/2412.09416v2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Unifying AI Tutor Evaluation: An Evaluation Taxonomy for Pedagogical Ability Assessment of LLM-Powered AI Tutors | alphaXiv&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/kaushal0494/UnifyingAITutorEvaluation&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;kaushal0494/UnifyingAITutorEvaluation: An Evaluation Taxonomy for Pedagogical Ability Assessment of LLM-Powered AI Tutors&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;paper-cool&#34;&gt;Paper-Cool
&lt;/h2&gt;&lt;h3 id=&#34;q1-这篇论文试图解决什么问题&#34;&gt;&lt;strong&gt;Q1&lt;/strong&gt;: 这篇论文试图解决什么问题？
&lt;/h3&gt;&lt;p&gt;这篇论文试图解决的问题是如何有效地评估大型语言模型（LLMs）作为AI助教在教育对话中的表现，特别是在学生错误纠正方面。具体来说，论文试图解决以下几个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;评估标准的统一性&lt;/strong&gt;：之前对AI助教的评估工作受限于主观协议和基准，缺乏统一的评估框架。论文提出了一个基于学习科学原则的统一评估分类体系，包含八个教学维度，旨在评估LLM驱动的AI助教在数学领域的学生错误纠正中的教学价值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估的客观性和可靠性&lt;/strong&gt;：现有的评估方法往往依赖于主观评价，缺乏客观性和可比性。论文通过提出一个新的评估基准MRBench，并提供人工标注的八个教学维度，来提高评估的客观性和可靠性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI助教的实际教学能力&lt;/strong&gt;：论文通过对比不同LLMs作为AI助教的能力和人类助教的表现，揭示了当前LLMs在教学能力上的不足，并指出了改进的方向。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估过程的简化和标准化&lt;/strong&gt;：论文希望通过提出的分类体系、基准和人工标注的标签，简化AI助教的评估过程，并帮助跟踪AI助教发展的进步。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总的来说，这篇论文旨在通过提出一个新的评估框架和基准，来解决当前AI助教评估中存在的问题，推动AI助教的发展，并为未来的研究提供便利。&lt;/p&gt;
&lt;h3 id=&#34;q2-有哪些相关研究&#34;&gt;&lt;strong&gt;Q2&lt;/strong&gt;: 有哪些相关研究？
&lt;/h3&gt;&lt;p&gt;相关研究涵盖了以下几个领域：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;AI助教评估&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;Tack和Piech (2022) 以及 Tack 等人 (2023) 从教师语言、学生理解和帮助学生的角度评估模型的响应。&lt;/li&gt;
&lt;li&gt;Macina 等人 (2023) 专注于连贯性、正确性和公平教学来评估模型作为教师的响应。&lt;/li&gt;
&lt;li&gt;Wang 等人 (2024a) 评估了有用性、关怀和人类化。&lt;/li&gt;
&lt;li&gt;Daheim 等人 (2024) 集中于针对性、正确性和可执行性来评估教师响应的质量。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自然语言生成（NLG）和LLM基础评估&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;一般领域的NLG指标，如BLEU (Papineni et al., 2002)、BERTScore (Lin, 2004) 和 DialogRPT (Gao et al., 2020) 等，被用作衡量AI助教响应的连贯性和类人性，但这些指标不考虑教学价值，且常需要真实答案来评估匹配响应。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;面向教学的评估&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;传统学习科学中的评估方法主要设计用于评估人类教师，由于缺乏自我报告，不易直接应用于AI教师。&lt;/li&gt;
&lt;li&gt;研究人员考虑不同的教学维度及其相关定义 (Wollny et al., 2021; Tack et al., 2023; Denny et al., 2024)。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;学生错误纠正任务&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;专注于数学领域的教育对话，特别是学生的失误或困惑，AI教师的目标是回应以纠正这些错误或困惑。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些相关研究提供了评估AI助教的不同视角和方法，但存在评估方案和定义的差异，缺乏标准化，使得跟踪现有AI教师的进步和实际性能变得复杂。这篇论文提出的评估分类体系旨在统一这些评估方法，并提供一个基于学习科学原则的评估框架。&lt;/p&gt;
&lt;h3 id=&#34;q3-论文如何解决这个问题&#34;&gt;&lt;strong&gt;Q3&lt;/strong&gt;: 论文如何解决这个问题？
&lt;/h3&gt;&lt;p&gt;论文通过以下几个步骤解决AI助教评估的问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;提出统一评估分类体系&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文提出了一个基于学习科学原则的统一评估分类体系，包含八个教学维度，用于评估LLM驱动的AI助教在数学领域的学生错误纠正中的教学价值。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;构建评估基准MRBench&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文编译并发布了一个新的评估基准MRBench，该基准包含来自两个公共数据集的192个对话和1596个响应，这些响应来自七个最先进的基于LLM的和人类助教，并提供了八个教学维度的黄金标注。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;人类和LLM评估&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;利用部分对话历史，展示了学生的失误，生成了七个最先进的LLM作为助教的响应，并通过人类和LLM基础评估来评估这些模型的教学能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分析LLM作为评估者的可靠性&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文探讨了LLM作为评估者的可靠性，通过将LLM生成的评估与人类判断进行相关性分析，指出LLM在复杂教学维度上的评估是不可靠的。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;讨论改进方向&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文基于人类评估指出了LLMs在响应中表现出的特定教学能力的不足，并讨论了改进AI助教教学能力的最相关方向。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;资源公开&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文承诺将公开分类体系、基准和人类标注，以促进未来在这一重要领域的研究。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通过这些步骤，论文旨在简化AI助教的评估过程，并帮助跟踪AI助教发展的进步。此外，该研究还为创建和标注可用于强化学习和微调的数据集提供了可能性，帮助未来的AI助教与人类和教学价值观保持一致。&lt;/p&gt;
&lt;h3 id=&#34;q4-论文做了哪些实验&#34;&gt;&lt;strong&gt;Q4&lt;/strong&gt;: 论文做了哪些实验？
&lt;/h3&gt;&lt;p&gt;论文中进行了一系列实验来验证提出的评估分类体系的有效性，并评估不同LLM作为AI助教的教学能力。以下是主要的实验步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;评估分类体系验证&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;进行了验证实验，以确定提出的八个评估维度是否足够且无冗余。实验包括四名注释者对八个随机抽样的对话进行独立标注，并计算Fleiss&amp;rsquo; kappa值来衡量注释者间的一致性，结果表明有实质性的一致性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基准准备&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;从Bridge和MathDial数据集中编译了MRBench评估基准，并为192个实例生成了基于七个最先进的LLM的响应。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;人类标注&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;四名训练有素的标注者使用验证过的分类体系对MRBench进行了标注，每个标注者负责48个对话，总共192个实例被标注，其中40个实例由两名标注者独立标注，以计算标注者间的一致性，平均Cohen&amp;rsquo;s kappa得分为0.71，表明有实质性的一致性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LLM基础标注&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;使用Prometheus2 LLM作为评估者对MRBench进行标注，以评估LLM作为评估者的可靠性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估指标&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;使用期望标注匹配率（DAMR）和标注相关性（AC）两个关键指标来定量评估LLM和人类教师的教学效果，并进行比较分析。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;关键发现&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;基于人类和LLM对MRBench的评估，总结了不同LLM作为AI助教的教学能力的关键发现，并讨论了LLM作为评估者的可靠性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些实验步骤不仅验证了提出的评估分类体系的有效性，而且提供了对不同LLM在教学能力方面的深入分析，并探讨了LLM作为评估者的可行性。通过这些实验，论文展示了当前LLM作为AI助教的能力和局限性，并指出了未来改进的方向。&lt;/p&gt;
&lt;h3 id=&#34;q5-有什么可以进一步探索的点&#34;&gt;&lt;strong&gt;Q5&lt;/strong&gt;: 有什么可以进一步探索的点？
&lt;/h3&gt;&lt;p&gt;论文在最后部分提出了一些可以进一步探索的点，这些包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;扩展到其他任务和学科领域&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文提出的评估分类体系主要集中在数学领域的学生错误纠正任务上。未来的研究可以验证并可能适应这个分类体系，以应用于其他任务（如概念学习）和学科（如科学、语言学习等）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;考虑学生视角&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;目前的分类体系和标注方案关注于教师响应的适当性，但未考虑辅导对话对学生学习过程和学习成果的整体影响。未来的研究可以将评估扩展到对话层面，以更好地评估AI教师的教学能力对学生学习的影响。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用其他LLM作为评估者&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文中限制了LLM基础评估到Prometheus2 LLM作为批评者的使用。未来的研究可以探索更多先进的LLM作为批评者，并尝试使用多种提示模板。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;创建和标注数据集&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文提到，创建和标注可用于强化学习和微调的数据集，可以帮助未来的AI教师与人类和教学价值观保持一致。这是一个重要的研究方向，可以促进AI教师的发展。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;改进LLM的教学能力&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文的研究发现，即使是最先进的LLM也缺乏一些有效的教学能力。未来的研究可以探索如何改进LLMs，使其更符合教学的有效性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估LLM生成内容的伦理和风险&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;考虑到LLM可能生成事实上不正确、无意义或甚至冒犯的内容，未来的研究需要考虑评估LLM在教育领域使用时的伦理风险，并探索如何减轻这些问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些探索点为AI助教评估和开发的未来研究提供了明确的方向，并强调了需要进一步工作以提高AI教师的教学效果和可靠性。&lt;/p&gt;
&lt;h3 id=&#34;q6-总结一下论文的主要内容&#34;&gt;&lt;strong&gt;Q6&lt;/strong&gt;: 总结一下论文的主要内容
&lt;/h3&gt;&lt;p&gt;这篇论文的主要内容包括以下几个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;研究动机&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文探讨了当前最先进的大型语言模型（LLMs）是否能够作为有效的AI助教，并展示必要的教学能力，特别是在教育对话中纠正学生错误和困惑的场景。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估分类体系&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;提出了一个统一的评估分类体系，包含八个基于学习科学原则的教学维度，用于评估LLM驱动的AI助教在数学领域的学生错误纠正中的教学价值。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估基准MRBench&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;发布了一个新的评估基准MRBench，包含192个对话和1596个响应，这些响应来自七个最先进的基于LLM的和人类助教，并提供了八个教学维度的黄金标注。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;人类和LLM评估&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;通过人类和LLM基础评估，分析了不同LLM作为AI助教的教学能力，并讨论了LLM作为评估者的可靠性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;研究发现&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;发现尽管最先进的LLMs如GPT-4在回答问题方面表现良好，但作为教师时往往不够胜任，特别是在不立即透露答案和提供指导方面。&lt;/li&gt;
&lt;li&gt;Llama-3.1-405B在评估中表现最好，而GPT-4作为教师时太快透露答案，Gemini的响应不够连贯，Sonnet虽然注重人类化和鼓励性，但在其他维度上效果较差，Phi3的表现最差。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;结论和未来工作&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文得出结论，当前的LLMs作为AI教师还不够好，有很大的改进空间，并指出了最相关的改进方向。&lt;/li&gt;
&lt;li&gt;论文希望发布的资源能够简化评估过程，并帮助跟踪AI教师的发展。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;局限性和伦理声明&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;论文承认了研究的局限性，并强调了LLM输出可能带来的风险，尤其是在教育领域可能误导学生和传播偏见的问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这篇论文为AI助教的评估提供了一个统一的框架和基准，并通过对现有技术的评估，揭示了AI助教在教学能力上的不足和未来改进的方向。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>李宏毅机器学习2025 · Transformer</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-transformer/</link>
        <pubDate>Sat, 06 Sep 2025 17:39:34 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-transformer/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1aiADewEBC&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;李宏毅机器学习2025&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;transformer&#34;&gt;Transformer
&lt;/h1&gt;</description>
        </item>
        <item>
        <title>李宏毅机器学习2025 · Agent</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/</link>
        <pubDate>Wed, 03 Sep 2025 17:13:34 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1aiADewEBC&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;李宏毅机器学习2025&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;agent&#34;&gt;Agent
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;传统AI：给定明确步骤、指令，AI完成任务&lt;/p&gt;
&lt;p&gt;Agent：给定目标，由Agent想办法完成&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Agent将通过观察Environment，采取特定的Action&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;强化学习：通过强化学习方法得到的Agent是可行的，但是不具备通用能力（围棋Agent不能处理五子棋）&lt;/li&gt;
&lt;li&gt;LLM：通过文字描述进行交互，具备通用能力&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Goal、Environment1、Action1、Environment2、Action2……&lt;/p&gt;
&lt;p&gt;本质上也是在接龙&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;回合制的交互会比较好做，有时候会需要被实时打断&lt;/p&gt;
&lt;p&gt;即：Action执行时，Environment变化，会需要Agent中断Action，进行新的Action&lt;/p&gt;
&lt;p&gt;常见应用：语音聊天&lt;/p&gt;
&lt;h2 id=&#34;memory&#34;&gt;Memory
&lt;/h2&gt;&lt;p&gt;交互的次数足够多时，记忆量过大，会造成Agent性能下降&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903173912076.png&#34;
	width=&#34;979&#34;
	height=&#34;438&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903173912076_hu_367f3630cccba63d.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903173912076_hu_2b228b5efbfd68d5.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Relevant Experience&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;223&#34;
		data-flex-basis=&#34;536px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;因此针对相关经验做一些记忆的检索和筛选是必要的&lt;/p&gt;
&lt;p&gt;可以直接套RAG的技术&lt;/p&gt;
&lt;p&gt;但这里最好不要提供模型&lt;strong&gt;过去的错误例子&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这里的情景似乎没有做一些纠错任务，给了错误的例子性能会发生下降&lt;/p&gt;
&lt;p&gt;因此设计Agent时需要考虑一下哪些内容是应该提供或筛除的&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;模型的使用技巧：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;告诉模型&lt;strong&gt;应该做什么&lt;/strong&gt;比告诉模型&lt;strong&gt;不要做什么&lt;/strong&gt;效果更好&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903174906691.png&#34;
	width=&#34;996&#34;
	height=&#34;562&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903174906691_hu_f6af179a283dfdc5.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903174906691_hu_821175316e4721a6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;其他模块&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;425px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;从存储角度出发&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;有些记忆没有存储的必要，因此可以引入一个Write模型去分类筛选&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有些记忆可以被格式化、转化成更好、更通用的内容，可以引入Reflection模块做转化，存储到合适的载体中，方便Read去做RAG&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;function-call&#34;&gt;Function Call
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175717235.png&#34;
	width=&#34;914&#34;
	height=&#34;506&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175717235_hu_ed1a5d1a14bada8b.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175717235_hu_e71df3da242a3060.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;180&#34;
		data-flex-basis=&#34;433px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175818476.png&#34;
	width=&#34;917&#34;
	height=&#34;467&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175818476_hu_22c32e30ae66218a.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903175818476_hu_5c8473782c8d6e9a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;196&#34;
		data-flex-basis=&#34;471px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;通常会把调用方法、工具列表放在System Prompt中&lt;/p&gt;
&lt;p&gt;让用户通过User Prompt进行交互&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Function过多时，可以参考上述的Memory方法去做选择&lt;/li&gt;
&lt;li&gt;Agent也可以自己做一个Function，放入Memory中&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;Agent有时候会过度相信工具&lt;/p&gt;
&lt;p&gt;因此需要看看模型自己是否有辨别的能力（室温10000°？不对，这里是工具出错了）&lt;/p&gt;
&lt;p&gt;但其实加一个Reflection也不错&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;课堂中探索了哪些信息是容易被模型采纳的&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903180638418.png&#34;
	width=&#34;1004&#34;
	height=&#34;447&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903180638418_hu_288966a3f1308ca0.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903180638418_hu_7fc90cbfb0772e7d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Ex1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;224&#34;
		data-flex-basis=&#34;539px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;当原始上下文逐渐被不切实际的值修改时，LLM（大语言模型）会越来越多地回归到其先验知识&lt;/li&gt;
&lt;li&gt;LLM坚持遵循上下文中检索到的信息的可能性，与其在没有上下文时对自身回复的信心呈负相关。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;省流：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;外部知识如果和模型知识差距越大，模型会对模型知识更有信心；差距越小，模型更愿意相信外部知识&lt;/li&gt;
&lt;li&gt;模型对模型知识的likelihood越大，对外部知识的likelihood越小&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181056340.png&#34;
	width=&#34;980&#34;
	height=&#34;345&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181056340_hu_9337652e32037257.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181056340_hu_4a48cefaca72e4f5.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Ex2&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;284&#34;
		data-flex-basis=&#34;681px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;AI和人类分别给出两个意见不同的文章，AI倾向于相信AI&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ex单独抽取了AI回答错误的例子（排除AI与AI回答类似，造成偏好的情况），但仍然是AI更相信AI&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体原因未知，猜测是AI的文章结构、表达上比人类更好&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2401.11911&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181530086.png&#34;
	width=&#34;992&#34;
	height=&#34;443&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181530086_hu_ce69793f148b679b.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903181530086_hu_3f116d49e637459e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Ex3&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;223&#34;
		data-flex-basis=&#34;537px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;（这里首先都是用了AI生成的文章做实验，避免偏好问题，并且文章都是假的）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Meta Data会影响模型的采纳&lt;/li&gt;
&lt;li&gt;其中时间影响较大&lt;/li&gt;
&lt;li&gt;资料来源写Wikipedia还是其他来源，似乎没有什么影响（这里比较反直觉）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是实验做得似乎比较粗糙，看看就好&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;总结：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型总会犯错&lt;/li&gt;
&lt;li&gt;Function Call要不要采用取决模型本身能力，如果模型可以自己解决没必要Call&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;plan&#34;&gt;Plan
&lt;/h2&gt;&lt;p&gt;目前的Agent都喜欢做一个Plan，再开始Action&lt;/p&gt;
&lt;p&gt;但是Plan不能定太死&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;操作浏览器时突然出现一个广告弹窗&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182236824.png&#34;
	width=&#34;1040&#34;
	height=&#34;351&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182236824_hu_655a62e81b69f692.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182236824_hu_9d822b41853c3318.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Plan&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;296&#34;
		data-flex-basis=&#34;711px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;因此Plan需要灵活，一种方案是：每次思考一下Plan要不要重新制定&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;如何强化模型的规划能力？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182925762.png&#34;
	width=&#34;1036&#34;
	height=&#34;530&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182925762_hu_e0ecbc68cec78b03.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903182925762_hu_c450aee5b61cfd30.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;搜索与剪枝&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;195&#34;
		data-flex-basis=&#34;469px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;让模型实际去探索一下（本质是搜索）&lt;/li&gt;
&lt;li&gt;可以剪枝（自问自答：当前还有机会完成任务吗？）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（不适合不容易回溯状态的任务，例如：订餐）&lt;/p&gt;
&lt;p&gt;（但是可以引入一个World Model，让模型扮演环境本身去做反馈，模拟）&lt;/p&gt;
&lt;p&gt;从Agent的角度去看待模型Thinking Mode：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903183347542.png&#34;
	width=&#34;1062&#34;
	height=&#34;542&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903183347542_hu_7409da7ba96a6ac5.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-agent/assets/image-20250903183347542_hu_71f6bd0b8e42b3cb.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Thinking Mode&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;195&#34;
		data-flex-basis=&#34;470px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;一些杂谈：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;做benchmark或一些实验的时候，思考一下这个任务LLM会不会在互联网数据中提前得到&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>李宏毅机器学习2025 · 前言</title>
        <link>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/</link>
        <pubDate>Tue, 02 Sep 2025 20:46:34 +0800</pubDate>
        
        <guid>https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1aiADewEBC&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;李宏毅机器学习2025&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;被手搓大模型橄榄了，写BPE写的心态爆了&lt;/p&gt;
&lt;p&gt;不如我们先停下来推一下一些比较有趣的课程&lt;/p&gt;
&lt;h1 id=&#34;前言&#34;&gt;前言
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;Those token could be anything.&lt;/p&gt;
&lt;p&gt;解析任何事物为若干有限的基本单位（token），你就可以使用生成式AI做任何事情&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;auto-regressive-generation&#34;&gt;Auto Regressive Generation
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;自回归生成（其实就是词语接龙）&lt;/li&gt;
&lt;/ul&gt;
$$
x_1,x_2,...,x_j \to y_1\\
x_1,x_2,...,x_j,y_1 \to y_2\\
x_1,x_2,...,x_j,y_1,y_2 \to ...\\
x_1,x_2,...,x_j,y_1,y_2,... \to \text{end token}\\
$$&lt;p&gt;token作为文字时：语言模型&lt;/p&gt;
&lt;p&gt;（但是不管是什么都会被称为语言模型，因为热度太大了）&lt;/p&gt;
&lt;p&gt;本质上都是在有限的选择中做出选择完成输出&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902210520749.png&#34;
	width=&#34;877&#34;
	height=&#34;483&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902210520749_hu_c6d279eefb5346cf.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902210520749_hu_8732fdb1d4ca93a8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;生成式AI&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;181&#34;
		data-flex-basis=&#34;435px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过Neural Network，得到的是各个token的概率分布
&lt;ul&gt;
&lt;li&gt;模型架构（超参数）：由人类确定&lt;/li&gt;
&lt;li&gt;模型参数：由数据决定&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;thinking-mode&#34;&gt;Thinking Mode
&lt;/h2&gt;&lt;p&gt;对于现实中的问题，往往足够复杂，哪怕模型足够巨大，层数足够多，可能也无法处理&lt;/p&gt;
&lt;p&gt;而带有思考能力的LLM表现良好，可以从模型层数的角度进行解释&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902210943599.png&#34;
	width=&#34;903&#34;
	height=&#34;427&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902210943599_hu_6aee250c4eea9f13.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902210943599_hu_dc25cb538fafd38d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Thinking Mode&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;211&#34;
		data-flex-basis=&#34;507px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;每次给定输入token集合，产生一个token的输出，模型会过一遍所有的Layer&lt;/p&gt;
&lt;p&gt;所以只要不断思考，本质上是一直在重复这个模型Layer的堆积&lt;/p&gt;
&lt;p&gt;因此思考长度足够，似乎是在使用一个&lt;strong&gt;巨深的模型&lt;/strong&gt;进行推理&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;训练时缩放（Training Time Scaling）&lt;/strong&gt;：通过训练来让模型变得更强大。这需要巨大的成本重新训练模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;增加模型参数量（scale up）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;增加训练数据&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;延长训练时间（增加计算量）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;测试时缩放（Testing Time Scaling）&lt;/strong&gt;：&lt;strong&gt;模型已经训练好了，参数固定不变。&lt;/strong&gt; 我们通过一些“技巧”，在&lt;strong&gt;使用&lt;/strong&gt;这个模型的时候投入更多的计算资源&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;生成多个答案然后挑最好的&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;更仔细地推理&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Testing Time Scaling：在不改变模型本身weights的情况下，仅通过改变inference或testing时的方法和计算量，就能显著提升模型性能的一种现象或技术集合。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902213913156.png&#34;
	width=&#34;928&#34;
	height=&#34;402&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902213913156_hu_492ada79126596e9.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902213913156_hu_6bb28dd1c56cb705.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;TTS&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;230&#34;
		data-flex-basis=&#34;554px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;本质上是在叠加模型层数，如图，思考的token开销越多，性能确实越好&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如何控制token？一个粗暴的方法，在结束的时候把end变成wait&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;development&#34;&gt;Development
&lt;/h2&gt;&lt;p&gt;模型的演变经历了专用模型到通用模型的趋势&lt;/p&gt;
&lt;p&gt;而通用模型的演变也非常迅速&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902215817397.png&#34;
	width=&#34;938&#34;
	height=&#34;485&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902215817397_hu_4de31912bfc26bb8.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902215817397_hu_83cd7663fa05fbf4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Encoder&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;464px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Encoder：将文本encode成向量
&lt;ul&gt;
&lt;li&gt;配套专用模型完成输出&lt;/li&gt;
&lt;li&gt;架构不同&lt;/li&gt;
&lt;li&gt;参数不同&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902220023151.png&#34;
	width=&#34;923&#34;
	height=&#34;486&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902220023151_hu_1a956035b96d2c2b.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902220023151_hu_8a168de1792f4caa.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Fine-tune&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;189&#34;
		data-flex-basis=&#34;455px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fine-Tune：通过微调适配不同任务
&lt;ul&gt;
&lt;li&gt;架构相同&lt;/li&gt;
&lt;li&gt;参数不同&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902220142932.png&#34;
	width=&#34;920&#34;
	height=&#34;482&#34;
	srcset=&#34;https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902220142932_hu_3f5c6b335bc46f46.png 480w, https://example.com/p/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A02025-%E5%89%8D%E8%A8%80/assets/image-20250902220142932_hu_79525b51f8b740bb.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Prompt&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;190&#34;
		data-flex-basis=&#34;458px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prompt：直接给指令做不同任务
&lt;ul&gt;
&lt;li&gt;架构相同&lt;/li&gt;
&lt;li&gt;参数相同&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Homework1就不做了，一个RAG任务，之前做过类似的&lt;/p&gt;
</description>
        </item>
        <item>
        <title>大语言模型教育纠错 · 论文笔记（二）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/</link>
        <pubDate>Wed, 16 Jul 2025 02:45:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2406.19949&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2406.19949 Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro
&lt;/h2&gt;&lt;p&gt;存在的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;基于分类器的黑盒方法虽然准确，但无法提供解释性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;现有生成评分理由的方法（如AERA框架(&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2305.12962&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2305.12962 Distilling ChatGPT for Explainable Automated Student Answer Assessment&lt;/a&gt;）存在以下问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;评分准确性不如分类器方法。&lt;/li&gt;
&lt;li&gt;生成的评分理由可能不忠实于学生答案或评分标准。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;paper贡献&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提出一种新框架，通过模仿人类评分过程生成更忠实的评分理由，同时匹配或超越分类器方法的评分性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;paper方法&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;模仿人类评分过程&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用大语言模型（LLM）生成“思维树”（Thought Tree），将评分任务分解为中间决策步骤。&lt;/li&gt;
&lt;li&gt;每条树路径代表一个评分决策序列，最终汇总为评分理由。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;合成数据生成&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从思维树路径中提取合成评分理由和偏好数据。&lt;/li&gt;
&lt;li&gt;通过两阶段训练校准LLM：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;监督微调（SFT）&lt;/strong&gt;：使用合成的评分理由数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;偏好优化（DPO）&lt;/strong&gt;：使用合成的偏好数据，提升评分理由的准确性和忠实性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;paper贡献&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提出通过思维树生成更忠实的评分理由的方法。&lt;/li&gt;
&lt;li&gt;开发基于思维树路径正确性的合成偏好数据生成技术。&lt;/li&gt;
&lt;li&gt;实验表明，框架在QWK分数上比现有方法提升38%，同时生成更高质量的评分理由。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;framework&#34;&gt;Framework
&lt;/h2&gt;&lt;h3 id=&#34;problem-set-up&#34;&gt;Problem Set Up
&lt;/h3&gt;$$
D = \left \{ (x_i, y_i)\right \}
$$&lt;p&gt;
表示学生$i$对某道题目的答案与得分&lt;/p&gt;
&lt;p&gt;对于一道题目，可以划分出$M$个关键得分点$K = \left {k_j\right }$&lt;/p&gt;
$$
v(x_i, K)
$$&lt;p&gt;
该向量的第$j$维度若为1，则表示$x_i$成功回答了$k_j$，否则没有成功回答&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;独热向量 (One-hot Vector)&lt;/strong&gt;：用于表示一个样本&lt;strong&gt;只属于一个类别&lt;/strong&gt;的情况。例如，如果一个动物只能是“- 猫”或“狗”中的一种，那么“猫”可能表示为 &lt;code&gt;[1, 0]&lt;/code&gt;，“狗”表示为 &lt;code&gt;[0, 1]&lt;/code&gt;。向量中&lt;strong&gt;只有一个 1&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;多热向量 (Multi-hot Vector)&lt;/strong&gt;：用于表示一个样本&lt;strong&gt;可以同时属于多个类别&lt;/strong&gt;的情况。例如，一个人既是“学生”又是“运动员”，那么可能表示为 &lt;code&gt;[1, 1, 0]&lt;/code&gt;（假设第一个位置是学生，第二个是运动员）。向量中可以有&lt;strong&gt;多个 1&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
$$
y_i = f_r(v(x_i,K))
$$&lt;p&gt;
省流：问题的关键在如何判断$x_i$正确回答了$k_j$，记为$1_{x_i}(k_j)$，是一个二分类任务&lt;/p&gt;
&lt;h3 id=&#34;stage-1-imitate-human-assessment-process-via-thought-trees&#34;&gt;Stage 1: Imitate Human Assessment Process via Thought Trees
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/assets/image-20250716031327371.png&#34;
	width=&#34;961&#34;
	height=&#34;611&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/assets/image-20250716031327371_hu_72b7ba402e41067b.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/assets/image-20250716031327371_hu_9fdc14ddcae9f199.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Thought Trees&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;157&#34;
		data-flex-basis=&#34;377px&#34;
	
&gt;&lt;/p&gt;
$$
z_j^{(t)} = \text{LLM}_\theta(x_i, k_j), \quad t=1,2,...,n,\ \forall k_j \in K
$$&lt;p&gt;
$z_j^{(t)}$ 表示第 $t$ 次采样的决策&lt;/p&gt;
&lt;p&gt;我们将这些判定结果汇总，得到如下的平均决策概率：&lt;/p&gt;
$$
P(z_j^{\text{Yes}}) = \frac{|\{t : z_j^{(t)} = 1\}|}{n},\quad
P(z_j^{\text{No}}) = \frac{|\{t : z_j^{(t)} = 0\}|}{n}
$$&lt;p&gt;
为了后续聚合，我们为每个关键要素生成简洁的解释性理由 $r_j$，例如：&lt;/p&gt;
$$
r_j = \text{LLM}_\theta(x_i, k_j, z_j)
$$&lt;p&gt;
一旦所有关键要素评估完成，我们便能根据每一组决策 $\mathbf{Z}$ 构造路径。假设总共 $d$ 条路径（最多 $2^{M-1}$ 条），每条路径表示一种判定组合：&lt;/p&gt;
$$
\text{path}_l = \hat{\mathbf{v}}(\mathbf{Z}),\quad l=1,2,...,d
$$&lt;p&gt;其中，$\hat{\mathbf{v}}$ 是对向量 $\mathbf{v}$ 的估计，表示关键要素是否被覆盖；$\mathbf{Z}$ 是判定集合（由上面的判定概率组成）。路径的概率等于该路径上每个判定概率的乘积：&lt;/p&gt;
$$
P(\text{path}_l) = \prod_{j=1}^{M} P(z_j)
$$&lt;p&gt;
我们利用打分函数 $f_r$（例如程序化的rubric规则）对每条路径打分，获得预测得分：&lt;/p&gt;
$$
\hat{y}_{\text{path}_l} = f_r(\text{path}_l)
$$&lt;blockquote&gt;
&lt;p&gt;省流：蒙特卡洛树，从中抽取所有路径，计算概率和对应的分数，选择概率最高的&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;最后，选取概率最高的路径作为最终思维树输出结果：&lt;/p&gt;
$$
\hat{y}_{\text{tree}} = \hat{y}_{\text{path}_{l^*}} \quad l^* = \arg\max_l P(\text{path}_l)
$$&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;在实际操作中，我们使用LLM动态地将rubric文本转换为可执行Python代码，该代码以关键要素评估决策为输入，输出最终分数。&amp;rdquo;&lt;/p&gt;
&lt;p&gt;人话：LLM会将打分标准生成Python代码，直接传入关键要素的多热向量就可以直接算分&lt;/p&gt;&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>大语言模型数据清洗 · 论文笔记（五）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/</link>
        <pubDate>Thu, 10 Jul 2025 11:16:32 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&#34;essential-web-v10-24t-tokens-of-organized-web-data&#34;&gt;Essential-Web v1.0 24T tokens of organized web data
&lt;/h1&gt;&lt;h2 id=&#34;preview&#34;&gt;Preview
&lt;/h2&gt;&lt;p&gt;构建了多维度的分类体系，适合通过SQL等方式进行数据筛选出新的数据集&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用开源模型进行数据标签的标注，得到了EAI-Distill-0.5b&lt;/li&gt;
&lt;li&gt;推理清洗了23.6B的数据，花费了90000 AMD MI300x GPU-hours&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;The inference job ran on 512 AMD MI300x for about 1 week.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;分类体系：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个有限的类别集合 $T=\left { C_1, C_2, &amp;hellip;, C_k \right } $。&lt;/li&gt;
&lt;li&gt;每个类别$C_i$都有一个非空、有限的标签集$L_i$。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;标注形式为$T(d) = \left { (\lambda_1, \mu_1), &amp;hellip;\right}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其中，$λ_i\in L_i$ 是类别$C_i$的主要标签&lt;/li&gt;
&lt;li&gt;$\mu_i \in (L_i \setminus {\lambda_i}) \cup {\bot}$ 是一个可选的次要标签，必须与$\lambda_i$不同
&lt;ul&gt;
&lt;li&gt;当文档适合两个标签时非常有用&lt;/li&gt;
&lt;li&gt;$\bot$表示弃权（abstention）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;所有类别和标签集都是预先固定的，这允许训练一个单一的静态分类器&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/assets/image-20250710141259250.png&#34;
	width=&#34;923&#34;
	height=&#34;234&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/assets/image-20250710141259250_hu_35e32e8ea56e9d9f.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/assets/image-20250710141259250_hu_7dca944e0ae04e92.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;PipeLine&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;394&#34;
		data-flex-basis=&#34;946px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;实验设置&#34;&gt;实验设置
&lt;/h2&gt;&lt;blockquote&gt;
&lt;h2 id=&#34;chinchilla最优计算比例&#34;&gt;Chinchilla最优计算比例
&lt;/h2&gt;&lt;p&gt;Chinchilla缩放定律发现了一个最优比例：大约每个参数需要20个训练token &lt;a class=&#34;link&#34; href=&#34;https://epoch.ai/blog/chinchilla-scaling-a-replication-attempt&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Epoch AI&lt;/a&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.analyticsvidhya.com/blog/2024/09/chinchilla-scaling-law/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Analytics Vidhya&lt;/a&gt;。这个比例是DeepMind通过训练400多个语言模型得出的计算最优配置。&lt;/p&gt;
&lt;p&gt;具体来说：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chinchilla模型有70B参数，在1.4万亿tokens上训练，达到20 tokens per parameter的比例 &lt;a class=&#34;link&#34; href=&#34;https://epoch.ai/blog/chinchilla-scaling-a-replication-attempt&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Chinchilla Scaling: A Replication Attempt | Epoch AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;这个20:1的比例被认为是在给定计算预算下实现最佳性能的理想配置&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/assets/image-20250710142401273.png&#34;
	width=&#34;608&#34;
	height=&#34;269&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/assets/image-20250710142401273_hu_1c12a53edcfe7eaf.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%94/assets/image-20250710142401273_hu_1c71ffbb1c3f701e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Train&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;226&#34;
		data-flex-basis=&#34;542px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;所有数据集在训练前均使用了 13-gram Bloom Filter&lt;/p&gt;
&lt;p&gt;选用了两个2.3B模型对数据进行评估&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;预训练（3200亿Token）：该阶段帮助模型学到广泛的语言知识&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;General-base：仅使用网络数据（DCLM-baseline）做&lt;strong&gt;预训练&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Code-base：使用网络数据（DCLM-baseline）+代码数据（Stack v2 Dedup中的Python），各占50%做&lt;strong&gt;预训练&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;退火（800亿token）：为了评估特定领域数据集的性能，采用需要评估的新数据集&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;学习率接近零的目的是在新的领域数据上进行“微调”，而不是进行大规模的“重新训练”&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;每个模型总计处理 4000 亿 token 数据量，是Chinchilla的10倍数据&lt;/p&gt;
&lt;h2 id=&#34;蒸馏&#34;&gt;蒸馏
&lt;/h2&gt;&lt;h3 id=&#34;蒸馏方案&#34;&gt;蒸馏方案
&lt;/h3&gt;&lt;h4 id=&#34;数据来源与规模&#34;&gt;&lt;strong&gt;数据来源与规模&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;标注数据&lt;/strong&gt;：使用Qwen2.5-32B-Instruct对104.6M文档共82Btoken进行两轮标注，生成合成标签用于蒸馏训练。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;第一轮&lt;/strong&gt;：标注8个分类类别（如FDC、Document Type V1/V2等）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;第二轮&lt;/strong&gt;：扩展至12个类别（新增Bloom、Technical Correctness等）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;数据预处理&#34;&gt;&lt;strong&gt;数据预处理&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;子采样&lt;/strong&gt;：对超过30,000字符的文档，截取开头、随机中间段和结尾（Algorithm 12），避免长文本影响推理速度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;质量过滤&lt;/strong&gt;：通过统计和模型信号（如DCLM分类器）过滤低质量文档（Algorithm 1）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;模型架构&#34;&gt;&lt;strong&gt;模型架构&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;基础模型&lt;/strong&gt;：Qwen2.5-0.5b-Instruct（5亿参数），基于Gemma 3架构，使用QK-norm稳定注意力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;序列长度&lt;/strong&gt;：16,384 tokens，支持长上下文。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;训练参数&#34;&gt;&lt;strong&gt;训练参数&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优化器&lt;/strong&gt;：AdamW（β1=0.9, β2=0.95），权重衰减0.1。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;学习率&lt;/strong&gt;：峰值1e-4，线性预热2B tokens，余弦衰减至1e-5，最后线性退火至0。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;批量大小&lt;/strong&gt;：全局2M tokens，梯度累积实现大批次训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;训练量&lt;/strong&gt;：82B tokens（合成标签数据）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;损失计算&lt;/strong&gt;：仅对教师模型生成的标签token计算损失，输入文档和系统提示被掩码。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;教师模型选择&#34;&gt;&lt;strong&gt;教师模型选择&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;教师&lt;/strong&gt;：Qwen2.5-32B-Instruct，因其标注一致性（κ=0.74）与推理速度平衡（1.4 RPS/GPU）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;蒸馏步骤&#34;&gt;&lt;strong&gt;蒸馏步骤&lt;/strong&gt;
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;标签生成&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;教师模型生成多分类标签（如FDC层级、Document Type等），格式为&lt;code&gt;主标签,次标签&lt;/code&gt;（Algorithm 13）。&lt;/li&gt;
&lt;li&gt;压缩输出：从平均791 tokens缩短至51 tokens，提升推理速度50倍（Table 12）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;上下文蒸馏&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;移除教师模型的提示模板（Prompt 1/2），直接训练学生模型生成压缩格式标签。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;评估方案&#34;&gt;评估方案
&lt;/h3&gt;&lt;h4 id=&#34;metrics&#34;&gt;Metrics
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;正确性：多人分类的结果应该类似，验证模型打标签是否标准一致
&lt;ul&gt;
&lt;li&gt;使用GPT-4o和Claude Sonnet-3.5作为专家模型&lt;/li&gt;
&lt;li&gt;使用kappa系数作为指标&lt;/li&gt;
&lt;li&gt;取对4o的系数和对claude的系数的均值作为结果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;检测方式是验证模型与专家模型的标准是否一致，对于指标paper中进行了变种&lt;/p&gt;
&lt;p&gt;对于某个模型的分类结果$S\in \left { \phi, (\text{label}), (\text{label1, label2}) \right }$​&lt;/p&gt;
&lt;p&gt;最少是一个标签（主标签），有时可以加一个次标签&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;标注结果一致的判定：两模型的$S$​有交集&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然后套公式&lt;/p&gt;
&lt;p&gt;Qwen2.5-32B-Instruct ≈ 0.74&lt;/p&gt;
&lt;p&gt;EAI-Distill-0.5b ≈ 0.71~0.73&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;正交性：不同分类体系之间的标签应该是独立的
&lt;ul&gt;
&lt;li&gt;例如在某分类A下打了a，分类B始终是b，发生了绑定&lt;/li&gt;
&lt;li&gt;需计算互信息、香农熵&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
$$
&gt;\text{NMI}(X, Y) = \frac{2 I(X; Y)}{H(X) + H(Y)}
&gt;$$&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$p(x)$按$x$出现的频率，$p(x,y)$按$x,y$同时出现的频率计算&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;$I(X; Y)$：互信息&lt;/li&gt;
&lt;/ul&gt;
$$
&gt;  I(X; Y) = \sum_{x, y} p(x, y) \cdot \log \frac{p(x, y)}{p(x)p(y)}
&gt;  $$&lt;ul&gt;
&lt;li&gt;$H(X)$：X 的香农熵&lt;/li&gt;
&lt;/ul&gt;
$$
&gt;  H(X) = -\sum_{x} p(x) \cdot \log p(x)
&gt;  $$&lt;p&gt;Qwen2.5-32B 平均 NMI ≈ 0.079&lt;/p&gt;
&lt;p&gt;EAI-Distill-0.5b 平均 NMI ≈ 0.092&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Domain Recall
&lt;ul&gt;
&lt;li&gt;定了Golden URL（认为arxiv和……30 个 base URL的都是高质量数据）&lt;/li&gt;
&lt;li&gt;统计有多少能被模型召回&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;dataset&#34;&gt;Dataset
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Random Set：随机采样（需要避免撞车训练数据）&lt;/li&gt;
&lt;li&gt;STEM Set：从特定领域集合（科学领域）随机采样&lt;/li&gt;
&lt;li&gt;通过Golden URL采样&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>大语言模型教育纠错 · 论文笔记（一）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/</link>
        <pubDate>Mon, 23 Jun 2025 15:13:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2412.16838&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2412.16838 Ask-Before-Detection: Identifying and Mitigating Conformity Bias in LLM-Powered Error Detector for Math Word Problem Solutions&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;AED（Automatic Error Detection）
&lt;ul&gt;
&lt;li&gt;本文定义为：给定问题-解答的输入对，识别错误步骤以及错误类型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250623164618186.png&#34;
	width=&#34;1119&#34;
	height=&#34;594&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250623164618186_hu_529466cf46b0a084.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250623164618186_hu_44cdd8acc43cea4e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;188&#34;
		data-flex-basis=&#34;452px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;如图，paper点出传统的方法使用可以对问题的&lt;strong&gt;常规解法&lt;/strong&gt;进行正确错误检测&lt;/p&gt;
&lt;p&gt;但是单个问题的解法可以&lt;strong&gt;存在多个&lt;/strong&gt;，认为之前的做法泛用性较差&lt;/p&gt;
&lt;p&gt;常规解法与非常规解法会产生7%的性能差距，先进的闭源模型也无法避免&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLM错误检测器表现&lt;code&gt;conformity bias&lt;/code&gt;（从众偏差）
&lt;ul&gt;
&lt;li&gt;倾向“遵循主流答案（训练中经常出现的）”而忽略可能也正确但不常见的其他解法&lt;/li&gt;
&lt;li&gt;导致模型对标准答案的识别准确，却对非常规解法的识别薄弱&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;论文针对缓解模型的&lt;code&gt;conformity bias&lt;/code&gt;进行工作&lt;/p&gt;
&lt;p&gt;提出AskBD框架，为每个Solution自适应生成参考答案（合适的参考答案能显著提升性能）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;直接调用模型，无微调，拓展性强&lt;/li&gt;
&lt;li&gt;自适应方式高度契合给定Solution，降低Bias&lt;/li&gt;
&lt;li&gt;框架可协同CoT技术增强性能&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminary-study&#34;&gt;Preliminary Study
&lt;/h2&gt;&lt;p&gt;Paper构建了一个Alternative Solution数据集用于充分暴露模型的从众偏差效应，帮助进行后续的探索&lt;/p&gt;
&lt;h3 id=&#34;automatic-solution-permutation&#34;&gt;Automatic Solution Permutation
&lt;/h3&gt;&lt;p&gt;paper希望构建一个高质量的Alternative Solution数据集&lt;/p&gt;
&lt;p&gt;给定问题和Solution，希望替换掉整个解决方案为Alternative Solution&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;低质量&lt;/strong&gt;：对常规Solution只是简单的&lt;strong&gt;语义替换&lt;/strong&gt;，并没有深层的逻辑变换&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250623172108657.png&#34;
	width=&#34;1094&#34;
	height=&#34;316&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250623172108657_hu_c5b1e501f2aed034.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250623172108657_hu_c24cb789034894c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;346&#34;
		data-flex-basis=&#34;830px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ASP&lt;/strong&gt;（自动解法置换），如图，对应了Solution和数学表达式的关系，使用LLM prompt独立执行：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Extract：常规Solution -&amp;gt; 数学表达式，完成后需要执行运算，检查是否能够得到正确计算结果，否则剔除&lt;/li&gt;
&lt;li&gt;Permute：因式分解、分配律，重新排列表达式（同样需要运算检验）&lt;/li&gt;
&lt;li&gt;Explain：置换后的表达式输入到LLM，引导生成高质量Alternative Solution&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;paper采样GPT-4o，从GSM8K数据集抽取200组问答对，构建常规数据集D&lt;/p&gt;
&lt;p&gt;对D中的每个样本，3次ASP生成3个Alternative Solution，由教育系研究生评审质量，选择三个之中最优的一个&lt;/p&gt;
&lt;p&gt;完成替换数据集D&amp;rsquo;的制作&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;erroneous-solution-generation&#34;&gt;Erroneous Solution Generation
&lt;/h3&gt;&lt;p&gt;需要将错误注入到D和D‘之中，生成测试样本&lt;/p&gt;
&lt;p&gt;主要参考：&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2406.00755&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2406.00755 Evaluating Mathematical Reasoning of Large Language Models: A Focus on Error Identification and Correction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;paper引入了四种错误：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\varepsilon_C$：calculation errors
&lt;ul&gt;
&lt;li&gt;Operands in expressions are correct but an error occurs in the calculated results.（表达式正确，计算结果出错）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Each gust blows the leaf forward 5 feet, so 11 gusts will blow it forward 5 ×11 = 50 feet. &lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$\varepsilon_R$：reference errors
&lt;ul&gt;
&lt;li&gt;Expression are incorrectly referencing the question conditions or the results from prior steps.（错误引用了题目条件或之前的计算结果）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Each gust blows the leaf forward 5 feet, so 10 gusts will blow it forward 5 ×10 = 50 feet. &lt;/code&gt;（题目原条件是11，不是10）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$\varepsilon_M$ ：missing steps
&lt;ul&gt;
&lt;li&gt;Operands or expressions in the step that lack of references or support from the question conditions or prior steps.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Each swirl after a gust blows it back 2 feet, so 11 swirls will blow it back 2 ×11 = 22feet. Step 2. After 11 gusts, the leaf has traveled 55 − 22 = 33 feet down the sidewalk.&lt;/code&gt;（缺少了得到55这个数字的计算过程）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$\varepsilon_H$：hallucinations（幻觉）
&lt;ul&gt;
&lt;li&gt;Statements or operands in the listed expression are fabricated or inconsistent with the question’s conditions.（虚构或与条件不一致）&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;It is worth noting that this study specifically aims to explore conformity bias, and therefore, &lt;strong&gt;we do not include all possible error types.&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;针对D和D&amp;rsquo;的每个样本，随机错误步骤的位置编号，每个样本生成了四种不同错误类型的样本，总共2000条&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154336790.png&#34;
	width=&#34;473&#34;
	height=&#34;212&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154336790_hu_396c502f844b6a72.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154336790_hu_4f52005375b8ff83.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Table 5&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;223&#34;
		data-flex-basis=&#34;535px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;analysis-and-findings&#34;&gt;Analysis and Findings
&lt;/h3&gt;&lt;h4 id=&#34;conformity-bias-identification&#34;&gt;Conformity Bias Identification
&lt;/h4&gt;&lt;p&gt;评估指标：The evaluation metric is the identification accuracy across both correct and erroneous solutions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需要识别错误位置、错误类型&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Paper使用提示词进行纠错，明确LLM本题存在替代解法，强调所有合理解决方案应该被接受，并且明确定义错误类别&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Given the &amp;lt;question&amp;gt;, please judge whether each step in &amp;lt;solution&amp;gt; is correct. **During the judging process, you should know that the &amp;lt;question&amp;gt; does not always have only one standard solution, and any reasonable &amp;lt;solution&amp;gt; should be accepted. You should pay attention to both the expressions and the statements in each step, and take care about the logic consistency between different steps. Additionally, consider arithmetic expression equivalency and avoid rejecting solutions solely because they use equivalent expressions.**
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;In each step, if no errors are found, respond with Step X: &amp;lt;correct&amp;gt;. If you find that the operands in the listed expressions are correct but an error occurs in the calculated result, respond with Step X: &amp;lt;calculation error&amp;gt;. If you find statements or operands in the listed expression are incorrectly referencing the question conditions or the results from prior steps, respond with Step X: &amp;lt;reference error&amp;gt;. If you find operands or expressions in the step that is lack of references or support from the question conditions or prior steps, respond with Step X: &amp;lt;missing step&amp;gt;. If you find statements or operands in the listed expression are fabricated or inconsistent with the question’s conditions, respond with: Step X: &amp;lt;hallucination&amp;gt;. If an error is a follow-on issue due to mistakes in previous steps rather than an independent error, respond with: Step X: &amp;lt;secondary error&amp;gt;.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;question&amp;gt; [Question Text] &amp;lt;solution&amp;gt; [Solution Text]  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Now, please start to respond.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;参与测试的LLM：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154400250.png&#34;
	width=&#34;441&#34;
	height=&#34;436&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154400250_hu_926cdad944d5de03.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154400250_hu_488d9a30ae5b5c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Table 6&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;101&#34;
		data-flex-basis=&#34;242px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;平均错误检测准确率的测试结果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154615400.png&#34;
	width=&#34;423&#34;
	height=&#34;305&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154615400_hu_e91b30da751b4c25.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626154615400_hu_4a904fb7a1a5feee.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Table 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;138&#34;
		data-flex-basis=&#34;332px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;证实了LLM在AED任务中存在明显的从众偏差&lt;/p&gt;
&lt;h4 id=&#34;solution-likelihood-score-analysis&#34;&gt;Solution Likelihood Score Analysis
&lt;/h4&gt;&lt;p&gt;对于当前问题$q$，我们可以计算LLM生成答案$s$的概率$P(s|q)$&lt;/p&gt;
&lt;p&gt;我们可以把$s$拆分成多个token：$s_i$&lt;/p&gt;
$$
P(s|q) = P(s_1, s_2, ...,s_{|s|} | q)
$$$$
P(s|q) = P(s_1|q) \times P(s_2|q,s_1) \times P(s_3|q,s_1,s_2) \times ...
$$$$
\log P(s|q) = \sum_{i=1}^{|s|} \log P(s_i|q,s_1:s_{i-1})
$$&lt;p&gt;
这个值就是&lt;strong&gt;对数似然分数&lt;/strong&gt; （Log-Likelihood Score）&lt;/p&gt;
&lt;p&gt;它衡量了模型在给定问题 &lt;em&gt;q&lt;/em&gt; 的情况下，对答案 &lt;em&gt;s&lt;/em&gt; 的“信任度”或理解程度&lt;/p&gt;
$$
\log L_{\theta}(s|q) = \frac{\log L_\theta(s|q)}{|s|}
$$&lt;p&gt;
其中$\theta$表示LLM的参数（闭源模型的似然分数无法获取，采取了开源模型的似然分数均值做伪指标）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163200484.png&#34;
	width=&#34;562&#34;
	height=&#34;478&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163200484_hu_9a5549ae053eac12.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163200484_hu_cfa275c0f051adca.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Advance Model&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;117&#34;
		data-flex-basis=&#34;282px&#34;
	
&gt; &lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163307581.png&#34;
	width=&#34;564&#34;
	height=&#34;480&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163307581_hu_49803f1626247f18.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163307581_hu_926314100216a0c1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Base Model&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;117&#34;
		data-flex-basis=&#34;282px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;同时喂入 了常规解法+替代解法，根据似然分数分成四个档进行对比&lt;/p&gt;
&lt;p&gt;显然似然值越高，Acc越高&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163347218.png&#34;
	width=&#34;577&#34;
	height=&#34;482&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163347218_hu_f8a58aeee4e02655.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626163347218_hu_3fada5ac724549e7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Likehood Distribution&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;119&#34;
		data-flex-basis=&#34;287px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;对于开源模型，替代解法的似然分数显然低于常规解法&lt;/p&gt;
&lt;h4 id=&#34;reference-based-detection-findings&#34;&gt;Reference-based Detection Findings
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;不太可能直接提高替代Solution的似然值
&lt;ul&gt;
&lt;li&gt;通过改变数据集进行微调，但是无法解决根本问题，仍有可能碰见其他的未遇见情况&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考：&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2407.09136&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2407.09136 Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors&lt;/a&gt;，提出引入参考答案提升了常规解法的检测性能&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;将学生解题步骤与标准答案对齐&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;本paper尝试推广到替代解法，但是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;实际情况下，参考答案并不是总能获取&lt;/li&gt;
&lt;li&gt;即便能够获取，一般也是常规解法的参考答案&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;paper采用了两条技术路线进行对比：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用常规解法作为参考答案&lt;/li&gt;
&lt;li&gt;自适应使用对应解法作为参考答案（？细节不太清楚，后文兴许会说）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626171423880.png&#34;
	width=&#34;458&#34;
	height=&#34;343&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626171423880_hu_38c9f63332d673bf.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626171423880_hu_6c0b72c548df9ffd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;常规解法作为参考答案&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;  &lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626171459301.png&#34;
	width=&#34;459&#34;
	height=&#34;348&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626171459301_hu_a726c1661fa683e4.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626171459301_hu_a94969f7c01bb73c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;自适应选择参考答案&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;131&#34;
		data-flex-basis=&#34;316px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;根据与前文提示词的测试结果进行对比，引入参考答案对两个数据集的&lt;strong&gt;acc都有显著的提升&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;但是使用常规解法做参考答案加剧了bias，而自适应选择明显缓解了bias&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因此选择合适的参考答案是能起到关键作用的&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method
&lt;/h2&gt;&lt;p&gt;提出AskBD（Ask-Before-Detection）框架，在评分过程中为每个待评答案动态生成适配的参考解法&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626172743783.png&#34;
	width=&#34;1227&#34;
	height=&#34;482&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626172743783_hu_dcc20bd97ebdb160.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626172743783_hu_1c39f4b9cd82f898.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Pipeline&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;254&#34;
		data-flex-basis=&#34;610px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;输入：问题文本$q$，解答文本$s$，LLM$f$，提示词$p$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Condition and question extractor(CQE)
&lt;ul&gt;
&lt;li&gt;从问题文本中抽取条件$q_c$和提问文本$q_i$&lt;/li&gt;
&lt;li&gt;$(q_c, q_i) = f([p_{cqe}, q])$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Solution Step Inquirer(SSI)
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;为提高生成结果的稳定性，SSI 会先总结每个步骤的结论再构建对应问题。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;将解答文本转化为分步骤问题列表文本$Q$，&lt;strong&gt;末尾附加提问文本$q_i$&lt;/strong&gt;，以确保生成的参考解答能够回应原始问题的核心任务。&lt;/li&gt;
&lt;li&gt;$Q = [f([p_{ssi},s]), q_i]$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step Question Responder (SQR)
&lt;ul&gt;
&lt;li&gt;通过条件文本总结$Q$中每个问题的答案，生成参考答案$r$&lt;/li&gt;
&lt;li&gt;$r = f([p_{sqr},q_c, Q])$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reference-Enhanced Grader (REG)
&lt;ul&gt;
&lt;li&gt;根据$q, s, r$生成错误位置$y_s$和错误类型$y_e$&lt;/li&gt;
&lt;li&gt;$y=f([p_{reg},q,s,r])$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;输出：$y_s, y_e$&lt;/p&gt;
&lt;h2 id=&#34;experiment&#34;&gt;Experiment
&lt;/h2&gt;&lt;p&gt;实验目的是验证核心的三个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;是否缓解从众偏差&lt;/li&gt;
&lt;li&gt;是否有额外的性能优势&lt;/li&gt;
&lt;li&gt;与CoT等推理技术的兼容性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实验方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;采用前文数据集，相同的10个LLM，用于对比前两个问题&lt;/li&gt;
&lt;li&gt;整合了CoT技术，评估兼容性&lt;/li&gt;
&lt;li&gt;所有实验分别实验三种不同的随机seed，报告平均错误检测准确率&lt;/li&gt;
&lt;li&gt;前文测试和CoT方案作为两个baseline&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CoT的提示词&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Before the &amp;lt;response&amp;gt;, you should provide your step-by-step &amp;lt;thinking&amp;gt; about your judging process.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &amp;lt;question&amp;gt; [Question Text] &amp;lt;solution&amp;gt; [Solution Text]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; Now, please start to think first and then respond.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626175506489.png&#34;
	width=&#34;884&#34;
	height=&#34;476&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626175506489_hu_bb07b79c8d6c3c11.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250626175506489_hu_5250d244aa5b549e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;实验结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;185&#34;
		data-flex-basis=&#34;445px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;对于问题1&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;重点分析M0和M2在$\Delta$列的差距
&lt;ul&gt;
&lt;li&gt;Base版本的优化并不明显，认为是模型推理能力不足，限制了框架效用&lt;/li&gt;
&lt;li&gt;对比M1与M2，CoT也有缓解Bias的能力，在多数Advance模型中，框架的优化能力强于CoT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于问题2&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在D、D&amp;rsquo;列对比M2和M0
&lt;ul&gt;
&lt;li&gt;框架确实提升了acc性能&lt;/li&gt;
&lt;li&gt;对比M1 M2，CoT也体现出了性能提升
&lt;ul&gt;
&lt;li&gt;在base模型中CoT技术更胜一筹&lt;/li&gt;
&lt;li&gt;在Advance模型中框架更强（……）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;针对问题3&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;M3和M1对比，确实变强了&lt;/li&gt;
&lt;li&gt;兼容性好&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;limitation&#34;&gt;Limitation
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;只考虑了四个错误类型，忽略了学生解答中那些更罕见却更具挑战性的错误类型&lt;/li&gt;
&lt;li&gt;仅聚焦于数学应用题&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>大语言模型教育纠错 · 论文笔记（零）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/</link>
        <pubDate>Fri, 20 Jun 2025 14:52:55 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&#34;temporal-consistency-for-llm-reasoning-process-error-identification&#34;&gt;Temporal Consistency for LLM Reasoning Process Error Identification
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2503.14495&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2503.14495 Temporal Consistency for LLM Reasoning Process Error Identification&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;无训练过程&lt;/li&gt;
&lt;li&gt;纯迭代反思&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;应用领域主要是大模型自己的解题步骤的错误检测&lt;/p&gt;
&lt;p&gt;算是一个比较通用的做法，数学题之外有分步性质的应该也ok&lt;/p&gt;
&lt;p&gt;可以借鉴一下其&lt;strong&gt;Reflection&lt;/strong&gt;的方法&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;输入定义如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$P$：题目原文（例如数学问题）；&lt;/li&gt;
&lt;li&gt;$S = [s_1, s_2, &amp;hellip;, s_n]$：模型生成的解题步骤，按步分段；&lt;/li&gt;
&lt;li&gt;$L$：目标是预测哪一段 $s_i$ 是 &lt;strong&gt;首个错误步骤&lt;/strong&gt;（或无错误）；&lt;/li&gt;
&lt;li&gt;$R_t$：第 $t$ 轮的模型判断（包含错误定位和解释）；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总共准备了K个模型并行进行推理，对于单个模型需要做以下事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;给定题目、解题步骤、自己的上轮判断&lt;/li&gt;
&lt;li&gt;模型需要结合该信息判断、解释&lt;/li&gt;
&lt;li&gt;持续迭代&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对K个模型投票，票数最多的即为结果&lt;/p&gt;
&lt;p&gt;设定的终止条件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单个模型连续$q$轮给出稳定结论&lt;/li&gt;
&lt;li&gt;K个模型的过去$q$轮的主体结果投票比例不能下降&lt;/li&gt;
&lt;li&gt;或者T轮迭代上限（防止死循环）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/assets/image-20250630152911616.png&#34;
	width=&#34;1790&#34;
	height=&#34;595&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/assets/image-20250630152911616_hu_d160ac2e2571813e.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/assets/image-20250630152911616_hu_970feda48933cee3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Pipeline&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;300&#34;
		data-flex-basis=&#34;722px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如图，三个模型进行迭代，最后得到一致的结果&lt;/p&gt;
&lt;p&gt;下面两个模型一开始不能得到正确答案，但是经过迭代得到正确结果&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;实验结果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/assets/image-20250630153824194.png&#34;
	width=&#34;501&#34;
	height=&#34;703&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/assets/image-20250630153824194_hu_1377b258bcc30ccd.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%99%E8%82%B2%E7%BA%A0%E9%94%99-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E9%9B%B6/assets/image-20250630153824194_hu_be26e3e2ea566e58.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Table&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;71&#34;
		data-flex-basis=&#34;171px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;todo&#34;&gt;Todo
&lt;/h1&gt;&lt;p&gt;2406.00755&lt;/p&gt;
</description>
        </item>
        <item>
        <title>大语言模型数据清洗 · 论文笔记（四）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E5%9B%9B/</link>
        <pubDate>Sat, 14 Jun 2025 16:35:54 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E5%9B%9B/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/html/2303.16854&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://arxiv.org/html/2303.16854&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;preview&#34;&gt;Preview
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;解释 - 标注 双阶段方法
&lt;ul&gt;
&lt;li&gt;LLM生成少量人类标注的解释&lt;/li&gt;
&lt;li&gt;自动构建思维链+fewshot提示词&lt;/li&gt;
&lt;li&gt;自动标注&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;approach&#34;&gt;Approach
&lt;/h2&gt;&lt;p&gt;从人类标注者的培训中可以发现，我们需要提供一定的引导、样例，才能规范人类标注一致性&lt;/p&gt;
&lt;p&gt;模型标注也是同理&lt;/p&gt;
&lt;h3 id=&#34;解释&#34;&gt;解释
&lt;/h3&gt;&lt;p&gt;使用GPT3.5进行生成解释：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Directions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Given&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;engine&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;google data studio sharepoint&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;first&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;consider&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;what&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;could&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;have&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mind&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;they&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;allow&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;misspellings&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;other&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ambiguity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;then&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;classify&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;sharepoint migration tool file share&amp;#34;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;into&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;one&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;following&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;categories&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Definitions&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;categories&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;This&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;can&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;include&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;broader&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;narrower&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;product&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;selection&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;competitor&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;alternative&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;products&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;accessories&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;products&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;often&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;purchased&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;together&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;related&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topics&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;well&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;direct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;matches&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;There&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;no&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relationship&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;between&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;This&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;includes&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;but&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;limited&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;incorrect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unrelated&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;product&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;unrelated&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wrong&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;location&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;location&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;important&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cannot&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;be&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;used&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;place&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;product&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nor&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;are&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;they&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;commonly&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;purchased&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;together&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;etc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Briefly&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;explain&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;why&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;length&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exceeding&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;构建提示词&#34;&gt;构建提示词
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Given&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;engine&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;first&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;consider&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;what&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;could&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;have&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mind&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;they&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;allow&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;misspellings&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;other&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ambiguity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;then&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;classify&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;into&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;one&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;following&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;categories&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;definitions&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;categories&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;are&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;This&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;can&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;include&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;broader&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;narrower&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;product&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;selection&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;competitor&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;alternative&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;products&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;accessories&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;products&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;often&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;purchased&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;together&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;related&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topics&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;well&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;direct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;matches&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;There&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;no&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relationship&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;between&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;This&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;includes&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;but&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;limited&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;incorrect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unrelated&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;product&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;unrelated&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wrong&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;location&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;location&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;important&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cannot&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;be&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;used&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;place&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;product&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nor&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;are&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;they&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;commonly&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;purchased&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;together&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;etc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Please&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predict&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;whether&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;answer&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;should&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;be&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exact&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;### Examples:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;google&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;studio&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sharepoint&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Keyword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sharepoint&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;migration&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tool&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;share&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Answer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;sharepoint migration tool file share&amp;#34;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;google data studio sharepoint&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;This&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;it&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pertains&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;different&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tool&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;technology&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SharePoint&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;that&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mentioned&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;focuses&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;on&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;migration&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tool&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SharePoint&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sharing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;focused&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;on&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Google&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Data&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Studio&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;There&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;no&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relationship&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;between&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;two&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;so&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Therefore&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;2.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;motorhomes&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sale&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Keyword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rv&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sale&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;used&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;c&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Answer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;rv sale used class c&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;rv sale used class c&amp;#34;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;information&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;motorhomes sale&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;It&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;includes&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;specific&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;motorhome&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;class c&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;that&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;being&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sold&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;used&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;which&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;product&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;selection&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Additionally&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;rv sale used class c&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;direct&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;match&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;commonly&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;purchased&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;together&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;products&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Therefore&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;3.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;southern&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exposure&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exchange&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;company&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Keyword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;uk&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;poppy&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seeds&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Answer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;uk poppy seeds&amp;#34;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;southern exposure seed exchange company&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;This&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;because&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;about&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exchange&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;company&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;uk poppy seeds&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;specific&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;that&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;could&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;be&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;offered&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;by&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;such&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;company&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Even&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;though&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;company&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mentioned&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;based&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;southern&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;hemisphere&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;they&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;may&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;still&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;offer&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seeds&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;other&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;regions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;including&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;UK&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;which&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;could&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;include&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;poppy&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;seeds&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Therefore&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Not bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;4.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nissan&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parts&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;canada&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Keyword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;purchase&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tires&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Answer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;purchase tires&amp;#34;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;nissan parts canada&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;purchase tires&amp;#34;&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;directly&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;related&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;’&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Nissan&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parts&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Canada&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Tires&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;are&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;part&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Nissan&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;car&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;therefore&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;are&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevant&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Nissan&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Additionally&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;does&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relate&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;common&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;purchase&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Nissan&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;it&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;substitute&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;search&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Therefore&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;relevance&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;### Task:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Query&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Keyword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;keyword&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Answer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>大语言模型数据清洗 · 论文笔记（三）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/</link>
        <pubDate>Tue, 10 Jun 2025 14:54:12 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/</guid>
        <description>&lt;h1 id=&#34;finerweb-10bt-refining-web-data-with-llm-based-line-level-filtering&#34;&gt;FinerWeb-10BT: Refining Web Data with LLM-Based Line-Level Filtering
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2501.07314&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2501.07314FinerWeb-10BT: Refining Web Data with LLM-Based Line-Level Filtering&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/TurkuNLP/finerweb-10bt&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/TurkuNLP/finerweb-10bt&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;概述&#34;&gt;概述
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;GPT-4o mini 对 FineWeb 中 20,000 份文档样本进行逐行标注，使模型能够为低质量文本行创建描述性标签&lt;/li&gt;
&lt;li&gt;标签被归纳为九大类别，并训练 DeBERTa-v3 分类器将过滤规模扩展至 FineWeb 的 100 亿 token 子集&lt;/li&gt;
&lt;li&gt;结果表明：使用过滤数据训练的模型在 HellaSwag 基准测试中准确率更高，且能以最多减少 25%的数据量更快达到性能目标&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;核心问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How well can an LLM identify low-quality content missed by &lt;strong&gt;heuristic filters&lt;/strong&gt;?&lt;/li&gt;
&lt;li&gt;Does LLM-based &lt;strong&gt;quality filtering&lt;/strong&gt; of training datasets &lt;strong&gt;improve model performance&lt;/strong&gt;?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;paper定义高质量数据为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;human-written, continuous English text from the main content of a website, reflecting natural language use across diverse contexts and domains.&lt;/p&gt;
&lt;p&gt;网站主体内容中人类撰写的连贯英文文本，能反映跨领域自然语言使用。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;典型实例包括访谈核心文本、论坛帖子、新闻文章、博客和食谱。&lt;/li&gt;
&lt;li&gt;与之相对，低质量内容则包含导航菜单、版权声明、编程代码和元数据等重复性元素。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;过滤分为三个级别：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文档级：基于简单规则整篇剔除文档
&lt;ul&gt;
&lt;li&gt;少于三句话的文档&lt;/li&gt;
&lt;li&gt;存在过度重复内容的文档&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;行级：
&lt;ul&gt;
&lt;li&gt;删除含&lt;code&gt;javascript&lt;/code&gt;等术语的行、纯数字行或低于长度阈值的行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;字符级：
&lt;ul&gt;
&lt;li&gt;移除维基百科常见的引用标记如&lt;code&gt;[1]&lt;/code&gt;和&lt;code&gt;[citation needed]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;现存的过滤方法具有数据集特异性，相关指标与数据集本身有关&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;行末标点比例≤0.12的文档（移除10.14% token，相比C4终止标点过滤的30%更高效）&lt;/li&gt;
&lt;li&gt;重复行字符比例≥0.1的文档（移除12.47% token）&lt;/li&gt;
&lt;li&gt;短行（&amp;lt;30字符）比例≥0.67的文档（移除3.73% token）&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;method&#34;&gt;Method
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;数据来源：Fineweb，构建来自 FineWeb 的 100 亿 token（约 1500 万文档）样本，称为 FineWeb-10BT&lt;/li&gt;
&lt;li&gt;抽样20,000份文档进行GPT-4o mini 标注
-   为每行生成描述性标签，分为高质量或低质量类别&lt;/li&gt;
&lt;li&gt;O1-preview将生成的大量标签归类为更小、更方便管理的集合&lt;/li&gt;
&lt;li&gt;训练基于encoder的分类器，scale到Fineweb10BT&lt;/li&gt;
&lt;li&gt;使用清洗前后的Fineweb10BT训练GPT-2，在HellaSwag上benchmark&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;全过程是数据驱动的，不依赖于固定的类别&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments
&lt;/h2&gt;&lt;h3 id=&#34;gpt-4o-mini-标签标注&#34;&gt;GPT-4o mini 标签标注
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;86
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 系统提示词&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;system&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;You are an expert text classifier specializing in LLM training data. Your task is to classify each line of text based on its suitability for inclusion in a language model training dataset. High-quality content is clean, meaningful, well-structured, and useful for training language models. Low-quality content includes boilerplate elements (e.g., navigation menus, footers), non-linguistic symbols, formatting tags, placeholders like &amp;#39;Lorem ipsum&amp;#39;, and spammy, irrelevant, or toxic language.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 用户提示词&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;prompt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    **Instructions:**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    1. **Line Identification and Separation**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Each line starts with &amp;#34;Line X:&amp;#34; where X is the line number. Treat each &amp;#34;Line X:&amp;#34; as a single unit, regardless of length; do not split lines.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Lines are separated by newline characters (`&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;n`) and dashes (`------`). If there&amp;#39;s no newline character, treat the entire text as a single line.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    2. **Contextual Classification**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Use the context of all lines when classifying each one, as they are sequential and from the same document.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - For example, a line starting with a hyphen might be part of a list and should be classified as &amp;#34;Clean.&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    3. **Assigning Labels**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Assign **exactly one label** to each line.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - If the line is suitable for inclusion, label it **&amp;#34;Clean&amp;#34;**.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - If not, assign a specific and descriptive label explaining why it&amp;#39;s unsuitable.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - **Prefer labels from the provided list**. Only create a new label (max three words) if absolutely necessary.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - **Do not use vague labels** like &amp;#34;Low-Quality,&amp;#34; &amp;#34;Bad,&amp;#34; &amp;#34;Unsuitable,&amp;#34; etc. Labels must be specific and descriptive.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    4. **Focus on Linguistic Content**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Retain valuable and diverse linguistic content suitable for language model pre-training, including natural language patterns, standard advertising copy, commercial language, and promotional content written in natural language.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    5. **Tolerance for Minor Errors and Toxic Language**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Minor grammatical errors, typos, or small mistakes do not disqualify a line from being &amp;#34;Clean.&amp;#34; Only exclude lines with pervasive errors that significantly hinder understanding.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Mild expletives and controversial opinions do not disqualify a line from being &amp;#34;Clean.&amp;#34; Only exclude lines with blatantly hateful, harmful or toxic content.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    6. **Output Format**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Your output must have exactly the same number of lines as the input, matching each line number correctly.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Output only the line number followed by the label, separated by a colon.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Do not include any additional text or explanations.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;       - Do not output dashes between the lines.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    **Guidelines for &amp;#34;Clean&amp;#34; Lines**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Assign &amp;#34;Clean&amp;#34; to lines that:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Represent natural language suitable for training language models.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Include informal internet language, grammatical errors, questions, partial sentences, and common online expressions.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Contain standard advertising or commercial language in natural sentences.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Have properly formatted titles, headings, and readable content, even with stylistic elements.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Include minor in-text elements like email addresses, dates, or URLs within natural sentences.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Are general promotional content written in natural language.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    **Guidelines for Non-&amp;#34;Clean&amp;#34; Lines**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Lines not classified as &amp;#34;Clean&amp;#34; need a specific and descriptive label. Examples include lines that:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Contain blatantly hateful or harmful language. 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Are long passages of non-English text (excluding common foreign phrases used in English).
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Include disclaimers, copyright notices, terms, and conditions.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Consist of menu items, login links, buttons, or navigation menus.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Contain random characters, garbled text, or excessive symbols.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Include programming code, HTML tags, or markup languages (when actual code or markup appears).
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Present keywords, tags, or similar data without sufficient context.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Are irrelevant or spam-like content not suitable for training.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    - Are **excessively** promotional without natural language structure (e.g., a list of product names and prices without sentences).
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    **Possible Labels for Non-&amp;#34;Clean&amp;#34; Lines**:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;non_quality_labels&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    **Example Input:**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 1: Welcome to our website!
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    ------
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 2: Contact us at support@example.com.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    ------
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 3: ***** $$$$$
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    ------
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 4: &amp;lt;div&amp;gt;Content&amp;lt;/div&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    ------
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    **Example Output:**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 1: Clean  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 2: Clean  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 3: Encoding Errors  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Line 4: HTML Tags
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    **Now, classify the following lines:**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;指令&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;行标识与分隔&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;每行以&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;开头&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X为行号&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;将每个&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;视为一个独立单元&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;无论长度如何&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;；&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;请勿拆分&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;行之间用换行符&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（`&lt;/span&gt;\&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;`）&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;和短横线&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（`&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;------&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;`）&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;分隔&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;若无换行符&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;则将整个文本视为单行&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;2.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;上下文分类&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;分类时需考虑所有行的上下文&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;因为它们来自同一文档且顺序相关&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;例如&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;以连字符开头的行可能是列表的一部分&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;应标记为&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;3.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;标签分配&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;每行&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;必须分配一个标签&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;若适合纳入训练数据&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;标记为&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;若不适合&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;需提供具体描述性标签说明原因&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;优先使用提供的标签列表&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;仅在必要时创建新标签&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;最多三个单词&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;）。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;禁止使用模糊标签&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;如&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;低质量&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”、“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;差&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”、“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;不合适&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;等&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;标签必须具体明确&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;4.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;语言内容聚焦&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;保留对语言模型预训练有价值的多样化语言内容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;包括自然语言模式&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;标准广告文案&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;商业用语和自然语言编写的推广内容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;5.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;对轻微错误和毒性内容的容忍&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;轻微语法错误&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;拼写问题或小错误不影响标记为&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”。&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;仅当错误严重影响理解时才排除&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;轻度脏话或有争议的观点不影响标记为&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”。&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;仅排除明显仇恨&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;有害或毒性内容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mf&#34;&gt;6.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;输出格式&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;输出行数必须与输入完全一致&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;且行号对应正确&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;每行输出格式为&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;标签&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;仅包含行号和标签&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;禁止额外解释或文本&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;行间禁止输出短横线&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;行标准&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;符合以下条件的行标记为&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;代表适合训练的自然语言&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;包含网络用语&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;语法错误&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;问题&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;不完整句子或常见网络表达&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;含有自然句式中的标准广告或商业用语&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;格式正确的标题&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;题头或可读内容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;即使包含样式元素&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;）。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;自然句子中的邮箱&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;日期或URL等次要元素&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;以自然语言编写的常规推广内容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;非&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;行标准&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;需提供具体描述性标签&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;例如&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;包含明显仇恨或有害内容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;大段非英语文本&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;英语中常用的外语短语除外&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;）。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;免责声明&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;版权声明&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;条款协议&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;菜单项&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;登录链接&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;按钮或导航菜单&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;随机字符&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;乱码或过多符号&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;编程代码&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;、&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HTML标签或标记语言&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;实际代码或标签出现时&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;）。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;缺乏上下文的关键词或标签&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;与训练无关的垃圾内容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;过度推广&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;且无自然语言结构&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;如纯产品名和价格列表&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;）。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;非&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;”&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;行标签示例&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;non_quality_labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;输入示例&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;欢迎访问我们的网站&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;！&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;联系支持邮箱&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;support&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@example.com&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*****&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$$$$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;div&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;内容&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;div&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;输出示例&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Clean&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;编码错误&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Line&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;HTML标签&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;请对以下行进行分类&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;一开始并不提供任何的非Clean标签，由模型逐渐生成，优先使用已有的标签，否则进行扩充&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;未避免顺序带来的影响，每次迭代后随即打乱标签列表&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;文档最多被分割为多个chunk，每个chunk最多15行，方便结合上下文&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;单行不能超过200字符，否则按照标点进行切割为新的行&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;paper提到：超长行会导致模型的错误输出&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610184759762.png&#34;
	width=&#34;875&#34;
	height=&#34;596&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610184759762_hu_77126521573083f.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610184759762_hu_c2d6a7a748645646.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;50个最常见的标签 - 二维UMAP投影&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;146&#34;
		data-flex-basis=&#34;352px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;其中每个圆点的大小对应相应类别的相对出现频率&lt;/p&gt;
&lt;p&gt;法律文本出现在左上角，成人及有害内容集中于右上方中部，而参考文献则靠近底部。联系方式（如时间、日期和电话号码）松散分布在左侧，技术类内容（如编程代码）则位于中部。这些分布模式表明，LLM 生成的标签能够有效区分文本行质量，为我们最终构建分类体系提供了可靠依据。&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;83%的数据被标记为清洁&lt;/li&gt;
&lt;li&gt;547个生成的标签，其中部分只出现了一次
&lt;ul&gt;
&lt;li&gt;人工复查，直接标记为清洁&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;标签分组&#34;&gt;标签分组
&lt;/h3&gt;&lt;p&gt;对于实现剩下的382个标签，通过O1-preview（推理模型）归类为更简洁、更易管理的宽泛类别&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指导该模型创建清晰、明确的分类&lt;/li&gt;
&lt;li&gt;每个标签只能属于一个组别&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Categories&lt;/th&gt;
          &lt;th&gt;Lines&lt;/th&gt;
          &lt;th&gt;%&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Clean&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;283,267&lt;/td&gt;
          &lt;td&gt;86.24&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Formatting, Style &amp;amp; Errors 格式、风格与错误&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;13,150&lt;/td&gt;
          &lt;td&gt;4.00&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Bibliographical &amp;amp; Citation References 参考文献与引用规范&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;8,768&lt;/td&gt;
          &lt;td&gt;2.67&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Promotional &amp;amp; Spam Content 促销与垃圾内容&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;7,339&lt;/td&gt;
          &lt;td&gt;2.23&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Contact &amp;amp; Identification Information 联系与身份识别信息&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;3,898&lt;/td&gt;
          &lt;td&gt;1.19&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Navigation &amp;amp; Interface Elements 导航与界面元素&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;3,327&lt;/td&gt;
          &lt;td&gt;1.01&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Technical Specifications &amp;amp; Metadata 技术规范与元数据&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;3,298&lt;/td&gt;
          &lt;td&gt;1.00&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Legal &amp;amp; Administrative Content 法律与行政内容&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;2,992&lt;/td&gt;
          &lt;td&gt;0.91&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;em&gt;Offensive or Inappropriate Content 冒犯性或不当内容&lt;/em&gt;&lt;/td&gt;
          &lt;td&gt;2,433&lt;/td&gt;
          &lt;td&gt;0.74&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Total 总计&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;328,472&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;100&lt;/strong&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;模型可能会发生错误，例如未能分配全部标签、标签归入多个类别……&lt;/p&gt;
&lt;p&gt;人工修正一下即可&lt;/p&gt;
&lt;h4 id=&#34;inter-annotator-agreement--人工标注者一致性iaa实验&#34;&gt;Inter-Annotator Agreement  人工标注者一致性（IAA）实验
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;抽取50篇文档的726行，人工独立分类到九个标签之内&lt;/li&gt;
&lt;/ul&gt;
$$
\kappa = \frac{p_o - p_e}{1 - p_e}
$$&lt;blockquote&gt;
&lt;p&gt;假设两位标注员（A 和 B）对 100 条文本进行情感分类，标签为 &lt;strong&gt;正面（Positive）&lt;/strong&gt; 或 &lt;strong&gt;负面（Negative）&lt;/strong&gt;。他们的标注结果如下表：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;&lt;/th&gt;
          &lt;th&gt;B: Positive&lt;/th&gt;
          &lt;th&gt;B: Negative&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;总计&lt;/strong&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;A: Positive&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;50&lt;/td&gt;
          &lt;td&gt;10&lt;/td&gt;
          &lt;td&gt;60&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;A: Negative&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;20&lt;/td&gt;
          &lt;td&gt;20&lt;/td&gt;
          &lt;td&gt;40&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;总计&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;70&lt;/td&gt;
          &lt;td&gt;30&lt;/td&gt;
          &lt;td&gt;100&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;$p_o$是两位标注员&lt;strong&gt;实际一致的比例&lt;/strong&gt;，即对角线单元格的和除以总数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;两位标注员在 70 条样本上达成一致（50 条 Positive + 20 条 Negative），因此$p_o = 0.7$&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;$p_e$ 是假设两位标注员&lt;strong&gt;随机标注&lt;/strong&gt;时预期的一致比例。需分别计算每个类别随机一致的联合概率，再求和。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;A 标注 Positive 的概率&lt;/strong&gt;：$P_{\text{A+}} = \frac{60}{100} = 0.6$
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;A 标注 Negative 的概率&lt;/strong&gt;：$P_{\text{A-}} = \frac{40}{100} = 0.4$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;B 标注 Positive 的概率&lt;/strong&gt;：$P_{\text{B+}} = \frac{70}{100} = 0.7$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;B 标注 Negative 的概率&lt;/strong&gt;：$P_{\text{B-}} = \frac{30}{100} = 0.3$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;已知以上概率，接下来计算在随机标注的情况下，两人同时一致的概率：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;随机都标为 Positive 的概率：$P_{\text{A+}} \times P_{\text{B+}} = 0.6 \times 0.7 = 0.42$
&lt;ul&gt;
&lt;li&gt;随机都标为 Negative 的概率：$P_{\text{A-}} \times P_{\text{B-}} = 0.4 \times 0.3 = 0.12$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此：$p_e = 0.42 + 0.12 = 0.54$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解释&lt;/strong&gt;：&lt;br&gt;
如果两位标注员完全随机标注，预计会有 54% 的样本因巧合而一致。&lt;/p&gt;
&lt;hr&gt;
$$
&gt;   \kappa = \frac{p_o - p_e}{1 - p_e} = \frac{0.7 - 0.54}{1 - 0.54} = \frac{0.16}{0.46} \approx 0.348
&gt;   $$&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;κ ≈ 0.35&lt;/strong&gt;：介于 0.2~0.4 之间，说明两位标注员的一致性为“一般”（仅略高于随机水平）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对比简单一致率 70%&lt;/strong&gt;：若直接用 70% 会高估一致性，而 Cohen&amp;rsquo;s Kappa 通过剔除随机影响，给出了更严格的评估。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;\( p_o \)&lt;/strong&gt;：直接观察到的对角线比例。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;\( p_e \)&lt;/strong&gt;：基于边际分布的“随机一致”概率，反映巧合带来的虚假一致性。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Kappa 的意义&lt;/strong&gt;：量化了&lt;strong&gt;超越随机水平的一致性&lt;/strong&gt;，避免高估可靠性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;&lt;strong&gt;κ值范围&lt;/strong&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;&lt;strong&gt;一致性强度&lt;/strong&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;&lt;strong&gt;解释&lt;/strong&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;κ ≤ 0&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;比随机还差&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;一致性低于随机猜测（罕见，可能表示系统性分歧或标注错误）。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;0 &amp;lt; κ ≤ 0.2&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;轻微一致（可忽略）&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;一致性极低，几乎无实际意义。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;0.2 &amp;lt; κ ≤ 0.4&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;一般一致（弱）&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;一致性较弱，但高于随机水平（需谨慎对待结果）。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;0.4 &amp;lt; κ ≤ 0.6&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;中等一致&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;一致性适中，结果有一定可靠性（常见于人工标注任务）。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;0.6 &amp;lt; κ ≤ 0.8&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;高度一致&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;一致性较强，结果可靠（如专业医生诊断或严格标注流程）。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;0.8 &amp;lt; κ ≤ 1&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;几乎完全一致&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;一致性极高，接近完美（罕见，通常需检查是否过拟合或标注规则过于简单）。&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;通过IAA实验，得到：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;A1&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;strong&gt;A2&lt;/strong&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;strong&gt;Avg. 平均&lt;/strong&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;All labels 所有标签&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.79&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.60&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.70&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;Clean vs. Non-clean 清洁与非清洁&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.78&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.67&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.73&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;基于 LLM 的分类方法总体上能为 FineWeb 文本生成可接受的标签。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;分类器训练&#34;&gt;分类器训练
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;DeBERTa-v3&lt;/li&gt;
&lt;li&gt;Stella-en-400M-v5&lt;/li&gt;
&lt;li&gt;XLM-RoBERTa-base（支持多语言）&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;我们首先从文档中提取独立文本行，将每行作为单独样本。随后对数据进行随机打乱，并通过分层抽样划分为训练集（70%）、开发集（10%）和测试集（20%）。我们在每个模型上添加分类头，为每行文本生成 9 个类别的概率分布，同时微调分类头与基础模型。&lt;/p&gt;
&lt;p&gt;我们采用 bfloat16 精度，学习率设为 1e-5，批处理大小为 16。基于评估损失值实施早停机制（耐心值为 5），最大训练轮数设为 5 轮，但模型通常在首轮后即收敛。我们对交叉熵损失函数施加 0.1 的标签平滑处理以提升泛化能力。所有训练均在单块 A100 GPU 上完成。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610192229209.png&#34;
	width=&#34;899&#34;
	height=&#34;634&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610192229209_hu_9bd47b2a1e06ee33.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610192229209_hu_d11c68ec86e2dc63.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;分类器混淆矩阵&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;141&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大多数误分类样本被归入 Clean 类别，表明其他类别间具有较强区分度&lt;/li&gt;
&lt;li&gt;冒犯性或不当内容区分度最低，源于 LLM 训练数据中对冒犯性材料定义边界存在固有困难&lt;/li&gt;
&lt;li&gt;参考文献与引用类别因其易于识别的格式和内容特征，成为区分度最高的类别&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分类器更倾向于将低质量文本行误标为&amp;quot;清洁&amp;quot;&lt;/p&gt;
&lt;p&gt;而非错误地将高质量行标记为低质量&lt;/p&gt;
&lt;p&gt;这种偏差有助于降低从数据集中丢弃有价值数据的风险&lt;/p&gt;
&lt;h3 id=&#34;数据清洗&#34;&gt;数据清洗
&lt;/h3&gt;&lt;p&gt;Clean数据占比86%确实可能会带来模型预测过度自信的问题&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;采用 Platt 缩放法
&lt;ul&gt;
&lt;li&gt;在保留测试集上训练 Platt 逻辑回归模型&lt;/li&gt;
&lt;li&gt;在为 FineWeb-10BT 数据集预测质量分数时将其叠加应用于分类器之上&lt;/li&gt;
&lt;li&gt;留坑，先不研究&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对整个数据集进行分片，每个分片128行为一个批次&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;转化为分类问题，只判断是否为Clean&lt;/li&gt;
&lt;li&gt;阈值分别设为0.5或0.9&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610194623280.png&#34;
	width=&#34;701&#34;
	height=&#34;485&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610194623280_hu_f739427efcc7e2.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%89/assets/image-20250610194623280_hu_31a6a550d7d615f5.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;GPT-2训练结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;144&#34;
		data-flex-basis=&#34;346px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>大语言模型数据清洗 · 论文笔记（二）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/</link>
        <pubDate>Fri, 06 Jun 2025 13:12:32 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/</guid>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&#34;the-pile-an-800gb-dataset-of-diverse-text-for-language-modeling&#34;&gt;The Pile: An 800GB Dataset of Diverse Text for Language Modeling
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2101.00027&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;arXiv 2101.00027 The Pile: An 800GB Dataset of Diverse Text for Language Modeling&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/EleutherAI/the-pile&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Github EleutherAI/the-pile&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过合成多个数据集，提升多样性，提升大规模语言模型的跨领域通用知识与下游任务泛化能力&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;稍微看偏了，paper更多的精华在如何去衡量数据集对模型性能的提升水平&lt;/p&gt;
&lt;p&gt;和清洗关系不大&lt;/p&gt;
&lt;h2 id=&#34;the-pile-datasets&#34;&gt;The Pile Datasets
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;由22个部分组成&lt;/li&gt;
&lt;li&gt;由于不同数据集存在差异（维基百科质量更高），因此进行了加权处理
&lt;ul&gt;
&lt;li&gt;权重越高，被使用的概率越高（更可能被重复使用次数）&lt;/li&gt;
&lt;li&gt;例如维基百科重复采用3次&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;部分表格：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Dataset Name&lt;/th&gt;
          &lt;th&gt;Raw Size (before sampling)&lt;/th&gt;
          &lt;th&gt;Weight (%)&lt;/th&gt;
          &lt;th&gt;Epochs&lt;/th&gt;
          &lt;th&gt;Effective Size&lt;/th&gt;
          &lt;th&gt;Mean Document Size&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;Pile-CC&lt;/td&gt;
          &lt;td&gt;227.12 GiB&lt;/td&gt;
          &lt;td&gt;18.11%&lt;/td&gt;
          &lt;td&gt;1.0&lt;/td&gt;
          &lt;td&gt;227.12 GiB&lt;/td&gt;
          &lt;td&gt;4.33 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;PubMed Central&lt;/td&gt;
          &lt;td&gt;90.27 GiB&lt;/td&gt;
          &lt;td&gt;14.40%&lt;/td&gt;
          &lt;td&gt;2.0&lt;/td&gt;
          &lt;td&gt;180.55 GiB&lt;/td&gt;
          &lt;td&gt;30.55 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Books3&lt;/td&gt;
          &lt;td&gt;100.96 GiB&lt;/td&gt;
          &lt;td&gt;12.07%&lt;/td&gt;
          &lt;td&gt;1.5&lt;/td&gt;
          &lt;td&gt;151.44 GiB&lt;/td&gt;
          &lt;td&gt;538.36 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;OpenWebText2&lt;/td&gt;
          &lt;td&gt;62.77 GiB&lt;/td&gt;
          &lt;td&gt;10.01%&lt;/td&gt;
          &lt;td&gt;2.0&lt;/td&gt;
          &lt;td&gt;125.54 GiB&lt;/td&gt;
          &lt;td&gt;3.85 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ArXiv&lt;/td&gt;
          &lt;td&gt;56.21 GiB&lt;/td&gt;
          &lt;td&gt;8.96%&lt;/td&gt;
          &lt;td&gt;2.0&lt;/td&gt;
          &lt;td&gt;112.42 GiB&lt;/td&gt;
          &lt;td&gt;46.61 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Github&lt;/td&gt;
          &lt;td&gt;95.16 GiB&lt;/td&gt;
          &lt;td&gt;7.59%&lt;/td&gt;
          &lt;td&gt;1.0&lt;/td&gt;
          &lt;td&gt;95.16 GiB&lt;/td&gt;
          &lt;td&gt;5.25 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;FreeLaw&lt;/td&gt;
          &lt;td&gt;51.15 GiB&lt;/td&gt;
          &lt;td&gt;6.12%&lt;/td&gt;
          &lt;td&gt;1.5&lt;/td&gt;
          &lt;td&gt;76.73 GiB&lt;/td&gt;
          &lt;td&gt;15.06 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;StackExchange&lt;/td&gt;
          &lt;td&gt;32.20 GiB&lt;/td&gt;
          &lt;td&gt;5.13%&lt;/td&gt;
          &lt;td&gt;2.0&lt;/td&gt;
          &lt;td&gt;64.39 GiB&lt;/td&gt;
          &lt;td&gt;2.16 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;USPTO Backgrounds&lt;/td&gt;
          &lt;td&gt;22.90 GiB&lt;/td&gt;
          &lt;td&gt;3.65%&lt;/td&gt;
          &lt;td&gt;2.0&lt;/td&gt;
          &lt;td&gt;45.81 GiB&lt;/td&gt;
          &lt;td&gt;4.08 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;PubMed Abstracts&lt;/td&gt;
          &lt;td&gt;19.26 GiB&lt;/td&gt;
          &lt;td&gt;3.07%&lt;/td&gt;
          &lt;td&gt;2.0&lt;/td&gt;
          &lt;td&gt;38.53 GiB&lt;/td&gt;
          &lt;td&gt;1.30 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gutenberg (PG-19)&lt;/td&gt;
          &lt;td&gt;10.88 GiB&lt;/td&gt;
          &lt;td&gt;2.17%&lt;/td&gt;
          &lt;td&gt;2.5&lt;/td&gt;
          &lt;td&gt;27.19 GiB&lt;/td&gt;
          &lt;td&gt;398.73 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;OpenSubtitles&lt;/td&gt;
          &lt;td&gt;12.98 GiB&lt;/td&gt;
          &lt;td&gt;1.55%&lt;/td&gt;
          &lt;td&gt;1.5&lt;/td&gt;
          &lt;td&gt;19.47 GiB&lt;/td&gt;
          &lt;td&gt;30.48 KiB&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Wikipedia (en)&lt;/td&gt;
          &lt;td&gt;6.38 GiB&lt;/td&gt;
          &lt;td&gt;1.53%&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;3.0&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;19.13 GiB&lt;/td&gt;
          &lt;td&gt;1.11 KiB&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;Raw Size：采样前的大小&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weight ：采样后的大小占比&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Epochs：被采样次数&lt;/p&gt;
&lt;p&gt;Effective Size：采样后的有效大小&lt;/p&gt;
&lt;p&gt;Mean Document Size：平均文档大小&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;部分数据已被发布者清洗的很好，只进行了最小程度的预处理&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pile-cc&#34;&gt;Pile-CC
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;由CC数据集清洗得到&lt;/li&gt;
&lt;li&gt;使用justText清洗raw HTTP responses including page HTML，相比于&lt;code&gt;.WET&lt;/code&gt;的纯文本效果更好&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;others&#34;&gt;Others
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;分类&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;来源&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;学术文献&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;ArXiv、PubMed Central、NIH ExPorter&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;图书与出版物&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;Books3、Project Gutenberg (PG-19)、BookCorpus2&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;代码与技术文档&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;GitHub、StackExchange&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;法律与政府文件&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;FreeLaw、USPTO Backgrounds&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;多语言与翻译文本&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;EuroParl、OpenSubtitles&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;社交与对话数据&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;HackerNews、Ubuntu IRC、Enron Emails&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;特殊领域数据&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;DeepMind Mathematics、PhilPapers（哲学）、YouTube字幕&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;网络爬取内容&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;Pile-CC（新构建的Clean Common Crawl子集）&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;benchmarking-language-models-with-the-pile&#34;&gt;Benchmarking Language Models with the Pile
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;可以训练数据，同时因为涉及领域广泛，也可以基准测试&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;划分为训练集、验证集、测试集（$0.1%$测试集+验证集，虽然比例很低但是仍各自超过1G）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;尽管去重，但是肯定还是存在重复&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;paper中首选了BPB作为评测指标：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;输入：负对数似然损失（Negative Log-Likelihood Loss）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型在测试数据上输出一个损失值 $L$，表示其预测能力。&lt;/li&gt;
&lt;li&gt;越低的 $L$ 表示模型越能准确预测下一个词。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;转换为 BPB：&lt;/strong&gt;（bits per UTF-8 encoded byte）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用公式将损失 $L$ 转换为每字节的比特数&lt;/li&gt;
&lt;/ul&gt;
$$
    BPB = \frac{L_T}{L_B}\log_2 e^L = \frac{L_T}{L_B}\times \frac{L}{\ln2}
    $$&lt;ul&gt;
&lt;li&gt;其中：
&lt;ul&gt;
&lt;li&gt;$L_T$：数据集以 token 为单位的长度&lt;/li&gt;
&lt;li&gt;$L_B$：数据集以 UTF-8 编码字节为单位的长度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;和困惑度有一点相似，用于衡量模型对数据的压缩效率或预测能力&lt;/p&gt;
&lt;p&gt;与Bits per Character (bpc)不同的一点，字符不是一个很好的定义（Unicode 中字符的界定可能复杂（例如组合字符、emoji 等），导致统计不一致。）&lt;/p&gt;
&lt;p&gt;同时bpb不受到分词的影响，UTF-8的字节定义是准确的，适合基于不同模型、分词进行比较&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;指标&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;优点&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;缺点&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;适用场景&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Bits per Byte&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;分词无关、字节标准明确&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;对非字节级任务不直观&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;跨模型比较、数据压缩评估&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Bits per Char&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;更贴近人类理解&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Unicode 字符定义模糊&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;字符级生成任务（需统一字符定义）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Perplexity&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;直接反映预测不确定性&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;依赖分词、数值范围不稳定&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;单一模型调参、生成质量评估&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;更加完整的解释&#34;&gt;更加完整的解释
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;自信息：指的是当我们接收到一个消息时所获得的信息量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在信息论中，自信息衡量一个事件携带的信息量，由概率$p$决定。&lt;/p&gt;
$$
I(p) = -\log_2(p)
$$&lt;p&gt;为了编码这一事件，我们选择霍夫曼编码这类最优编码，同时为了最小化平均码长：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高频事件：分配短码&lt;/li&gt;
&lt;li&gt;低频事件：分配长码&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;如果事件 $A$ 的概率  $p = 1/2$ ，则  $I(A) = -\log_2(1/2) = 1$  比特。这表示需要用 1 位二进制码（如 &lt;code&gt;0&lt;/code&gt; 或 &lt;code&gt;1&lt;/code&gt;）编码。
-   如果事件  $B$  的概率  $p = 1/8$ ，则  $I(B) = -\log_2(1/8) = 3$  比特。需要用 3 位二进制码（如 &lt;code&gt;000&lt;/code&gt; 到 &lt;code&gt;111&lt;/code&gt; 之一）编码。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
$$
L = -\ln p
$$&lt;p&gt;
一般使用的是自然对数，同时其恰好表示了概率为$p$的事件的信息量（单位为纳特（底数取e））&lt;/p&gt;
$$
Bits = I(p) = -\log_2(p) =-\frac{\ln p}{\ln 2} =\frac{L}{\ln 2}
$$&lt;p&gt;
&lt;strong&gt;同时，模型的损失是基于token计算的，即每个token的预测损失&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以这里的单位是：Bits per token&lt;/p&gt;
$$
bpb =  \frac{L_T}{L_B}\times \frac{L}{\ln2}
$$&lt;p&gt;
这样就得到了：Bits per Byte，消除了分词器、语种编码等其他影响，可以直接衡量模型输出的质量&lt;/p&gt;
&lt;h2 id=&#34;评测&#34;&gt;评测
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;然后paper实验验证了一下用训练集训练过的模型会更nb&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;通过分析哪些Pile子数据集的表现最差，就知道模型的训练数据分布在这块比较浅，就可以使用pile这块数据集进行补充&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了探索哪些数据集是模型表现较差的，显然不能直接使用困惑度进行比较（数据集熵值不一样）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结构化的数据（熵值低）困惑度天然会比非结构化的更低&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;困惑度可以用于衡量一个数据集是否更接近另一个数据集&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如CCNet，在维基百科内训练一个模型，计算其他数据集的困惑度&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;所以如果要比较的话，可以通过模型的损失值，拟合得越好，说明训练数据中包含了这部分，否则就是缺失&lt;/p&gt;
&lt;p&gt;如果钱多的话，当然是直接把所有数据集用模型train一下，看看损失值，与没有train过的原模型（GPT-3），在测试集上比一下Loss&lt;/p&gt;
&lt;p&gt;paper这里钱不够，改用了GPT2做了一个trick：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;首先需要知道GPT3比GPT2强多少&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;参考数据集：OWT2（与GPT训练数据高度相似的一个数据集）&lt;/li&gt;
&lt;li&gt;用原生的GPT3和在Pile训练的GPT2进行比较&lt;/li&gt;
&lt;li&gt;得到一个基准差值&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
$$
L^{GPT-3}_{OWT2} - L^{GPT-2-Pile}_{OWT2}
$$&lt;ul&gt;
&lt;li&gt;
$$
L^{GPT-3}_{TargetSet} - L^{GPT-2-Pile}_{TargetSet}
$$&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;两个值作差：大概能衡量出在目标数据集上的提升水平&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/assets/image-20250606162030021.png&#34;
	width=&#34;1172&#34;
	height=&#34;571&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/assets/image-20250606162030021_hu_c35f4776da27d503.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%BA%8C/assets/image-20250606162030021_hu_a020da3b1c3d156d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;205&#34;
		data-flex-basis=&#34;492px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Books3等数据集与GPT-3训练数据高度相似，因此不会有过多的提升（0）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;清洗&#34;&gt;清洗
&lt;/h2&gt;&lt;p&gt;看不动了，以后再说，整理一下清洗的东西：&lt;/p&gt;
&lt;h3 id=&#34;c1-pile-ccclean-common-crawl&#34;&gt;C.1 Pile-CC（Clean Common Crawl）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Common Crawl 的 WARC 文件（2013–2020 年）。&lt;/li&gt;
&lt;li&gt;提取工具
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;jusText&lt;/code&gt; 提取网页正文，去除菜单、页脚等模板文本。&lt;/li&gt;
&lt;li&gt;对比了 &lt;code&gt;Trafilatura&lt;/code&gt;、&lt;code&gt;Newspaper&lt;/code&gt;、&lt;code&gt;Goose3&lt;/code&gt;、&lt;code&gt;DragNet&lt;/code&gt;，最终选择 &lt;code&gt;jusText&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;语言过滤
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;pycld2&lt;/code&gt; 检测网页语言，仅保留英文内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;质量控制
&lt;ul&gt;
&lt;li&gt;使用 FastText 分类器对 OpenWebText2 和 Common Crawl 进行分类，过滤低质量页面。&lt;/li&gt;
&lt;li&gt;参数 α = 3，使用 Pareto 分布阈值进行过滤。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;去重
&lt;ul&gt;
&lt;li&gt;使用 MinHash LSH 算法在内存中进行文档级去重。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;其他说明
&lt;ul&gt;
&lt;li&gt;未使用 WET 文件，因其包含大量模板文本。&lt;/li&gt;
&lt;li&gt;与 Brown et al. (2020) 类似，但只处理了部分 WARC 文件。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c2-pubmed-centralpmc&#34;&gt;C.2 PubMed Central（PMC）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：美国国家生物技术信息中心（NCBI）提供。&lt;/li&gt;
&lt;li&gt;格式转换
&lt;ul&gt;
&lt;li&gt;使用 Pandoc 将 JATS 格式转为 Markdown。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;清理步骤
&lt;ul&gt;
&lt;li&gt;删除以 &lt;code&gt;:::&lt;/code&gt; 开头的行（Pandoc 添加的 HTML 类标签）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c3-books3&#34;&gt;C.3 Books3
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：未具体说明，但为高质量书籍数据集。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;处理细节&lt;/strong&gt; ：无额外处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c4-openwebtext2owt2&#34;&gt;C.4 OpenWebText2（OWT2）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Reddit 提交链接。&lt;/li&gt;
&lt;li&gt;处理步骤
&lt;ul&gt;
&lt;li&gt;提取 URL 及其元数据。&lt;/li&gt;
&lt;li&gt;去除得分低于 3 的链接。&lt;/li&gt;
&lt;li&gt;使用 Newspaper 抓取网页内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;去重
&lt;ul&gt;
&lt;li&gt;使用 DataSketch 库进行文档级 MinHash LSH 去重。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c5-arxiv&#34;&gt;C.5 ArXiv
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：arXiv.org 学术论文。&lt;/li&gt;
&lt;li&gt;处理步骤
&lt;ul&gt;
&lt;li&gt;转换为纯文本。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;去重
&lt;ul&gt;
&lt;li&gt;使用与验证/测试集对比的方法去重。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c6-github&#34;&gt;C.6 GitHub
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：GitHub 上的开源项目。&lt;/li&gt;
&lt;li&gt;获取方式
&lt;ul&gt;
&lt;li&gt;收集星标数 &amp;gt; 100 的仓库。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;提取内容
&lt;ul&gt;
&lt;li&gt;提取可用于语言建模的文本（代码、README、注释等）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;限制条件
&lt;ul&gt;
&lt;li&gt;单个仓库克隆和提取时间不超过 300 秒。&lt;/li&gt;
&lt;li&gt;文件大小上限为 100KB（避免大文件中的重复自动生成内容）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c7-freelaw&#34;&gt;C.7 FreeLaw
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：法律数据库。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;未提供详细清洗步骤。&lt;/li&gt;
&lt;li&gt;数据来自已有结构化格式，可能已做过预处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c8-stack-exchange&#34;&gt;C.8 Stack Exchange
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Stack Overflow 等问答网站。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;提取问题、回答、评论。&lt;/li&gt;
&lt;li&gt;按照层级结构组织。&lt;/li&gt;
&lt;li&gt;保留 &lt;code&gt;/me&lt;/code&gt; 类型的动作描述，删除系统消息。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c9-uspto-backgrounds&#34;&gt;C.9 USPTO Backgrounds
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：美国专利商标局（USPTO）公开数据。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;处理 XML 格式的专利文件。&lt;/li&gt;
&lt;li&gt;提取“Background”部分内容。&lt;/li&gt;
&lt;li&gt;处理不同格式变化（APS → XML）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c10-pubmed-abstracts&#34;&gt;C.10 PubMed Abstracts
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：PubMed 数据库摘要。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;排除缺失或格式错误的条目。&lt;/li&gt;
&lt;li&gt;合并标题和摘要，去除版权信息。&lt;/li&gt;
&lt;li&gt;排除已在 PMC 中出现的内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c11-project-gutenbergpg-19&#34;&gt;C.11 Project Gutenberg（PG-19）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：古登堡计划电子书。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;处理方式&lt;/strong&gt; ：无额外处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c12-opensubtitles&#34;&gt;C.12 OpenSubtitles
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Tiedemann (2016) 提供的英文字幕数据。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;提取 XML 文件中的字幕文本。&lt;/li&gt;
&lt;li&gt;忽略元数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c13-wikipedia-en&#34;&gt;C.13 Wikipedia (en)
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Wikipedia English dataset from TensorFlow Datasets。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;wikipedia/20200301.en&lt;/code&gt; 数据集。&lt;/li&gt;
&lt;li&gt;在每篇文章开头添加标题。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c14-deepmind-mathematicsdm-math&#34;&gt;C.14 DeepMind Mathematics（DM Math）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：DeepMind 数学数据集。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;包含 Easy、Medium、Hard 难度。&lt;/li&gt;
&lt;li&gt;将每个题目拆分为 8 KiB 块。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c15-ubuntu-irc&#34;&gt;C.15 Ubuntu IRC
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Ubuntu IRC 日志（2004–2020）。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;删除系统消息（如加入、离开频道）。&lt;/li&gt;
&lt;li&gt;保留 &lt;code&gt;/me&lt;/code&gt; 动作。&lt;/li&gt;
&lt;li&gt;去除时间戳。&lt;/li&gt;
&lt;li&gt;每周日志合并为一个文档，按日期分隔。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c16-bookcorpus2&#34;&gt;C.16 BookCorpus2
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：基于 Kobayashi (2018) 方法重新构建。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;收集更多书籍（共 17,868 本，原版为 11,038 本）。&lt;/li&gt;
&lt;li&gt;使用修改后的 EPUB 解析器提取文本。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c17-europarl&#34;&gt;C.17 EuroParl
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：欧洲议会会议记录。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;已经是干净文本，无需额外清洗。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c18-hackernews&#34;&gt;C.18 HackerNews
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Hacker News 提交链接。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;提取文章标题、URL、子标题、作者。&lt;/li&gt;
&lt;li&gt;按照评论层级组织内容。&lt;/li&gt;
&lt;li&gt;使用 html2text 提取 HTML 文本。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c19-youtube-subtitles&#34;&gt;C.19 YouTube Subtitles
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：YouTube 视频字幕。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;三阶段构建：
&lt;ol&gt;
&lt;li&gt;GPT-3 生成搜索关键词。&lt;/li&gt;
&lt;li&gt;下载相关视频。&lt;/li&gt;
&lt;li&gt;提取字幕并按时间对齐。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;多语言字幕按分钟段落对齐，并标注语言。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c20-philpapers&#34;&gt;C.20 PhilPapers
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：PhilPapers 数据库（哲学论文）。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;使用 OAI-MPH 协议抓取元数据。&lt;/li&gt;
&lt;li&gt;转换为纯文本。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c21-nih-exporter&#34;&gt;C.21 NIH ExPorter
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：NIH Grant Application 数据。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;合并 ExPORTER 和 CRISP 数据。&lt;/li&gt;
&lt;li&gt;按申请 ID 去重。&lt;/li&gt;
&lt;li&gt;删除空或太短的摘要。&lt;/li&gt;
&lt;li&gt;去除行政模板内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;c22-enron-emails&#34;&gt;C.22 Enron Emails
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;来源&lt;/strong&gt; ：Enron 公司邮件存档。&lt;/li&gt;
&lt;li&gt;处理方式
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;mailparser&lt;/code&gt; 提取邮件正文作为文档。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>大语言模型数据清洗 · 论文笔记（一）</title>
        <link>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/</link>
        <pubDate>Fri, 06 Jun 2025 01:38:32 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/</guid>
        <description>&lt;h2 id=&#34;ccnet-extracting-high-quality-monolingual-datasets-from-web-crawl-data&#34;&gt;CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1911.00359&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ArXiv1911.00359 CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/facebookresearch/cc_net&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Github facebookresearch/cc_net: Tools to download and cleanup Common Crawl data&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;概述&#34;&gt;概述
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;为保证数据质量，倾向于通过维基百科等高质量数据来源合成&lt;code&gt;ad-hoc datasets&lt;/code&gt;（专门构建的数据集），但是低资源语言不好做&lt;/li&gt;
&lt;li&gt;paper从CC数据集出发，执行了FastText所提出的pipeline，但不同之处：
&lt;ul&gt;
&lt;li&gt;保留文档级别的结构，支持Bert等需要段落级别的模型训练
&lt;ul&gt;
&lt;li&gt;之前的方法切成单个句子，只关心局部上下文，切分成了n-gram&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;增加一个可选的&lt;strong&gt;单语言过滤&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;针对目标语言进行筛选&lt;/li&gt;
&lt;li&gt;筛选出接近维基百科风格的文档
&lt;ul&gt;
&lt;li&gt;在目标语言的维基百科等语料上训练一个语言模型&lt;/li&gt;
&lt;li&gt;通过困惑度进行文档打分，只保留那些 perplexity 较低的文档&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;与传统方法相比：
&lt;ul&gt;
&lt;li&gt;传统方法：多数只适用于英语的特殊方法，手动设置规则&lt;/li&gt;
&lt;li&gt;paper：通用性强，适用于多种语言&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;method&#34;&gt;Method
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250605191955047.png&#34;
	width=&#34;1142&#34;
	height=&#34;594&#34;
	srcset=&#34;https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250605191955047_hu_c0a8034b02c0e136.png 480w, https://example.com/p/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E4%B8%80/assets/image-20250605191955047_hu_f79931d4cc592469.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Figure 1&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;192&#34;
		data-flex-basis=&#34;461px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;下载网页快照的.WET文件，为每个段落生成哈希值，转化为.bin的二进制文件&lt;/li&gt;
&lt;li&gt;独立处理每个WET下的文档，通过哈希进行去重，识别语言，计算困惑度&lt;/li&gt;
&lt;li&gt;按照语言和困惑度得分重新分组，保存为 JSON 格式的文件&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;预处理&#34;&gt;预处理
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;每个快照包含大约 20 到 30TB 的未压缩纯文本&lt;/li&gt;
&lt;li&gt;将 WET 文件分组为每个 5GB 的分片（shard），转化为json格式&lt;/li&gt;
&lt;li&gt;json中的每一条entry：记录了url、文本等信息，代表了一个网页的内容
&lt;ul&gt;
&lt;li&gt;文本中含有段落&lt;/li&gt;
&lt;li&gt;所以这里的逻辑是：快照（.WET） &amp;gt; shard &amp;gt; entry &amp;gt; 段落&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;去重&#34;&gt;去重
&lt;/h3&gt;&lt;p&gt;需要删除不同网页之间的重复段落（占了70%），为方便去重：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;标准化&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;字符全部小写&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;所有数字变成0&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;删除所有Unicode的Punctuation Marks（标点符号）、Accent Marks（重音符号），完成段落标准化&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;标点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;英文标点：&lt;code&gt;.,!?;:&amp;quot;&#39;()[]{}-–—…@#$%^&amp;amp;*&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;中文标点：&lt;code&gt;，。！？；：“”‘’（）【】《》……&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;法语标点：&lt;code&gt;«»&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;阿拉伯语标点：&lt;code&gt;،؛؟&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;日文标点：&lt;code&gt;、。，・「」『』&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Accent：表示发音变化或区分拼写&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;法语：&lt;code&gt;à, é, ô, ù, ç&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;西班牙语：&lt;code&gt;ñ, á, é&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;德语：&lt;code&gt;ä, ö, ü&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;波兰语：&lt;code&gt;ą, ę, ś, ź&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;希腊语：&lt;code&gt;ά, έ, ό&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;计算哈希
&lt;ul&gt;
&lt;li&gt;对每个shard的每个段落计算SHA哈希值（160位），保存为二进制文件&lt;code&gt;.bin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;每个段落的前64位作为其id便于维护&lt;/li&gt;
&lt;li&gt;对每个段落，查询处理过的**一些（见后文）**shard的二进制文件，若出现过则舍弃，否则保存在本shard二进制文件中&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于很多步骤都是独立的，因此支持并行&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于网页数据，需要去掉导航栏、cookie、联系信息等&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;语言识别&#34;&gt;语言识别
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;FastText模型，基于 Wikipedia、Tatoeba 和 SETimes 数据集进行训练&lt;/li&gt;
&lt;li&gt;支持176种语言，为每一种语言输出0-1的置信度（总和为1）&lt;/li&gt;
&lt;li&gt;若某语言得分超过0.5则进行确认，否则舍弃（无法识别语言）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;语言模型过滤&#34;&gt;语言模型过滤
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;对每种语言，训练了一个tokenizer和语言模型
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;KenLM 库&lt;/strong&gt;实现的5-gram模型（处理大量数据效率高）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;使用tokenizer对每一个entry进行分词，使用语言模型计算每个段落的困惑度&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;消融实验&#34;&gt;消融实验
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;先去重再语言识别
&lt;ul&gt;
&lt;li&gt;可以去除一些英文的Cookie警告，防止误识别为英文&lt;/li&gt;
&lt;li&gt;去重跨越的shard越多去除内容越多，去重效果越好，但是自然开销变大
&lt;ul&gt;
&lt;li&gt;选择50均衡了资源与性能&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;最终数据集的指标&#34;&gt;最终数据集的指标
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;使用训练好的语言模型对段落进行困惑度（perplexity）评分，作为衡量文本质量的代理指标。&lt;/li&gt;
&lt;li&gt;结果发现：
&lt;ul&gt;
&lt;li&gt;高质量内容（如新闻、写作规范的内容）通常位于数据集的“头部”（head）&lt;/li&gt;
&lt;li&gt;含有关键词列表或与 Wikipedia 差异较大的口语化内容会落在“尾部”（tail）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;不同语言的困惑度分布差异较大，这主要是由于训练语言模型所使用的 Wikipedia 数据大小不同，而不是某些语言本身缺乏高质量内容。&lt;/li&gt;
&lt;li&gt;因此，为每种语言设置了不同的困惑度阈值，将语料库划分为三个部分：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Head（头部）&lt;/strong&gt; ：高质量段落&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Middle（中部）&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tail（尾部）&lt;/strong&gt; ：较低质量段落&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了验证数据集的质量，作者使用 fastText 和 BERT 模型进行实验：&lt;/p&gt;
&lt;h4 id=&#34;fasttext-实验&#34;&gt;fastText 实验
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;对英语和波兰语的不同质量子集（head、mid、tail）训练词向量&lt;/li&gt;
&lt;li&gt;在标准的类比任务数据集（Mikolov et al., 2013）上评估性能&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;结果表明&lt;/strong&gt; ：随着从 tail 到 head 的变化，模型性能逐步提升，说明基于困惑度的过滤方法能有效提升数据质量&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;子集&lt;/th&gt;
          &lt;th&gt;英语总分&lt;/th&gt;
          &lt;th&gt;波兰语总分&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;head&lt;/td&gt;
          &lt;td&gt;77.9&lt;/td&gt;
          &lt;td&gt;65.3&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;mid&lt;/td&gt;
          &lt;td&gt;74.2&lt;/td&gt;
          &lt;td&gt;62.8&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;tail&lt;/td&gt;
          &lt;td&gt;62.0&lt;/td&gt;
          &lt;td&gt;59.9&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;bert-实验&#34;&gt;BERT 实验
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;分别使用 Wikipedia 和 CCNet 提取的 head 数据训练 BERT-BASE 模型&lt;/li&gt;
&lt;li&gt;训练语言包括：英语（en）、俄语（ru）、中文（zh）、乌尔都语（ur）&lt;/li&gt;
&lt;li&gt;使用 XNLI 任务评估模型表现&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;语言&lt;/th&gt;
          &lt;th&gt;Wikipedia 准确率&lt;/th&gt;
          &lt;th&gt;CCNet 准确率&lt;/th&gt;
          &lt;th&gt;提升幅度&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;en&lt;/td&gt;
          &lt;td&gt;82.8&lt;/td&gt;
          &lt;td&gt;85.0&lt;/td&gt;
          &lt;td&gt;+2.2&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ru&lt;/td&gt;
          &lt;td&gt;73.3&lt;/td&gt;
          &lt;td&gt;76.4&lt;/td&gt;
          &lt;td&gt;+3.1&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;zh&lt;/td&gt;
          &lt;td&gt;77.0&lt;/td&gt;
          &lt;td&gt;77.9&lt;/td&gt;
          &lt;td&gt;+0.9&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ur&lt;/td&gt;
          &lt;td&gt;57.3&lt;/td&gt;
          &lt;td&gt;64.3&lt;/td&gt;
          &lt;td&gt;+7.0 ✅（显著提升）&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;特别是对于低资源语言乌尔都语（ur），Wikipedia 数据太小导致模型几乎无效，而使用 CCNet 提取的数据训练后，准确率提升了 &lt;strong&gt;7 个百分点&lt;/strong&gt; ，证明了该数据集对低资源语言预训练的重要性。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;维基百科的数据不足，CCNet从CC中提取了高质量语言专用的数据，效果显著&lt;/p&gt;
</description>
        </item>
        <item>
        <title>CritiQ 工作文档</title>
        <link>https://example.com/p/critiq-%E5%B7%A5%E4%BD%9C%E6%96%87%E6%A1%A3/</link>
        <pubDate>Thu, 03 Apr 2025 15:06:24 +0800</pubDate>
        
        <guid>https://example.com/p/critiq-%E5%B7%A5%E4%BD%9C%E6%96%87%E6%A1%A3/</guid>
        <description>&lt;h1 id=&#34;critiq-记录&#34;&gt;CritiQ 记录
&lt;/h1&gt;&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;目标&#34;&gt;目标
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;训练模型，由模型判断语料文本数据的质量（高/低），完成质量检测，帮助后续模型训练&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;训练数据准备&#34;&gt;训练数据准备
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;至少需要300正例+300负例，希望是人类专家的标注&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在训练数据不足1w的情况，使用CritiQ去做数据标注&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;传统训练都是训练集&amp;gt;测试集&lt;/p&gt;
&lt;p&gt;这里是通过挖掘人类偏好，测试集合远大于训练集，使用训练集挖掘出来的指标，对测试集进行标注&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;当训练数据超过1w的时候，可以直接跳过这个部分去做分类模型训练&lt;/p&gt;
&lt;h3 id=&#34;knowledge-base&#34;&gt;Knowledge Base
&lt;/h3&gt;&lt;p&gt;对于数据质量评估，如果完全交由模型生成评估指标，从各个角度来说都很水&lt;/p&gt;
&lt;p&gt;参考：&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2502.19279&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2502.19279] CritiQ: Mining Data Quality Criteria from Human Preferences&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;workflow：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从huggingface的数据集中寻找参考论文列表&lt;/li&gt;
&lt;li&gt;从arxiv能找到的论文中爬取摘要&lt;/li&gt;
&lt;li&gt;通过制作agent分析摘要，判断论文中是否有关于数据集评价等内容&lt;/li&gt;
&lt;li&gt;提取评估指标&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最后论文作者得到了一个370+数量的指标&lt;/p&gt;
&lt;p&gt;根据不同的待测数据集，跑一遍，选择准确度较高的&lt;/p&gt;
&lt;p&gt;数量不够让模型生成&lt;/p&gt;
&lt;h2 id=&#34;training&#34;&gt;Training
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/KYLN24/CritiQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;github&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;环境&#34;&gt;环境
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;cuda 12.4 + torch 2.6 + Python3.10&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda create -n critiq_env &lt;span class=&#34;nv&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;3.10 -y
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda activate critiq_env
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip3 install torch torchvision torchaudio
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;python&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;import torch; print(&amp;#39;PyTorch版本:&amp;#39;, torch.__version__); print(&amp;#39;GPU可用:&amp;#39;, torch.cuda.is_available()); print(&amp;#39;GPU名称:&amp;#39;, torch.cuda.get_device_name(0) if torch.cuda.is_available() else &amp;#39;无可用GPU&amp;#39;)&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/KYLN24/CritiQ
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; CritiQ
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install -e &lt;span class=&#34;s2&#34;&gt;&amp;#34;.[vllm,train]&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;之后如果网络不太行，换一个源：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;environ&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;HF_ENDPOINT&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;https://hf-mirror.com&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;数据集&#34;&gt;数据集
&lt;/h3&gt;&lt;p&gt;Pair Data格式如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;PairData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TypedDict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;answer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Literal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;A&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;训练数据格式（保存为&lt;code&gt;train_reward.jsonl&lt;/code&gt;）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;A&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;金属的导热系数显著高于木材（铁约80 W/m·K vs 木材约0.1 W/m·K），根据傅里叶定律q=-k∇T，更高的导热系数导致更快的热传导速率，使手部热量迅速流失。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;金属传热特别快，能迅速把你手上的热量带走，所以摸起来凉；木头传热慢，热量不容易流失，感觉就没那么凉。就像夏天坐金属凳子比坐木凳子感觉更凉快。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;answer&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;A&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;由牛顿第一定律可知，物体保持原有运动状态。当汽车以加速度a减速时，乘客因惯性保持原速v，直到受到座椅摩擦力f=μN的作用才减速。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;因为你的身体想保持原来的运动状态。车停了，但你的身体还在往前，所以会往前倾。就像跑步时突然停下，身体还会往前冲一样。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;answer&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Reward模型输入格式（保存为&lt;code&gt;predict_reward.jsonl&lt;/code&gt;）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;金属的导热系数显著高于木材（铁约80 W/m·K vs 木材约0.1 W/m·K），根据傅里叶定律q=-k∇T，更高的导热系数导致更快的热传导速率，使手部热量迅速流失。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;金属传热特别快，能迅速把你手上的热量带走，所以摸起来凉；木头传热慢，热量不容易流失，感觉就没那么凉。就像夏天坐金属凳子比坐木凳子感觉更凉快。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;由牛顿第一定律可知，物体保持原有运动状态。当汽车以加速度a减速时，乘客因惯性保持原速v，直到受到座椅摩擦力f=μN的作用才减速。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;因为你的身体想保持原来的运动状态。车停了，但你的身体还在往前，所以会往前倾。就像跑步时突然停下，身体还会往前冲一样。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;光从光密介质（水，n=1.33）进入光疏介质（空气，n≈1）时发生折射，根据斯涅尔定律n₁sinθ₁=n₂sinθ₂，折射角大于入射角导致视觉偏移。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;因为光从水进入空气时会拐弯，让我们看到的位置和实际位置不一样，所以筷子看起来像是弯的。就像把吸管插进水里也会看起来弯折一样。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;一共准备了137条数据：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-txt&#34; data-lang=&#34;txt&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;请生成100个初中物理现象问题与解答，要求：  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;1. 每个问题包含两种回答：  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - **A**：专业严谨的物理解释（含公式、原理名称、数据等）  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - **B**：通俗易懂的讲解（用比喻、生活实例，语言口语化）  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - **answer**：固定标注&amp;#34;B&amp;#34;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;2. 数据格式：每行一个完整JSON对象，严格遵循以下结构：  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   {&amp;#34;A&amp;#34;: &amp;#34;...&amp;#34;, &amp;#34;B&amp;#34;: &amp;#34;...&amp;#34;, &amp;#34;answer&amp;#34;: &amp;#34;B&amp;#34;}  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;3. 内容要求：  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - 物理现象需贴近日常生活（如热学、光学、力学等）  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - B回答必须正确且易于理解，避免专业术语  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   - 示例类比需直观（如&amp;#34;像磁铁吸住&amp;#34;&amp;#34;像气球爆炸&amp;#34;）  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;4. 输出：直接给出结果，无需注释，禁止使用```包裹  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;示例格式：  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{&amp;#34;A&amp;#34;: &amp;#34;金属导热系数较高（铁80 W/m·K），根据傅里叶定律q=-k∇T...&amp;#34;, &amp;#34;B&amp;#34;: &amp;#34;金属像‘传热快手’，迅速带走热量，所以摸起来更凉&amp;#34;, &amp;#34;answer&amp;#34;: &amp;#34;B&amp;#34;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;由模型生成&lt;/p&gt;
&lt;p&gt;先做一个预测：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python ./critiq/scripts/reward_predict.py --model Qwen/Qwen2.5-1.5B-Instruct --data ./data/predict_reward.jsonl --output_dir ./output
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;输出结果在&lt;code&gt;output&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;金属的导热系数显著高于木材（铁约80 W/m·K vs 木材约0.1 W/m·K），根据傅里叶定律q=-k∇T，更高的导热系数导致更快的热传导速率，使手部热量迅速流失。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9465966820716858&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;金属传热特别快，能迅速把你手上的热量带走，所以摸起来凉；木头传热慢，热量不容易流失，感觉就没那么凉。就像夏天坐金属凳子比坐木凳子感觉更凉快。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9046503901481628&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;由牛顿第一定律可知，物体保持原有运动状态。当汽车以加速度a减速时，乘客因惯性保持原速v，直到受到座椅摩擦力f=μN的作用才减速。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9736446738243103&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;因为你的身体想保持原来的运动状态。车停了，但你的身体还在往前，所以会往前倾。就像跑步时突然停下，身体还会往前冲一样。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9664104580879211&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;光从光密介质（水，n=1.33）进入光疏介质（空气，n≈1）时发生折射，根据斯涅尔定律n₁sinθ₁=n₂sinθ₂，折射角大于入射角导致视觉偏移。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9532749652862549&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;因为光从水进入空气时会拐弯，让我们看到的位置和实际位置不一样，所以筷子看起来像是弯的。就像把吸管插进水里也会看起来弯折一样。&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9845753908157349&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;给的分数都很高，因为两种风格的文本质量都不低&lt;/p&gt;
&lt;p&gt;为了让模型出现人类的偏好，我们开始训练一下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python ./critiq/scripts/train_reward.py --data ./data/train_reward.jsonl --eval_steps 40
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;code&gt;eval_steps&lt;/code&gt;一定要开大一点……原代码是1，每一步保存一个模型，磁盘炸的很快&lt;/p&gt;
&lt;p&gt;训练的模型保存路径：&lt;code&gt;&amp;lt;output_dir&amp;gt;/&amp;lt;job_name&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;我这里是&lt;code&gt;./output/tmp&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;再跑一下预测：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python ./critiq/scripts/reward_predict.py --model ./output/tmp/checkpoint-109 --data ./data/predict_reward.jsonl --output_dir ./output
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;还没fixed的bug：&lt;/p&gt;
&lt;p&gt;predict不知道为什么给的结果永远是：0.9以上&lt;/p&gt;
&lt;p&gt;我直接修改了train.py，训练完直接跑预测，结果是对的（&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;突然关水龙头像‘管道撞车’，水流‘刹车不及’撞出巨响&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9999999586005831&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;磁致伸缩ΔL/L≈10^-5（镍），逆效应用于超声换能器&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;2.2827974365423323e-05&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;磁致伸缩材料像‘会呼吸的磁铁’，磁场一变就‘伸缩’&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9999999123574378&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;防晒霜氧化锌散射UV，粒径d≈20 nm最优&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.568953403843032e-05&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;物理防晒像‘纳米镜子’，把紫外线‘弹弹球’般反射&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9999999918479713&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;橡皮船浮力F=ρgV，PVC材料ρ≈1.4 g/cm³&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.0129980850990629e-05&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;充气船像‘塑料泡泡’，空气‘内胆’让它漂水面&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;reward&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.9999985406223194&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        
    </channel>
</rss>
